{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "        BsmtFinSF2    BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean     46.549315   567.240411  1057.429452  1162.626712   346.992466   \n",
       "std     161.319273   441.866955   438.705324   386.587738   436.528436   \n",
       "min       0.000000     0.000000     0.000000   334.000000     0.000000   \n",
       "25%       0.000000   223.000000   795.750000   882.000000     0.000000   \n",
       "50%       0.000000   477.500000   991.500000  1087.000000     0.000000   \n",
       "75%       0.000000   808.000000  1298.250000  1391.250000   728.000000   \n",
       "max    1474.000000  2336.000000  6110.000000  4692.000000  2065.000000   \n",
       "\n",
       "       LowQualFinSF    GrLivArea  BsmtFullBath  BsmtHalfBath     FullBath  \\\n",
       "count   1460.000000  1460.000000   1460.000000   1460.000000  1460.000000   \n",
       "mean       5.844521  1515.463699      0.425342      0.057534     1.565068   \n",
       "std       48.623081   525.480383      0.518911      0.238753     0.550916   \n",
       "min        0.000000   334.000000      0.000000      0.000000     0.000000   \n",
       "25%        0.000000  1129.500000      0.000000      0.000000     1.000000   \n",
       "50%        0.000000  1464.000000      0.000000      0.000000     2.000000   \n",
       "75%        0.000000  1776.750000      1.000000      0.000000     2.000000   \n",
       "max      572.000000  5642.000000      3.000000      2.000000     3.000000   \n",
       "\n",
       "          HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd   Fireplaces  \\\n",
       "count  1460.000000   1460.000000   1460.000000   1460.000000  1460.000000   \n",
       "mean      0.382877      2.866438      1.046575      6.517808     0.613014   \n",
       "std       0.502885      0.815778      0.220338      1.625393     0.644666   \n",
       "min       0.000000      0.000000      0.000000      2.000000     0.000000   \n",
       "25%       0.000000      2.000000      1.000000      5.000000     0.000000   \n",
       "50%       0.000000      3.000000      1.000000      6.000000     1.000000   \n",
       "75%       1.000000      3.000000      1.000000      7.000000     1.000000   \n",
       "max       2.000000      8.000000      3.000000     14.000000     3.000000   \n",
       "\n",
       "       GarageYrBlt   GarageCars   GarageArea   WoodDeckSF  OpenPorchSF  \\\n",
       "count  1379.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean   1978.506164     1.767123   472.980137    94.244521    46.660274   \n",
       "std      24.689725     0.747315   213.804841   125.338794    66.256028   \n",
       "min    1900.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1961.000000     1.000000   334.500000     0.000000     0.000000   \n",
       "50%    1980.000000     2.000000   480.000000     0.000000    25.000000   \n",
       "75%    2002.000000     2.000000   576.000000   168.000000    68.000000   \n",
       "max    2010.000000     4.000000  1418.000000   857.000000   547.000000   \n",
       "\n",
       "       EnclosedPorch    3SsnPorch  ScreenPorch     PoolArea       MiscVal  \\\n",
       "count    1460.000000  1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean       21.954110     3.409589    15.060959     2.758904     43.489041   \n",
       "std        61.119149    29.317331    55.757415    40.177307    496.123024   \n",
       "min         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "50%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "75%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "max       552.000000   508.000000   480.000000   738.000000  15500.000000   \n",
       "\n",
       "            MoSold       YrSold      SalePrice  \n",
       "count  1460.000000  1460.000000    1460.000000  \n",
       "mean      6.321918  2007.815753  180921.195890  \n",
       "std       2.703626     1.328095   79442.502883  \n",
       "min       1.000000  2006.000000   34900.000000  \n",
       "25%       5.000000  2007.000000  129975.000000  \n",
       "50%       6.000000  2008.000000  163000.000000  \n",
       "75%       8.000000  2009.000000  214000.000000  \n",
       "max      12.000000  2010.000000  755000.000000  "
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "data = pd.read_csv('./datasets/housing.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1710</td>\n",
       "      <td>150</td>\n",
       "      <td>548</td>\n",
       "      <td>706</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1262</td>\n",
       "      <td>284</td>\n",
       "      <td>460</td>\n",
       "      <td>978</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1786</td>\n",
       "      <td>434</td>\n",
       "      <td>608</td>\n",
       "      <td>486</td>\n",
       "      <td>2002</td>\n",
       "      <td>920</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1717</td>\n",
       "      <td>540</td>\n",
       "      <td>642</td>\n",
       "      <td>216</td>\n",
       "      <td>1970</td>\n",
       "      <td>756</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>2198</td>\n",
       "      <td>490</td>\n",
       "      <td>836</td>\n",
       "      <td>655</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  LotArea  GrLivArea  BsmtUnfSF  GarageArea  BsmtFinSF1  \\\n",
       "0         65.0     8450       1710        150         548         706   \n",
       "1         80.0     9600       1262        284         460         978   \n",
       "2         68.0    11250       1786        434         608         486   \n",
       "3         60.0     9550       1717        540         642         216   \n",
       "4         84.0    14260       2198        490         836         655   \n",
       "\n",
       "   YearRemodAdd  TotalBsmtSF  YearBuilt  SalePrice  \n",
       "0          2003          856       2003     208500  \n",
       "1          1976         1262       1976     181500  \n",
       "2          2002          920       2001     223500  \n",
       "3          1970          756       1915     140000  \n",
       "4          2000         1145       2000     250000  "
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[['LotFrontage', 'LotArea', 'GrLivArea', 'BsmtUnfSF', 'GarageArea', 'BsmtFinSF1', 'YearRemodAdd', 'TotalBsmtSF', 'YearBuilt', 'SalePrice']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1201, 9])"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HousingDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    _data = pd.read_csv(f'./datasets/housing.csv')[[\n",
    "      'LotFrontage',\n",
    "      'LotArea',\n",
    "      'GrLivArea',\n",
    "      'BsmtUnfSF',\n",
    "      'GarageArea',\n",
    "      'BsmtFinSF1',\n",
    "      'YearRemodAdd',\n",
    "      'TotalBsmtSF',\n",
    "      'YearBuilt',\n",
    "      'SalePrice']].dropna()\n",
    "\n",
    "    self.labels = torch.Tensor(\n",
    "      _data[['SalePrice']]\n",
    "        .astype('float32')\n",
    "        .to_numpy())\n",
    "\n",
    "    self.data = torch.Tensor(\n",
    "      _data\n",
    "        .drop(['SalePrice'], axis=1)\n",
    "        .astype('float32')\n",
    "        .to_numpy())\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = HousingDataset()\n",
    "\n",
    "data_mean = dataset.data.mean(dim=0, keepdim=True)\n",
    "data_std = dataset.data.std(dim=0, keepdim=True)\n",
    "\n",
    "labels_mean = dataset.labels.mean(dim=0, keepdim=True)\n",
    "labels_std = dataset.labels.std(dim=0, keepdim=True)\n",
    "\n",
    "dataset.data = (dataset.data - data_mean) / (data_std + 1e-7)\n",
    "dataset.labels = (dataset.labels - labels_mean) / (labels_std + 1e-7)\n",
    "\n",
    "generator = torch.Generator().manual_seed(69)\n",
    "train, validation, test = torch.utils.data.random_split(dataset, [.7, .2, .1], generator)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=True)\n",
    "\n",
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HousingNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=50, bias=True)\n",
      "    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class HousingNeuralNetwork(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear_relu_stack = torch.nn.Sequential(\n",
    "      torch.nn.Linear(9, 50),\n",
    "      torch.nn.BatchNorm1d(50),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Dropout(p=0.2),\n",
    "      torch.nn.Linear(50, 1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "  \n",
    "model = HousingNeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.303, Validation Loss: 0.242\n",
      "Epoch: 1, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 2, Train Loss: 0.265, Validation Loss: 0.248\n",
      "Epoch: 3, Train Loss: 0.239, Validation Loss: 0.244\n",
      "Epoch: 4, Train Loss: 0.179, Validation Loss: 0.242\n",
      "Epoch: 5, Train Loss: 0.223, Validation Loss: 0.246\n",
      "Epoch: 6, Train Loss: 0.244, Validation Loss: 0.241\n",
      "Epoch: 7, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 8, Train Loss: 0.520, Validation Loss: 0.249\n",
      "Epoch: 9, Train Loss: 0.212, Validation Loss: 0.244\n",
      "Epoch: 10, Train Loss: 0.216, Validation Loss: 0.241\n",
      "Epoch: 11, Train Loss: 0.293, Validation Loss: 0.242\n",
      "Epoch: 12, Train Loss: 0.281, Validation Loss: 0.243\n",
      "Epoch: 13, Train Loss: 0.295, Validation Loss: 0.246\n",
      "Epoch: 14, Train Loss: 0.245, Validation Loss: 0.244\n",
      "Epoch: 15, Train Loss: 0.190, Validation Loss: 0.240\n",
      "Epoch: 16, Train Loss: 0.214, Validation Loss: 0.241\n",
      "Epoch: 17, Train Loss: 0.186, Validation Loss: 0.243\n",
      "Epoch: 18, Train Loss: 0.272, Validation Loss: 0.244\n",
      "Epoch: 19, Train Loss: 0.203, Validation Loss: 0.243\n",
      "Epoch: 20, Train Loss: 0.276, Validation Loss: 0.244\n",
      "Epoch: 21, Train Loss: 0.382, Validation Loss: 0.241\n",
      "Epoch: 22, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 23, Train Loss: 0.290, Validation Loss: 0.244\n",
      "Epoch: 24, Train Loss: 0.215, Validation Loss: 0.240\n",
      "Epoch: 25, Train Loss: 0.227, Validation Loss: 0.242\n",
      "Epoch: 26, Train Loss: 0.155, Validation Loss: 0.242\n",
      "Epoch: 27, Train Loss: 0.246, Validation Loss: 0.244\n",
      "Epoch: 28, Train Loss: 0.263, Validation Loss: 0.242\n",
      "Epoch: 29, Train Loss: 0.360, Validation Loss: 0.246\n",
      "Epoch: 30, Train Loss: 0.267, Validation Loss: 0.242\n",
      "Epoch: 31, Train Loss: 0.236, Validation Loss: 0.244\n",
      "Epoch: 32, Train Loss: 0.239, Validation Loss: 0.242\n",
      "Epoch: 33, Train Loss: 0.266, Validation Loss: 0.241\n",
      "Epoch: 34, Train Loss: 0.306, Validation Loss: 0.243\n",
      "Epoch: 35, Train Loss: 0.289, Validation Loss: 0.242\n",
      "Epoch: 36, Train Loss: 0.176, Validation Loss: 0.241\n",
      "Epoch: 37, Train Loss: 0.269, Validation Loss: 0.239\n",
      "Epoch: 38, Train Loss: 0.294, Validation Loss: 0.244\n",
      "Epoch: 39, Train Loss: 0.225, Validation Loss: 0.244\n",
      "Epoch: 40, Train Loss: 0.257, Validation Loss: 0.240\n",
      "Epoch: 41, Train Loss: 0.504, Validation Loss: 0.246\n",
      "Epoch: 42, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 43, Train Loss: 0.307, Validation Loss: 0.240\n",
      "Epoch: 44, Train Loss: 0.315, Validation Loss: 0.240\n",
      "Epoch: 45, Train Loss: 0.208, Validation Loss: 0.241\n",
      "Epoch: 46, Train Loss: 0.448, Validation Loss: 0.242\n",
      "Epoch: 47, Train Loss: 0.389, Validation Loss: 0.240\n",
      "Epoch: 48, Train Loss: 0.371, Validation Loss: 0.239\n",
      "Epoch: 49, Train Loss: 0.423, Validation Loss: 0.250\n",
      "Epoch: 50, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 51, Train Loss: 0.291, Validation Loss: 0.242\n",
      "Epoch: 52, Train Loss: 0.278, Validation Loss: 0.245\n",
      "Epoch: 53, Train Loss: 0.444, Validation Loss: 0.241\n",
      "Epoch: 54, Train Loss: 0.395, Validation Loss: 0.245\n",
      "Epoch: 55, Train Loss: 0.261, Validation Loss: 0.243\n",
      "Epoch: 56, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 57, Train Loss: 0.377, Validation Loss: 0.247\n",
      "Epoch: 58, Train Loss: 0.232, Validation Loss: 0.243\n",
      "Epoch: 59, Train Loss: 0.251, Validation Loss: 0.242\n",
      "Epoch: 60, Train Loss: 0.324, Validation Loss: 0.245\n",
      "Epoch: 61, Train Loss: 0.321, Validation Loss: 0.241\n",
      "Epoch: 62, Train Loss: 0.300, Validation Loss: 0.241\n",
      "Epoch: 63, Train Loss: 0.234, Validation Loss: 0.242\n",
      "Epoch: 64, Train Loss: 0.326, Validation Loss: 0.243\n",
      "Epoch: 65, Train Loss: 0.239, Validation Loss: 0.243\n",
      "Epoch: 66, Train Loss: 0.256, Validation Loss: 0.241\n",
      "Epoch: 67, Train Loss: 0.207, Validation Loss: 0.243\n",
      "Epoch: 68, Train Loss: 0.231, Validation Loss: 0.242\n",
      "Epoch: 69, Train Loss: 0.316, Validation Loss: 0.246\n",
      "Epoch: 70, Train Loss: 0.245, Validation Loss: 0.241\n",
      "Epoch: 71, Train Loss: 0.178, Validation Loss: 0.241\n",
      "Epoch: 72, Train Loss: 0.353, Validation Loss: 0.243\n",
      "Epoch: 73, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 74, Train Loss: 0.266, Validation Loss: 0.240\n",
      "Epoch: 75, Train Loss: 0.241, Validation Loss: 0.241\n",
      "Epoch: 76, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 77, Train Loss: 0.336, Validation Loss: 0.242\n",
      "Epoch: 78, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 79, Train Loss: 0.335, Validation Loss: 0.240\n",
      "Epoch: 80, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 81, Train Loss: 0.570, Validation Loss: 0.246\n",
      "Epoch: 82, Train Loss: 0.335, Validation Loss: 0.246\n",
      "Epoch: 83, Train Loss: 0.276, Validation Loss: 0.245\n",
      "Epoch: 84, Train Loss: 0.289, Validation Loss: 0.240\n",
      "Epoch: 85, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 86, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 87, Train Loss: 0.227, Validation Loss: 0.240\n",
      "Epoch: 88, Train Loss: 0.349, Validation Loss: 0.244\n",
      "Epoch: 89, Train Loss: 0.251, Validation Loss: 0.242\n",
      "Epoch: 90, Train Loss: 0.164, Validation Loss: 0.244\n",
      "Epoch: 91, Train Loss: 0.179, Validation Loss: 0.242\n",
      "Epoch: 92, Train Loss: 0.280, Validation Loss: 0.244\n",
      "Epoch: 93, Train Loss: 0.320, Validation Loss: 0.241\n",
      "Epoch: 94, Train Loss: 0.209, Validation Loss: 0.240\n",
      "Epoch: 95, Train Loss: 0.192, Validation Loss: 0.239\n",
      "Epoch: 96, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 97, Train Loss: 0.218, Validation Loss: 0.242\n",
      "Epoch: 98, Train Loss: 0.286, Validation Loss: 0.251\n",
      "Epoch: 99, Train Loss: 0.251, Validation Loss: 0.251\n",
      "Epoch: 100, Train Loss: 0.290, Validation Loss: 0.240\n",
      "Epoch: 101, Train Loss: 0.295, Validation Loss: 0.243\n",
      "Epoch: 102, Train Loss: 0.272, Validation Loss: 0.241\n",
      "Epoch: 103, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 104, Train Loss: 0.253, Validation Loss: 0.242\n",
      "Epoch: 105, Train Loss: 0.232, Validation Loss: 0.242\n",
      "Epoch: 106, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 107, Train Loss: 0.343, Validation Loss: 0.242\n",
      "Epoch: 108, Train Loss: 0.240, Validation Loss: 0.249\n",
      "Epoch: 109, Train Loss: 0.221, Validation Loss: 0.241\n",
      "Epoch: 110, Train Loss: 0.201, Validation Loss: 0.243\n",
      "Epoch: 111, Train Loss: 0.180, Validation Loss: 0.241\n",
      "Epoch: 112, Train Loss: 0.323, Validation Loss: 0.241\n",
      "Epoch: 113, Train Loss: 0.180, Validation Loss: 0.242\n",
      "Epoch: 114, Train Loss: 0.484, Validation Loss: 0.243\n",
      "Epoch: 115, Train Loss: 0.551, Validation Loss: 0.240\n",
      "Epoch: 116, Train Loss: 0.493, Validation Loss: 0.244\n",
      "Epoch: 117, Train Loss: 0.247, Validation Loss: 0.244\n",
      "Epoch: 118, Train Loss: 0.277, Validation Loss: 0.241\n",
      "Epoch: 119, Train Loss: 0.501, Validation Loss: 0.245\n",
      "Epoch: 120, Train Loss: 0.343, Validation Loss: 0.242\n",
      "Epoch: 121, Train Loss: 0.258, Validation Loss: 0.242\n",
      "Epoch: 122, Train Loss: 0.328, Validation Loss: 0.244\n",
      "Epoch: 123, Train Loss: 0.338, Validation Loss: 0.241\n",
      "Epoch: 124, Train Loss: 0.257, Validation Loss: 0.242\n",
      "Epoch: 125, Train Loss: 0.374, Validation Loss: 0.246\n",
      "Epoch: 126, Train Loss: 0.503, Validation Loss: 0.241\n",
      "Epoch: 127, Train Loss: 0.205, Validation Loss: 0.241\n",
      "Epoch: 128, Train Loss: 0.289, Validation Loss: 0.244\n",
      "Epoch: 129, Train Loss: 0.313, Validation Loss: 0.240\n",
      "Epoch: 130, Train Loss: 0.216, Validation Loss: 0.241\n",
      "Epoch: 131, Train Loss: 0.278, Validation Loss: 0.241\n",
      "Epoch: 132, Train Loss: 0.252, Validation Loss: 0.242\n",
      "Epoch: 133, Train Loss: 0.345, Validation Loss: 0.242\n",
      "Epoch: 134, Train Loss: 0.209, Validation Loss: 0.241\n",
      "Epoch: 135, Train Loss: 0.311, Validation Loss: 0.240\n",
      "Epoch: 136, Train Loss: 0.261, Validation Loss: 0.243\n",
      "Epoch: 137, Train Loss: 0.211, Validation Loss: 0.242\n",
      "Epoch: 138, Train Loss: 0.654, Validation Loss: 0.246\n",
      "Epoch: 139, Train Loss: 0.239, Validation Loss: 0.242\n",
      "Epoch: 140, Train Loss: 0.267, Validation Loss: 0.242\n",
      "Epoch: 141, Train Loss: 0.537, Validation Loss: 0.248\n",
      "Epoch: 142, Train Loss: 0.192, Validation Loss: 0.244\n",
      "Epoch: 143, Train Loss: 0.282, Validation Loss: 0.241\n",
      "Epoch: 144, Train Loss: 0.267, Validation Loss: 0.240\n",
      "Epoch: 145, Train Loss: 0.292, Validation Loss: 0.241\n",
      "Epoch: 146, Train Loss: 0.631, Validation Loss: 0.245\n",
      "Epoch: 147, Train Loss: 0.308, Validation Loss: 0.241\n",
      "Epoch: 148, Train Loss: 0.302, Validation Loss: 0.244\n",
      "Epoch: 149, Train Loss: 0.344, Validation Loss: 0.242\n",
      "Epoch: 150, Train Loss: 0.242, Validation Loss: 0.241\n",
      "Epoch: 151, Train Loss: 0.261, Validation Loss: 0.239\n",
      "Epoch: 152, Train Loss: 0.181, Validation Loss: 0.241\n",
      "Epoch: 153, Train Loss: 0.222, Validation Loss: 0.241\n",
      "Epoch: 154, Train Loss: 0.283, Validation Loss: 0.239\n",
      "Epoch: 155, Train Loss: 0.225, Validation Loss: 0.241\n",
      "Epoch: 156, Train Loss: 0.317, Validation Loss: 0.240\n",
      "Epoch: 157, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 158, Train Loss: 0.238, Validation Loss: 0.242\n",
      "Epoch: 159, Train Loss: 0.255, Validation Loss: 0.241\n",
      "Epoch: 160, Train Loss: 0.331, Validation Loss: 0.247\n",
      "Epoch: 161, Train Loss: 0.378, Validation Loss: 0.243\n",
      "Epoch: 162, Train Loss: 0.169, Validation Loss: 0.244\n",
      "Epoch: 163, Train Loss: 0.284, Validation Loss: 0.243\n",
      "Epoch: 164, Train Loss: 0.167, Validation Loss: 0.240\n",
      "Epoch: 165, Train Loss: 0.205, Validation Loss: 0.239\n",
      "Epoch: 166, Train Loss: 0.333, Validation Loss: 0.240\n",
      "Epoch: 167, Train Loss: 0.443, Validation Loss: 0.242\n",
      "Epoch: 168, Train Loss: 0.383, Validation Loss: 0.241\n",
      "Epoch: 169, Train Loss: 0.210, Validation Loss: 0.241\n",
      "Epoch: 170, Train Loss: 0.177, Validation Loss: 0.240\n",
      "Epoch: 171, Train Loss: 0.233, Validation Loss: 0.240\n",
      "Epoch: 172, Train Loss: 0.288, Validation Loss: 0.243\n",
      "Epoch: 173, Train Loss: 0.253, Validation Loss: 0.241\n",
      "Epoch: 174, Train Loss: 0.225, Validation Loss: 0.243\n",
      "Epoch: 175, Train Loss: 0.215, Validation Loss: 0.242\n",
      "Epoch: 176, Train Loss: 0.260, Validation Loss: 0.240\n",
      "Epoch: 177, Train Loss: 0.301, Validation Loss: 0.241\n",
      "Epoch: 178, Train Loss: 0.409, Validation Loss: 0.245\n",
      "Epoch: 179, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 180, Train Loss: 0.329, Validation Loss: 0.238\n",
      "Epoch: 181, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 182, Train Loss: 0.311, Validation Loss: 0.241\n",
      "Epoch: 183, Train Loss: 0.295, Validation Loss: 0.238\n",
      "Epoch: 184, Train Loss: 0.282, Validation Loss: 0.240\n",
      "Epoch: 185, Train Loss: 0.296, Validation Loss: 0.244\n",
      "Epoch: 186, Train Loss: 0.363, Validation Loss: 0.241\n",
      "Epoch: 187, Train Loss: 0.208, Validation Loss: 0.238\n",
      "Epoch: 188, Train Loss: 0.214, Validation Loss: 0.240\n",
      "Epoch: 189, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 190, Train Loss: 0.408, Validation Loss: 0.239\n",
      "Epoch: 191, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 192, Train Loss: 0.528, Validation Loss: 0.246\n",
      "Epoch: 193, Train Loss: 0.525, Validation Loss: 0.246\n",
      "Epoch: 194, Train Loss: 0.296, Validation Loss: 0.239\n",
      "Epoch: 195, Train Loss: 0.231, Validation Loss: 0.242\n",
      "Epoch: 196, Train Loss: 0.195, Validation Loss: 0.238\n",
      "Epoch: 197, Train Loss: 0.364, Validation Loss: 0.239\n",
      "Epoch: 198, Train Loss: 0.224, Validation Loss: 0.241\n",
      "Epoch: 199, Train Loss: 0.284, Validation Loss: 0.245\n",
      "Epoch: 200, Train Loss: 0.292, Validation Loss: 0.239\n",
      "Epoch: 201, Train Loss: 0.177, Validation Loss: 0.239\n",
      "Epoch: 202, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 203, Train Loss: 0.442, Validation Loss: 0.245\n",
      "Epoch: 204, Train Loss: 0.232, Validation Loss: 0.243\n",
      "Epoch: 205, Train Loss: 0.299, Validation Loss: 0.241\n",
      "Epoch: 206, Train Loss: 0.461, Validation Loss: 0.243\n",
      "Epoch: 207, Train Loss: 0.316, Validation Loss: 0.241\n",
      "Epoch: 208, Train Loss: 0.260, Validation Loss: 0.243\n",
      "Epoch: 209, Train Loss: 0.259, Validation Loss: 0.245\n",
      "Epoch: 210, Train Loss: 0.231, Validation Loss: 0.243\n",
      "Epoch: 211, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 212, Train Loss: 0.293, Validation Loss: 0.238\n",
      "Epoch: 213, Train Loss: 0.205, Validation Loss: 0.237\n",
      "Epoch: 214, Train Loss: 0.313, Validation Loss: 0.242\n",
      "Epoch: 215, Train Loss: 0.287, Validation Loss: 0.240\n",
      "Epoch: 216, Train Loss: 0.241, Validation Loss: 0.238\n",
      "Epoch: 217, Train Loss: 0.374, Validation Loss: 0.239\n",
      "Epoch: 218, Train Loss: 0.258, Validation Loss: 0.240\n",
      "Epoch: 219, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 220, Train Loss: 0.262, Validation Loss: 0.240\n",
      "Epoch: 221, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 222, Train Loss: 0.356, Validation Loss: 0.237\n",
      "Epoch: 223, Train Loss: 0.188, Validation Loss: 0.239\n",
      "Epoch: 224, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 225, Train Loss: 0.315, Validation Loss: 0.238\n",
      "Epoch: 226, Train Loss: 0.330, Validation Loss: 0.240\n",
      "Epoch: 227, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 228, Train Loss: 0.182, Validation Loss: 0.239\n",
      "Epoch: 229, Train Loss: 0.584, Validation Loss: 0.244\n",
      "Epoch: 230, Train Loss: 0.397, Validation Loss: 0.241\n",
      "Epoch: 231, Train Loss: 0.294, Validation Loss: 0.239\n",
      "Epoch: 232, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 233, Train Loss: 0.257, Validation Loss: 0.241\n",
      "Epoch: 234, Train Loss: 0.448, Validation Loss: 0.240\n",
      "Epoch: 235, Train Loss: 0.375, Validation Loss: 0.242\n",
      "Epoch: 236, Train Loss: 0.331, Validation Loss: 0.242\n",
      "Epoch: 237, Train Loss: 0.219, Validation Loss: 0.243\n",
      "Epoch: 238, Train Loss: 0.202, Validation Loss: 0.242\n",
      "Epoch: 239, Train Loss: 0.283, Validation Loss: 0.241\n",
      "Epoch: 240, Train Loss: 0.327, Validation Loss: 0.241\n",
      "Epoch: 241, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 242, Train Loss: 0.448, Validation Loss: 0.241\n",
      "Epoch: 243, Train Loss: 0.351, Validation Loss: 0.241\n",
      "Epoch: 244, Train Loss: 0.346, Validation Loss: 0.240\n",
      "Epoch: 245, Train Loss: 0.235, Validation Loss: 0.240\n",
      "Epoch: 246, Train Loss: 0.219, Validation Loss: 0.241\n",
      "Epoch: 247, Train Loss: 0.447, Validation Loss: 0.247\n",
      "Epoch: 248, Train Loss: 0.300, Validation Loss: 0.241\n",
      "Epoch: 249, Train Loss: 0.468, Validation Loss: 0.245\n",
      "Epoch: 250, Train Loss: 0.201, Validation Loss: 0.240\n",
      "Epoch: 251, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 252, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 253, Train Loss: 0.352, Validation Loss: 0.240\n",
      "Epoch: 254, Train Loss: 0.246, Validation Loss: 0.240\n",
      "Epoch: 255, Train Loss: 0.204, Validation Loss: 0.241\n",
      "Epoch: 256, Train Loss: 0.339, Validation Loss: 0.240\n",
      "Epoch: 257, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 258, Train Loss: 0.410, Validation Loss: 0.246\n",
      "Epoch: 259, Train Loss: 0.298, Validation Loss: 0.242\n",
      "Epoch: 260, Train Loss: 0.166, Validation Loss: 0.241\n",
      "Epoch: 261, Train Loss: 0.241, Validation Loss: 0.241\n",
      "Epoch: 262, Train Loss: 0.268, Validation Loss: 0.240\n",
      "Epoch: 263, Train Loss: 0.265, Validation Loss: 0.240\n",
      "Epoch: 264, Train Loss: 0.206, Validation Loss: 0.242\n",
      "Epoch: 265, Train Loss: 0.368, Validation Loss: 0.245\n",
      "Epoch: 266, Train Loss: 0.204, Validation Loss: 0.243\n",
      "Epoch: 267, Train Loss: 0.187, Validation Loss: 0.241\n",
      "Epoch: 268, Train Loss: 0.207, Validation Loss: 0.242\n",
      "Epoch: 269, Train Loss: 0.201, Validation Loss: 0.241\n",
      "Epoch: 270, Train Loss: 0.208, Validation Loss: 0.240\n",
      "Epoch: 271, Train Loss: 0.434, Validation Loss: 0.244\n",
      "Epoch: 272, Train Loss: 0.223, Validation Loss: 0.243\n",
      "Epoch: 273, Train Loss: 0.208, Validation Loss: 0.241\n",
      "Epoch: 274, Train Loss: 0.292, Validation Loss: 0.243\n",
      "Epoch: 275, Train Loss: 0.369, Validation Loss: 0.241\n",
      "Epoch: 276, Train Loss: 0.465, Validation Loss: 0.244\n",
      "Epoch: 277, Train Loss: 0.223, Validation Loss: 0.243\n",
      "Epoch: 278, Train Loss: 0.282, Validation Loss: 0.240\n",
      "Epoch: 279, Train Loss: 0.320, Validation Loss: 0.239\n",
      "Epoch: 280, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 281, Train Loss: 0.155, Validation Loss: 0.239\n",
      "Epoch: 282, Train Loss: 0.300, Validation Loss: 0.240\n",
      "Epoch: 283, Train Loss: 0.200, Validation Loss: 0.241\n",
      "Epoch: 284, Train Loss: 0.346, Validation Loss: 0.246\n",
      "Epoch: 285, Train Loss: 0.554, Validation Loss: 0.243\n",
      "Epoch: 286, Train Loss: 0.227, Validation Loss: 0.242\n",
      "Epoch: 287, Train Loss: 0.238, Validation Loss: 0.245\n",
      "Epoch: 288, Train Loss: 0.213, Validation Loss: 0.244\n",
      "Epoch: 289, Train Loss: 0.254, Validation Loss: 0.246\n",
      "Epoch: 290, Train Loss: 0.339, Validation Loss: 0.243\n",
      "Epoch: 291, Train Loss: 0.232, Validation Loss: 0.241\n",
      "Epoch: 292, Train Loss: 0.250, Validation Loss: 0.242\n",
      "Epoch: 293, Train Loss: 0.230, Validation Loss: 0.239\n",
      "Epoch: 294, Train Loss: 0.640, Validation Loss: 0.245\n",
      "Epoch: 295, Train Loss: 0.262, Validation Loss: 0.245\n",
      "Epoch: 296, Train Loss: 0.191, Validation Loss: 0.240\n",
      "Epoch: 297, Train Loss: 0.191, Validation Loss: 0.243\n",
      "Epoch: 298, Train Loss: 0.281, Validation Loss: 0.242\n",
      "Epoch: 299, Train Loss: 0.287, Validation Loss: 0.244\n",
      "Epoch: 300, Train Loss: 0.262, Validation Loss: 0.241\n",
      "Epoch: 301, Train Loss: 0.295, Validation Loss: 0.248\n",
      "Epoch: 302, Train Loss: 0.183, Validation Loss: 0.240\n",
      "Epoch: 303, Train Loss: 0.160, Validation Loss: 0.241\n",
      "Epoch: 304, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 305, Train Loss: 0.175, Validation Loss: 0.240\n",
      "Epoch: 306, Train Loss: 0.336, Validation Loss: 0.244\n",
      "Epoch: 307, Train Loss: 0.249, Validation Loss: 0.244\n",
      "Epoch: 308, Train Loss: 0.367, Validation Loss: 0.242\n",
      "Epoch: 309, Train Loss: 0.315, Validation Loss: 0.244\n",
      "Epoch: 310, Train Loss: 0.415, Validation Loss: 0.240\n",
      "Epoch: 311, Train Loss: 0.470, Validation Loss: 0.244\n",
      "Epoch: 312, Train Loss: 0.344, Validation Loss: 0.241\n",
      "Epoch: 313, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 314, Train Loss: 0.308, Validation Loss: 0.242\n",
      "Epoch: 315, Train Loss: 0.325, Validation Loss: 0.240\n",
      "Epoch: 316, Train Loss: 0.255, Validation Loss: 0.245\n",
      "Epoch: 317, Train Loss: 0.554, Validation Loss: 0.243\n",
      "Epoch: 318, Train Loss: 0.258, Validation Loss: 0.240\n",
      "Epoch: 319, Train Loss: 0.338, Validation Loss: 0.241\n",
      "Epoch: 320, Train Loss: 0.358, Validation Loss: 0.245\n",
      "Epoch: 321, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 322, Train Loss: 0.541, Validation Loss: 0.245\n",
      "Epoch: 323, Train Loss: 0.333, Validation Loss: 0.244\n",
      "Epoch: 324, Train Loss: 0.192, Validation Loss: 0.244\n",
      "Epoch: 325, Train Loss: 0.272, Validation Loss: 0.241\n",
      "Epoch: 326, Train Loss: 0.480, Validation Loss: 0.241\n",
      "Epoch: 327, Train Loss: 0.253, Validation Loss: 0.243\n",
      "Epoch: 328, Train Loss: 0.486, Validation Loss: 0.240\n",
      "Epoch: 329, Train Loss: 0.203, Validation Loss: 0.242\n",
      "Epoch: 330, Train Loss: 0.195, Validation Loss: 0.244\n",
      "Epoch: 331, Train Loss: 0.169, Validation Loss: 0.241\n",
      "Epoch: 332, Train Loss: 0.282, Validation Loss: 0.241\n",
      "Epoch: 333, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 334, Train Loss: 0.349, Validation Loss: 0.239\n",
      "Epoch: 335, Train Loss: 0.251, Validation Loss: 0.242\n",
      "Epoch: 336, Train Loss: 0.196, Validation Loss: 0.241\n",
      "Epoch: 337, Train Loss: 0.215, Validation Loss: 0.246\n",
      "Epoch: 338, Train Loss: 0.346, Validation Loss: 0.244\n",
      "Epoch: 339, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 340, Train Loss: 0.263, Validation Loss: 0.239\n",
      "Epoch: 341, Train Loss: 0.217, Validation Loss: 0.241\n",
      "Epoch: 342, Train Loss: 0.303, Validation Loss: 0.240\n",
      "Epoch: 343, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 344, Train Loss: 0.290, Validation Loss: 0.239\n",
      "Epoch: 345, Train Loss: 0.264, Validation Loss: 0.243\n",
      "Epoch: 346, Train Loss: 0.278, Validation Loss: 0.239\n",
      "Epoch: 347, Train Loss: 0.176, Validation Loss: 0.241\n",
      "Epoch: 348, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 349, Train Loss: 0.365, Validation Loss: 0.240\n",
      "Epoch: 350, Train Loss: 0.320, Validation Loss: 0.244\n",
      "Epoch: 351, Train Loss: 0.272, Validation Loss: 0.240\n",
      "Epoch: 352, Train Loss: 0.466, Validation Loss: 0.244\n",
      "Epoch: 353, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 354, Train Loss: 0.348, Validation Loss: 0.240\n",
      "Epoch: 355, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 356, Train Loss: 0.172, Validation Loss: 0.240\n",
      "Epoch: 357, Train Loss: 0.480, Validation Loss: 0.243\n",
      "Epoch: 358, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 359, Train Loss: 0.211, Validation Loss: 0.242\n",
      "Epoch: 360, Train Loss: 0.195, Validation Loss: 0.240\n",
      "Epoch: 361, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 362, Train Loss: 0.226, Validation Loss: 0.238\n",
      "Epoch: 363, Train Loss: 0.337, Validation Loss: 0.242\n",
      "Epoch: 364, Train Loss: 0.308, Validation Loss: 0.237\n",
      "Epoch: 365, Train Loss: 0.252, Validation Loss: 0.237\n",
      "Epoch: 366, Train Loss: 0.255, Validation Loss: 0.237\n",
      "Epoch: 367, Train Loss: 0.229, Validation Loss: 0.237\n",
      "Epoch: 368, Train Loss: 0.318, Validation Loss: 0.237\n",
      "Epoch: 369, Train Loss: 0.270, Validation Loss: 0.238\n",
      "Epoch: 370, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 371, Train Loss: 0.291, Validation Loss: 0.241\n",
      "Epoch: 372, Train Loss: 0.155, Validation Loss: 0.239\n",
      "Epoch: 373, Train Loss: 0.268, Validation Loss: 0.241\n",
      "Epoch: 374, Train Loss: 0.194, Validation Loss: 0.237\n",
      "Epoch: 375, Train Loss: 0.249, Validation Loss: 0.238\n",
      "Epoch: 376, Train Loss: 0.217, Validation Loss: 0.238\n",
      "Epoch: 377, Train Loss: 0.205, Validation Loss: 0.242\n",
      "Epoch: 378, Train Loss: 0.153, Validation Loss: 0.238\n",
      "Epoch: 379, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 380, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 381, Train Loss: 0.230, Validation Loss: 0.238\n",
      "Epoch: 382, Train Loss: 0.325, Validation Loss: 0.239\n",
      "Epoch: 383, Train Loss: 0.249, Validation Loss: 0.238\n",
      "Epoch: 384, Train Loss: 0.311, Validation Loss: 0.239\n",
      "Epoch: 385, Train Loss: 0.567, Validation Loss: 0.244\n",
      "Epoch: 386, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 387, Train Loss: 0.232, Validation Loss: 0.239\n",
      "Epoch: 388, Train Loss: 0.263, Validation Loss: 0.239\n",
      "Epoch: 389, Train Loss: 0.269, Validation Loss: 0.240\n",
      "Epoch: 390, Train Loss: 0.234, Validation Loss: 0.239\n",
      "Epoch: 391, Train Loss: 0.322, Validation Loss: 0.242\n",
      "Epoch: 392, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 393, Train Loss: 0.230, Validation Loss: 0.240\n",
      "Epoch: 394, Train Loss: 0.177, Validation Loss: 0.239\n",
      "Epoch: 395, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 396, Train Loss: 0.167, Validation Loss: 0.241\n",
      "Epoch: 397, Train Loss: 0.273, Validation Loss: 0.242\n",
      "Epoch: 398, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 399, Train Loss: 0.173, Validation Loss: 0.240\n",
      "Epoch: 400, Train Loss: 0.180, Validation Loss: 0.241\n",
      "Epoch: 401, Train Loss: 0.248, Validation Loss: 0.237\n",
      "Epoch: 402, Train Loss: 0.285, Validation Loss: 0.239\n",
      "Epoch: 403, Train Loss: 0.277, Validation Loss: 0.240\n",
      "Epoch: 404, Train Loss: 0.368, Validation Loss: 0.238\n",
      "Epoch: 405, Train Loss: 0.216, Validation Loss: 0.241\n",
      "Epoch: 406, Train Loss: 0.164, Validation Loss: 0.238\n",
      "Epoch: 407, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 408, Train Loss: 0.178, Validation Loss: 0.241\n",
      "Epoch: 409, Train Loss: 0.289, Validation Loss: 0.244\n",
      "Epoch: 410, Train Loss: 0.308, Validation Loss: 0.241\n",
      "Epoch: 411, Train Loss: 0.420, Validation Loss: 0.238\n",
      "Epoch: 412, Train Loss: 0.221, Validation Loss: 0.238\n",
      "Epoch: 413, Train Loss: 0.202, Validation Loss: 0.244\n",
      "Epoch: 414, Train Loss: 0.268, Validation Loss: 0.237\n",
      "Epoch: 415, Train Loss: 0.303, Validation Loss: 0.237\n",
      "Epoch: 416, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 417, Train Loss: 0.217, Validation Loss: 0.242\n",
      "Epoch: 418, Train Loss: 0.148, Validation Loss: 0.239\n",
      "Epoch: 419, Train Loss: 0.344, Validation Loss: 0.239\n",
      "Epoch: 420, Train Loss: 0.242, Validation Loss: 0.244\n",
      "Epoch: 421, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 422, Train Loss: 0.248, Validation Loss: 0.237\n",
      "Epoch: 423, Train Loss: 0.510, Validation Loss: 0.238\n",
      "Epoch: 424, Train Loss: 0.228, Validation Loss: 0.240\n",
      "Epoch: 425, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 426, Train Loss: 0.325, Validation Loss: 0.239\n",
      "Epoch: 427, Train Loss: 0.306, Validation Loss: 0.237\n",
      "Epoch: 428, Train Loss: 0.370, Validation Loss: 0.237\n",
      "Epoch: 429, Train Loss: 0.226, Validation Loss: 0.238\n",
      "Epoch: 430, Train Loss: 0.299, Validation Loss: 0.243\n",
      "Epoch: 431, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 432, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 433, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 434, Train Loss: 0.267, Validation Loss: 0.240\n",
      "Epoch: 435, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 436, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 437, Train Loss: 0.305, Validation Loss: 0.241\n",
      "Epoch: 438, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 439, Train Loss: 0.289, Validation Loss: 0.240\n",
      "Epoch: 440, Train Loss: 0.243, Validation Loss: 0.245\n",
      "Epoch: 441, Train Loss: 0.303, Validation Loss: 0.240\n",
      "Epoch: 442, Train Loss: 0.273, Validation Loss: 0.240\n",
      "Epoch: 443, Train Loss: 0.304, Validation Loss: 0.241\n",
      "Epoch: 444, Train Loss: 0.171, Validation Loss: 0.240\n",
      "Epoch: 445, Train Loss: 0.287, Validation Loss: 0.240\n",
      "Epoch: 446, Train Loss: 0.286, Validation Loss: 0.240\n",
      "Epoch: 447, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 448, Train Loss: 0.190, Validation Loss: 0.237\n",
      "Epoch: 449, Train Loss: 0.274, Validation Loss: 0.239\n",
      "Epoch: 450, Train Loss: 0.240, Validation Loss: 0.238\n",
      "Epoch: 451, Train Loss: 0.233, Validation Loss: 0.237\n",
      "Epoch: 452, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 453, Train Loss: 0.250, Validation Loss: 0.240\n",
      "Epoch: 454, Train Loss: 0.192, Validation Loss: 0.240\n",
      "Epoch: 455, Train Loss: 0.208, Validation Loss: 0.238\n",
      "Epoch: 456, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 457, Train Loss: 0.278, Validation Loss: 0.238\n",
      "Epoch: 458, Train Loss: 0.191, Validation Loss: 0.238\n",
      "Epoch: 459, Train Loss: 0.278, Validation Loss: 0.244\n",
      "Epoch: 460, Train Loss: 0.205, Validation Loss: 0.244\n",
      "Epoch: 461, Train Loss: 0.258, Validation Loss: 0.238\n",
      "Epoch: 462, Train Loss: 0.241, Validation Loss: 0.239\n",
      "Epoch: 463, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 464, Train Loss: 0.474, Validation Loss: 0.247\n",
      "Epoch: 465, Train Loss: 0.314, Validation Loss: 0.242\n",
      "Epoch: 466, Train Loss: 0.359, Validation Loss: 0.237\n",
      "Epoch: 467, Train Loss: 0.304, Validation Loss: 0.242\n",
      "Epoch: 468, Train Loss: 0.410, Validation Loss: 0.239\n",
      "Epoch: 469, Train Loss: 0.267, Validation Loss: 0.242\n",
      "Epoch: 470, Train Loss: 0.391, Validation Loss: 0.238\n",
      "Epoch: 471, Train Loss: 0.260, Validation Loss: 0.238\n",
      "Epoch: 472, Train Loss: 0.193, Validation Loss: 0.238\n",
      "Epoch: 473, Train Loss: 0.230, Validation Loss: 0.241\n",
      "Epoch: 474, Train Loss: 0.199, Validation Loss: 0.237\n",
      "Epoch: 475, Train Loss: 0.331, Validation Loss: 0.236\n",
      "Epoch: 476, Train Loss: 0.220, Validation Loss: 0.238\n",
      "Epoch: 477, Train Loss: 0.355, Validation Loss: 0.238\n",
      "Epoch: 478, Train Loss: 0.203, Validation Loss: 0.236\n",
      "Epoch: 479, Train Loss: 0.290, Validation Loss: 0.237\n",
      "Epoch: 480, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 481, Train Loss: 0.251, Validation Loss: 0.238\n",
      "Epoch: 482, Train Loss: 0.258, Validation Loss: 0.241\n",
      "Epoch: 483, Train Loss: 0.160, Validation Loss: 0.238\n",
      "Epoch: 484, Train Loss: 0.256, Validation Loss: 0.236\n",
      "Epoch: 485, Train Loss: 0.327, Validation Loss: 0.237\n",
      "Epoch: 486, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 487, Train Loss: 0.203, Validation Loss: 0.236\n",
      "Epoch: 488, Train Loss: 0.465, Validation Loss: 0.237\n",
      "Epoch: 489, Train Loss: 0.193, Validation Loss: 0.237\n",
      "Epoch: 490, Train Loss: 0.195, Validation Loss: 0.238\n",
      "Epoch: 491, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 492, Train Loss: 0.223, Validation Loss: 0.236\n",
      "Epoch: 493, Train Loss: 0.389, Validation Loss: 0.246\n",
      "Epoch: 494, Train Loss: 0.177, Validation Loss: 0.237\n",
      "Epoch: 495, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 496, Train Loss: 0.280, Validation Loss: 0.236\n",
      "Epoch: 497, Train Loss: 0.190, Validation Loss: 0.236\n",
      "Epoch: 498, Train Loss: 0.251, Validation Loss: 0.237\n",
      "Epoch: 499, Train Loss: 0.248, Validation Loss: 0.240\n",
      "Epoch: 500, Train Loss: 0.338, Validation Loss: 0.238\n",
      "Epoch: 501, Train Loss: 0.218, Validation Loss: 0.239\n",
      "Epoch: 502, Train Loss: 0.368, Validation Loss: 0.240\n",
      "Epoch: 503, Train Loss: 0.246, Validation Loss: 0.241\n",
      "Epoch: 504, Train Loss: 0.441, Validation Loss: 0.242\n",
      "Epoch: 505, Train Loss: 0.195, Validation Loss: 0.240\n",
      "Epoch: 506, Train Loss: 0.258, Validation Loss: 0.243\n",
      "Epoch: 507, Train Loss: 0.312, Validation Loss: 0.239\n",
      "Epoch: 508, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 509, Train Loss: 0.298, Validation Loss: 0.238\n",
      "Epoch: 510, Train Loss: 0.248, Validation Loss: 0.240\n",
      "Epoch: 511, Train Loss: 0.155, Validation Loss: 0.238\n",
      "Epoch: 512, Train Loss: 0.188, Validation Loss: 0.241\n",
      "Epoch: 513, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 514, Train Loss: 0.430, Validation Loss: 0.241\n",
      "Epoch: 515, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 516, Train Loss: 0.405, Validation Loss: 0.247\n",
      "Epoch: 517, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 518, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 519, Train Loss: 0.309, Validation Loss: 0.240\n",
      "Epoch: 520, Train Loss: 0.355, Validation Loss: 0.240\n",
      "Epoch: 521, Train Loss: 0.261, Validation Loss: 0.238\n",
      "Epoch: 522, Train Loss: 0.270, Validation Loss: 0.236\n",
      "Epoch: 523, Train Loss: 0.400, Validation Loss: 0.238\n",
      "Epoch: 524, Train Loss: 0.225, Validation Loss: 0.238\n",
      "Epoch: 525, Train Loss: 0.426, Validation Loss: 0.240\n",
      "Epoch: 526, Train Loss: 0.260, Validation Loss: 0.239\n",
      "Epoch: 527, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 528, Train Loss: 0.222, Validation Loss: 0.237\n",
      "Epoch: 529, Train Loss: 0.408, Validation Loss: 0.238\n",
      "Epoch: 530, Train Loss: 0.168, Validation Loss: 0.240\n",
      "Epoch: 531, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 532, Train Loss: 0.266, Validation Loss: 0.237\n",
      "Epoch: 533, Train Loss: 0.240, Validation Loss: 0.240\n",
      "Epoch: 534, Train Loss: 0.246, Validation Loss: 0.237\n",
      "Epoch: 535, Train Loss: 0.302, Validation Loss: 0.239\n",
      "Epoch: 536, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 537, Train Loss: 0.224, Validation Loss: 0.239\n",
      "Epoch: 538, Train Loss: 0.313, Validation Loss: 0.242\n",
      "Epoch: 539, Train Loss: 0.249, Validation Loss: 0.241\n",
      "Epoch: 540, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 541, Train Loss: 0.259, Validation Loss: 0.239\n",
      "Epoch: 542, Train Loss: 0.295, Validation Loss: 0.241\n",
      "Epoch: 543, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 544, Train Loss: 0.257, Validation Loss: 0.238\n",
      "Epoch: 545, Train Loss: 0.307, Validation Loss: 0.240\n",
      "Epoch: 546, Train Loss: 0.249, Validation Loss: 0.238\n",
      "Epoch: 547, Train Loss: 0.241, Validation Loss: 0.241\n",
      "Epoch: 548, Train Loss: 0.405, Validation Loss: 0.244\n",
      "Epoch: 549, Train Loss: 0.274, Validation Loss: 0.241\n",
      "Epoch: 550, Train Loss: 0.252, Validation Loss: 0.240\n",
      "Epoch: 551, Train Loss: 0.295, Validation Loss: 0.242\n",
      "Epoch: 552, Train Loss: 0.324, Validation Loss: 0.242\n",
      "Epoch: 553, Train Loss: 0.207, Validation Loss: 0.243\n",
      "Epoch: 554, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 555, Train Loss: 0.230, Validation Loss: 0.241\n",
      "Epoch: 556, Train Loss: 0.311, Validation Loss: 0.239\n",
      "Epoch: 557, Train Loss: 0.218, Validation Loss: 0.239\n",
      "Epoch: 558, Train Loss: 0.275, Validation Loss: 0.237\n",
      "Epoch: 559, Train Loss: 0.197, Validation Loss: 0.243\n",
      "Epoch: 560, Train Loss: 0.173, Validation Loss: 0.239\n",
      "Epoch: 561, Train Loss: 0.169, Validation Loss: 0.237\n",
      "Epoch: 562, Train Loss: 0.190, Validation Loss: 0.240\n",
      "Epoch: 563, Train Loss: 0.258, Validation Loss: 0.238\n",
      "Epoch: 564, Train Loss: 0.178, Validation Loss: 0.239\n",
      "Epoch: 565, Train Loss: 0.254, Validation Loss: 0.237\n",
      "Epoch: 566, Train Loss: 0.300, Validation Loss: 0.238\n",
      "Epoch: 567, Train Loss: 0.329, Validation Loss: 0.244\n",
      "Epoch: 568, Train Loss: 0.662, Validation Loss: 0.244\n",
      "Epoch: 569, Train Loss: 0.289, Validation Loss: 0.243\n",
      "Epoch: 570, Train Loss: 0.408, Validation Loss: 0.239\n",
      "Epoch: 571, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 572, Train Loss: 0.244, Validation Loss: 0.238\n",
      "Epoch: 573, Train Loss: 0.435, Validation Loss: 0.238\n",
      "Epoch: 574, Train Loss: 0.319, Validation Loss: 0.239\n",
      "Epoch: 575, Train Loss: 0.499, Validation Loss: 0.243\n",
      "Epoch: 576, Train Loss: 0.348, Validation Loss: 0.239\n",
      "Epoch: 577, Train Loss: 0.224, Validation Loss: 0.237\n",
      "Epoch: 578, Train Loss: 0.257, Validation Loss: 0.240\n",
      "Epoch: 579, Train Loss: 0.291, Validation Loss: 0.241\n",
      "Epoch: 580, Train Loss: 0.361, Validation Loss: 0.244\n",
      "Epoch: 581, Train Loss: 0.306, Validation Loss: 0.239\n",
      "Epoch: 582, Train Loss: 0.268, Validation Loss: 0.238\n",
      "Epoch: 583, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 584, Train Loss: 0.297, Validation Loss: 0.240\n",
      "Epoch: 585, Train Loss: 0.368, Validation Loss: 0.238\n",
      "Epoch: 586, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 587, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 588, Train Loss: 0.186, Validation Loss: 0.239\n",
      "Epoch: 589, Train Loss: 0.369, Validation Loss: 0.238\n",
      "Epoch: 590, Train Loss: 0.215, Validation Loss: 0.241\n",
      "Epoch: 591, Train Loss: 0.261, Validation Loss: 0.240\n",
      "Epoch: 592, Train Loss: 0.512, Validation Loss: 0.242\n",
      "Epoch: 593, Train Loss: 0.215, Validation Loss: 0.236\n",
      "Epoch: 594, Train Loss: 0.183, Validation Loss: 0.236\n",
      "Epoch: 595, Train Loss: 0.236, Validation Loss: 0.236\n",
      "Epoch: 596, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 597, Train Loss: 0.211, Validation Loss: 0.241\n",
      "Epoch: 598, Train Loss: 0.289, Validation Loss: 0.236\n",
      "Epoch: 599, Train Loss: 0.283, Validation Loss: 0.237\n",
      "Epoch: 600, Train Loss: 0.154, Validation Loss: 0.239\n",
      "Epoch: 601, Train Loss: 0.229, Validation Loss: 0.238\n",
      "Epoch: 602, Train Loss: 0.176, Validation Loss: 0.237\n",
      "Epoch: 603, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 604, Train Loss: 0.290, Validation Loss: 0.239\n",
      "Epoch: 605, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 606, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 607, Train Loss: 0.205, Validation Loss: 0.239\n",
      "Epoch: 608, Train Loss: 0.191, Validation Loss: 0.237\n",
      "Epoch: 609, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 610, Train Loss: 0.346, Validation Loss: 0.238\n",
      "Epoch: 611, Train Loss: 0.218, Validation Loss: 0.242\n",
      "Epoch: 612, Train Loss: 0.282, Validation Loss: 0.236\n",
      "Epoch: 613, Train Loss: 0.256, Validation Loss: 0.237\n",
      "Epoch: 614, Train Loss: 0.267, Validation Loss: 0.238\n",
      "Epoch: 615, Train Loss: 0.441, Validation Loss: 0.238\n",
      "Epoch: 616, Train Loss: 0.378, Validation Loss: 0.240\n",
      "Epoch: 617, Train Loss: 0.231, Validation Loss: 0.236\n",
      "Epoch: 618, Train Loss: 0.514, Validation Loss: 0.237\n",
      "Epoch: 619, Train Loss: 0.259, Validation Loss: 0.239\n",
      "Epoch: 620, Train Loss: 0.277, Validation Loss: 0.238\n",
      "Epoch: 621, Train Loss: 0.194, Validation Loss: 0.238\n",
      "Epoch: 622, Train Loss: 0.258, Validation Loss: 0.239\n",
      "Epoch: 623, Train Loss: 0.264, Validation Loss: 0.238\n",
      "Epoch: 624, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 625, Train Loss: 0.277, Validation Loss: 0.239\n",
      "Epoch: 626, Train Loss: 0.440, Validation Loss: 0.237\n",
      "Epoch: 627, Train Loss: 0.283, Validation Loss: 0.238\n",
      "Epoch: 628, Train Loss: 0.271, Validation Loss: 0.242\n",
      "Epoch: 629, Train Loss: 0.284, Validation Loss: 0.246\n",
      "Epoch: 630, Train Loss: 0.244, Validation Loss: 0.238\n",
      "Epoch: 631, Train Loss: 0.191, Validation Loss: 0.238\n",
      "Epoch: 632, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 633, Train Loss: 0.222, Validation Loss: 0.243\n",
      "Epoch: 634, Train Loss: 0.302, Validation Loss: 0.240\n",
      "Epoch: 635, Train Loss: 0.212, Validation Loss: 0.240\n",
      "Epoch: 636, Train Loss: 0.517, Validation Loss: 0.240\n",
      "Epoch: 637, Train Loss: 0.243, Validation Loss: 0.239\n",
      "Epoch: 638, Train Loss: 0.323, Validation Loss: 0.238\n",
      "Epoch: 639, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 640, Train Loss: 0.347, Validation Loss: 0.241\n",
      "Epoch: 641, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 642, Train Loss: 0.293, Validation Loss: 0.239\n",
      "Epoch: 643, Train Loss: 0.275, Validation Loss: 0.239\n",
      "Epoch: 644, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 645, Train Loss: 0.341, Validation Loss: 0.238\n",
      "Epoch: 646, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 647, Train Loss: 0.270, Validation Loss: 0.238\n",
      "Epoch: 648, Train Loss: 0.246, Validation Loss: 0.240\n",
      "Epoch: 649, Train Loss: 0.286, Validation Loss: 0.238\n",
      "Epoch: 650, Train Loss: 0.485, Validation Loss: 0.241\n",
      "Epoch: 651, Train Loss: 0.275, Validation Loss: 0.242\n",
      "Epoch: 652, Train Loss: 0.265, Validation Loss: 0.236\n",
      "Epoch: 653, Train Loss: 0.423, Validation Loss: 0.240\n",
      "Epoch: 654, Train Loss: 0.292, Validation Loss: 0.235\n",
      "Epoch: 655, Train Loss: 0.267, Validation Loss: 0.236\n",
      "Epoch: 656, Train Loss: 0.365, Validation Loss: 0.243\n",
      "Epoch: 657, Train Loss: 0.260, Validation Loss: 0.239\n",
      "Epoch: 658, Train Loss: 0.225, Validation Loss: 0.238\n",
      "Epoch: 659, Train Loss: 0.290, Validation Loss: 0.239\n",
      "Epoch: 660, Train Loss: 0.199, Validation Loss: 0.240\n",
      "Epoch: 661, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 662, Train Loss: 0.339, Validation Loss: 0.244\n",
      "Epoch: 663, Train Loss: 0.434, Validation Loss: 0.241\n",
      "Epoch: 664, Train Loss: 0.301, Validation Loss: 0.239\n",
      "Epoch: 665, Train Loss: 0.172, Validation Loss: 0.238\n",
      "Epoch: 666, Train Loss: 0.261, Validation Loss: 0.239\n",
      "Epoch: 667, Train Loss: 0.165, Validation Loss: 0.237\n",
      "Epoch: 668, Train Loss: 0.492, Validation Loss: 0.241\n",
      "Epoch: 669, Train Loss: 0.240, Validation Loss: 0.238\n",
      "Epoch: 670, Train Loss: 0.254, Validation Loss: 0.237\n",
      "Epoch: 671, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 672, Train Loss: 0.326, Validation Loss: 0.236\n",
      "Epoch: 673, Train Loss: 0.293, Validation Loss: 0.236\n",
      "Epoch: 674, Train Loss: 0.318, Validation Loss: 0.241\n",
      "Epoch: 675, Train Loss: 0.273, Validation Loss: 0.240\n",
      "Epoch: 676, Train Loss: 0.205, Validation Loss: 0.238\n",
      "Epoch: 677, Train Loss: 0.196, Validation Loss: 0.236\n",
      "Epoch: 678, Train Loss: 0.183, Validation Loss: 0.236\n",
      "Epoch: 679, Train Loss: 0.311, Validation Loss: 0.240\n",
      "Epoch: 680, Train Loss: 0.318, Validation Loss: 0.239\n",
      "Epoch: 681, Train Loss: 0.411, Validation Loss: 0.238\n",
      "Epoch: 682, Train Loss: 0.333, Validation Loss: 0.237\n",
      "Epoch: 683, Train Loss: 0.221, Validation Loss: 0.242\n",
      "Epoch: 684, Train Loss: 0.272, Validation Loss: 0.245\n",
      "Epoch: 685, Train Loss: 0.413, Validation Loss: 0.237\n",
      "Epoch: 686, Train Loss: 0.276, Validation Loss: 0.237\n",
      "Epoch: 687, Train Loss: 0.432, Validation Loss: 0.238\n",
      "Epoch: 688, Train Loss: 0.355, Validation Loss: 0.239\n",
      "Epoch: 689, Train Loss: 0.828, Validation Loss: 0.243\n",
      "Epoch: 690, Train Loss: 0.359, Validation Loss: 0.239\n",
      "Epoch: 691, Train Loss: 0.182, Validation Loss: 0.238\n",
      "Epoch: 692, Train Loss: 0.284, Validation Loss: 0.237\n",
      "Epoch: 693, Train Loss: 0.354, Validation Loss: 0.239\n",
      "Epoch: 694, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 695, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 696, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 697, Train Loss: 0.188, Validation Loss: 0.242\n",
      "Epoch: 698, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 699, Train Loss: 0.277, Validation Loss: 0.235\n",
      "Epoch: 700, Train Loss: 0.253, Validation Loss: 0.235\n",
      "Epoch: 701, Train Loss: 0.200, Validation Loss: 0.238\n",
      "Epoch: 702, Train Loss: 0.238, Validation Loss: 0.238\n",
      "Epoch: 703, Train Loss: 0.276, Validation Loss: 0.243\n",
      "Epoch: 704, Train Loss: 0.246, Validation Loss: 0.236\n",
      "Epoch: 705, Train Loss: 0.315, Validation Loss: 0.235\n",
      "Epoch: 706, Train Loss: 0.229, Validation Loss: 0.238\n",
      "Epoch: 707, Train Loss: 0.241, Validation Loss: 0.241\n",
      "Epoch: 708, Train Loss: 0.422, Validation Loss: 0.241\n",
      "Epoch: 709, Train Loss: 0.214, Validation Loss: 0.237\n",
      "Epoch: 710, Train Loss: 0.180, Validation Loss: 0.239\n",
      "Epoch: 711, Train Loss: 0.272, Validation Loss: 0.237\n",
      "Epoch: 712, Train Loss: 0.321, Validation Loss: 0.237\n",
      "Epoch: 713, Train Loss: 0.210, Validation Loss: 0.235\n",
      "Epoch: 714, Train Loss: 0.217, Validation Loss: 0.235\n",
      "Epoch: 715, Train Loss: 0.242, Validation Loss: 0.236\n",
      "Epoch: 716, Train Loss: 0.243, Validation Loss: 0.237\n",
      "Epoch: 717, Train Loss: 0.222, Validation Loss: 0.236\n",
      "Epoch: 718, Train Loss: 0.214, Validation Loss: 0.236\n",
      "Epoch: 719, Train Loss: 0.291, Validation Loss: 0.234\n",
      "Epoch: 720, Train Loss: 0.350, Validation Loss: 0.234\n",
      "Epoch: 721, Train Loss: 0.339, Validation Loss: 0.234\n",
      "Epoch: 722, Train Loss: 0.504, Validation Loss: 0.234\n",
      "Epoch: 723, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 724, Train Loss: 0.253, Validation Loss: 0.236\n",
      "Epoch: 725, Train Loss: 0.208, Validation Loss: 0.235\n",
      "Epoch: 726, Train Loss: 0.358, Validation Loss: 0.235\n",
      "Epoch: 727, Train Loss: 0.238, Validation Loss: 0.237\n",
      "Epoch: 728, Train Loss: 0.237, Validation Loss: 0.235\n",
      "Epoch: 729, Train Loss: 0.306, Validation Loss: 0.238\n",
      "Epoch: 730, Train Loss: 0.215, Validation Loss: 0.234\n",
      "Epoch: 731, Train Loss: 0.278, Validation Loss: 0.238\n",
      "Epoch: 732, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 733, Train Loss: 0.235, Validation Loss: 0.236\n",
      "Epoch: 734, Train Loss: 0.245, Validation Loss: 0.235\n",
      "Epoch: 735, Train Loss: 0.389, Validation Loss: 0.235\n",
      "Epoch: 736, Train Loss: 0.203, Validation Loss: 0.236\n",
      "Epoch: 737, Train Loss: 0.314, Validation Loss: 0.241\n",
      "Epoch: 738, Train Loss: 0.245, Validation Loss: 0.235\n",
      "Epoch: 739, Train Loss: 0.239, Validation Loss: 0.235\n",
      "Epoch: 740, Train Loss: 0.327, Validation Loss: 0.235\n",
      "Epoch: 741, Train Loss: 0.361, Validation Loss: 0.237\n",
      "Epoch: 742, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 743, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 744, Train Loss: 0.251, Validation Loss: 0.239\n",
      "Epoch: 745, Train Loss: 0.259, Validation Loss: 0.237\n",
      "Epoch: 746, Train Loss: 0.255, Validation Loss: 0.238\n",
      "Epoch: 747, Train Loss: 0.215, Validation Loss: 0.243\n",
      "Epoch: 748, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 749, Train Loss: 0.158, Validation Loss: 0.237\n",
      "Epoch: 750, Train Loss: 0.362, Validation Loss: 0.243\n",
      "Epoch: 751, Train Loss: 0.284, Validation Loss: 0.241\n",
      "Epoch: 752, Train Loss: 0.365, Validation Loss: 0.238\n",
      "Epoch: 753, Train Loss: 0.512, Validation Loss: 0.242\n",
      "Epoch: 754, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 755, Train Loss: 0.283, Validation Loss: 0.241\n",
      "Epoch: 756, Train Loss: 0.225, Validation Loss: 0.237\n",
      "Epoch: 757, Train Loss: 0.233, Validation Loss: 0.238\n",
      "Epoch: 758, Train Loss: 0.242, Validation Loss: 0.241\n",
      "Epoch: 759, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 760, Train Loss: 0.292, Validation Loss: 0.239\n",
      "Epoch: 761, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 762, Train Loss: 0.307, Validation Loss: 0.240\n",
      "Epoch: 763, Train Loss: 0.217, Validation Loss: 0.237\n",
      "Epoch: 764, Train Loss: 0.239, Validation Loss: 0.237\n",
      "Epoch: 765, Train Loss: 0.198, Validation Loss: 0.237\n",
      "Epoch: 766, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 767, Train Loss: 0.288, Validation Loss: 0.237\n",
      "Epoch: 768, Train Loss: 0.298, Validation Loss: 0.238\n",
      "Epoch: 769, Train Loss: 0.383, Validation Loss: 0.239\n",
      "Epoch: 770, Train Loss: 0.267, Validation Loss: 0.238\n",
      "Epoch: 771, Train Loss: 0.296, Validation Loss: 0.241\n",
      "Epoch: 772, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 773, Train Loss: 0.268, Validation Loss: 0.240\n",
      "Epoch: 774, Train Loss: 0.258, Validation Loss: 0.242\n",
      "Epoch: 775, Train Loss: 0.416, Validation Loss: 0.238\n",
      "Epoch: 776, Train Loss: 0.216, Validation Loss: 0.237\n",
      "Epoch: 777, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 778, Train Loss: 0.505, Validation Loss: 0.238\n",
      "Epoch: 779, Train Loss: 0.551, Validation Loss: 0.242\n",
      "Epoch: 780, Train Loss: 0.252, Validation Loss: 0.238\n",
      "Epoch: 781, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 782, Train Loss: 0.494, Validation Loss: 0.241\n",
      "Epoch: 783, Train Loss: 0.198, Validation Loss: 0.238\n",
      "Epoch: 784, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 785, Train Loss: 0.213, Validation Loss: 0.243\n",
      "Epoch: 786, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 787, Train Loss: 0.252, Validation Loss: 0.237\n",
      "Epoch: 788, Train Loss: 0.277, Validation Loss: 0.236\n",
      "Epoch: 789, Train Loss: 0.285, Validation Loss: 0.237\n",
      "Epoch: 790, Train Loss: 0.233, Validation Loss: 0.237\n",
      "Epoch: 791, Train Loss: 0.339, Validation Loss: 0.237\n",
      "Epoch: 792, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 793, Train Loss: 0.317, Validation Loss: 0.238\n",
      "Epoch: 794, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 795, Train Loss: 0.175, Validation Loss: 0.236\n",
      "Epoch: 796, Train Loss: 0.589, Validation Loss: 0.241\n",
      "Epoch: 797, Train Loss: 0.192, Validation Loss: 0.236\n",
      "Epoch: 798, Train Loss: 0.166, Validation Loss: 0.236\n",
      "Epoch: 799, Train Loss: 0.219, Validation Loss: 0.236\n",
      "Epoch: 800, Train Loss: 0.227, Validation Loss: 0.235\n",
      "Epoch: 801, Train Loss: 0.311, Validation Loss: 0.237\n",
      "Epoch: 802, Train Loss: 0.249, Validation Loss: 0.234\n",
      "Epoch: 803, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 804, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 805, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 806, Train Loss: 0.222, Validation Loss: 0.238\n",
      "Epoch: 807, Train Loss: 0.240, Validation Loss: 0.238\n",
      "Epoch: 808, Train Loss: 0.245, Validation Loss: 0.240\n",
      "Epoch: 809, Train Loss: 0.514, Validation Loss: 0.239\n",
      "Epoch: 810, Train Loss: 0.265, Validation Loss: 0.236\n",
      "Epoch: 811, Train Loss: 0.165, Validation Loss: 0.239\n",
      "Epoch: 812, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 813, Train Loss: 0.368, Validation Loss: 0.243\n",
      "Epoch: 814, Train Loss: 0.235, Validation Loss: 0.236\n",
      "Epoch: 815, Train Loss: 0.469, Validation Loss: 0.239\n",
      "Epoch: 816, Train Loss: 0.250, Validation Loss: 0.238\n",
      "Epoch: 817, Train Loss: 0.262, Validation Loss: 0.240\n",
      "Epoch: 818, Train Loss: 0.254, Validation Loss: 0.242\n",
      "Epoch: 819, Train Loss: 0.250, Validation Loss: 0.238\n",
      "Epoch: 820, Train Loss: 0.209, Validation Loss: 0.237\n",
      "Epoch: 821, Train Loss: 0.317, Validation Loss: 0.241\n",
      "Epoch: 822, Train Loss: 0.229, Validation Loss: 0.241\n",
      "Epoch: 823, Train Loss: 0.204, Validation Loss: 0.238\n",
      "Epoch: 824, Train Loss: 0.169, Validation Loss: 0.243\n",
      "Epoch: 825, Train Loss: 0.215, Validation Loss: 0.240\n",
      "Epoch: 826, Train Loss: 0.181, Validation Loss: 0.238\n",
      "Epoch: 827, Train Loss: 0.283, Validation Loss: 0.239\n",
      "Epoch: 828, Train Loss: 0.367, Validation Loss: 0.237\n",
      "Epoch: 829, Train Loss: 0.206, Validation Loss: 0.237\n",
      "Epoch: 830, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 831, Train Loss: 0.272, Validation Loss: 0.240\n",
      "Epoch: 832, Train Loss: 0.229, Validation Loss: 0.244\n",
      "Epoch: 833, Train Loss: 0.264, Validation Loss: 0.238\n",
      "Epoch: 834, Train Loss: 0.209, Validation Loss: 0.238\n",
      "Epoch: 835, Train Loss: 0.528, Validation Loss: 0.242\n",
      "Epoch: 836, Train Loss: 0.198, Validation Loss: 0.238\n",
      "Epoch: 837, Train Loss: 0.333, Validation Loss: 0.237\n",
      "Epoch: 838, Train Loss: 0.392, Validation Loss: 0.240\n",
      "Epoch: 839, Train Loss: 0.393, Validation Loss: 0.238\n",
      "Epoch: 840, Train Loss: 0.286, Validation Loss: 0.239\n",
      "Epoch: 841, Train Loss: 0.187, Validation Loss: 0.240\n",
      "Epoch: 842, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 843, Train Loss: 0.317, Validation Loss: 0.236\n",
      "Epoch: 844, Train Loss: 0.290, Validation Loss: 0.237\n",
      "Epoch: 845, Train Loss: 0.287, Validation Loss: 0.240\n",
      "Epoch: 846, Train Loss: 0.605, Validation Loss: 0.241\n",
      "Epoch: 847, Train Loss: 0.256, Validation Loss: 0.238\n",
      "Epoch: 848, Train Loss: 0.228, Validation Loss: 0.240\n",
      "Epoch: 849, Train Loss: 0.268, Validation Loss: 0.238\n",
      "Epoch: 850, Train Loss: 0.243, Validation Loss: 0.238\n",
      "Epoch: 851, Train Loss: 0.283, Validation Loss: 0.238\n",
      "Epoch: 852, Train Loss: 0.218, Validation Loss: 0.237\n",
      "Epoch: 853, Train Loss: 0.205, Validation Loss: 0.236\n",
      "Epoch: 854, Train Loss: 0.234, Validation Loss: 0.240\n",
      "Epoch: 855, Train Loss: 0.244, Validation Loss: 0.241\n",
      "Epoch: 856, Train Loss: 0.263, Validation Loss: 0.239\n",
      "Epoch: 857, Train Loss: 0.327, Validation Loss: 0.242\n",
      "Epoch: 858, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 859, Train Loss: 0.264, Validation Loss: 0.237\n",
      "Epoch: 860, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 861, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 862, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 863, Train Loss: 0.179, Validation Loss: 0.237\n",
      "Epoch: 864, Train Loss: 0.296, Validation Loss: 0.237\n",
      "Epoch: 865, Train Loss: 0.231, Validation Loss: 0.237\n",
      "Epoch: 866, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 867, Train Loss: 0.702, Validation Loss: 0.246\n",
      "Epoch: 868, Train Loss: 0.220, Validation Loss: 0.238\n",
      "Epoch: 869, Train Loss: 0.261, Validation Loss: 0.238\n",
      "Epoch: 870, Train Loss: 0.255, Validation Loss: 0.237\n",
      "Epoch: 871, Train Loss: 0.223, Validation Loss: 0.237\n",
      "Epoch: 872, Train Loss: 0.321, Validation Loss: 0.239\n",
      "Epoch: 873, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 874, Train Loss: 0.295, Validation Loss: 0.244\n",
      "Epoch: 875, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 876, Train Loss: 0.284, Validation Loss: 0.239\n",
      "Epoch: 877, Train Loss: 0.175, Validation Loss: 0.240\n",
      "Epoch: 878, Train Loss: 0.515, Validation Loss: 0.246\n",
      "Epoch: 879, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 880, Train Loss: 0.387, Validation Loss: 0.240\n",
      "Epoch: 881, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 882, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 883, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 884, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 885, Train Loss: 0.185, Validation Loss: 0.240\n",
      "Epoch: 886, Train Loss: 0.175, Validation Loss: 0.238\n",
      "Epoch: 887, Train Loss: 0.274, Validation Loss: 0.238\n",
      "Epoch: 888, Train Loss: 0.263, Validation Loss: 0.236\n",
      "Epoch: 889, Train Loss: 0.614, Validation Loss: 0.242\n",
      "Epoch: 890, Train Loss: 0.243, Validation Loss: 0.238\n",
      "Epoch: 891, Train Loss: 0.177, Validation Loss: 0.240\n",
      "Epoch: 892, Train Loss: 0.277, Validation Loss: 0.237\n",
      "Epoch: 893, Train Loss: 0.350, Validation Loss: 0.239\n",
      "Epoch: 894, Train Loss: 0.199, Validation Loss: 0.237\n",
      "Epoch: 895, Train Loss: 0.318, Validation Loss: 0.237\n",
      "Epoch: 896, Train Loss: 0.258, Validation Loss: 0.240\n",
      "Epoch: 897, Train Loss: 0.232, Validation Loss: 0.239\n",
      "Epoch: 898, Train Loss: 0.234, Validation Loss: 0.236\n",
      "Epoch: 899, Train Loss: 0.311, Validation Loss: 0.239\n",
      "Epoch: 900, Train Loss: 0.296, Validation Loss: 0.236\n",
      "Epoch: 901, Train Loss: 0.192, Validation Loss: 0.236\n",
      "Epoch: 902, Train Loss: 0.277, Validation Loss: 0.238\n",
      "Epoch: 903, Train Loss: 0.254, Validation Loss: 0.237\n",
      "Epoch: 904, Train Loss: 0.194, Validation Loss: 0.236\n",
      "Epoch: 905, Train Loss: 0.201, Validation Loss: 0.237\n",
      "Epoch: 906, Train Loss: 0.304, Validation Loss: 0.240\n",
      "Epoch: 907, Train Loss: 0.280, Validation Loss: 0.237\n",
      "Epoch: 908, Train Loss: 0.268, Validation Loss: 0.236\n",
      "Epoch: 909, Train Loss: 0.452, Validation Loss: 0.240\n",
      "Epoch: 910, Train Loss: 0.335, Validation Loss: 0.239\n",
      "Epoch: 911, Train Loss: 0.274, Validation Loss: 0.239\n",
      "Epoch: 912, Train Loss: 0.180, Validation Loss: 0.235\n",
      "Epoch: 913, Train Loss: 0.173, Validation Loss: 0.236\n",
      "Epoch: 914, Train Loss: 0.300, Validation Loss: 0.239\n",
      "Epoch: 915, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 916, Train Loss: 0.334, Validation Loss: 0.237\n",
      "Epoch: 917, Train Loss: 0.274, Validation Loss: 0.238\n",
      "Epoch: 918, Train Loss: 0.282, Validation Loss: 0.240\n",
      "Epoch: 919, Train Loss: 0.193, Validation Loss: 0.238\n",
      "Epoch: 920, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 921, Train Loss: 0.229, Validation Loss: 0.238\n",
      "Epoch: 922, Train Loss: 0.270, Validation Loss: 0.237\n",
      "Epoch: 923, Train Loss: 0.438, Validation Loss: 0.238\n",
      "Epoch: 924, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 925, Train Loss: 0.257, Validation Loss: 0.237\n",
      "Epoch: 926, Train Loss: 0.263, Validation Loss: 0.237\n",
      "Epoch: 927, Train Loss: 0.261, Validation Loss: 0.240\n",
      "Epoch: 928, Train Loss: 0.251, Validation Loss: 0.241\n",
      "Epoch: 929, Train Loss: 0.458, Validation Loss: 0.237\n",
      "Epoch: 930, Train Loss: 0.276, Validation Loss: 0.237\n",
      "Epoch: 931, Train Loss: 0.173, Validation Loss: 0.240\n",
      "Epoch: 932, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 933, Train Loss: 0.247, Validation Loss: 0.238\n",
      "Epoch: 934, Train Loss: 0.288, Validation Loss: 0.239\n",
      "Epoch: 935, Train Loss: 0.503, Validation Loss: 0.243\n",
      "Epoch: 936, Train Loss: 0.259, Validation Loss: 0.242\n",
      "Epoch: 937, Train Loss: 0.305, Validation Loss: 0.238\n",
      "Epoch: 938, Train Loss: 0.266, Validation Loss: 0.238\n",
      "Epoch: 939, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 940, Train Loss: 0.213, Validation Loss: 0.237\n",
      "Epoch: 941, Train Loss: 0.436, Validation Loss: 0.242\n",
      "Epoch: 942, Train Loss: 0.444, Validation Loss: 0.247\n",
      "Epoch: 943, Train Loss: 0.306, Validation Loss: 0.238\n",
      "Epoch: 944, Train Loss: 0.223, Validation Loss: 0.238\n",
      "Epoch: 945, Train Loss: 0.277, Validation Loss: 0.240\n",
      "Epoch: 946, Train Loss: 0.219, Validation Loss: 0.240\n",
      "Epoch: 947, Train Loss: 0.185, Validation Loss: 0.241\n",
      "Epoch: 948, Train Loss: 0.286, Validation Loss: 0.240\n",
      "Epoch: 949, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 950, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 951, Train Loss: 0.275, Validation Loss: 0.238\n",
      "Epoch: 952, Train Loss: 0.312, Validation Loss: 0.240\n",
      "Epoch: 953, Train Loss: 0.229, Validation Loss: 0.236\n",
      "Epoch: 954, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 955, Train Loss: 0.230, Validation Loss: 0.239\n",
      "Epoch: 956, Train Loss: 0.539, Validation Loss: 0.241\n",
      "Epoch: 957, Train Loss: 0.272, Validation Loss: 0.239\n",
      "Epoch: 958, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 959, Train Loss: 0.483, Validation Loss: 0.239\n",
      "Epoch: 960, Train Loss: 0.347, Validation Loss: 0.238\n",
      "Epoch: 961, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 962, Train Loss: 0.234, Validation Loss: 0.240\n",
      "Epoch: 963, Train Loss: 0.184, Validation Loss: 0.239\n",
      "Epoch: 964, Train Loss: 0.180, Validation Loss: 0.236\n",
      "Epoch: 965, Train Loss: 0.252, Validation Loss: 0.236\n",
      "Epoch: 966, Train Loss: 0.207, Validation Loss: 0.238\n",
      "Epoch: 967, Train Loss: 0.204, Validation Loss: 0.240\n",
      "Epoch: 968, Train Loss: 0.231, Validation Loss: 0.239\n",
      "Epoch: 969, Train Loss: 0.666, Validation Loss: 0.242\n",
      "Epoch: 970, Train Loss: 0.293, Validation Loss: 0.239\n",
      "Epoch: 971, Train Loss: 0.349, Validation Loss: 0.243\n",
      "Epoch: 972, Train Loss: 0.326, Validation Loss: 0.239\n",
      "Epoch: 973, Train Loss: 0.296, Validation Loss: 0.237\n",
      "Epoch: 974, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 975, Train Loss: 0.294, Validation Loss: 0.239\n",
      "Epoch: 976, Train Loss: 0.209, Validation Loss: 0.237\n",
      "Epoch: 977, Train Loss: 0.216, Validation Loss: 0.237\n",
      "Epoch: 978, Train Loss: 0.225, Validation Loss: 0.238\n",
      "Epoch: 979, Train Loss: 0.305, Validation Loss: 0.237\n",
      "Epoch: 980, Train Loss: 0.273, Validation Loss: 0.236\n",
      "Epoch: 981, Train Loss: 0.290, Validation Loss: 0.236\n",
      "Epoch: 982, Train Loss: 0.183, Validation Loss: 0.238\n",
      "Epoch: 983, Train Loss: 0.247, Validation Loss: 0.237\n",
      "Epoch: 984, Train Loss: 0.190, Validation Loss: 0.236\n",
      "Epoch: 985, Train Loss: 0.321, Validation Loss: 0.239\n",
      "Epoch: 986, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 987, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 988, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 989, Train Loss: 0.338, Validation Loss: 0.238\n",
      "Epoch: 990, Train Loss: 0.322, Validation Loss: 0.240\n",
      "Epoch: 991, Train Loss: 0.176, Validation Loss: 0.238\n",
      "Epoch: 992, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 993, Train Loss: 0.240, Validation Loss: 0.242\n",
      "Epoch: 994, Train Loss: 0.451, Validation Loss: 0.238\n",
      "Epoch: 995, Train Loss: 0.221, Validation Loss: 0.240\n",
      "Epoch: 996, Train Loss: 0.367, Validation Loss: 0.238\n",
      "Epoch: 997, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 998, Train Loss: 0.255, Validation Loss: 0.238\n",
      "Epoch: 999, Train Loss: 0.177, Validation Loss: 0.237\n",
      "Epoch: 1000, Train Loss: 0.205, Validation Loss: 0.238\n",
      "Epoch: 1001, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 1002, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 1003, Train Loss: 0.325, Validation Loss: 0.242\n",
      "Epoch: 1004, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 1005, Train Loss: 0.305, Validation Loss: 0.239\n",
      "Epoch: 1006, Train Loss: 0.224, Validation Loss: 0.236\n",
      "Epoch: 1007, Train Loss: 0.189, Validation Loss: 0.236\n",
      "Epoch: 1008, Train Loss: 0.181, Validation Loss: 0.236\n",
      "Epoch: 1009, Train Loss: 0.184, Validation Loss: 0.236\n",
      "Epoch: 1010, Train Loss: 0.315, Validation Loss: 0.237\n",
      "Epoch: 1011, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 1012, Train Loss: 0.221, Validation Loss: 0.238\n",
      "Epoch: 1013, Train Loss: 0.310, Validation Loss: 0.238\n",
      "Epoch: 1014, Train Loss: 0.228, Validation Loss: 0.235\n",
      "Epoch: 1015, Train Loss: 0.267, Validation Loss: 0.237\n",
      "Epoch: 1016, Train Loss: 0.243, Validation Loss: 0.246\n",
      "Epoch: 1017, Train Loss: 0.255, Validation Loss: 0.242\n",
      "Epoch: 1018, Train Loss: 0.203, Validation Loss: 0.237\n",
      "Epoch: 1019, Train Loss: 0.306, Validation Loss: 0.237\n",
      "Epoch: 1020, Train Loss: 0.242, Validation Loss: 0.238\n",
      "Epoch: 1021, Train Loss: 0.283, Validation Loss: 0.237\n",
      "Epoch: 1022, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 1023, Train Loss: 0.347, Validation Loss: 0.240\n",
      "Epoch: 1024, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 1025, Train Loss: 0.222, Validation Loss: 0.241\n",
      "Epoch: 1026, Train Loss: 0.399, Validation Loss: 0.238\n",
      "Epoch: 1027, Train Loss: 0.193, Validation Loss: 0.237\n",
      "Epoch: 1028, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 1029, Train Loss: 0.233, Validation Loss: 0.238\n",
      "Epoch: 1030, Train Loss: 0.296, Validation Loss: 0.239\n",
      "Epoch: 1031, Train Loss: 0.172, Validation Loss: 0.238\n",
      "Epoch: 1032, Train Loss: 0.170, Validation Loss: 0.236\n",
      "Epoch: 1033, Train Loss: 0.541, Validation Loss: 0.241\n",
      "Epoch: 1034, Train Loss: 0.370, Validation Loss: 0.239\n",
      "Epoch: 1035, Train Loss: 0.253, Validation Loss: 0.240\n",
      "Epoch: 1036, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 1037, Train Loss: 0.457, Validation Loss: 0.238\n",
      "Epoch: 1038, Train Loss: 0.252, Validation Loss: 0.238\n",
      "Epoch: 1039, Train Loss: 0.179, Validation Loss: 0.238\n",
      "Epoch: 1040, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 1041, Train Loss: 0.260, Validation Loss: 0.237\n",
      "Epoch: 1042, Train Loss: 0.263, Validation Loss: 0.239\n",
      "Epoch: 1043, Train Loss: 0.311, Validation Loss: 0.239\n",
      "Epoch: 1044, Train Loss: 0.291, Validation Loss: 0.237\n",
      "Epoch: 1045, Train Loss: 0.223, Validation Loss: 0.238\n",
      "Epoch: 1046, Train Loss: 0.556, Validation Loss: 0.239\n",
      "Epoch: 1047, Train Loss: 0.369, Validation Loss: 0.238\n",
      "Epoch: 1048, Train Loss: 0.224, Validation Loss: 0.235\n",
      "Epoch: 1049, Train Loss: 0.389, Validation Loss: 0.242\n",
      "Epoch: 1050, Train Loss: 0.226, Validation Loss: 0.240\n",
      "Epoch: 1051, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 1052, Train Loss: 0.213, Validation Loss: 0.238\n",
      "Epoch: 1053, Train Loss: 0.279, Validation Loss: 0.239\n",
      "Epoch: 1054, Train Loss: 0.407, Validation Loss: 0.237\n",
      "Epoch: 1055, Train Loss: 0.192, Validation Loss: 0.240\n",
      "Epoch: 1056, Train Loss: 0.264, Validation Loss: 0.238\n",
      "Epoch: 1057, Train Loss: 0.333, Validation Loss: 0.236\n",
      "Epoch: 1058, Train Loss: 0.222, Validation Loss: 0.237\n",
      "Epoch: 1059, Train Loss: 0.365, Validation Loss: 0.239\n",
      "Epoch: 1060, Train Loss: 0.338, Validation Loss: 0.238\n",
      "Epoch: 1061, Train Loss: 0.294, Validation Loss: 0.238\n",
      "Epoch: 1062, Train Loss: 0.172, Validation Loss: 0.237\n",
      "Epoch: 1063, Train Loss: 0.211, Validation Loss: 0.235\n",
      "Epoch: 1064, Train Loss: 0.200, Validation Loss: 0.236\n",
      "Epoch: 1065, Train Loss: 0.217, Validation Loss: 0.238\n",
      "Epoch: 1066, Train Loss: 0.445, Validation Loss: 0.237\n",
      "Epoch: 1067, Train Loss: 0.247, Validation Loss: 0.236\n",
      "Epoch: 1068, Train Loss: 0.222, Validation Loss: 0.237\n",
      "Epoch: 1069, Train Loss: 0.268, Validation Loss: 0.236\n",
      "Epoch: 1070, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 1071, Train Loss: 0.459, Validation Loss: 0.241\n",
      "Epoch: 1072, Train Loss: 0.261, Validation Loss: 0.238\n",
      "Epoch: 1073, Train Loss: 0.230, Validation Loss: 0.237\n",
      "Epoch: 1074, Train Loss: 0.344, Validation Loss: 0.237\n",
      "Epoch: 1075, Train Loss: 0.319, Validation Loss: 0.237\n",
      "Epoch: 1076, Train Loss: 0.317, Validation Loss: 0.239\n",
      "Epoch: 1077, Train Loss: 0.279, Validation Loss: 0.239\n",
      "Epoch: 1078, Train Loss: 0.201, Validation Loss: 0.235\n",
      "Epoch: 1079, Train Loss: 0.618, Validation Loss: 0.240\n",
      "Epoch: 1080, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 1081, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 1082, Train Loss: 0.196, Validation Loss: 0.240\n",
      "Epoch: 1083, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 1084, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 1085, Train Loss: 0.278, Validation Loss: 0.238\n",
      "Epoch: 1086, Train Loss: 0.190, Validation Loss: 0.239\n",
      "Epoch: 1087, Train Loss: 0.260, Validation Loss: 0.237\n",
      "Epoch: 1088, Train Loss: 0.258, Validation Loss: 0.236\n",
      "Epoch: 1089, Train Loss: 0.384, Validation Loss: 0.238\n",
      "Epoch: 1090, Train Loss: 0.239, Validation Loss: 0.238\n",
      "Epoch: 1091, Train Loss: 0.218, Validation Loss: 0.240\n",
      "Epoch: 1092, Train Loss: 0.305, Validation Loss: 0.239\n",
      "Epoch: 1093, Train Loss: 0.212, Validation Loss: 0.239\n",
      "Epoch: 1094, Train Loss: 0.170, Validation Loss: 0.239\n",
      "Epoch: 1095, Train Loss: 0.235, Validation Loss: 0.240\n",
      "Epoch: 1096, Train Loss: 0.204, Validation Loss: 0.241\n",
      "Epoch: 1097, Train Loss: 0.298, Validation Loss: 0.239\n",
      "Epoch: 1098, Train Loss: 0.311, Validation Loss: 0.240\n",
      "Epoch: 1099, Train Loss: 0.258, Validation Loss: 0.239\n",
      "Epoch: 1100, Train Loss: 0.339, Validation Loss: 0.240\n",
      "Epoch: 1101, Train Loss: 0.315, Validation Loss: 0.240\n",
      "Epoch: 1102, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 1103, Train Loss: 0.341, Validation Loss: 0.239\n",
      "Epoch: 1104, Train Loss: 0.295, Validation Loss: 0.238\n",
      "Epoch: 1105, Train Loss: 0.173, Validation Loss: 0.238\n",
      "Epoch: 1106, Train Loss: 0.295, Validation Loss: 0.241\n",
      "Epoch: 1107, Train Loss: 0.196, Validation Loss: 0.240\n",
      "Epoch: 1108, Train Loss: 0.250, Validation Loss: 0.238\n",
      "Epoch: 1109, Train Loss: 0.240, Validation Loss: 0.237\n",
      "Epoch: 1110, Train Loss: 0.258, Validation Loss: 0.236\n",
      "Epoch: 1111, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 1112, Train Loss: 0.283, Validation Loss: 0.242\n",
      "Epoch: 1113, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 1114, Train Loss: 0.204, Validation Loss: 0.236\n",
      "Epoch: 1115, Train Loss: 0.252, Validation Loss: 0.236\n",
      "Epoch: 1116, Train Loss: 0.388, Validation Loss: 0.236\n",
      "Epoch: 1117, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 1118, Train Loss: 0.345, Validation Loss: 0.240\n",
      "Epoch: 1119, Train Loss: 0.238, Validation Loss: 0.238\n",
      "Epoch: 1120, Train Loss: 0.358, Validation Loss: 0.236\n",
      "Epoch: 1121, Train Loss: 0.288, Validation Loss: 0.236\n",
      "Epoch: 1122, Train Loss: 0.272, Validation Loss: 0.237\n",
      "Epoch: 1123, Train Loss: 0.216, Validation Loss: 0.237\n",
      "Epoch: 1124, Train Loss: 0.306, Validation Loss: 0.238\n",
      "Epoch: 1125, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 1126, Train Loss: 0.273, Validation Loss: 0.239\n",
      "Epoch: 1127, Train Loss: 0.179, Validation Loss: 0.238\n",
      "Epoch: 1128, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 1129, Train Loss: 0.256, Validation Loss: 0.241\n",
      "Epoch: 1130, Train Loss: 0.260, Validation Loss: 0.239\n",
      "Epoch: 1131, Train Loss: 0.533, Validation Loss: 0.243\n",
      "Epoch: 1132, Train Loss: 0.288, Validation Loss: 0.239\n",
      "Epoch: 1133, Train Loss: 0.303, Validation Loss: 0.239\n",
      "Epoch: 1134, Train Loss: 0.548, Validation Loss: 0.244\n",
      "Epoch: 1135, Train Loss: 0.213, Validation Loss: 0.243\n",
      "Epoch: 1136, Train Loss: 0.484, Validation Loss: 0.247\n",
      "Epoch: 1137, Train Loss: 0.259, Validation Loss: 0.239\n",
      "Epoch: 1138, Train Loss: 0.626, Validation Loss: 0.238\n",
      "Epoch: 1139, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 1140, Train Loss: 0.205, Validation Loss: 0.240\n",
      "Epoch: 1141, Train Loss: 0.281, Validation Loss: 0.237\n",
      "Epoch: 1142, Train Loss: 0.248, Validation Loss: 0.237\n",
      "Epoch: 1143, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 1144, Train Loss: 0.413, Validation Loss: 0.240\n",
      "Epoch: 1145, Train Loss: 0.318, Validation Loss: 0.240\n",
      "Epoch: 1146, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 1147, Train Loss: 0.143, Validation Loss: 0.236\n",
      "Epoch: 1148, Train Loss: 0.174, Validation Loss: 0.236\n",
      "Epoch: 1149, Train Loss: 0.271, Validation Loss: 0.240\n",
      "Epoch: 1150, Train Loss: 0.409, Validation Loss: 0.236\n",
      "Epoch: 1151, Train Loss: 0.212, Validation Loss: 0.236\n",
      "Epoch: 1152, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 1153, Train Loss: 0.516, Validation Loss: 0.235\n",
      "Epoch: 1154, Train Loss: 0.185, Validation Loss: 0.236\n",
      "Epoch: 1155, Train Loss: 0.299, Validation Loss: 0.237\n",
      "Epoch: 1156, Train Loss: 0.279, Validation Loss: 0.237\n",
      "Epoch: 1157, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 1158, Train Loss: 0.488, Validation Loss: 0.237\n",
      "Epoch: 1159, Train Loss: 0.336, Validation Loss: 0.243\n",
      "Epoch: 1160, Train Loss: 0.260, Validation Loss: 0.238\n",
      "Epoch: 1161, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 1162, Train Loss: 0.278, Validation Loss: 0.237\n",
      "Epoch: 1163, Train Loss: 0.345, Validation Loss: 0.237\n",
      "Epoch: 1164, Train Loss: 0.356, Validation Loss: 0.237\n",
      "Epoch: 1165, Train Loss: 0.310, Validation Loss: 0.237\n",
      "Epoch: 1166, Train Loss: 0.370, Validation Loss: 0.241\n",
      "Epoch: 1167, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 1168, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 1169, Train Loss: 0.508, Validation Loss: 0.237\n",
      "Epoch: 1170, Train Loss: 0.284, Validation Loss: 0.240\n",
      "Epoch: 1171, Train Loss: 0.277, Validation Loss: 0.237\n",
      "Epoch: 1172, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 1173, Train Loss: 0.483, Validation Loss: 0.238\n",
      "Epoch: 1174, Train Loss: 0.183, Validation Loss: 0.236\n",
      "Epoch: 1175, Train Loss: 0.230, Validation Loss: 0.239\n",
      "Epoch: 1176, Train Loss: 0.188, Validation Loss: 0.237\n",
      "Epoch: 1177, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 1178, Train Loss: 0.452, Validation Loss: 0.240\n",
      "Epoch: 1179, Train Loss: 0.231, Validation Loss: 0.239\n",
      "Epoch: 1180, Train Loss: 0.183, Validation Loss: 0.238\n",
      "Epoch: 1181, Train Loss: 0.317, Validation Loss: 0.239\n",
      "Epoch: 1182, Train Loss: 0.182, Validation Loss: 0.237\n",
      "Epoch: 1183, Train Loss: 0.251, Validation Loss: 0.238\n",
      "Epoch: 1184, Train Loss: 0.235, Validation Loss: 0.242\n",
      "Epoch: 1185, Train Loss: 0.275, Validation Loss: 0.244\n",
      "Epoch: 1186, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 1187, Train Loss: 0.341, Validation Loss: 0.237\n",
      "Epoch: 1188, Train Loss: 0.206, Validation Loss: 0.237\n",
      "Epoch: 1189, Train Loss: 0.702, Validation Loss: 0.240\n",
      "Epoch: 1190, Train Loss: 0.261, Validation Loss: 0.240\n",
      "Epoch: 1191, Train Loss: 0.278, Validation Loss: 0.238\n",
      "Epoch: 1192, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 1193, Train Loss: 0.281, Validation Loss: 0.241\n",
      "Epoch: 1194, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 1195, Train Loss: 0.318, Validation Loss: 0.239\n",
      "Epoch: 1196, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 1197, Train Loss: 0.259, Validation Loss: 0.242\n",
      "Epoch: 1198, Train Loss: 0.165, Validation Loss: 0.240\n",
      "Epoch: 1199, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 1200, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 1201, Train Loss: 0.506, Validation Loss: 0.243\n",
      "Epoch: 1202, Train Loss: 0.179, Validation Loss: 0.241\n",
      "Epoch: 1203, Train Loss: 0.264, Validation Loss: 0.242\n",
      "Epoch: 1204, Train Loss: 0.492, Validation Loss: 0.244\n",
      "Epoch: 1205, Train Loss: 0.203, Validation Loss: 0.240\n",
      "Epoch: 1206, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 1207, Train Loss: 0.203, Validation Loss: 0.239\n",
      "Epoch: 1208, Train Loss: 0.280, Validation Loss: 0.240\n",
      "Epoch: 1209, Train Loss: 0.191, Validation Loss: 0.239\n",
      "Epoch: 1210, Train Loss: 0.641, Validation Loss: 0.244\n",
      "Epoch: 1211, Train Loss: 0.328, Validation Loss: 0.241\n",
      "Epoch: 1212, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 1213, Train Loss: 0.401, Validation Loss: 0.239\n",
      "Epoch: 1214, Train Loss: 0.347, Validation Loss: 0.248\n",
      "Epoch: 1215, Train Loss: 0.511, Validation Loss: 0.249\n",
      "Epoch: 1216, Train Loss: 0.225, Validation Loss: 0.238\n",
      "Epoch: 1217, Train Loss: 0.273, Validation Loss: 0.238\n",
      "Epoch: 1218, Train Loss: 0.266, Validation Loss: 0.239\n",
      "Epoch: 1219, Train Loss: 0.539, Validation Loss: 0.238\n",
      "Epoch: 1220, Train Loss: 0.322, Validation Loss: 0.243\n",
      "Epoch: 1221, Train Loss: 0.287, Validation Loss: 0.239\n",
      "Epoch: 1222, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 1223, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 1224, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 1225, Train Loss: 0.240, Validation Loss: 0.240\n",
      "Epoch: 1226, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 1227, Train Loss: 0.252, Validation Loss: 0.240\n",
      "Epoch: 1228, Train Loss: 0.306, Validation Loss: 0.240\n",
      "Epoch: 1229, Train Loss: 0.380, Validation Loss: 0.238\n",
      "Epoch: 1230, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 1231, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 1232, Train Loss: 0.208, Validation Loss: 0.240\n",
      "Epoch: 1233, Train Loss: 0.233, Validation Loss: 0.237\n",
      "Epoch: 1234, Train Loss: 0.252, Validation Loss: 0.236\n",
      "Epoch: 1235, Train Loss: 0.205, Validation Loss: 0.239\n",
      "Epoch: 1236, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 1237, Train Loss: 0.416, Validation Loss: 0.238\n",
      "Epoch: 1238, Train Loss: 0.204, Validation Loss: 0.242\n",
      "Epoch: 1239, Train Loss: 0.491, Validation Loss: 0.238\n",
      "Epoch: 1240, Train Loss: 0.279, Validation Loss: 0.240\n",
      "Epoch: 1241, Train Loss: 0.293, Validation Loss: 0.239\n",
      "Epoch: 1242, Train Loss: 0.214, Validation Loss: 0.236\n",
      "Epoch: 1243, Train Loss: 0.228, Validation Loss: 0.238\n",
      "Epoch: 1244, Train Loss: 0.223, Validation Loss: 0.241\n",
      "Epoch: 1245, Train Loss: 0.330, Validation Loss: 0.242\n",
      "Epoch: 1246, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 1247, Train Loss: 0.315, Validation Loss: 0.237\n",
      "Epoch: 1248, Train Loss: 0.198, Validation Loss: 0.239\n",
      "Epoch: 1249, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 1250, Train Loss: 0.237, Validation Loss: 0.236\n",
      "Epoch: 1251, Train Loss: 0.272, Validation Loss: 0.237\n",
      "Epoch: 1252, Train Loss: 0.261, Validation Loss: 0.237\n",
      "Epoch: 1253, Train Loss: 0.196, Validation Loss: 0.238\n",
      "Epoch: 1254, Train Loss: 0.316, Validation Loss: 0.242\n",
      "Epoch: 1255, Train Loss: 0.326, Validation Loss: 0.241\n",
      "Epoch: 1256, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 1257, Train Loss: 0.293, Validation Loss: 0.242\n",
      "Epoch: 1258, Train Loss: 0.276, Validation Loss: 0.241\n",
      "Epoch: 1259, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 1260, Train Loss: 0.247, Validation Loss: 0.239\n",
      "Epoch: 1261, Train Loss: 0.351, Validation Loss: 0.243\n",
      "Epoch: 1262, Train Loss: 0.303, Validation Loss: 0.241\n",
      "Epoch: 1263, Train Loss: 0.268, Validation Loss: 0.238\n",
      "Epoch: 1264, Train Loss: 0.264, Validation Loss: 0.239\n",
      "Epoch: 1265, Train Loss: 0.252, Validation Loss: 0.241\n",
      "Epoch: 1266, Train Loss: 0.171, Validation Loss: 0.241\n",
      "Epoch: 1267, Train Loss: 0.445, Validation Loss: 0.239\n",
      "Epoch: 1268, Train Loss: 0.241, Validation Loss: 0.238\n",
      "Epoch: 1269, Train Loss: 0.268, Validation Loss: 0.237\n",
      "Epoch: 1270, Train Loss: 0.240, Validation Loss: 0.240\n",
      "Epoch: 1271, Train Loss: 0.139, Validation Loss: 0.238\n",
      "Epoch: 1272, Train Loss: 0.223, Validation Loss: 0.237\n",
      "Epoch: 1273, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 1274, Train Loss: 0.285, Validation Loss: 0.239\n",
      "Epoch: 1275, Train Loss: 0.492, Validation Loss: 0.238\n",
      "Epoch: 1276, Train Loss: 0.197, Validation Loss: 0.238\n",
      "Epoch: 1277, Train Loss: 0.470, Validation Loss: 0.241\n",
      "Epoch: 1278, Train Loss: 0.298, Validation Loss: 0.238\n",
      "Epoch: 1279, Train Loss: 0.236, Validation Loss: 0.239\n",
      "Epoch: 1280, Train Loss: 0.274, Validation Loss: 0.239\n",
      "Epoch: 1281, Train Loss: 0.185, Validation Loss: 0.241\n",
      "Epoch: 1282, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 1283, Train Loss: 0.196, Validation Loss: 0.241\n",
      "Epoch: 1284, Train Loss: 0.284, Validation Loss: 0.240\n",
      "Epoch: 1285, Train Loss: 0.405, Validation Loss: 0.239\n",
      "Epoch: 1286, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 1287, Train Loss: 0.231, Validation Loss: 0.239\n",
      "Epoch: 1288, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 1289, Train Loss: 0.534, Validation Loss: 0.240\n",
      "Epoch: 1290, Train Loss: 0.388, Validation Loss: 0.239\n",
      "Epoch: 1291, Train Loss: 0.344, Validation Loss: 0.241\n",
      "Epoch: 1292, Train Loss: 0.349, Validation Loss: 0.238\n",
      "Epoch: 1293, Train Loss: 0.177, Validation Loss: 0.239\n",
      "Epoch: 1294, Train Loss: 0.345, Validation Loss: 0.244\n",
      "Epoch: 1295, Train Loss: 0.317, Validation Loss: 0.243\n",
      "Epoch: 1296, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 1297, Train Loss: 0.508, Validation Loss: 0.245\n",
      "Epoch: 1298, Train Loss: 0.206, Validation Loss: 0.242\n",
      "Epoch: 1299, Train Loss: 0.265, Validation Loss: 0.243\n",
      "Epoch: 1300, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 1301, Train Loss: 0.297, Validation Loss: 0.241\n",
      "Epoch: 1302, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 1303, Train Loss: 0.315, Validation Loss: 0.239\n",
      "Epoch: 1304, Train Loss: 0.290, Validation Loss: 0.242\n",
      "Epoch: 1305, Train Loss: 0.456, Validation Loss: 0.239\n",
      "Epoch: 1306, Train Loss: 0.178, Validation Loss: 0.241\n",
      "Epoch: 1307, Train Loss: 0.257, Validation Loss: 0.242\n",
      "Epoch: 1308, Train Loss: 0.264, Validation Loss: 0.238\n",
      "Epoch: 1309, Train Loss: 0.249, Validation Loss: 0.240\n",
      "Epoch: 1310, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 1311, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 1312, Train Loss: 0.424, Validation Loss: 0.247\n",
      "Epoch: 1313, Train Loss: 0.267, Validation Loss: 0.245\n",
      "Epoch: 1314, Train Loss: 0.234, Validation Loss: 0.240\n",
      "Epoch: 1315, Train Loss: 0.243, Validation Loss: 0.243\n",
      "Epoch: 1316, Train Loss: 0.316, Validation Loss: 0.239\n",
      "Epoch: 1317, Train Loss: 0.258, Validation Loss: 0.239\n",
      "Epoch: 1318, Train Loss: 0.396, Validation Loss: 0.243\n",
      "Epoch: 1319, Train Loss: 0.484, Validation Loss: 0.239\n",
      "Epoch: 1320, Train Loss: 0.228, Validation Loss: 0.237\n",
      "Epoch: 1321, Train Loss: 0.376, Validation Loss: 0.237\n",
      "Epoch: 1322, Train Loss: 0.161, Validation Loss: 0.236\n",
      "Epoch: 1323, Train Loss: 0.261, Validation Loss: 0.236\n",
      "Epoch: 1324, Train Loss: 0.256, Validation Loss: 0.242\n",
      "Epoch: 1325, Train Loss: 0.240, Validation Loss: 0.242\n",
      "Epoch: 1326, Train Loss: 0.259, Validation Loss: 0.237\n",
      "Epoch: 1327, Train Loss: 0.199, Validation Loss: 0.239\n",
      "Epoch: 1328, Train Loss: 0.254, Validation Loss: 0.240\n",
      "Epoch: 1329, Train Loss: 0.182, Validation Loss: 0.238\n",
      "Epoch: 1330, Train Loss: 0.244, Validation Loss: 0.238\n",
      "Epoch: 1331, Train Loss: 0.209, Validation Loss: 0.239\n",
      "Epoch: 1332, Train Loss: 0.203, Validation Loss: 0.240\n",
      "Epoch: 1333, Train Loss: 0.197, Validation Loss: 0.240\n",
      "Epoch: 1334, Train Loss: 0.215, Validation Loss: 0.238\n",
      "Epoch: 1335, Train Loss: 0.398, Validation Loss: 0.241\n",
      "Epoch: 1336, Train Loss: 0.357, Validation Loss: 0.239\n",
      "Epoch: 1337, Train Loss: 0.302, Validation Loss: 0.241\n",
      "Epoch: 1338, Train Loss: 0.140, Validation Loss: 0.241\n",
      "Epoch: 1339, Train Loss: 0.199, Validation Loss: 0.240\n",
      "Epoch: 1340, Train Loss: 0.177, Validation Loss: 0.239\n",
      "Epoch: 1341, Train Loss: 0.243, Validation Loss: 0.237\n",
      "Epoch: 1342, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 1343, Train Loss: 0.261, Validation Loss: 0.239\n",
      "Epoch: 1344, Train Loss: 0.275, Validation Loss: 0.245\n",
      "Epoch: 1345, Train Loss: 0.242, Validation Loss: 0.238\n",
      "Epoch: 1346, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 1347, Train Loss: 0.221, Validation Loss: 0.240\n",
      "Epoch: 1348, Train Loss: 0.372, Validation Loss: 0.238\n",
      "Epoch: 1349, Train Loss: 0.322, Validation Loss: 0.239\n",
      "Epoch: 1350, Train Loss: 0.220, Validation Loss: 0.241\n",
      "Epoch: 1351, Train Loss: 0.186, Validation Loss: 0.241\n",
      "Epoch: 1352, Train Loss: 0.262, Validation Loss: 0.242\n",
      "Epoch: 1353, Train Loss: 0.219, Validation Loss: 0.241\n",
      "Epoch: 1354, Train Loss: 0.208, Validation Loss: 0.239\n",
      "Epoch: 1355, Train Loss: 0.284, Validation Loss: 0.240\n",
      "Epoch: 1356, Train Loss: 0.562, Validation Loss: 0.245\n",
      "Epoch: 1357, Train Loss: 0.309, Validation Loss: 0.239\n",
      "Epoch: 1358, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 1359, Train Loss: 0.520, Validation Loss: 0.242\n",
      "Epoch: 1360, Train Loss: 0.209, Validation Loss: 0.240\n",
      "Epoch: 1361, Train Loss: 0.422, Validation Loss: 0.241\n",
      "Epoch: 1362, Train Loss: 0.490, Validation Loss: 0.239\n",
      "Epoch: 1363, Train Loss: 0.298, Validation Loss: 0.237\n",
      "Epoch: 1364, Train Loss: 0.278, Validation Loss: 0.241\n",
      "Epoch: 1365, Train Loss: 0.284, Validation Loss: 0.236\n",
      "Epoch: 1366, Train Loss: 0.319, Validation Loss: 0.240\n",
      "Epoch: 1367, Train Loss: 0.230, Validation Loss: 0.237\n",
      "Epoch: 1368, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 1369, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 1370, Train Loss: 0.279, Validation Loss: 0.238\n",
      "Epoch: 1371, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 1372, Train Loss: 0.326, Validation Loss: 0.240\n",
      "Epoch: 1373, Train Loss: 0.214, Validation Loss: 0.237\n",
      "Epoch: 1374, Train Loss: 0.254, Validation Loss: 0.236\n",
      "Epoch: 1375, Train Loss: 0.362, Validation Loss: 0.239\n",
      "Epoch: 1376, Train Loss: 0.384, Validation Loss: 0.240\n",
      "Epoch: 1377, Train Loss: 0.326, Validation Loss: 0.236\n",
      "Epoch: 1378, Train Loss: 0.153, Validation Loss: 0.237\n",
      "Epoch: 1379, Train Loss: 0.384, Validation Loss: 0.240\n",
      "Epoch: 1380, Train Loss: 0.194, Validation Loss: 0.237\n",
      "Epoch: 1381, Train Loss: 0.197, Validation Loss: 0.237\n",
      "Epoch: 1382, Train Loss: 0.206, Validation Loss: 0.235\n",
      "Epoch: 1383, Train Loss: 0.272, Validation Loss: 0.237\n",
      "Epoch: 1384, Train Loss: 0.206, Validation Loss: 0.237\n",
      "Epoch: 1385, Train Loss: 0.204, Validation Loss: 0.238\n",
      "Epoch: 1386, Train Loss: 0.353, Validation Loss: 0.238\n",
      "Epoch: 1387, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 1388, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 1389, Train Loss: 0.214, Validation Loss: 0.240\n",
      "Epoch: 1390, Train Loss: 0.150, Validation Loss: 0.240\n",
      "Epoch: 1391, Train Loss: 0.208, Validation Loss: 0.240\n",
      "Epoch: 1392, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 1393, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 1394, Train Loss: 0.241, Validation Loss: 0.246\n",
      "Epoch: 1395, Train Loss: 0.253, Validation Loss: 0.241\n",
      "Epoch: 1396, Train Loss: 0.166, Validation Loss: 0.240\n",
      "Epoch: 1397, Train Loss: 0.180, Validation Loss: 0.241\n",
      "Epoch: 1398, Train Loss: 0.140, Validation Loss: 0.240\n",
      "Epoch: 1399, Train Loss: 0.230, Validation Loss: 0.243\n",
      "Epoch: 1400, Train Loss: 0.186, Validation Loss: 0.241\n",
      "Epoch: 1401, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 1402, Train Loss: 0.165, Validation Loss: 0.239\n",
      "Epoch: 1403, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 1404, Train Loss: 0.198, Validation Loss: 0.239\n",
      "Epoch: 1405, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 1406, Train Loss: 0.199, Validation Loss: 0.237\n",
      "Epoch: 1407, Train Loss: 0.185, Validation Loss: 0.239\n",
      "Epoch: 1408, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 1409, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 1410, Train Loss: 0.497, Validation Loss: 0.244\n",
      "Epoch: 1411, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 1412, Train Loss: 0.296, Validation Loss: 0.238\n",
      "Epoch: 1413, Train Loss: 0.335, Validation Loss: 0.237\n",
      "Epoch: 1414, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 1415, Train Loss: 0.321, Validation Loss: 0.240\n",
      "Epoch: 1416, Train Loss: 0.224, Validation Loss: 0.241\n",
      "Epoch: 1417, Train Loss: 0.241, Validation Loss: 0.240\n",
      "Epoch: 1418, Train Loss: 0.217, Validation Loss: 0.240\n",
      "Epoch: 1419, Train Loss: 0.205, Validation Loss: 0.242\n",
      "Epoch: 1420, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 1421, Train Loss: 0.275, Validation Loss: 0.240\n",
      "Epoch: 1422, Train Loss: 0.301, Validation Loss: 0.236\n",
      "Epoch: 1423, Train Loss: 0.603, Validation Loss: 0.236\n",
      "Epoch: 1424, Train Loss: 0.347, Validation Loss: 0.238\n",
      "Epoch: 1425, Train Loss: 0.566, Validation Loss: 0.239\n",
      "Epoch: 1426, Train Loss: 0.557, Validation Loss: 0.241\n",
      "Epoch: 1427, Train Loss: 0.376, Validation Loss: 0.238\n",
      "Epoch: 1428, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 1429, Train Loss: 0.282, Validation Loss: 0.239\n",
      "Epoch: 1430, Train Loss: 0.355, Validation Loss: 0.241\n",
      "Epoch: 1431, Train Loss: 0.277, Validation Loss: 0.242\n",
      "Epoch: 1432, Train Loss: 0.309, Validation Loss: 0.238\n",
      "Epoch: 1433, Train Loss: 0.211, Validation Loss: 0.240\n",
      "Epoch: 1434, Train Loss: 0.250, Validation Loss: 0.238\n",
      "Epoch: 1435, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 1436, Train Loss: 0.212, Validation Loss: 0.240\n",
      "Epoch: 1437, Train Loss: 0.244, Validation Loss: 0.237\n",
      "Epoch: 1438, Train Loss: 0.242, Validation Loss: 0.238\n",
      "Epoch: 1439, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 1440, Train Loss: 0.247, Validation Loss: 0.239\n",
      "Epoch: 1441, Train Loss: 0.400, Validation Loss: 0.244\n",
      "Epoch: 1442, Train Loss: 0.288, Validation Loss: 0.242\n",
      "Epoch: 1443, Train Loss: 0.262, Validation Loss: 0.236\n",
      "Epoch: 1444, Train Loss: 0.252, Validation Loss: 0.236\n",
      "Epoch: 1445, Train Loss: 0.237, Validation Loss: 0.237\n",
      "Epoch: 1446, Train Loss: 0.279, Validation Loss: 0.237\n",
      "Epoch: 1447, Train Loss: 0.272, Validation Loss: 0.235\n",
      "Epoch: 1448, Train Loss: 0.253, Validation Loss: 0.236\n",
      "Epoch: 1449, Train Loss: 0.249, Validation Loss: 0.236\n",
      "Epoch: 1450, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 1451, Train Loss: 0.318, Validation Loss: 0.242\n",
      "Epoch: 1452, Train Loss: 0.267, Validation Loss: 0.237\n",
      "Epoch: 1453, Train Loss: 0.191, Validation Loss: 0.238\n",
      "Epoch: 1454, Train Loss: 0.426, Validation Loss: 0.240\n",
      "Epoch: 1455, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 1456, Train Loss: 0.287, Validation Loss: 0.239\n",
      "Epoch: 1457, Train Loss: 0.275, Validation Loss: 0.236\n",
      "Epoch: 1458, Train Loss: 0.670, Validation Loss: 0.242\n",
      "Epoch: 1459, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 1460, Train Loss: 0.161, Validation Loss: 0.241\n",
      "Epoch: 1461, Train Loss: 0.274, Validation Loss: 0.240\n",
      "Epoch: 1462, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 1463, Train Loss: 0.310, Validation Loss: 0.241\n",
      "Epoch: 1464, Train Loss: 0.268, Validation Loss: 0.238\n",
      "Epoch: 1465, Train Loss: 0.464, Validation Loss: 0.238\n",
      "Epoch: 1466, Train Loss: 0.410, Validation Loss: 0.237\n",
      "Epoch: 1467, Train Loss: 0.542, Validation Loss: 0.244\n",
      "Epoch: 1468, Train Loss: 0.537, Validation Loss: 0.246\n",
      "Epoch: 1469, Train Loss: 0.404, Validation Loss: 0.246\n",
      "Epoch: 1470, Train Loss: 0.366, Validation Loss: 0.242\n",
      "Epoch: 1471, Train Loss: 0.331, Validation Loss: 0.238\n",
      "Epoch: 1472, Train Loss: 0.322, Validation Loss: 0.238\n",
      "Epoch: 1473, Train Loss: 0.211, Validation Loss: 0.241\n",
      "Epoch: 1474, Train Loss: 0.319, Validation Loss: 0.244\n",
      "Epoch: 1475, Train Loss: 0.286, Validation Loss: 0.237\n",
      "Epoch: 1476, Train Loss: 0.430, Validation Loss: 0.239\n",
      "Epoch: 1477, Train Loss: 0.205, Validation Loss: 0.240\n",
      "Epoch: 1478, Train Loss: 0.235, Validation Loss: 0.240\n",
      "Epoch: 1479, Train Loss: 0.319, Validation Loss: 0.239\n",
      "Epoch: 1480, Train Loss: 0.567, Validation Loss: 0.241\n",
      "Epoch: 1481, Train Loss: 0.203, Validation Loss: 0.239\n",
      "Epoch: 1482, Train Loss: 0.460, Validation Loss: 0.243\n",
      "Epoch: 1483, Train Loss: 0.204, Validation Loss: 0.239\n",
      "Epoch: 1484, Train Loss: 0.271, Validation Loss: 0.238\n",
      "Epoch: 1485, Train Loss: 0.191, Validation Loss: 0.237\n",
      "Epoch: 1486, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 1487, Train Loss: 0.291, Validation Loss: 0.243\n",
      "Epoch: 1488, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 1489, Train Loss: 0.175, Validation Loss: 0.238\n",
      "Epoch: 1490, Train Loss: 0.181, Validation Loss: 0.238\n",
      "Epoch: 1491, Train Loss: 0.201, Validation Loss: 0.238\n",
      "Epoch: 1492, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 1493, Train Loss: 0.640, Validation Loss: 0.240\n",
      "Epoch: 1494, Train Loss: 0.336, Validation Loss: 0.238\n",
      "Epoch: 1495, Train Loss: 0.303, Validation Loss: 0.239\n",
      "Epoch: 1496, Train Loss: 0.308, Validation Loss: 0.239\n",
      "Epoch: 1497, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 1498, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 1499, Train Loss: 0.162, Validation Loss: 0.238\n",
      "Epoch: 1500, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 1501, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 1502, Train Loss: 0.220, Validation Loss: 0.238\n",
      "Epoch: 1503, Train Loss: 0.209, Validation Loss: 0.238\n",
      "Epoch: 1504, Train Loss: 0.230, Validation Loss: 0.240\n",
      "Epoch: 1505, Train Loss: 0.199, Validation Loss: 0.240\n",
      "Epoch: 1506, Train Loss: 0.380, Validation Loss: 0.239\n",
      "Epoch: 1507, Train Loss: 0.226, Validation Loss: 0.240\n",
      "Epoch: 1508, Train Loss: 0.259, Validation Loss: 0.240\n",
      "Epoch: 1509, Train Loss: 0.198, Validation Loss: 0.242\n",
      "Epoch: 1510, Train Loss: 0.286, Validation Loss: 0.239\n",
      "Epoch: 1511, Train Loss: 0.435, Validation Loss: 0.239\n",
      "Epoch: 1512, Train Loss: 0.311, Validation Loss: 0.239\n",
      "Epoch: 1513, Train Loss: 0.234, Validation Loss: 0.244\n",
      "Epoch: 1514, Train Loss: 0.269, Validation Loss: 0.239\n",
      "Epoch: 1515, Train Loss: 0.294, Validation Loss: 0.239\n",
      "Epoch: 1516, Train Loss: 0.307, Validation Loss: 0.237\n",
      "Epoch: 1517, Train Loss: 0.223, Validation Loss: 0.238\n",
      "Epoch: 1518, Train Loss: 0.327, Validation Loss: 0.237\n",
      "Epoch: 1519, Train Loss: 0.153, Validation Loss: 0.241\n",
      "Epoch: 1520, Train Loss: 0.472, Validation Loss: 0.238\n",
      "Epoch: 1521, Train Loss: 0.194, Validation Loss: 0.241\n",
      "Epoch: 1522, Train Loss: 0.239, Validation Loss: 0.237\n",
      "Epoch: 1523, Train Loss: 0.304, Validation Loss: 0.238\n",
      "Epoch: 1524, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 1525, Train Loss: 0.205, Validation Loss: 0.238\n",
      "Epoch: 1526, Train Loss: 0.260, Validation Loss: 0.237\n",
      "Epoch: 1527, Train Loss: 0.313, Validation Loss: 0.238\n",
      "Epoch: 1528, Train Loss: 0.282, Validation Loss: 0.241\n",
      "Epoch: 1529, Train Loss: 0.253, Validation Loss: 0.237\n",
      "Epoch: 1530, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 1531, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 1532, Train Loss: 0.357, Validation Loss: 0.237\n",
      "Epoch: 1533, Train Loss: 0.336, Validation Loss: 0.242\n",
      "Epoch: 1534, Train Loss: 0.301, Validation Loss: 0.239\n",
      "Epoch: 1535, Train Loss: 0.210, Validation Loss: 0.239\n",
      "Epoch: 1536, Train Loss: 0.206, Validation Loss: 0.235\n",
      "Epoch: 1537, Train Loss: 0.198, Validation Loss: 0.237\n",
      "Epoch: 1538, Train Loss: 0.195, Validation Loss: 0.238\n",
      "Epoch: 1539, Train Loss: 0.221, Validation Loss: 0.238\n",
      "Epoch: 1540, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 1541, Train Loss: 0.351, Validation Loss: 0.236\n",
      "Epoch: 1542, Train Loss: 0.408, Validation Loss: 0.236\n",
      "Epoch: 1543, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 1544, Train Loss: 0.187, Validation Loss: 0.240\n",
      "Epoch: 1545, Train Loss: 0.263, Validation Loss: 0.237\n",
      "Epoch: 1546, Train Loss: 0.368, Validation Loss: 0.239\n",
      "Epoch: 1547, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 1548, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 1549, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 1550, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 1551, Train Loss: 0.321, Validation Loss: 0.241\n",
      "Epoch: 1552, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 1553, Train Loss: 0.433, Validation Loss: 0.239\n",
      "Epoch: 1554, Train Loss: 0.250, Validation Loss: 0.241\n",
      "Epoch: 1555, Train Loss: 0.194, Validation Loss: 0.238\n",
      "Epoch: 1556, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 1557, Train Loss: 0.431, Validation Loss: 0.241\n",
      "Epoch: 1558, Train Loss: 0.285, Validation Loss: 0.243\n",
      "Epoch: 1559, Train Loss: 0.250, Validation Loss: 0.241\n",
      "Epoch: 1560, Train Loss: 0.171, Validation Loss: 0.240\n",
      "Epoch: 1561, Train Loss: 0.255, Validation Loss: 0.243\n",
      "Epoch: 1562, Train Loss: 0.303, Validation Loss: 0.246\n",
      "Epoch: 1563, Train Loss: 0.582, Validation Loss: 0.243\n",
      "Epoch: 1564, Train Loss: 0.192, Validation Loss: 0.238\n",
      "Epoch: 1565, Train Loss: 0.272, Validation Loss: 0.239\n",
      "Epoch: 1566, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 1567, Train Loss: 0.532, Validation Loss: 0.246\n",
      "Epoch: 1568, Train Loss: 0.208, Validation Loss: 0.241\n",
      "Epoch: 1569, Train Loss: 0.213, Validation Loss: 0.241\n",
      "Epoch: 1570, Train Loss: 0.181, Validation Loss: 0.238\n",
      "Epoch: 1571, Train Loss: 0.371, Validation Loss: 0.244\n",
      "Epoch: 1572, Train Loss: 0.229, Validation Loss: 0.237\n",
      "Epoch: 1573, Train Loss: 0.289, Validation Loss: 0.238\n",
      "Epoch: 1574, Train Loss: 0.260, Validation Loss: 0.239\n",
      "Epoch: 1575, Train Loss: 0.215, Validation Loss: 0.237\n",
      "Epoch: 1576, Train Loss: 0.379, Validation Loss: 0.237\n",
      "Epoch: 1577, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 1578, Train Loss: 0.201, Validation Loss: 0.242\n",
      "Epoch: 1579, Train Loss: 0.290, Validation Loss: 0.240\n",
      "Epoch: 1580, Train Loss: 0.249, Validation Loss: 0.238\n",
      "Epoch: 1581, Train Loss: 0.272, Validation Loss: 0.239\n",
      "Epoch: 1582, Train Loss: 0.292, Validation Loss: 0.242\n",
      "Epoch: 1583, Train Loss: 0.357, Validation Loss: 0.239\n",
      "Epoch: 1584, Train Loss: 0.292, Validation Loss: 0.242\n",
      "Epoch: 1585, Train Loss: 0.346, Validation Loss: 0.244\n",
      "Epoch: 1586, Train Loss: 0.306, Validation Loss: 0.240\n",
      "Epoch: 1587, Train Loss: 0.559, Validation Loss: 0.239\n",
      "Epoch: 1588, Train Loss: 0.195, Validation Loss: 0.240\n",
      "Epoch: 1589, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 1590, Train Loss: 0.523, Validation Loss: 0.242\n",
      "Epoch: 1591, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 1592, Train Loss: 0.208, Validation Loss: 0.238\n",
      "Epoch: 1593, Train Loss: 0.520, Validation Loss: 0.243\n",
      "Epoch: 1594, Train Loss: 0.340, Validation Loss: 0.241\n",
      "Epoch: 1595, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 1596, Train Loss: 0.357, Validation Loss: 0.239\n",
      "Epoch: 1597, Train Loss: 0.299, Validation Loss: 0.239\n",
      "Epoch: 1598, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 1599, Train Loss: 0.452, Validation Loss: 0.239\n",
      "Epoch: 1600, Train Loss: 0.224, Validation Loss: 0.240\n",
      "Epoch: 1601, Train Loss: 0.185, Validation Loss: 0.240\n",
      "Epoch: 1602, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 1603, Train Loss: 0.292, Validation Loss: 0.241\n",
      "Epoch: 1604, Train Loss: 0.187, Validation Loss: 0.244\n",
      "Epoch: 1605, Train Loss: 0.308, Validation Loss: 0.240\n",
      "Epoch: 1606, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 1607, Train Loss: 0.307, Validation Loss: 0.242\n",
      "Epoch: 1608, Train Loss: 0.529, Validation Loss: 0.240\n",
      "Epoch: 1609, Train Loss: 0.282, Validation Loss: 0.239\n",
      "Epoch: 1610, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 1611, Train Loss: 0.200, Validation Loss: 0.238\n",
      "Epoch: 1612, Train Loss: 0.362, Validation Loss: 0.240\n",
      "Epoch: 1613, Train Loss: 0.392, Validation Loss: 0.236\n",
      "Epoch: 1614, Train Loss: 0.234, Validation Loss: 0.236\n",
      "Epoch: 1615, Train Loss: 0.448, Validation Loss: 0.240\n",
      "Epoch: 1616, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 1617, Train Loss: 0.289, Validation Loss: 0.238\n",
      "Epoch: 1618, Train Loss: 0.335, Validation Loss: 0.240\n",
      "Epoch: 1619, Train Loss: 0.241, Validation Loss: 0.238\n",
      "Epoch: 1620, Train Loss: 0.272, Validation Loss: 0.238\n",
      "Epoch: 1621, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 1622, Train Loss: 0.236, Validation Loss: 0.240\n",
      "Epoch: 1623, Train Loss: 0.207, Validation Loss: 0.240\n",
      "Epoch: 1624, Train Loss: 0.251, Validation Loss: 0.237\n",
      "Epoch: 1625, Train Loss: 0.338, Validation Loss: 0.239\n",
      "Epoch: 1626, Train Loss: 0.239, Validation Loss: 0.237\n",
      "Epoch: 1627, Train Loss: 0.352, Validation Loss: 0.237\n",
      "Epoch: 1628, Train Loss: 0.229, Validation Loss: 0.240\n",
      "Epoch: 1629, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 1630, Train Loss: 0.332, Validation Loss: 0.237\n",
      "Epoch: 1631, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 1632, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 1633, Train Loss: 0.282, Validation Loss: 0.239\n",
      "Epoch: 1634, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 1635, Train Loss: 0.255, Validation Loss: 0.239\n",
      "Epoch: 1636, Train Loss: 0.291, Validation Loss: 0.240\n",
      "Epoch: 1637, Train Loss: 0.244, Validation Loss: 0.241\n",
      "Epoch: 1638, Train Loss: 0.262, Validation Loss: 0.238\n",
      "Epoch: 1639, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 1640, Train Loss: 0.249, Validation Loss: 0.238\n",
      "Epoch: 1641, Train Loss: 0.323, Validation Loss: 0.240\n",
      "Epoch: 1642, Train Loss: 0.546, Validation Loss: 0.239\n",
      "Epoch: 1643, Train Loss: 0.189, Validation Loss: 0.240\n",
      "Epoch: 1644, Train Loss: 0.161, Validation Loss: 0.242\n",
      "Epoch: 1645, Train Loss: 0.331, Validation Loss: 0.243\n",
      "Epoch: 1646, Train Loss: 0.238, Validation Loss: 0.238\n",
      "Epoch: 1647, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 1648, Train Loss: 0.303, Validation Loss: 0.239\n",
      "Epoch: 1649, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 1650, Train Loss: 0.171, Validation Loss: 0.238\n",
      "Epoch: 1651, Train Loss: 0.400, Validation Loss: 0.238\n",
      "Epoch: 1652, Train Loss: 0.266, Validation Loss: 0.240\n",
      "Epoch: 1653, Train Loss: 0.340, Validation Loss: 0.246\n",
      "Epoch: 1654, Train Loss: 0.218, Validation Loss: 0.242\n",
      "Epoch: 1655, Train Loss: 0.269, Validation Loss: 0.240\n",
      "Epoch: 1656, Train Loss: 0.266, Validation Loss: 0.240\n",
      "Epoch: 1657, Train Loss: 0.235, Validation Loss: 0.241\n",
      "Epoch: 1658, Train Loss: 0.281, Validation Loss: 0.243\n",
      "Epoch: 1659, Train Loss: 0.319, Validation Loss: 0.241\n",
      "Epoch: 1660, Train Loss: 0.269, Validation Loss: 0.239\n",
      "Epoch: 1661, Train Loss: 0.228, Validation Loss: 0.243\n",
      "Epoch: 1662, Train Loss: 0.243, Validation Loss: 0.245\n",
      "Epoch: 1663, Train Loss: 0.349, Validation Loss: 0.248\n",
      "Epoch: 1664, Train Loss: 0.199, Validation Loss: 0.239\n",
      "Epoch: 1665, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 1666, Train Loss: 0.255, Validation Loss: 0.239\n",
      "Epoch: 1667, Train Loss: 0.212, Validation Loss: 0.241\n",
      "Epoch: 1668, Train Loss: 0.492, Validation Loss: 0.239\n",
      "Epoch: 1669, Train Loss: 0.271, Validation Loss: 0.238\n",
      "Epoch: 1670, Train Loss: 0.240, Validation Loss: 0.237\n",
      "Epoch: 1671, Train Loss: 0.271, Validation Loss: 0.237\n",
      "Epoch: 1672, Train Loss: 0.226, Validation Loss: 0.239\n",
      "Epoch: 1673, Train Loss: 0.491, Validation Loss: 0.238\n",
      "Epoch: 1674, Train Loss: 0.286, Validation Loss: 0.237\n",
      "Epoch: 1675, Train Loss: 0.178, Validation Loss: 0.237\n",
      "Epoch: 1676, Train Loss: 0.156, Validation Loss: 0.240\n",
      "Epoch: 1677, Train Loss: 0.289, Validation Loss: 0.240\n",
      "Epoch: 1678, Train Loss: 0.227, Validation Loss: 0.237\n",
      "Epoch: 1679, Train Loss: 0.399, Validation Loss: 0.239\n",
      "Epoch: 1680, Train Loss: 0.185, Validation Loss: 0.240\n",
      "Epoch: 1681, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 1682, Train Loss: 0.183, Validation Loss: 0.238\n",
      "Epoch: 1683, Train Loss: 0.299, Validation Loss: 0.239\n",
      "Epoch: 1684, Train Loss: 0.337, Validation Loss: 0.242\n",
      "Epoch: 1685, Train Loss: 0.241, Validation Loss: 0.240\n",
      "Epoch: 1686, Train Loss: 0.358, Validation Loss: 0.242\n",
      "Epoch: 1687, Train Loss: 0.322, Validation Loss: 0.240\n",
      "Epoch: 1688, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 1689, Train Loss: 0.203, Validation Loss: 0.241\n",
      "Epoch: 1690, Train Loss: 0.518, Validation Loss: 0.245\n",
      "Epoch: 1691, Train Loss: 0.351, Validation Loss: 0.240\n",
      "Epoch: 1692, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 1693, Train Loss: 0.548, Validation Loss: 0.243\n",
      "Epoch: 1694, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 1695, Train Loss: 0.227, Validation Loss: 0.237\n",
      "Epoch: 1696, Train Loss: 0.204, Validation Loss: 0.237\n",
      "Epoch: 1697, Train Loss: 0.276, Validation Loss: 0.238\n",
      "Epoch: 1698, Train Loss: 0.293, Validation Loss: 0.240\n",
      "Epoch: 1699, Train Loss: 0.226, Validation Loss: 0.238\n",
      "Epoch: 1700, Train Loss: 0.185, Validation Loss: 0.237\n",
      "Epoch: 1701, Train Loss: 0.166, Validation Loss: 0.237\n",
      "Epoch: 1702, Train Loss: 0.216, Validation Loss: 0.239\n",
      "Epoch: 1703, Train Loss: 0.190, Validation Loss: 0.240\n",
      "Epoch: 1704, Train Loss: 0.262, Validation Loss: 0.240\n",
      "Epoch: 1705, Train Loss: 0.370, Validation Loss: 0.239\n",
      "Epoch: 1706, Train Loss: 0.776, Validation Loss: 0.244\n",
      "Epoch: 1707, Train Loss: 0.360, Validation Loss: 0.242\n",
      "Epoch: 1708, Train Loss: 0.254, Validation Loss: 0.240\n",
      "Epoch: 1709, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 1710, Train Loss: 0.286, Validation Loss: 0.239\n",
      "Epoch: 1711, Train Loss: 0.409, Validation Loss: 0.239\n",
      "Epoch: 1712, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 1713, Train Loss: 0.290, Validation Loss: 0.240\n",
      "Epoch: 1714, Train Loss: 0.266, Validation Loss: 0.239\n",
      "Epoch: 1715, Train Loss: 0.466, Validation Loss: 0.243\n",
      "Epoch: 1716, Train Loss: 0.227, Validation Loss: 0.240\n",
      "Epoch: 1717, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 1718, Train Loss: 0.288, Validation Loss: 0.239\n",
      "Epoch: 1719, Train Loss: 0.362, Validation Loss: 0.241\n",
      "Epoch: 1720, Train Loss: 0.275, Validation Loss: 0.239\n",
      "Epoch: 1721, Train Loss: 0.212, Validation Loss: 0.241\n",
      "Epoch: 1722, Train Loss: 0.406, Validation Loss: 0.245\n",
      "Epoch: 1723, Train Loss: 0.218, Validation Loss: 0.239\n",
      "Epoch: 1724, Train Loss: 0.539, Validation Loss: 0.239\n",
      "Epoch: 1725, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 1726, Train Loss: 0.476, Validation Loss: 0.240\n",
      "Epoch: 1727, Train Loss: 0.665, Validation Loss: 0.243\n",
      "Epoch: 1728, Train Loss: 0.229, Validation Loss: 0.240\n",
      "Epoch: 1729, Train Loss: 0.172, Validation Loss: 0.243\n",
      "Epoch: 1730, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 1731, Train Loss: 0.492, Validation Loss: 0.239\n",
      "Epoch: 1732, Train Loss: 0.255, Validation Loss: 0.241\n",
      "Epoch: 1733, Train Loss: 0.308, Validation Loss: 0.237\n",
      "Epoch: 1734, Train Loss: 0.231, Validation Loss: 0.238\n",
      "Epoch: 1735, Train Loss: 0.209, Validation Loss: 0.239\n",
      "Epoch: 1736, Train Loss: 0.317, Validation Loss: 0.237\n",
      "Epoch: 1737, Train Loss: 0.207, Validation Loss: 0.238\n",
      "Epoch: 1738, Train Loss: 0.262, Validation Loss: 0.240\n",
      "Epoch: 1739, Train Loss: 0.323, Validation Loss: 0.237\n",
      "Epoch: 1740, Train Loss: 0.242, Validation Loss: 0.236\n",
      "Epoch: 1741, Train Loss: 0.225, Validation Loss: 0.236\n",
      "Epoch: 1742, Train Loss: 0.418, Validation Loss: 0.237\n",
      "Epoch: 1743, Train Loss: 0.161, Validation Loss: 0.239\n",
      "Epoch: 1744, Train Loss: 0.223, Validation Loss: 0.242\n",
      "Epoch: 1745, Train Loss: 0.272, Validation Loss: 0.241\n",
      "Epoch: 1746, Train Loss: 0.429, Validation Loss: 0.242\n",
      "Epoch: 1747, Train Loss: 0.496, Validation Loss: 0.245\n",
      "Epoch: 1748, Train Loss: 0.250, Validation Loss: 0.242\n",
      "Epoch: 1749, Train Loss: 0.278, Validation Loss: 0.240\n",
      "Epoch: 1750, Train Loss: 0.186, Validation Loss: 0.237\n",
      "Epoch: 1751, Train Loss: 0.271, Validation Loss: 0.238\n",
      "Epoch: 1752, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 1753, Train Loss: 0.306, Validation Loss: 0.246\n",
      "Epoch: 1754, Train Loss: 0.204, Validation Loss: 0.242\n",
      "Epoch: 1755, Train Loss: 0.547, Validation Loss: 0.241\n",
      "Epoch: 1756, Train Loss: 0.320, Validation Loss: 0.241\n",
      "Epoch: 1757, Train Loss: 0.282, Validation Loss: 0.239\n",
      "Epoch: 1758, Train Loss: 0.221, Validation Loss: 0.238\n",
      "Epoch: 1759, Train Loss: 0.197, Validation Loss: 0.239\n",
      "Epoch: 1760, Train Loss: 0.378, Validation Loss: 0.244\n",
      "Epoch: 1761, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 1762, Train Loss: 0.202, Validation Loss: 0.246\n",
      "Epoch: 1763, Train Loss: 0.229, Validation Loss: 0.238\n",
      "Epoch: 1764, Train Loss: 0.266, Validation Loss: 0.239\n",
      "Epoch: 1765, Train Loss: 0.257, Validation Loss: 0.239\n",
      "Epoch: 1766, Train Loss: 0.267, Validation Loss: 0.243\n",
      "Epoch: 1767, Train Loss: 0.208, Validation Loss: 0.238\n",
      "Epoch: 1768, Train Loss: 0.249, Validation Loss: 0.240\n",
      "Epoch: 1769, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 1770, Train Loss: 0.540, Validation Loss: 0.242\n",
      "Epoch: 1771, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 1772, Train Loss: 0.284, Validation Loss: 0.237\n",
      "Epoch: 1773, Train Loss: 0.233, Validation Loss: 0.238\n",
      "Epoch: 1774, Train Loss: 0.315, Validation Loss: 0.237\n",
      "Epoch: 1775, Train Loss: 0.279, Validation Loss: 0.237\n",
      "Epoch: 1776, Train Loss: 0.223, Validation Loss: 0.238\n",
      "Epoch: 1777, Train Loss: 0.233, Validation Loss: 0.235\n",
      "Epoch: 1778, Train Loss: 0.192, Validation Loss: 0.235\n",
      "Epoch: 1779, Train Loss: 0.263, Validation Loss: 0.237\n",
      "Epoch: 1780, Train Loss: 0.233, Validation Loss: 0.238\n",
      "Epoch: 1781, Train Loss: 0.285, Validation Loss: 0.240\n",
      "Epoch: 1782, Train Loss: 0.270, Validation Loss: 0.237\n",
      "Epoch: 1783, Train Loss: 0.337, Validation Loss: 0.239\n",
      "Epoch: 1784, Train Loss: 0.184, Validation Loss: 0.241\n",
      "Epoch: 1785, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 1786, Train Loss: 0.314, Validation Loss: 0.238\n",
      "Epoch: 1787, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 1788, Train Loss: 0.194, Validation Loss: 0.237\n",
      "Epoch: 1789, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 1790, Train Loss: 0.194, Validation Loss: 0.239\n",
      "Epoch: 1791, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 1792, Train Loss: 0.218, Validation Loss: 0.237\n",
      "Epoch: 1793, Train Loss: 0.253, Validation Loss: 0.237\n",
      "Epoch: 1794, Train Loss: 0.315, Validation Loss: 0.238\n",
      "Epoch: 1795, Train Loss: 0.243, Validation Loss: 0.242\n",
      "Epoch: 1796, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 1797, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 1798, Train Loss: 0.225, Validation Loss: 0.241\n",
      "Epoch: 1799, Train Loss: 0.202, Validation Loss: 0.238\n",
      "Epoch: 1800, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 1801, Train Loss: 0.187, Validation Loss: 0.241\n",
      "Epoch: 1802, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 1803, Train Loss: 0.469, Validation Loss: 0.238\n",
      "Epoch: 1804, Train Loss: 0.260, Validation Loss: 0.238\n",
      "Epoch: 1805, Train Loss: 0.174, Validation Loss: 0.239\n",
      "Epoch: 1806, Train Loss: 0.234, Validation Loss: 0.242\n",
      "Epoch: 1807, Train Loss: 0.310, Validation Loss: 0.240\n",
      "Epoch: 1808, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 1809, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 1810, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 1811, Train Loss: 0.176, Validation Loss: 0.238\n",
      "Epoch: 1812, Train Loss: 0.275, Validation Loss: 0.238\n",
      "Epoch: 1813, Train Loss: 0.189, Validation Loss: 0.240\n",
      "Epoch: 1814, Train Loss: 0.297, Validation Loss: 0.238\n",
      "Epoch: 1815, Train Loss: 0.381, Validation Loss: 0.241\n",
      "Epoch: 1816, Train Loss: 0.188, Validation Loss: 0.240\n",
      "Epoch: 1817, Train Loss: 0.282, Validation Loss: 0.239\n",
      "Epoch: 1818, Train Loss: 0.324, Validation Loss: 0.237\n",
      "Epoch: 1819, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 1820, Train Loss: 0.225, Validation Loss: 0.243\n",
      "Epoch: 1821, Train Loss: 0.260, Validation Loss: 0.242\n",
      "Epoch: 1822, Train Loss: 0.296, Validation Loss: 0.241\n",
      "Epoch: 1823, Train Loss: 0.746, Validation Loss: 0.239\n",
      "Epoch: 1824, Train Loss: 0.204, Validation Loss: 0.238\n",
      "Epoch: 1825, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 1826, Train Loss: 0.342, Validation Loss: 0.246\n",
      "Epoch: 1827, Train Loss: 0.181, Validation Loss: 0.236\n",
      "Epoch: 1828, Train Loss: 0.256, Validation Loss: 0.237\n",
      "Epoch: 1829, Train Loss: 0.200, Validation Loss: 0.237\n",
      "Epoch: 1830, Train Loss: 0.294, Validation Loss: 0.238\n",
      "Epoch: 1831, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 1832, Train Loss: 0.341, Validation Loss: 0.241\n",
      "Epoch: 1833, Train Loss: 0.405, Validation Loss: 0.238\n",
      "Epoch: 1834, Train Loss: 0.183, Validation Loss: 0.237\n",
      "Epoch: 1835, Train Loss: 0.262, Validation Loss: 0.240\n",
      "Epoch: 1836, Train Loss: 0.230, Validation Loss: 0.239\n",
      "Epoch: 1837, Train Loss: 0.207, Validation Loss: 0.238\n",
      "Epoch: 1838, Train Loss: 0.242, Validation Loss: 0.236\n",
      "Epoch: 1839, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 1840, Train Loss: 0.230, Validation Loss: 0.239\n",
      "Epoch: 1841, Train Loss: 0.291, Validation Loss: 0.237\n",
      "Epoch: 1842, Train Loss: 0.228, Validation Loss: 0.242\n",
      "Epoch: 1843, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 1844, Train Loss: 0.423, Validation Loss: 0.240\n",
      "Epoch: 1845, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 1846, Train Loss: 0.234, Validation Loss: 0.241\n",
      "Epoch: 1847, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 1848, Train Loss: 0.294, Validation Loss: 0.239\n",
      "Epoch: 1849, Train Loss: 0.167, Validation Loss: 0.241\n",
      "Epoch: 1850, Train Loss: 0.181, Validation Loss: 0.241\n",
      "Epoch: 1851, Train Loss: 0.414, Validation Loss: 0.236\n",
      "Epoch: 1852, Train Loss: 0.373, Validation Loss: 0.238\n",
      "Epoch: 1853, Train Loss: 0.353, Validation Loss: 0.237\n",
      "Epoch: 1854, Train Loss: 0.350, Validation Loss: 0.237\n",
      "Epoch: 1855, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 1856, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 1857, Train Loss: 0.227, Validation Loss: 0.240\n",
      "Epoch: 1858, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 1859, Train Loss: 0.272, Validation Loss: 0.240\n",
      "Epoch: 1860, Train Loss: 0.231, Validation Loss: 0.238\n",
      "Epoch: 1861, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 1862, Train Loss: 0.173, Validation Loss: 0.238\n",
      "Epoch: 1863, Train Loss: 0.194, Validation Loss: 0.239\n",
      "Epoch: 1864, Train Loss: 0.182, Validation Loss: 0.241\n",
      "Epoch: 1865, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 1866, Train Loss: 0.245, Validation Loss: 0.240\n",
      "Epoch: 1867, Train Loss: 0.249, Validation Loss: 0.240\n",
      "Epoch: 1868, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 1869, Train Loss: 0.213, Validation Loss: 0.239\n",
      "Epoch: 1870, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 1871, Train Loss: 0.324, Validation Loss: 0.240\n",
      "Epoch: 1872, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 1873, Train Loss: 0.317, Validation Loss: 0.243\n",
      "Epoch: 1874, Train Loss: 0.233, Validation Loss: 0.246\n",
      "Epoch: 1875, Train Loss: 0.229, Validation Loss: 0.243\n",
      "Epoch: 1876, Train Loss: 0.242, Validation Loss: 0.238\n",
      "Epoch: 1877, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 1878, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 1879, Train Loss: 0.175, Validation Loss: 0.239\n",
      "Epoch: 1880, Train Loss: 0.282, Validation Loss: 0.238\n",
      "Epoch: 1881, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 1882, Train Loss: 0.181, Validation Loss: 0.241\n",
      "Epoch: 1883, Train Loss: 0.268, Validation Loss: 0.241\n",
      "Epoch: 1884, Train Loss: 0.195, Validation Loss: 0.239\n",
      "Epoch: 1885, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 1886, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 1887, Train Loss: 0.274, Validation Loss: 0.238\n",
      "Epoch: 1888, Train Loss: 0.249, Validation Loss: 0.239\n",
      "Epoch: 1889, Train Loss: 0.366, Validation Loss: 0.238\n",
      "Epoch: 1890, Train Loss: 0.232, Validation Loss: 0.236\n",
      "Epoch: 1891, Train Loss: 0.290, Validation Loss: 0.236\n",
      "Epoch: 1892, Train Loss: 0.197, Validation Loss: 0.238\n",
      "Epoch: 1893, Train Loss: 0.267, Validation Loss: 0.245\n",
      "Epoch: 1894, Train Loss: 0.599, Validation Loss: 0.240\n",
      "Epoch: 1895, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 1896, Train Loss: 0.335, Validation Loss: 0.239\n",
      "Epoch: 1897, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 1898, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 1899, Train Loss: 0.418, Validation Loss: 0.240\n",
      "Epoch: 1900, Train Loss: 0.229, Validation Loss: 0.240\n",
      "Epoch: 1901, Train Loss: 0.222, Validation Loss: 0.238\n",
      "Epoch: 1902, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 1903, Train Loss: 0.256, Validation Loss: 0.239\n",
      "Epoch: 1904, Train Loss: 0.360, Validation Loss: 0.239\n",
      "Epoch: 1905, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 1906, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 1907, Train Loss: 0.359, Validation Loss: 0.237\n",
      "Epoch: 1908, Train Loss: 0.306, Validation Loss: 0.238\n",
      "Epoch: 1909, Train Loss: 0.238, Validation Loss: 0.244\n",
      "Epoch: 1910, Train Loss: 0.238, Validation Loss: 0.238\n",
      "Epoch: 1911, Train Loss: 0.331, Validation Loss: 0.238\n",
      "Epoch: 1912, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 1913, Train Loss: 0.274, Validation Loss: 0.238\n",
      "Epoch: 1914, Train Loss: 0.196, Validation Loss: 0.239\n",
      "Epoch: 1915, Train Loss: 0.203, Validation Loss: 0.237\n",
      "Epoch: 1916, Train Loss: 0.191, Validation Loss: 0.241\n",
      "Epoch: 1917, Train Loss: 0.226, Validation Loss: 0.239\n",
      "Epoch: 1918, Train Loss: 0.319, Validation Loss: 0.245\n",
      "Epoch: 1919, Train Loss: 0.188, Validation Loss: 0.239\n",
      "Epoch: 1920, Train Loss: 0.201, Validation Loss: 0.241\n",
      "Epoch: 1921, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 1922, Train Loss: 0.348, Validation Loss: 0.238\n",
      "Epoch: 1923, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 1924, Train Loss: 0.255, Validation Loss: 0.237\n",
      "Epoch: 1925, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 1926, Train Loss: 0.229, Validation Loss: 0.239\n",
      "Epoch: 1927, Train Loss: 0.249, Validation Loss: 0.237\n",
      "Epoch: 1928, Train Loss: 0.229, Validation Loss: 0.238\n",
      "Epoch: 1929, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 1930, Train Loss: 0.253, Validation Loss: 0.241\n",
      "Epoch: 1931, Train Loss: 0.313, Validation Loss: 0.239\n",
      "Epoch: 1932, Train Loss: 0.248, Validation Loss: 0.242\n",
      "Epoch: 1933, Train Loss: 0.407, Validation Loss: 0.240\n",
      "Epoch: 1934, Train Loss: 0.181, Validation Loss: 0.238\n",
      "Epoch: 1935, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 1936, Train Loss: 0.249, Validation Loss: 0.243\n",
      "Epoch: 1937, Train Loss: 0.195, Validation Loss: 0.240\n",
      "Epoch: 1938, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 1939, Train Loss: 0.354, Validation Loss: 0.239\n",
      "Epoch: 1940, Train Loss: 0.271, Validation Loss: 0.240\n",
      "Epoch: 1941, Train Loss: 0.182, Validation Loss: 0.243\n",
      "Epoch: 1942, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 1943, Train Loss: 0.173, Validation Loss: 0.242\n",
      "Epoch: 1944, Train Loss: 0.248, Validation Loss: 0.240\n",
      "Epoch: 1945, Train Loss: 0.247, Validation Loss: 0.242\n",
      "Epoch: 1946, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 1947, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 1948, Train Loss: 0.290, Validation Loss: 0.243\n",
      "Epoch: 1949, Train Loss: 0.234, Validation Loss: 0.241\n",
      "Epoch: 1950, Train Loss: 0.222, Validation Loss: 0.242\n",
      "Epoch: 1951, Train Loss: 0.242, Validation Loss: 0.240\n",
      "Epoch: 1952, Train Loss: 0.289, Validation Loss: 0.241\n",
      "Epoch: 1953, Train Loss: 0.337, Validation Loss: 0.239\n",
      "Epoch: 1954, Train Loss: 0.180, Validation Loss: 0.239\n",
      "Epoch: 1955, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 1956, Train Loss: 0.232, Validation Loss: 0.241\n",
      "Epoch: 1957, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 1958, Train Loss: 0.261, Validation Loss: 0.238\n",
      "Epoch: 1959, Train Loss: 0.252, Validation Loss: 0.243\n",
      "Epoch: 1960, Train Loss: 0.382, Validation Loss: 0.237\n",
      "Epoch: 1961, Train Loss: 0.188, Validation Loss: 0.237\n",
      "Epoch: 1962, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 1963, Train Loss: 0.250, Validation Loss: 0.242\n",
      "Epoch: 1964, Train Loss: 0.283, Validation Loss: 0.240\n",
      "Epoch: 1965, Train Loss: 0.491, Validation Loss: 0.243\n",
      "Epoch: 1966, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 1967, Train Loss: 0.274, Validation Loss: 0.241\n",
      "Epoch: 1968, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 1969, Train Loss: 0.317, Validation Loss: 0.239\n",
      "Epoch: 1970, Train Loss: 0.303, Validation Loss: 0.239\n",
      "Epoch: 1971, Train Loss: 0.215, Validation Loss: 0.241\n",
      "Epoch: 1972, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 1973, Train Loss: 0.274, Validation Loss: 0.240\n",
      "Epoch: 1974, Train Loss: 0.218, Validation Loss: 0.240\n",
      "Epoch: 1975, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 1976, Train Loss: 0.265, Validation Loss: 0.243\n",
      "Epoch: 1977, Train Loss: 0.269, Validation Loss: 0.241\n",
      "Epoch: 1978, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 1979, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 1980, Train Loss: 0.289, Validation Loss: 0.239\n",
      "Epoch: 1981, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 1982, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 1983, Train Loss: 0.355, Validation Loss: 0.241\n",
      "Epoch: 1984, Train Loss: 0.572, Validation Loss: 0.239\n",
      "Epoch: 1985, Train Loss: 0.275, Validation Loss: 0.238\n",
      "Epoch: 1986, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 1987, Train Loss: 0.191, Validation Loss: 0.238\n",
      "Epoch: 1988, Train Loss: 0.316, Validation Loss: 0.242\n",
      "Epoch: 1989, Train Loss: 0.269, Validation Loss: 0.238\n",
      "Epoch: 1990, Train Loss: 0.389, Validation Loss: 0.238\n",
      "Epoch: 1991, Train Loss: 0.367, Validation Loss: 0.237\n",
      "Epoch: 1992, Train Loss: 0.284, Validation Loss: 0.243\n",
      "Epoch: 1993, Train Loss: 0.290, Validation Loss: 0.241\n",
      "Epoch: 1994, Train Loss: 0.269, Validation Loss: 0.237\n",
      "Epoch: 1995, Train Loss: 0.251, Validation Loss: 0.239\n",
      "Epoch: 1996, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 1997, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 1998, Train Loss: 0.178, Validation Loss: 0.240\n",
      "Epoch: 1999, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 2000, Train Loss: 0.170, Validation Loss: 0.240\n",
      "Epoch: 2001, Train Loss: 0.277, Validation Loss: 0.240\n",
      "Epoch: 2002, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 2003, Train Loss: 0.318, Validation Loss: 0.247\n",
      "Epoch: 2004, Train Loss: 0.213, Validation Loss: 0.239\n",
      "Epoch: 2005, Train Loss: 0.308, Validation Loss: 0.241\n",
      "Epoch: 2006, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 2007, Train Loss: 0.289, Validation Loss: 0.239\n",
      "Epoch: 2008, Train Loss: 0.205, Validation Loss: 0.239\n",
      "Epoch: 2009, Train Loss: 0.414, Validation Loss: 0.245\n",
      "Epoch: 2010, Train Loss: 0.377, Validation Loss: 0.240\n",
      "Epoch: 2011, Train Loss: 0.292, Validation Loss: 0.239\n",
      "Epoch: 2012, Train Loss: 0.552, Validation Loss: 0.239\n",
      "Epoch: 2013, Train Loss: 0.303, Validation Loss: 0.238\n",
      "Epoch: 2014, Train Loss: 0.426, Validation Loss: 0.238\n",
      "Epoch: 2015, Train Loss: 0.223, Validation Loss: 0.240\n",
      "Epoch: 2016, Train Loss: 0.272, Validation Loss: 0.237\n",
      "Epoch: 2017, Train Loss: 0.213, Validation Loss: 0.235\n",
      "Epoch: 2018, Train Loss: 0.359, Validation Loss: 0.236\n",
      "Epoch: 2019, Train Loss: 0.215, Validation Loss: 0.238\n",
      "Epoch: 2020, Train Loss: 0.235, Validation Loss: 0.240\n",
      "Epoch: 2021, Train Loss: 0.224, Validation Loss: 0.237\n",
      "Epoch: 2022, Train Loss: 0.415, Validation Loss: 0.240\n",
      "Epoch: 2023, Train Loss: 0.214, Validation Loss: 0.237\n",
      "Epoch: 2024, Train Loss: 0.483, Validation Loss: 0.241\n",
      "Epoch: 2025, Train Loss: 0.303, Validation Loss: 0.241\n",
      "Epoch: 2026, Train Loss: 0.219, Validation Loss: 0.238\n",
      "Epoch: 2027, Train Loss: 0.389, Validation Loss: 0.242\n",
      "Epoch: 2028, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 2029, Train Loss: 0.496, Validation Loss: 0.237\n",
      "Epoch: 2030, Train Loss: 0.228, Validation Loss: 0.238\n",
      "Epoch: 2031, Train Loss: 0.178, Validation Loss: 0.237\n",
      "Epoch: 2032, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 2033, Train Loss: 0.258, Validation Loss: 0.242\n",
      "Epoch: 2034, Train Loss: 0.204, Validation Loss: 0.240\n",
      "Epoch: 2035, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 2036, Train Loss: 0.301, Validation Loss: 0.238\n",
      "Epoch: 2037, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 2038, Train Loss: 0.228, Validation Loss: 0.240\n",
      "Epoch: 2039, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 2040, Train Loss: 0.476, Validation Loss: 0.241\n",
      "Epoch: 2041, Train Loss: 0.307, Validation Loss: 0.239\n",
      "Epoch: 2042, Train Loss: 0.781, Validation Loss: 0.246\n",
      "Epoch: 2043, Train Loss: 0.191, Validation Loss: 0.242\n",
      "Epoch: 2044, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 2045, Train Loss: 0.205, Validation Loss: 0.240\n",
      "Epoch: 2046, Train Loss: 0.517, Validation Loss: 0.245\n",
      "Epoch: 2047, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 2048, Train Loss: 0.201, Validation Loss: 0.240\n",
      "Epoch: 2049, Train Loss: 0.247, Validation Loss: 0.242\n",
      "Epoch: 2050, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 2051, Train Loss: 0.273, Validation Loss: 0.237\n",
      "Epoch: 2052, Train Loss: 0.295, Validation Loss: 0.238\n",
      "Epoch: 2053, Train Loss: 0.221, Validation Loss: 0.237\n",
      "Epoch: 2054, Train Loss: 0.263, Validation Loss: 0.239\n",
      "Epoch: 2055, Train Loss: 0.289, Validation Loss: 0.242\n",
      "Epoch: 2056, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 2057, Train Loss: 0.305, Validation Loss: 0.239\n",
      "Epoch: 2058, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 2059, Train Loss: 0.226, Validation Loss: 0.239\n",
      "Epoch: 2060, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 2061, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 2062, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 2063, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 2064, Train Loss: 0.449, Validation Loss: 0.241\n",
      "Epoch: 2065, Train Loss: 0.258, Validation Loss: 0.238\n",
      "Epoch: 2066, Train Loss: 0.276, Validation Loss: 0.238\n",
      "Epoch: 2067, Train Loss: 0.194, Validation Loss: 0.239\n",
      "Epoch: 2068, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 2069, Train Loss: 0.251, Validation Loss: 0.239\n",
      "Epoch: 2070, Train Loss: 0.197, Validation Loss: 0.242\n",
      "Epoch: 2071, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 2072, Train Loss: 0.226, Validation Loss: 0.236\n",
      "Epoch: 2073, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 2074, Train Loss: 0.350, Validation Loss: 0.237\n",
      "Epoch: 2075, Train Loss: 0.307, Validation Loss: 0.239\n",
      "Epoch: 2076, Train Loss: 0.247, Validation Loss: 0.238\n",
      "Epoch: 2077, Train Loss: 0.492, Validation Loss: 0.242\n",
      "Epoch: 2078, Train Loss: 0.326, Validation Loss: 0.238\n",
      "Epoch: 2079, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 2080, Train Loss: 0.396, Validation Loss: 0.239\n",
      "Epoch: 2081, Train Loss: 0.303, Validation Loss: 0.244\n",
      "Epoch: 2082, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 2083, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 2084, Train Loss: 0.281, Validation Loss: 0.242\n",
      "Epoch: 2085, Train Loss: 0.646, Validation Loss: 0.247\n",
      "Epoch: 2086, Train Loss: 0.234, Validation Loss: 0.240\n",
      "Epoch: 2087, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 2088, Train Loss: 0.188, Validation Loss: 0.240\n",
      "Epoch: 2089, Train Loss: 0.258, Validation Loss: 0.239\n",
      "Epoch: 2090, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 2091, Train Loss: 0.215, Validation Loss: 0.241\n",
      "Epoch: 2092, Train Loss: 0.302, Validation Loss: 0.240\n",
      "Epoch: 2093, Train Loss: 0.251, Validation Loss: 0.238\n",
      "Epoch: 2094, Train Loss: 0.169, Validation Loss: 0.240\n",
      "Epoch: 2095, Train Loss: 0.199, Validation Loss: 0.241\n",
      "Epoch: 2096, Train Loss: 0.190, Validation Loss: 0.237\n",
      "Epoch: 2097, Train Loss: 0.269, Validation Loss: 0.236\n",
      "Epoch: 2098, Train Loss: 0.575, Validation Loss: 0.244\n",
      "Epoch: 2099, Train Loss: 0.343, Validation Loss: 0.243\n",
      "Epoch: 2100, Train Loss: 0.323, Validation Loss: 0.238\n",
      "Epoch: 2101, Train Loss: 0.175, Validation Loss: 0.240\n",
      "Epoch: 2102, Train Loss: 0.271, Validation Loss: 0.240\n",
      "Epoch: 2103, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 2104, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 2105, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 2106, Train Loss: 0.252, Validation Loss: 0.242\n",
      "Epoch: 2107, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 2108, Train Loss: 0.198, Validation Loss: 0.239\n",
      "Epoch: 2109, Train Loss: 0.174, Validation Loss: 0.238\n",
      "Epoch: 2110, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 2111, Train Loss: 0.405, Validation Loss: 0.238\n",
      "Epoch: 2112, Train Loss: 0.278, Validation Loss: 0.243\n",
      "Epoch: 2113, Train Loss: 0.276, Validation Loss: 0.243\n",
      "Epoch: 2114, Train Loss: 0.424, Validation Loss: 0.239\n",
      "Epoch: 2115, Train Loss: 0.477, Validation Loss: 0.245\n",
      "Epoch: 2116, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 2117, Train Loss: 0.278, Validation Loss: 0.242\n",
      "Epoch: 2118, Train Loss: 0.673, Validation Loss: 0.241\n",
      "Epoch: 2119, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 2120, Train Loss: 0.351, Validation Loss: 0.249\n",
      "Epoch: 2121, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 2122, Train Loss: 0.204, Validation Loss: 0.239\n",
      "Epoch: 2123, Train Loss: 0.245, Validation Loss: 0.239\n",
      "Epoch: 2124, Train Loss: 0.422, Validation Loss: 0.241\n",
      "Epoch: 2125, Train Loss: 0.571, Validation Loss: 0.245\n",
      "Epoch: 2126, Train Loss: 0.309, Validation Loss: 0.241\n",
      "Epoch: 2127, Train Loss: 0.298, Validation Loss: 0.243\n",
      "Epoch: 2128, Train Loss: 0.283, Validation Loss: 0.242\n",
      "Epoch: 2129, Train Loss: 0.157, Validation Loss: 0.238\n",
      "Epoch: 2130, Train Loss: 0.457, Validation Loss: 0.242\n",
      "Epoch: 2131, Train Loss: 0.188, Validation Loss: 0.240\n",
      "Epoch: 2132, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 2133, Train Loss: 0.304, Validation Loss: 0.239\n",
      "Epoch: 2134, Train Loss: 0.391, Validation Loss: 0.241\n",
      "Epoch: 2135, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 2136, Train Loss: 0.230, Validation Loss: 0.238\n",
      "Epoch: 2137, Train Loss: 0.200, Validation Loss: 0.238\n",
      "Epoch: 2138, Train Loss: 0.404, Validation Loss: 0.243\n",
      "Epoch: 2139, Train Loss: 0.252, Validation Loss: 0.240\n",
      "Epoch: 2140, Train Loss: 0.287, Validation Loss: 0.239\n",
      "Epoch: 2141, Train Loss: 0.158, Validation Loss: 0.239\n",
      "Epoch: 2142, Train Loss: 0.199, Validation Loss: 0.239\n",
      "Epoch: 2143, Train Loss: 0.280, Validation Loss: 0.239\n",
      "Epoch: 2144, Train Loss: 0.206, Validation Loss: 0.239\n",
      "Epoch: 2145, Train Loss: 0.197, Validation Loss: 0.239\n",
      "Epoch: 2146, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 2147, Train Loss: 0.301, Validation Loss: 0.238\n",
      "Epoch: 2148, Train Loss: 0.318, Validation Loss: 0.239\n",
      "Epoch: 2149, Train Loss: 0.303, Validation Loss: 0.240\n",
      "Epoch: 2150, Train Loss: 0.166, Validation Loss: 0.240\n",
      "Epoch: 2151, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 2152, Train Loss: 0.217, Validation Loss: 0.238\n",
      "Epoch: 2153, Train Loss: 0.709, Validation Loss: 0.244\n",
      "Epoch: 2154, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2155, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 2156, Train Loss: 0.187, Validation Loss: 0.238\n",
      "Epoch: 2157, Train Loss: 0.321, Validation Loss: 0.239\n",
      "Epoch: 2158, Train Loss: 0.385, Validation Loss: 0.246\n",
      "Epoch: 2159, Train Loss: 0.194, Validation Loss: 0.241\n",
      "Epoch: 2160, Train Loss: 0.183, Validation Loss: 0.238\n",
      "Epoch: 2161, Train Loss: 0.170, Validation Loss: 0.237\n",
      "Epoch: 2162, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 2163, Train Loss: 0.542, Validation Loss: 0.242\n",
      "Epoch: 2164, Train Loss: 0.309, Validation Loss: 0.242\n",
      "Epoch: 2165, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 2166, Train Loss: 0.335, Validation Loss: 0.239\n",
      "Epoch: 2167, Train Loss: 0.266, Validation Loss: 0.239\n",
      "Epoch: 2168, Train Loss: 0.212, Validation Loss: 0.238\n",
      "Epoch: 2169, Train Loss: 0.444, Validation Loss: 0.244\n",
      "Epoch: 2170, Train Loss: 0.236, Validation Loss: 0.237\n",
      "Epoch: 2171, Train Loss: 0.324, Validation Loss: 0.236\n",
      "Epoch: 2172, Train Loss: 0.189, Validation Loss: 0.240\n",
      "Epoch: 2173, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 2174, Train Loss: 0.332, Validation Loss: 0.236\n",
      "Epoch: 2175, Train Loss: 0.222, Validation Loss: 0.237\n",
      "Epoch: 2176, Train Loss: 0.477, Validation Loss: 0.241\n",
      "Epoch: 2177, Train Loss: 0.198, Validation Loss: 0.237\n",
      "Epoch: 2178, Train Loss: 0.303, Validation Loss: 0.236\n",
      "Epoch: 2179, Train Loss: 0.258, Validation Loss: 0.238\n",
      "Epoch: 2180, Train Loss: 0.303, Validation Loss: 0.238\n",
      "Epoch: 2181, Train Loss: 0.208, Validation Loss: 0.242\n",
      "Epoch: 2182, Train Loss: 0.297, Validation Loss: 0.241\n",
      "Epoch: 2183, Train Loss: 0.404, Validation Loss: 0.236\n",
      "Epoch: 2184, Train Loss: 0.342, Validation Loss: 0.243\n",
      "Epoch: 2185, Train Loss: 0.258, Validation Loss: 0.242\n",
      "Epoch: 2186, Train Loss: 0.306, Validation Loss: 0.238\n",
      "Epoch: 2187, Train Loss: 0.475, Validation Loss: 0.245\n",
      "Epoch: 2188, Train Loss: 0.551, Validation Loss: 0.243\n",
      "Epoch: 2189, Train Loss: 0.269, Validation Loss: 0.238\n",
      "Epoch: 2190, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 2191, Train Loss: 0.185, Validation Loss: 0.237\n",
      "Epoch: 2192, Train Loss: 0.186, Validation Loss: 0.238\n",
      "Epoch: 2193, Train Loss: 0.648, Validation Loss: 0.242\n",
      "Epoch: 2194, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 2195, Train Loss: 0.254, Validation Loss: 0.237\n",
      "Epoch: 2196, Train Loss: 0.241, Validation Loss: 0.239\n",
      "Epoch: 2197, Train Loss: 0.185, Validation Loss: 0.238\n",
      "Epoch: 2198, Train Loss: 0.257, Validation Loss: 0.236\n",
      "Epoch: 2199, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 2200, Train Loss: 0.496, Validation Loss: 0.243\n",
      "Epoch: 2201, Train Loss: 0.215, Validation Loss: 0.242\n",
      "Epoch: 2202, Train Loss: 0.266, Validation Loss: 0.240\n",
      "Epoch: 2203, Train Loss: 0.306, Validation Loss: 0.239\n",
      "Epoch: 2204, Train Loss: 0.377, Validation Loss: 0.238\n",
      "Epoch: 2205, Train Loss: 0.280, Validation Loss: 0.240\n",
      "Epoch: 2206, Train Loss: 0.426, Validation Loss: 0.239\n",
      "Epoch: 2207, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 2208, Train Loss: 0.196, Validation Loss: 0.239\n",
      "Epoch: 2209, Train Loss: 0.238, Validation Loss: 0.237\n",
      "Epoch: 2210, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 2211, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 2212, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 2213, Train Loss: 0.230, Validation Loss: 0.238\n",
      "Epoch: 2214, Train Loss: 0.425, Validation Loss: 0.236\n",
      "Epoch: 2215, Train Loss: 0.242, Validation Loss: 0.237\n",
      "Epoch: 2216, Train Loss: 0.473, Validation Loss: 0.238\n",
      "Epoch: 2217, Train Loss: 0.556, Validation Loss: 0.242\n",
      "Epoch: 2218, Train Loss: 0.321, Validation Loss: 0.240\n",
      "Epoch: 2219, Train Loss: 0.271, Validation Loss: 0.240\n",
      "Epoch: 2220, Train Loss: 0.265, Validation Loss: 0.240\n",
      "Epoch: 2221, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 2222, Train Loss: 0.268, Validation Loss: 0.238\n",
      "Epoch: 2223, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 2224, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 2225, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 2226, Train Loss: 0.208, Validation Loss: 0.238\n",
      "Epoch: 2227, Train Loss: 0.224, Validation Loss: 0.242\n",
      "Epoch: 2228, Train Loss: 0.308, Validation Loss: 0.242\n",
      "Epoch: 2229, Train Loss: 0.290, Validation Loss: 0.239\n",
      "Epoch: 2230, Train Loss: 0.470, Validation Loss: 0.239\n",
      "Epoch: 2231, Train Loss: 0.262, Validation Loss: 0.238\n",
      "Epoch: 2232, Train Loss: 0.295, Validation Loss: 0.238\n",
      "Epoch: 2233, Train Loss: 0.223, Validation Loss: 0.240\n",
      "Epoch: 2234, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 2235, Train Loss: 0.171, Validation Loss: 0.236\n",
      "Epoch: 2236, Train Loss: 0.335, Validation Loss: 0.237\n",
      "Epoch: 2237, Train Loss: 0.317, Validation Loss: 0.238\n",
      "Epoch: 2238, Train Loss: 0.300, Validation Loss: 0.237\n",
      "Epoch: 2239, Train Loss: 0.262, Validation Loss: 0.236\n",
      "Epoch: 2240, Train Loss: 0.284, Validation Loss: 0.238\n",
      "Epoch: 2241, Train Loss: 0.188, Validation Loss: 0.238\n",
      "Epoch: 2242, Train Loss: 0.207, Validation Loss: 0.240\n",
      "Epoch: 2243, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 2244, Train Loss: 0.189, Validation Loss: 0.236\n",
      "Epoch: 2245, Train Loss: 0.202, Validation Loss: 0.236\n",
      "Epoch: 2246, Train Loss: 0.292, Validation Loss: 0.243\n",
      "Epoch: 2247, Train Loss: 0.517, Validation Loss: 0.237\n",
      "Epoch: 2248, Train Loss: 0.231, Validation Loss: 0.238\n",
      "Epoch: 2249, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 2250, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 2251, Train Loss: 0.180, Validation Loss: 0.238\n",
      "Epoch: 2252, Train Loss: 0.251, Validation Loss: 0.239\n",
      "Epoch: 2253, Train Loss: 0.178, Validation Loss: 0.238\n",
      "Epoch: 2254, Train Loss: 0.405, Validation Loss: 0.238\n",
      "Epoch: 2255, Train Loss: 0.642, Validation Loss: 0.244\n",
      "Epoch: 2256, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 2257, Train Loss: 0.230, Validation Loss: 0.242\n",
      "Epoch: 2258, Train Loss: 0.209, Validation Loss: 0.239\n",
      "Epoch: 2259, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 2260, Train Loss: 0.278, Validation Loss: 0.239\n",
      "Epoch: 2261, Train Loss: 0.167, Validation Loss: 0.239\n",
      "Epoch: 2262, Train Loss: 0.287, Validation Loss: 0.243\n",
      "Epoch: 2263, Train Loss: 0.315, Validation Loss: 0.239\n",
      "Epoch: 2264, Train Loss: 0.280, Validation Loss: 0.244\n",
      "Epoch: 2265, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 2266, Train Loss: 0.242, Validation Loss: 0.236\n",
      "Epoch: 2267, Train Loss: 0.260, Validation Loss: 0.238\n",
      "Epoch: 2268, Train Loss: 0.282, Validation Loss: 0.237\n",
      "Epoch: 2269, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2270, Train Loss: 0.318, Validation Loss: 0.238\n",
      "Epoch: 2271, Train Loss: 0.353, Validation Loss: 0.237\n",
      "Epoch: 2272, Train Loss: 0.242, Validation Loss: 0.239\n",
      "Epoch: 2273, Train Loss: 0.535, Validation Loss: 0.241\n",
      "Epoch: 2274, Train Loss: 0.422, Validation Loss: 0.238\n",
      "Epoch: 2275, Train Loss: 0.299, Validation Loss: 0.240\n",
      "Epoch: 2276, Train Loss: 0.321, Validation Loss: 0.240\n",
      "Epoch: 2277, Train Loss: 0.266, Validation Loss: 0.238\n",
      "Epoch: 2278, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 2279, Train Loss: 0.207, Validation Loss: 0.238\n",
      "Epoch: 2280, Train Loss: 0.302, Validation Loss: 0.240\n",
      "Epoch: 2281, Train Loss: 0.272, Validation Loss: 0.241\n",
      "Epoch: 2282, Train Loss: 0.323, Validation Loss: 0.241\n",
      "Epoch: 2283, Train Loss: 0.260, Validation Loss: 0.240\n",
      "Epoch: 2284, Train Loss: 0.260, Validation Loss: 0.237\n",
      "Epoch: 2285, Train Loss: 0.259, Validation Loss: 0.236\n",
      "Epoch: 2286, Train Loss: 0.203, Validation Loss: 0.237\n",
      "Epoch: 2287, Train Loss: 0.203, Validation Loss: 0.236\n",
      "Epoch: 2288, Train Loss: 0.303, Validation Loss: 0.238\n",
      "Epoch: 2289, Train Loss: 0.189, Validation Loss: 0.236\n",
      "Epoch: 2290, Train Loss: 0.262, Validation Loss: 0.239\n",
      "Epoch: 2291, Train Loss: 0.273, Validation Loss: 0.241\n",
      "Epoch: 2292, Train Loss: 0.267, Validation Loss: 0.237\n",
      "Epoch: 2293, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 2294, Train Loss: 0.279, Validation Loss: 0.238\n",
      "Epoch: 2295, Train Loss: 0.278, Validation Loss: 0.239\n",
      "Epoch: 2296, Train Loss: 0.202, Validation Loss: 0.238\n",
      "Epoch: 2297, Train Loss: 0.289, Validation Loss: 0.240\n",
      "Epoch: 2298, Train Loss: 0.201, Validation Loss: 0.240\n",
      "Epoch: 2299, Train Loss: 0.196, Validation Loss: 0.237\n",
      "Epoch: 2300, Train Loss: 0.205, Validation Loss: 0.237\n",
      "Epoch: 2301, Train Loss: 0.183, Validation Loss: 0.237\n",
      "Epoch: 2302, Train Loss: 0.461, Validation Loss: 0.240\n",
      "Epoch: 2303, Train Loss: 0.212, Validation Loss: 0.237\n",
      "Epoch: 2304, Train Loss: 0.146, Validation Loss: 0.236\n",
      "Epoch: 2305, Train Loss: 0.202, Validation Loss: 0.237\n",
      "Epoch: 2306, Train Loss: 0.312, Validation Loss: 0.236\n",
      "Epoch: 2307, Train Loss: 0.300, Validation Loss: 0.240\n",
      "Epoch: 2308, Train Loss: 0.548, Validation Loss: 0.239\n",
      "Epoch: 2309, Train Loss: 0.296, Validation Loss: 0.237\n",
      "Epoch: 2310, Train Loss: 0.233, Validation Loss: 0.237\n",
      "Epoch: 2311, Train Loss: 0.274, Validation Loss: 0.240\n",
      "Epoch: 2312, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 2313, Train Loss: 0.206, Validation Loss: 0.238\n",
      "Epoch: 2314, Train Loss: 0.477, Validation Loss: 0.237\n",
      "Epoch: 2315, Train Loss: 0.532, Validation Loss: 0.242\n",
      "Epoch: 2316, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 2317, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 2318, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 2319, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 2320, Train Loss: 0.243, Validation Loss: 0.239\n",
      "Epoch: 2321, Train Loss: 0.161, Validation Loss: 0.238\n",
      "Epoch: 2322, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 2323, Train Loss: 0.197, Validation Loss: 0.238\n",
      "Epoch: 2324, Train Loss: 0.263, Validation Loss: 0.241\n",
      "Epoch: 2325, Train Loss: 0.318, Validation Loss: 0.242\n",
      "Epoch: 2326, Train Loss: 0.209, Validation Loss: 0.239\n",
      "Epoch: 2327, Train Loss: 0.361, Validation Loss: 0.237\n",
      "Epoch: 2328, Train Loss: 0.195, Validation Loss: 0.241\n",
      "Epoch: 2329, Train Loss: 0.466, Validation Loss: 0.237\n",
      "Epoch: 2330, Train Loss: 0.421, Validation Loss: 0.238\n",
      "Epoch: 2331, Train Loss: 0.316, Validation Loss: 0.240\n",
      "Epoch: 2332, Train Loss: 0.260, Validation Loss: 0.240\n",
      "Epoch: 2333, Train Loss: 0.479, Validation Loss: 0.239\n",
      "Epoch: 2334, Train Loss: 0.284, Validation Loss: 0.237\n",
      "Epoch: 2335, Train Loss: 0.257, Validation Loss: 0.238\n",
      "Epoch: 2336, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 2337, Train Loss: 0.444, Validation Loss: 0.246\n",
      "Epoch: 2338, Train Loss: 0.264, Validation Loss: 0.237\n",
      "Epoch: 2339, Train Loss: 0.234, Validation Loss: 0.236\n",
      "Epoch: 2340, Train Loss: 0.243, Validation Loss: 0.238\n",
      "Epoch: 2341, Train Loss: 0.206, Validation Loss: 0.236\n",
      "Epoch: 2342, Train Loss: 0.292, Validation Loss: 0.238\n",
      "Epoch: 2343, Train Loss: 0.406, Validation Loss: 0.236\n",
      "Epoch: 2344, Train Loss: 0.222, Validation Loss: 0.236\n",
      "Epoch: 2345, Train Loss: 0.193, Validation Loss: 0.241\n",
      "Epoch: 2346, Train Loss: 0.201, Validation Loss: 0.237\n",
      "Epoch: 2347, Train Loss: 0.377, Validation Loss: 0.236\n",
      "Epoch: 2348, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 2349, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 2350, Train Loss: 0.224, Validation Loss: 0.241\n",
      "Epoch: 2351, Train Loss: 0.240, Validation Loss: 0.239\n",
      "Epoch: 2352, Train Loss: 0.224, Validation Loss: 0.237\n",
      "Epoch: 2353, Train Loss: 0.180, Validation Loss: 0.238\n",
      "Epoch: 2354, Train Loss: 0.192, Validation Loss: 0.239\n",
      "Epoch: 2355, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 2356, Train Loss: 0.205, Validation Loss: 0.237\n",
      "Epoch: 2357, Train Loss: 0.287, Validation Loss: 0.236\n",
      "Epoch: 2358, Train Loss: 0.297, Validation Loss: 0.239\n",
      "Epoch: 2359, Train Loss: 0.222, Validation Loss: 0.245\n",
      "Epoch: 2360, Train Loss: 0.302, Validation Loss: 0.237\n",
      "Epoch: 2361, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 2362, Train Loss: 0.222, Validation Loss: 0.238\n",
      "Epoch: 2363, Train Loss: 0.234, Validation Loss: 0.237\n",
      "Epoch: 2364, Train Loss: 0.425, Validation Loss: 0.243\n",
      "Epoch: 2365, Train Loss: 0.293, Validation Loss: 0.236\n",
      "Epoch: 2366, Train Loss: 0.263, Validation Loss: 0.236\n",
      "Epoch: 2367, Train Loss: 0.220, Validation Loss: 0.236\n",
      "Epoch: 2368, Train Loss: 0.277, Validation Loss: 0.236\n",
      "Epoch: 2369, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 2370, Train Loss: 0.190, Validation Loss: 0.237\n",
      "Epoch: 2371, Train Loss: 0.242, Validation Loss: 0.236\n",
      "Epoch: 2372, Train Loss: 0.221, Validation Loss: 0.236\n",
      "Epoch: 2373, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 2374, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 2375, Train Loss: 0.247, Validation Loss: 0.238\n",
      "Epoch: 2376, Train Loss: 0.379, Validation Loss: 0.237\n",
      "Epoch: 2377, Train Loss: 0.171, Validation Loss: 0.238\n",
      "Epoch: 2378, Train Loss: 0.335, Validation Loss: 0.242\n",
      "Epoch: 2379, Train Loss: 0.223, Validation Loss: 0.239\n",
      "Epoch: 2380, Train Loss: 0.229, Validation Loss: 0.235\n",
      "Epoch: 2381, Train Loss: 0.266, Validation Loss: 0.241\n",
      "Epoch: 2382, Train Loss: 0.360, Validation Loss: 0.241\n",
      "Epoch: 2383, Train Loss: 0.206, Validation Loss: 0.237\n",
      "Epoch: 2384, Train Loss: 0.335, Validation Loss: 0.237\n",
      "Epoch: 2385, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 2386, Train Loss: 0.312, Validation Loss: 0.243\n",
      "Epoch: 2387, Train Loss: 0.469, Validation Loss: 0.240\n",
      "Epoch: 2388, Train Loss: 0.349, Validation Loss: 0.237\n",
      "Epoch: 2389, Train Loss: 0.199, Validation Loss: 0.240\n",
      "Epoch: 2390, Train Loss: 0.203, Validation Loss: 0.242\n",
      "Epoch: 2391, Train Loss: 0.228, Validation Loss: 0.238\n",
      "Epoch: 2392, Train Loss: 0.215, Validation Loss: 0.237\n",
      "Epoch: 2393, Train Loss: 0.351, Validation Loss: 0.239\n",
      "Epoch: 2394, Train Loss: 0.208, Validation Loss: 0.240\n",
      "Epoch: 2395, Train Loss: 0.198, Validation Loss: 0.238\n",
      "Epoch: 2396, Train Loss: 0.279, Validation Loss: 0.238\n",
      "Epoch: 2397, Train Loss: 0.372, Validation Loss: 0.237\n",
      "Epoch: 2398, Train Loss: 0.276, Validation Loss: 0.239\n",
      "Epoch: 2399, Train Loss: 0.342, Validation Loss: 0.238\n",
      "Epoch: 2400, Train Loss: 0.259, Validation Loss: 0.238\n",
      "Epoch: 2401, Train Loss: 0.266, Validation Loss: 0.237\n",
      "Epoch: 2402, Train Loss: 0.492, Validation Loss: 0.237\n",
      "Epoch: 2403, Train Loss: 0.254, Validation Loss: 0.236\n",
      "Epoch: 2404, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 2405, Train Loss: 0.340, Validation Loss: 0.236\n",
      "Epoch: 2406, Train Loss: 0.172, Validation Loss: 0.240\n",
      "Epoch: 2407, Train Loss: 0.306, Validation Loss: 0.239\n",
      "Epoch: 2408, Train Loss: 0.251, Validation Loss: 0.238\n",
      "Epoch: 2409, Train Loss: 0.371, Validation Loss: 0.241\n",
      "Epoch: 2410, Train Loss: 0.241, Validation Loss: 0.238\n",
      "Epoch: 2411, Train Loss: 0.326, Validation Loss: 0.236\n",
      "Epoch: 2412, Train Loss: 0.236, Validation Loss: 0.235\n",
      "Epoch: 2413, Train Loss: 0.300, Validation Loss: 0.235\n",
      "Epoch: 2414, Train Loss: 0.270, Validation Loss: 0.238\n",
      "Epoch: 2415, Train Loss: 0.250, Validation Loss: 0.241\n",
      "Epoch: 2416, Train Loss: 0.457, Validation Loss: 0.240\n",
      "Epoch: 2417, Train Loss: 0.248, Validation Loss: 0.241\n",
      "Epoch: 2418, Train Loss: 0.223, Validation Loss: 0.237\n",
      "Epoch: 2419, Train Loss: 0.172, Validation Loss: 0.236\n",
      "Epoch: 2420, Train Loss: 0.189, Validation Loss: 0.237\n",
      "Epoch: 2421, Train Loss: 0.227, Validation Loss: 0.238\n",
      "Epoch: 2422, Train Loss: 0.393, Validation Loss: 0.238\n",
      "Epoch: 2423, Train Loss: 0.259, Validation Loss: 0.239\n",
      "Epoch: 2424, Train Loss: 0.217, Validation Loss: 0.238\n",
      "Epoch: 2425, Train Loss: 0.192, Validation Loss: 0.238\n",
      "Epoch: 2426, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 2427, Train Loss: 0.255, Validation Loss: 0.238\n",
      "Epoch: 2428, Train Loss: 0.137, Validation Loss: 0.238\n",
      "Epoch: 2429, Train Loss: 0.233, Validation Loss: 0.237\n",
      "Epoch: 2430, Train Loss: 0.171, Validation Loss: 0.237\n",
      "Epoch: 2431, Train Loss: 0.230, Validation Loss: 0.236\n",
      "Epoch: 2432, Train Loss: 0.205, Validation Loss: 0.239\n",
      "Epoch: 2433, Train Loss: 0.198, Validation Loss: 0.239\n",
      "Epoch: 2434, Train Loss: 0.492, Validation Loss: 0.241\n",
      "Epoch: 2435, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 2436, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 2437, Train Loss: 0.457, Validation Loss: 0.240\n",
      "Epoch: 2438, Train Loss: 0.302, Validation Loss: 0.238\n",
      "Epoch: 2439, Train Loss: 0.320, Validation Loss: 0.244\n",
      "Epoch: 2440, Train Loss: 0.249, Validation Loss: 0.239\n",
      "Epoch: 2441, Train Loss: 0.533, Validation Loss: 0.238\n",
      "Epoch: 2442, Train Loss: 0.374, Validation Loss: 0.242\n",
      "Epoch: 2443, Train Loss: 0.314, Validation Loss: 0.241\n",
      "Epoch: 2444, Train Loss: 0.231, Validation Loss: 0.236\n",
      "Epoch: 2445, Train Loss: 0.244, Validation Loss: 0.236\n",
      "Epoch: 2446, Train Loss: 0.364, Validation Loss: 0.240\n",
      "Epoch: 2447, Train Loss: 0.261, Validation Loss: 0.238\n",
      "Epoch: 2448, Train Loss: 0.534, Validation Loss: 0.241\n",
      "Epoch: 2449, Train Loss: 0.272, Validation Loss: 0.238\n",
      "Epoch: 2450, Train Loss: 0.264, Validation Loss: 0.244\n",
      "Epoch: 2451, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2452, Train Loss: 0.229, Validation Loss: 0.236\n",
      "Epoch: 2453, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2454, Train Loss: 0.281, Validation Loss: 0.237\n",
      "Epoch: 2455, Train Loss: 0.232, Validation Loss: 0.237\n",
      "Epoch: 2456, Train Loss: 0.213, Validation Loss: 0.236\n",
      "Epoch: 2457, Train Loss: 0.300, Validation Loss: 0.237\n",
      "Epoch: 2458, Train Loss: 0.269, Validation Loss: 0.239\n",
      "Epoch: 2459, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 2460, Train Loss: 0.272, Validation Loss: 0.241\n",
      "Epoch: 2461, Train Loss: 0.193, Validation Loss: 0.239\n",
      "Epoch: 2462, Train Loss: 0.207, Validation Loss: 0.242\n",
      "Epoch: 2463, Train Loss: 0.297, Validation Loss: 0.238\n",
      "Epoch: 2464, Train Loss: 0.289, Validation Loss: 0.238\n",
      "Epoch: 2465, Train Loss: 0.487, Validation Loss: 0.243\n",
      "Epoch: 2466, Train Loss: 0.268, Validation Loss: 0.239\n",
      "Epoch: 2467, Train Loss: 0.240, Validation Loss: 0.239\n",
      "Epoch: 2468, Train Loss: 0.236, Validation Loss: 0.239\n",
      "Epoch: 2469, Train Loss: 0.430, Validation Loss: 0.240\n",
      "Epoch: 2470, Train Loss: 0.374, Validation Loss: 0.239\n",
      "Epoch: 2471, Train Loss: 0.206, Validation Loss: 0.239\n",
      "Epoch: 2472, Train Loss: 0.236, Validation Loss: 0.238\n",
      "Epoch: 2473, Train Loss: 0.186, Validation Loss: 0.238\n",
      "Epoch: 2474, Train Loss: 0.190, Validation Loss: 0.239\n",
      "Epoch: 2475, Train Loss: 0.382, Validation Loss: 0.239\n",
      "Epoch: 2476, Train Loss: 0.248, Validation Loss: 0.238\n",
      "Epoch: 2477, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 2478, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 2479, Train Loss: 0.221, Validation Loss: 0.242\n",
      "Epoch: 2480, Train Loss: 0.268, Validation Loss: 0.242\n",
      "Epoch: 2481, Train Loss: 0.317, Validation Loss: 0.240\n",
      "Epoch: 2482, Train Loss: 0.279, Validation Loss: 0.239\n",
      "Epoch: 2483, Train Loss: 0.193, Validation Loss: 0.240\n",
      "Epoch: 2484, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 2485, Train Loss: 0.178, Validation Loss: 0.239\n",
      "Epoch: 2486, Train Loss: 0.161, Validation Loss: 0.239\n",
      "Epoch: 2487, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 2488, Train Loss: 0.214, Validation Loss: 0.239\n",
      "Epoch: 2489, Train Loss: 0.260, Validation Loss: 0.242\n",
      "Epoch: 2490, Train Loss: 0.245, Validation Loss: 0.242\n",
      "Epoch: 2491, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 2492, Train Loss: 0.176, Validation Loss: 0.240\n",
      "Epoch: 2493, Train Loss: 0.239, Validation Loss: 0.244\n",
      "Epoch: 2494, Train Loss: 0.304, Validation Loss: 0.241\n",
      "Epoch: 2495, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 2496, Train Loss: 0.308, Validation Loss: 0.239\n",
      "Epoch: 2497, Train Loss: 0.206, Validation Loss: 0.240\n",
      "Epoch: 2498, Train Loss: 0.193, Validation Loss: 0.242\n",
      "Epoch: 2499, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 2500, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 2501, Train Loss: 0.257, Validation Loss: 0.240\n",
      "Epoch: 2502, Train Loss: 0.321, Validation Loss: 0.238\n",
      "Epoch: 2503, Train Loss: 0.284, Validation Loss: 0.241\n",
      "Epoch: 2504, Train Loss: 0.515, Validation Loss: 0.243\n",
      "Epoch: 2505, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 2506, Train Loss: 0.204, Validation Loss: 0.238\n",
      "Epoch: 2507, Train Loss: 0.277, Validation Loss: 0.242\n",
      "Epoch: 2508, Train Loss: 0.278, Validation Loss: 0.240\n",
      "Epoch: 2509, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 2510, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 2511, Train Loss: 0.190, Validation Loss: 0.237\n",
      "Epoch: 2512, Train Loss: 0.236, Validation Loss: 0.237\n",
      "Epoch: 2513, Train Loss: 0.297, Validation Loss: 0.237\n",
      "Epoch: 2514, Train Loss: 0.394, Validation Loss: 0.238\n",
      "Epoch: 2515, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 2516, Train Loss: 0.248, Validation Loss: 0.243\n",
      "Epoch: 2517, Train Loss: 0.435, Validation Loss: 0.238\n",
      "Epoch: 2518, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 2519, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 2520, Train Loss: 0.384, Validation Loss: 0.240\n",
      "Epoch: 2521, Train Loss: 0.305, Validation Loss: 0.240\n",
      "Epoch: 2522, Train Loss: 0.458, Validation Loss: 0.240\n",
      "Epoch: 2523, Train Loss: 0.232, Validation Loss: 0.242\n",
      "Epoch: 2524, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 2525, Train Loss: 0.242, Validation Loss: 0.240\n",
      "Epoch: 2526, Train Loss: 0.460, Validation Loss: 0.245\n",
      "Epoch: 2527, Train Loss: 0.206, Validation Loss: 0.242\n",
      "Epoch: 2528, Train Loss: 0.301, Validation Loss: 0.243\n",
      "Epoch: 2529, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 2530, Train Loss: 0.203, Validation Loss: 0.238\n",
      "Epoch: 2531, Train Loss: 0.238, Validation Loss: 0.238\n",
      "Epoch: 2532, Train Loss: 0.299, Validation Loss: 0.240\n",
      "Epoch: 2533, Train Loss: 0.259, Validation Loss: 0.239\n",
      "Epoch: 2534, Train Loss: 0.210, Validation Loss: 0.239\n",
      "Epoch: 2535, Train Loss: 0.188, Validation Loss: 0.238\n",
      "Epoch: 2536, Train Loss: 0.558, Validation Loss: 0.237\n",
      "Epoch: 2537, Train Loss: 0.304, Validation Loss: 0.239\n",
      "Epoch: 2538, Train Loss: 0.419, Validation Loss: 0.239\n",
      "Epoch: 2539, Train Loss: 0.245, Validation Loss: 0.238\n",
      "Epoch: 2540, Train Loss: 0.190, Validation Loss: 0.238\n",
      "Epoch: 2541, Train Loss: 0.280, Validation Loss: 0.238\n",
      "Epoch: 2542, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 2543, Train Loss: 0.193, Validation Loss: 0.242\n",
      "Epoch: 2544, Train Loss: 0.184, Validation Loss: 0.243\n",
      "Epoch: 2545, Train Loss: 0.281, Validation Loss: 0.242\n",
      "Epoch: 2546, Train Loss: 0.336, Validation Loss: 0.238\n",
      "Epoch: 2547, Train Loss: 0.251, Validation Loss: 0.237\n",
      "Epoch: 2548, Train Loss: 0.365, Validation Loss: 0.236\n",
      "Epoch: 2549, Train Loss: 0.548, Validation Loss: 0.239\n",
      "Epoch: 2550, Train Loss: 0.323, Validation Loss: 0.240\n",
      "Epoch: 2551, Train Loss: 0.355, Validation Loss: 0.238\n",
      "Epoch: 2552, Train Loss: 0.278, Validation Loss: 0.237\n",
      "Epoch: 2553, Train Loss: 0.323, Validation Loss: 0.236\n",
      "Epoch: 2554, Train Loss: 0.267, Validation Loss: 0.236\n",
      "Epoch: 2555, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 2556, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 2557, Train Loss: 0.199, Validation Loss: 0.239\n",
      "Epoch: 2558, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 2559, Train Loss: 0.275, Validation Loss: 0.238\n",
      "Epoch: 2560, Train Loss: 0.342, Validation Loss: 0.240\n",
      "Epoch: 2561, Train Loss: 0.234, Validation Loss: 0.245\n",
      "Epoch: 2562, Train Loss: 0.196, Validation Loss: 0.239\n",
      "Epoch: 2563, Train Loss: 0.196, Validation Loss: 0.239\n",
      "Epoch: 2564, Train Loss: 0.236, Validation Loss: 0.240\n",
      "Epoch: 2565, Train Loss: 0.310, Validation Loss: 0.240\n",
      "Epoch: 2566, Train Loss: 0.275, Validation Loss: 0.239\n",
      "Epoch: 2567, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 2568, Train Loss: 0.245, Validation Loss: 0.240\n",
      "Epoch: 2569, Train Loss: 0.293, Validation Loss: 0.245\n",
      "Epoch: 2570, Train Loss: 0.397, Validation Loss: 0.240\n",
      "Epoch: 2571, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 2572, Train Loss: 0.366, Validation Loss: 0.240\n",
      "Epoch: 2573, Train Loss: 0.447, Validation Loss: 0.239\n",
      "Epoch: 2574, Train Loss: 0.256, Validation Loss: 0.242\n",
      "Epoch: 2575, Train Loss: 0.346, Validation Loss: 0.239\n",
      "Epoch: 2576, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 2577, Train Loss: 0.232, Validation Loss: 0.244\n",
      "Epoch: 2578, Train Loss: 0.480, Validation Loss: 0.240\n",
      "Epoch: 2579, Train Loss: 0.255, Validation Loss: 0.238\n",
      "Epoch: 2580, Train Loss: 0.330, Validation Loss: 0.242\n",
      "Epoch: 2581, Train Loss: 0.276, Validation Loss: 0.237\n",
      "Epoch: 2582, Train Loss: 0.213, Validation Loss: 0.240\n",
      "Epoch: 2583, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 2584, Train Loss: 0.240, Validation Loss: 0.236\n",
      "Epoch: 2585, Train Loss: 0.283, Validation Loss: 0.237\n",
      "Epoch: 2586, Train Loss: 0.402, Validation Loss: 0.239\n",
      "Epoch: 2587, Train Loss: 0.231, Validation Loss: 0.239\n",
      "Epoch: 2588, Train Loss: 0.222, Validation Loss: 0.237\n",
      "Epoch: 2589, Train Loss: 0.282, Validation Loss: 0.237\n",
      "Epoch: 2590, Train Loss: 0.221, Validation Loss: 0.236\n",
      "Epoch: 2591, Train Loss: 0.247, Validation Loss: 0.238\n",
      "Epoch: 2592, Train Loss: 0.177, Validation Loss: 0.239\n",
      "Epoch: 2593, Train Loss: 0.202, Validation Loss: 0.238\n",
      "Epoch: 2594, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 2595, Train Loss: 0.407, Validation Loss: 0.237\n",
      "Epoch: 2596, Train Loss: 0.354, Validation Loss: 0.239\n",
      "Epoch: 2597, Train Loss: 0.181, Validation Loss: 0.236\n",
      "Epoch: 2598, Train Loss: 0.196, Validation Loss: 0.237\n",
      "Epoch: 2599, Train Loss: 0.266, Validation Loss: 0.237\n",
      "Epoch: 2600, Train Loss: 0.256, Validation Loss: 0.236\n",
      "Epoch: 2601, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 2602, Train Loss: 0.376, Validation Loss: 0.237\n",
      "Epoch: 2603, Train Loss: 0.185, Validation Loss: 0.236\n",
      "Epoch: 2604, Train Loss: 0.259, Validation Loss: 0.237\n",
      "Epoch: 2605, Train Loss: 0.339, Validation Loss: 0.237\n",
      "Epoch: 2606, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 2607, Train Loss: 0.214, Validation Loss: 0.237\n",
      "Epoch: 2608, Train Loss: 0.203, Validation Loss: 0.237\n",
      "Epoch: 2609, Train Loss: 0.199, Validation Loss: 0.237\n",
      "Epoch: 2610, Train Loss: 0.301, Validation Loss: 0.240\n",
      "Epoch: 2611, Train Loss: 0.280, Validation Loss: 0.240\n",
      "Epoch: 2612, Train Loss: 0.224, Validation Loss: 0.237\n",
      "Epoch: 2613, Train Loss: 0.224, Validation Loss: 0.236\n",
      "Epoch: 2614, Train Loss: 0.308, Validation Loss: 0.236\n",
      "Epoch: 2615, Train Loss: 0.642, Validation Loss: 0.241\n",
      "Epoch: 2616, Train Loss: 0.250, Validation Loss: 0.238\n",
      "Epoch: 2617, Train Loss: 0.446, Validation Loss: 0.238\n",
      "Epoch: 2618, Train Loss: 0.180, Validation Loss: 0.239\n",
      "Epoch: 2619, Train Loss: 0.228, Validation Loss: 0.237\n",
      "Epoch: 2620, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 2621, Train Loss: 0.305, Validation Loss: 0.240\n",
      "Epoch: 2622, Train Loss: 0.465, Validation Loss: 0.240\n",
      "Epoch: 2623, Train Loss: 0.275, Validation Loss: 0.238\n",
      "Epoch: 2624, Train Loss: 0.345, Validation Loss: 0.239\n",
      "Epoch: 2625, Train Loss: 0.256, Validation Loss: 0.237\n",
      "Epoch: 2626, Train Loss: 0.250, Validation Loss: 0.237\n",
      "Epoch: 2627, Train Loss: 0.334, Validation Loss: 0.236\n",
      "Epoch: 2628, Train Loss: 0.235, Validation Loss: 0.237\n",
      "Epoch: 2629, Train Loss: 0.260, Validation Loss: 0.236\n",
      "Epoch: 2630, Train Loss: 0.161, Validation Loss: 0.237\n",
      "Epoch: 2631, Train Loss: 0.323, Validation Loss: 0.236\n",
      "Epoch: 2632, Train Loss: 0.189, Validation Loss: 0.239\n",
      "Epoch: 2633, Train Loss: 0.244, Validation Loss: 0.240\n",
      "Epoch: 2634, Train Loss: 0.234, Validation Loss: 0.239\n",
      "Epoch: 2635, Train Loss: 0.208, Validation Loss: 0.239\n",
      "Epoch: 2636, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 2637, Train Loss: 0.232, Validation Loss: 0.237\n",
      "Epoch: 2638, Train Loss: 0.245, Validation Loss: 0.238\n",
      "Epoch: 2639, Train Loss: 0.216, Validation Loss: 0.236\n",
      "Epoch: 2640, Train Loss: 0.229, Validation Loss: 0.239\n",
      "Epoch: 2641, Train Loss: 0.335, Validation Loss: 0.236\n",
      "Epoch: 2642, Train Loss: 0.220, Validation Loss: 0.238\n",
      "Epoch: 2643, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 2644, Train Loss: 0.215, Validation Loss: 0.242\n",
      "Epoch: 2645, Train Loss: 0.305, Validation Loss: 0.241\n",
      "Epoch: 2646, Train Loss: 0.238, Validation Loss: 0.237\n",
      "Epoch: 2647, Train Loss: 0.184, Validation Loss: 0.237\n",
      "Epoch: 2648, Train Loss: 0.543, Validation Loss: 0.242\n",
      "Epoch: 2649, Train Loss: 0.223, Validation Loss: 0.237\n",
      "Epoch: 2650, Train Loss: 0.193, Validation Loss: 0.237\n",
      "Epoch: 2651, Train Loss: 0.273, Validation Loss: 0.237\n",
      "Epoch: 2652, Train Loss: 0.211, Validation Loss: 0.234\n",
      "Epoch: 2653, Train Loss: 0.237, Validation Loss: 0.236\n",
      "Epoch: 2654, Train Loss: 0.255, Validation Loss: 0.237\n",
      "Epoch: 2655, Train Loss: 0.177, Validation Loss: 0.237\n",
      "Epoch: 2656, Train Loss: 0.349, Validation Loss: 0.236\n",
      "Epoch: 2657, Train Loss: 0.327, Validation Loss: 0.239\n",
      "Epoch: 2658, Train Loss: 0.248, Validation Loss: 0.237\n",
      "Epoch: 2659, Train Loss: 0.216, Validation Loss: 0.235\n",
      "Epoch: 2660, Train Loss: 0.272, Validation Loss: 0.236\n",
      "Epoch: 2661, Train Loss: 0.213, Validation Loss: 0.239\n",
      "Epoch: 2662, Train Loss: 0.219, Validation Loss: 0.237\n",
      "Epoch: 2663, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 2664, Train Loss: 0.607, Validation Loss: 0.242\n",
      "Epoch: 2665, Train Loss: 0.228, Validation Loss: 0.238\n",
      "Epoch: 2666, Train Loss: 0.315, Validation Loss: 0.239\n",
      "Epoch: 2667, Train Loss: 0.482, Validation Loss: 0.238\n",
      "Epoch: 2668, Train Loss: 0.286, Validation Loss: 0.238\n",
      "Epoch: 2669, Train Loss: 0.200, Validation Loss: 0.237\n",
      "Epoch: 2670, Train Loss: 0.297, Validation Loss: 0.237\n",
      "Epoch: 2671, Train Loss: 0.194, Validation Loss: 0.239\n",
      "Epoch: 2672, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 2673, Train Loss: 0.308, Validation Loss: 0.238\n",
      "Epoch: 2674, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 2675, Train Loss: 0.215, Validation Loss: 0.236\n",
      "Epoch: 2676, Train Loss: 0.287, Validation Loss: 0.238\n",
      "Epoch: 2677, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 2678, Train Loss: 0.203, Validation Loss: 0.237\n",
      "Epoch: 2679, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 2680, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 2681, Train Loss: 0.216, Validation Loss: 0.236\n",
      "Epoch: 2682, Train Loss: 0.251, Validation Loss: 0.236\n",
      "Epoch: 2683, Train Loss: 0.219, Validation Loss: 0.235\n",
      "Epoch: 2684, Train Loss: 0.377, Validation Loss: 0.241\n",
      "Epoch: 2685, Train Loss: 0.382, Validation Loss: 0.243\n",
      "Epoch: 2686, Train Loss: 0.221, Validation Loss: 0.236\n",
      "Epoch: 2687, Train Loss: 0.278, Validation Loss: 0.238\n",
      "Epoch: 2688, Train Loss: 0.280, Validation Loss: 0.238\n",
      "Epoch: 2689, Train Loss: 0.273, Validation Loss: 0.242\n",
      "Epoch: 2690, Train Loss: 0.318, Validation Loss: 0.237\n",
      "Epoch: 2691, Train Loss: 0.280, Validation Loss: 0.239\n",
      "Epoch: 2692, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 2693, Train Loss: 0.214, Validation Loss: 0.238\n",
      "Epoch: 2694, Train Loss: 0.217, Validation Loss: 0.239\n",
      "Epoch: 2695, Train Loss: 0.239, Validation Loss: 0.241\n",
      "Epoch: 2696, Train Loss: 0.268, Validation Loss: 0.241\n",
      "Epoch: 2697, Train Loss: 0.238, Validation Loss: 0.239\n",
      "Epoch: 2698, Train Loss: 0.336, Validation Loss: 0.239\n",
      "Epoch: 2699, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 2700, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 2701, Train Loss: 0.472, Validation Loss: 0.242\n",
      "Epoch: 2702, Train Loss: 0.250, Validation Loss: 0.239\n",
      "Epoch: 2703, Train Loss: 0.247, Validation Loss: 0.239\n",
      "Epoch: 2704, Train Loss: 0.253, Validation Loss: 0.239\n",
      "Epoch: 2705, Train Loss: 0.213, Validation Loss: 0.239\n",
      "Epoch: 2706, Train Loss: 0.296, Validation Loss: 0.237\n",
      "Epoch: 2707, Train Loss: 0.284, Validation Loss: 0.237\n",
      "Epoch: 2708, Train Loss: 0.370, Validation Loss: 0.235\n",
      "Epoch: 2709, Train Loss: 0.386, Validation Loss: 0.235\n",
      "Epoch: 2710, Train Loss: 0.274, Validation Loss: 0.237\n",
      "Epoch: 2711, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 2712, Train Loss: 0.271, Validation Loss: 0.238\n",
      "Epoch: 2713, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 2714, Train Loss: 0.271, Validation Loss: 0.237\n",
      "Epoch: 2715, Train Loss: 0.192, Validation Loss: 0.236\n",
      "Epoch: 2716, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 2717, Train Loss: 0.241, Validation Loss: 0.237\n",
      "Epoch: 2718, Train Loss: 0.196, Validation Loss: 0.236\n",
      "Epoch: 2719, Train Loss: 0.231, Validation Loss: 0.240\n",
      "Epoch: 2720, Train Loss: 0.177, Validation Loss: 0.242\n",
      "Epoch: 2721, Train Loss: 0.209, Validation Loss: 0.242\n",
      "Epoch: 2722, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 2723, Train Loss: 0.220, Validation Loss: 0.237\n",
      "Epoch: 2724, Train Loss: 0.306, Validation Loss: 0.237\n",
      "Epoch: 2725, Train Loss: 0.223, Validation Loss: 0.240\n",
      "Epoch: 2726, Train Loss: 0.271, Validation Loss: 0.239\n",
      "Epoch: 2727, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 2728, Train Loss: 0.170, Validation Loss: 0.239\n",
      "Epoch: 2729, Train Loss: 0.307, Validation Loss: 0.240\n",
      "Epoch: 2730, Train Loss: 0.237, Validation Loss: 0.238\n",
      "Epoch: 2731, Train Loss: 0.320, Validation Loss: 0.241\n",
      "Epoch: 2732, Train Loss: 0.184, Validation Loss: 0.237\n",
      "Epoch: 2733, Train Loss: 0.196, Validation Loss: 0.237\n",
      "Epoch: 2734, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 2735, Train Loss: 0.171, Validation Loss: 0.242\n",
      "Epoch: 2736, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 2737, Train Loss: 0.210, Validation Loss: 0.237\n",
      "Epoch: 2738, Train Loss: 0.257, Validation Loss: 0.239\n",
      "Epoch: 2739, Train Loss: 0.278, Validation Loss: 0.242\n",
      "Epoch: 2740, Train Loss: 0.258, Validation Loss: 0.239\n",
      "Epoch: 2741, Train Loss: 0.279, Validation Loss: 0.239\n",
      "Epoch: 2742, Train Loss: 0.297, Validation Loss: 0.239\n",
      "Epoch: 2743, Train Loss: 0.209, Validation Loss: 0.240\n",
      "Epoch: 2744, Train Loss: 0.245, Validation Loss: 0.238\n",
      "Epoch: 2745, Train Loss: 0.216, Validation Loss: 0.237\n",
      "Epoch: 2746, Train Loss: 0.464, Validation Loss: 0.241\n",
      "Epoch: 2747, Train Loss: 0.353, Validation Loss: 0.240\n",
      "Epoch: 2748, Train Loss: 0.300, Validation Loss: 0.238\n",
      "Epoch: 2749, Train Loss: 0.281, Validation Loss: 0.242\n",
      "Epoch: 2750, Train Loss: 0.217, Validation Loss: 0.241\n",
      "Epoch: 2751, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 2752, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 2753, Train Loss: 0.483, Validation Loss: 0.239\n",
      "Epoch: 2754, Train Loss: 0.208, Validation Loss: 0.239\n",
      "Epoch: 2755, Train Loss: 0.207, Validation Loss: 0.238\n",
      "Epoch: 2756, Train Loss: 0.243, Validation Loss: 0.238\n",
      "Epoch: 2757, Train Loss: 0.174, Validation Loss: 0.239\n",
      "Epoch: 2758, Train Loss: 0.287, Validation Loss: 0.241\n",
      "Epoch: 2759, Train Loss: 0.367, Validation Loss: 0.237\n",
      "Epoch: 2760, Train Loss: 0.186, Validation Loss: 0.238\n",
      "Epoch: 2761, Train Loss: 0.283, Validation Loss: 0.238\n",
      "Epoch: 2762, Train Loss: 0.302, Validation Loss: 0.237\n",
      "Epoch: 2763, Train Loss: 0.279, Validation Loss: 0.237\n",
      "Epoch: 2764, Train Loss: 0.469, Validation Loss: 0.241\n",
      "Epoch: 2765, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 2766, Train Loss: 0.293, Validation Loss: 0.237\n",
      "Epoch: 2767, Train Loss: 0.233, Validation Loss: 0.238\n",
      "Epoch: 2768, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 2769, Train Loss: 0.236, Validation Loss: 0.238\n",
      "Epoch: 2770, Train Loss: 0.322, Validation Loss: 0.238\n",
      "Epoch: 2771, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 2772, Train Loss: 0.541, Validation Loss: 0.246\n",
      "Epoch: 2773, Train Loss: 0.205, Validation Loss: 0.240\n",
      "Epoch: 2774, Train Loss: 0.240, Validation Loss: 0.239\n",
      "Epoch: 2775, Train Loss: 0.205, Validation Loss: 0.238\n",
      "Epoch: 2776, Train Loss: 0.519, Validation Loss: 0.241\n",
      "Epoch: 2777, Train Loss: 0.306, Validation Loss: 0.240\n",
      "Epoch: 2778, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 2779, Train Loss: 0.284, Validation Loss: 0.244\n",
      "Epoch: 2780, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 2781, Train Loss: 0.178, Validation Loss: 0.240\n",
      "Epoch: 2782, Train Loss: 0.248, Validation Loss: 0.240\n",
      "Epoch: 2783, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 2784, Train Loss: 0.184, Validation Loss: 0.239\n",
      "Epoch: 2785, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 2786, Train Loss: 0.412, Validation Loss: 0.241\n",
      "Epoch: 2787, Train Loss: 0.223, Validation Loss: 0.238\n",
      "Epoch: 2788, Train Loss: 0.188, Validation Loss: 0.238\n",
      "Epoch: 2789, Train Loss: 0.317, Validation Loss: 0.242\n",
      "Epoch: 2790, Train Loss: 0.317, Validation Loss: 0.239\n",
      "Epoch: 2791, Train Loss: 0.322, Validation Loss: 0.243\n",
      "Epoch: 2792, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 2793, Train Loss: 0.263, Validation Loss: 0.243\n",
      "Epoch: 2794, Train Loss: 0.297, Validation Loss: 0.242\n",
      "Epoch: 2795, Train Loss: 0.198, Validation Loss: 0.238\n",
      "Epoch: 2796, Train Loss: 0.332, Validation Loss: 0.242\n",
      "Epoch: 2797, Train Loss: 0.328, Validation Loss: 0.240\n",
      "Epoch: 2798, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 2799, Train Loss: 0.449, Validation Loss: 0.243\n",
      "Epoch: 2800, Train Loss: 0.246, Validation Loss: 0.240\n",
      "Epoch: 2801, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 2802, Train Loss: 0.332, Validation Loss: 0.242\n",
      "Epoch: 2803, Train Loss: 0.226, Validation Loss: 0.237\n",
      "Epoch: 2804, Train Loss: 0.229, Validation Loss: 0.239\n",
      "Epoch: 2805, Train Loss: 0.333, Validation Loss: 0.238\n",
      "Epoch: 2806, Train Loss: 0.240, Validation Loss: 0.242\n",
      "Epoch: 2807, Train Loss: 0.295, Validation Loss: 0.237\n",
      "Epoch: 2808, Train Loss: 0.267, Validation Loss: 0.237\n",
      "Epoch: 2809, Train Loss: 0.269, Validation Loss: 0.237\n",
      "Epoch: 2810, Train Loss: 0.172, Validation Loss: 0.241\n",
      "Epoch: 2811, Train Loss: 0.221, Validation Loss: 0.242\n",
      "Epoch: 2812, Train Loss: 0.158, Validation Loss: 0.241\n",
      "Epoch: 2813, Train Loss: 0.310, Validation Loss: 0.238\n",
      "Epoch: 2814, Train Loss: 0.640, Validation Loss: 0.242\n",
      "Epoch: 2815, Train Loss: 0.349, Validation Loss: 0.241\n",
      "Epoch: 2816, Train Loss: 0.231, Validation Loss: 0.240\n",
      "Epoch: 2817, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 2818, Train Loss: 0.236, Validation Loss: 0.239\n",
      "Epoch: 2819, Train Loss: 0.204, Validation Loss: 0.241\n",
      "Epoch: 2820, Train Loss: 0.205, Validation Loss: 0.238\n",
      "Epoch: 2821, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 2822, Train Loss: 0.608, Validation Loss: 0.242\n",
      "Epoch: 2823, Train Loss: 0.282, Validation Loss: 0.240\n",
      "Epoch: 2824, Train Loss: 0.298, Validation Loss: 0.243\n",
      "Epoch: 2825, Train Loss: 0.174, Validation Loss: 0.239\n",
      "Epoch: 2826, Train Loss: 0.198, Validation Loss: 0.241\n",
      "Epoch: 2827, Train Loss: 0.259, Validation Loss: 0.244\n",
      "Epoch: 2828, Train Loss: 0.277, Validation Loss: 0.243\n",
      "Epoch: 2829, Train Loss: 0.296, Validation Loss: 0.239\n",
      "Epoch: 2830, Train Loss: 0.265, Validation Loss: 0.240\n",
      "Epoch: 2831, Train Loss: 0.257, Validation Loss: 0.241\n",
      "Epoch: 2832, Train Loss: 0.233, Validation Loss: 0.243\n",
      "Epoch: 2833, Train Loss: 0.234, Validation Loss: 0.243\n",
      "Epoch: 2834, Train Loss: 0.299, Validation Loss: 0.242\n",
      "Epoch: 2835, Train Loss: 0.189, Validation Loss: 0.240\n",
      "Epoch: 2836, Train Loss: 0.350, Validation Loss: 0.239\n",
      "Epoch: 2837, Train Loss: 0.287, Validation Loss: 0.241\n",
      "Epoch: 2838, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 2839, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 2840, Train Loss: 0.253, Validation Loss: 0.240\n",
      "Epoch: 2841, Train Loss: 0.305, Validation Loss: 0.240\n",
      "Epoch: 2842, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 2843, Train Loss: 0.223, Validation Loss: 0.239\n",
      "Epoch: 2844, Train Loss: 0.228, Validation Loss: 0.240\n",
      "Epoch: 2845, Train Loss: 0.157, Validation Loss: 0.239\n",
      "Epoch: 2846, Train Loss: 0.231, Validation Loss: 0.242\n",
      "Epoch: 2847, Train Loss: 0.239, Validation Loss: 0.241\n",
      "Epoch: 2848, Train Loss: 0.274, Validation Loss: 0.239\n",
      "Epoch: 2849, Train Loss: 0.209, Validation Loss: 0.240\n",
      "Epoch: 2850, Train Loss: 0.357, Validation Loss: 0.244\n",
      "Epoch: 2851, Train Loss: 0.267, Validation Loss: 0.240\n",
      "Epoch: 2852, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 2853, Train Loss: 0.187, Validation Loss: 0.238\n",
      "Epoch: 2854, Train Loss: 0.217, Validation Loss: 0.242\n",
      "Epoch: 2855, Train Loss: 0.622, Validation Loss: 0.240\n",
      "Epoch: 2856, Train Loss: 0.176, Validation Loss: 0.238\n",
      "Epoch: 2857, Train Loss: 0.213, Validation Loss: 0.238\n",
      "Epoch: 2858, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 2859, Train Loss: 0.187, Validation Loss: 0.238\n",
      "Epoch: 2860, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 2861, Train Loss: 0.232, Validation Loss: 0.239\n",
      "Epoch: 2862, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 2863, Train Loss: 0.217, Validation Loss: 0.239\n",
      "Epoch: 2864, Train Loss: 0.357, Validation Loss: 0.239\n",
      "Epoch: 2865, Train Loss: 0.321, Validation Loss: 0.244\n",
      "Epoch: 2866, Train Loss: 0.189, Validation Loss: 0.239\n",
      "Epoch: 2867, Train Loss: 0.381, Validation Loss: 0.240\n",
      "Epoch: 2868, Train Loss: 0.343, Validation Loss: 0.246\n",
      "Epoch: 2869, Train Loss: 0.283, Validation Loss: 0.242\n",
      "Epoch: 2870, Train Loss: 0.341, Validation Loss: 0.239\n",
      "Epoch: 2871, Train Loss: 0.533, Validation Loss: 0.242\n",
      "Epoch: 2872, Train Loss: 0.297, Validation Loss: 0.243\n",
      "Epoch: 2873, Train Loss: 0.209, Validation Loss: 0.240\n",
      "Epoch: 2874, Train Loss: 0.197, Validation Loss: 0.241\n",
      "Epoch: 2875, Train Loss: 0.240, Validation Loss: 0.242\n",
      "Epoch: 2876, Train Loss: 0.190, Validation Loss: 0.239\n",
      "Epoch: 2877, Train Loss: 0.262, Validation Loss: 0.238\n",
      "Epoch: 2878, Train Loss: 0.304, Validation Loss: 0.242\n",
      "Epoch: 2879, Train Loss: 0.186, Validation Loss: 0.241\n",
      "Epoch: 2880, Train Loss: 0.224, Validation Loss: 0.239\n",
      "Epoch: 2881, Train Loss: 0.204, Validation Loss: 0.242\n",
      "Epoch: 2882, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 2883, Train Loss: 0.387, Validation Loss: 0.240\n",
      "Epoch: 2884, Train Loss: 0.262, Validation Loss: 0.239\n",
      "Epoch: 2885, Train Loss: 0.235, Validation Loss: 0.241\n",
      "Epoch: 2886, Train Loss: 0.195, Validation Loss: 0.240\n",
      "Epoch: 2887, Train Loss: 0.188, Validation Loss: 0.239\n",
      "Epoch: 2888, Train Loss: 0.209, Validation Loss: 0.238\n",
      "Epoch: 2889, Train Loss: 0.232, Validation Loss: 0.238\n",
      "Epoch: 2890, Train Loss: 0.147, Validation Loss: 0.239\n",
      "Epoch: 2891, Train Loss: 0.227, Validation Loss: 0.237\n",
      "Epoch: 2892, Train Loss: 0.359, Validation Loss: 0.237\n",
      "Epoch: 2893, Train Loss: 0.213, Validation Loss: 0.237\n",
      "Epoch: 2894, Train Loss: 0.278, Validation Loss: 0.237\n",
      "Epoch: 2895, Train Loss: 0.196, Validation Loss: 0.239\n",
      "Epoch: 2896, Train Loss: 0.221, Validation Loss: 0.238\n",
      "Epoch: 2897, Train Loss: 0.384, Validation Loss: 0.242\n",
      "Epoch: 2898, Train Loss: 0.246, Validation Loss: 0.239\n",
      "Epoch: 2899, Train Loss: 0.234, Validation Loss: 0.239\n",
      "Epoch: 2900, Train Loss: 0.339, Validation Loss: 0.239\n",
      "Epoch: 2901, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 2902, Train Loss: 0.448, Validation Loss: 0.240\n",
      "Epoch: 2903, Train Loss: 0.405, Validation Loss: 0.239\n",
      "Epoch: 2904, Train Loss: 0.253, Validation Loss: 0.237\n",
      "Epoch: 2905, Train Loss: 0.227, Validation Loss: 0.240\n",
      "Epoch: 2906, Train Loss: 0.278, Validation Loss: 0.239\n",
      "Epoch: 2907, Train Loss: 0.452, Validation Loss: 0.237\n",
      "Epoch: 2908, Train Loss: 0.401, Validation Loss: 0.238\n",
      "Epoch: 2909, Train Loss: 0.278, Validation Loss: 0.239\n",
      "Epoch: 2910, Train Loss: 0.291, Validation Loss: 0.244\n",
      "Epoch: 2911, Train Loss: 0.199, Validation Loss: 0.238\n",
      "Epoch: 2912, Train Loss: 0.189, Validation Loss: 0.238\n",
      "Epoch: 2913, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 2914, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 2915, Train Loss: 0.196, Validation Loss: 0.240\n",
      "Epoch: 2916, Train Loss: 0.231, Validation Loss: 0.240\n",
      "Epoch: 2917, Train Loss: 0.359, Validation Loss: 0.240\n",
      "Epoch: 2918, Train Loss: 0.255, Validation Loss: 0.239\n",
      "Epoch: 2919, Train Loss: 0.182, Validation Loss: 0.238\n",
      "Epoch: 2920, Train Loss: 0.195, Validation Loss: 0.239\n",
      "Epoch: 2921, Train Loss: 0.249, Validation Loss: 0.240\n",
      "Epoch: 2922, Train Loss: 0.282, Validation Loss: 0.241\n",
      "Epoch: 2923, Train Loss: 0.217, Validation Loss: 0.239\n",
      "Epoch: 2924, Train Loss: 0.251, Validation Loss: 0.238\n",
      "Epoch: 2925, Train Loss: 0.201, Validation Loss: 0.238\n",
      "Epoch: 2926, Train Loss: 0.254, Validation Loss: 0.239\n",
      "Epoch: 2927, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 2928, Train Loss: 0.392, Validation Loss: 0.238\n",
      "Epoch: 2929, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2930, Train Loss: 0.178, Validation Loss: 0.238\n",
      "Epoch: 2931, Train Loss: 0.209, Validation Loss: 0.238\n",
      "Epoch: 2932, Train Loss: 0.240, Validation Loss: 0.237\n",
      "Epoch: 2933, Train Loss: 0.273, Validation Loss: 0.243\n",
      "Epoch: 2934, Train Loss: 0.253, Validation Loss: 0.238\n",
      "Epoch: 2935, Train Loss: 0.197, Validation Loss: 0.238\n",
      "Epoch: 2936, Train Loss: 0.331, Validation Loss: 0.244\n",
      "Epoch: 2937, Train Loss: 0.289, Validation Loss: 0.237\n",
      "Epoch: 2938, Train Loss: 0.266, Validation Loss: 0.243\n",
      "Epoch: 2939, Train Loss: 0.324, Validation Loss: 0.240\n",
      "Epoch: 2940, Train Loss: 0.194, Validation Loss: 0.239\n",
      "Epoch: 2941, Train Loss: 0.311, Validation Loss: 0.237\n",
      "Epoch: 2942, Train Loss: 0.235, Validation Loss: 0.240\n",
      "Epoch: 2943, Train Loss: 0.561, Validation Loss: 0.242\n",
      "Epoch: 2944, Train Loss: 0.285, Validation Loss: 0.238\n",
      "Epoch: 2945, Train Loss: 0.263, Validation Loss: 0.238\n",
      "Epoch: 2946, Train Loss: 0.192, Validation Loss: 0.239\n",
      "Epoch: 2947, Train Loss: 0.176, Validation Loss: 0.242\n",
      "Epoch: 2948, Train Loss: 0.331, Validation Loss: 0.242\n",
      "Epoch: 2949, Train Loss: 0.202, Validation Loss: 0.242\n",
      "Epoch: 2950, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 2951, Train Loss: 0.277, Validation Loss: 0.239\n",
      "Epoch: 2952, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 2953, Train Loss: 0.361, Validation Loss: 0.240\n",
      "Epoch: 2954, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 2955, Train Loss: 0.235, Validation Loss: 0.238\n",
      "Epoch: 2956, Train Loss: 0.210, Validation Loss: 0.239\n",
      "Epoch: 2957, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 2958, Train Loss: 0.234, Validation Loss: 0.238\n",
      "Epoch: 2959, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 2960, Train Loss: 0.218, Validation Loss: 0.239\n",
      "Epoch: 2961, Train Loss: 0.335, Validation Loss: 0.238\n",
      "Epoch: 2962, Train Loss: 0.190, Validation Loss: 0.238\n",
      "Epoch: 2963, Train Loss: 0.305, Validation Loss: 0.241\n",
      "Epoch: 2964, Train Loss: 0.151, Validation Loss: 0.238\n",
      "Epoch: 2965, Train Loss: 0.318, Validation Loss: 0.237\n",
      "Epoch: 2966, Train Loss: 0.242, Validation Loss: 0.238\n",
      "Epoch: 2967, Train Loss: 0.345, Validation Loss: 0.238\n",
      "Epoch: 2968, Train Loss: 0.220, Validation Loss: 0.238\n",
      "Epoch: 2969, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 2970, Train Loss: 0.372, Validation Loss: 0.236\n",
      "Epoch: 2971, Train Loss: 0.436, Validation Loss: 0.241\n",
      "Epoch: 2972, Train Loss: 0.322, Validation Loss: 0.240\n",
      "Epoch: 2973, Train Loss: 0.221, Validation Loss: 0.237\n",
      "Epoch: 2974, Train Loss: 0.239, Validation Loss: 0.236\n",
      "Epoch: 2975, Train Loss: 0.487, Validation Loss: 0.240\n",
      "Epoch: 2976, Train Loss: 0.206, Validation Loss: 0.239\n",
      "Epoch: 2977, Train Loss: 0.179, Validation Loss: 0.236\n",
      "Epoch: 2978, Train Loss: 0.338, Validation Loss: 0.236\n",
      "Epoch: 2979, Train Loss: 0.269, Validation Loss: 0.236\n",
      "Epoch: 2980, Train Loss: 0.276, Validation Loss: 0.239\n",
      "Epoch: 2981, Train Loss: 0.244, Validation Loss: 0.238\n",
      "Epoch: 2982, Train Loss: 0.387, Validation Loss: 0.240\n",
      "Epoch: 2983, Train Loss: 0.181, Validation Loss: 0.235\n",
      "Epoch: 2984, Train Loss: 0.410, Validation Loss: 0.237\n",
      "Epoch: 2985, Train Loss: 0.228, Validation Loss: 0.238\n",
      "Epoch: 2986, Train Loss: 0.211, Validation Loss: 0.238\n",
      "Epoch: 2987, Train Loss: 0.226, Validation Loss: 0.238\n",
      "Epoch: 2988, Train Loss: 0.239, Validation Loss: 0.237\n",
      "Epoch: 2989, Train Loss: 0.437, Validation Loss: 0.240\n",
      "Epoch: 2990, Train Loss: 0.200, Validation Loss: 0.240\n",
      "Epoch: 2991, Train Loss: 0.281, Validation Loss: 0.239\n",
      "Epoch: 2992, Train Loss: 0.323, Validation Loss: 0.237\n",
      "Epoch: 2993, Train Loss: 0.371, Validation Loss: 0.237\n",
      "Epoch: 2994, Train Loss: 0.156, Validation Loss: 0.239\n",
      "Epoch: 2995, Train Loss: 0.213, Validation Loss: 0.237\n",
      "Epoch: 2996, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 2997, Train Loss: 0.206, Validation Loss: 0.238\n",
      "Epoch: 2998, Train Loss: 0.254, Validation Loss: 0.240\n",
      "Epoch: 2999, Train Loss: 0.367, Validation Loss: 0.240\n",
      "Epoch: 3000, Train Loss: 0.253, Validation Loss: 0.241\n",
      "Epoch: 3001, Train Loss: 0.216, Validation Loss: 0.243\n",
      "Epoch: 3002, Train Loss: 0.281, Validation Loss: 0.240\n",
      "Epoch: 3003, Train Loss: 0.298, Validation Loss: 0.237\n",
      "Epoch: 3004, Train Loss: 0.196, Validation Loss: 0.241\n",
      "Epoch: 3005, Train Loss: 0.211, Validation Loss: 0.237\n",
      "Epoch: 3006, Train Loss: 0.391, Validation Loss: 0.238\n",
      "Epoch: 3007, Train Loss: 0.203, Validation Loss: 0.236\n",
      "Epoch: 3008, Train Loss: 0.312, Validation Loss: 0.238\n",
      "Epoch: 3009, Train Loss: 0.527, Validation Loss: 0.246\n",
      "Epoch: 3010, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 3011, Train Loss: 0.426, Validation Loss: 0.238\n",
      "Epoch: 3012, Train Loss: 0.242, Validation Loss: 0.240\n",
      "Epoch: 3013, Train Loss: 0.221, Validation Loss: 0.240\n",
      "Epoch: 3014, Train Loss: 0.424, Validation Loss: 0.244\n",
      "Epoch: 3015, Train Loss: 0.250, Validation Loss: 0.241\n",
      "Epoch: 3016, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 3017, Train Loss: 0.184, Validation Loss: 0.240\n",
      "Epoch: 3018, Train Loss: 0.166, Validation Loss: 0.242\n",
      "Epoch: 3019, Train Loss: 0.263, Validation Loss: 0.241\n",
      "Epoch: 3020, Train Loss: 0.166, Validation Loss: 0.244\n",
      "Epoch: 3021, Train Loss: 0.186, Validation Loss: 0.240\n",
      "Epoch: 3022, Train Loss: 0.457, Validation Loss: 0.243\n",
      "Epoch: 3023, Train Loss: 0.177, Validation Loss: 0.241\n",
      "Epoch: 3024, Train Loss: 0.426, Validation Loss: 0.241\n",
      "Epoch: 3025, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 3026, Train Loss: 0.252, Validation Loss: 0.240\n",
      "Epoch: 3027, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 3028, Train Loss: 0.224, Validation Loss: 0.243\n",
      "Epoch: 3029, Train Loss: 0.211, Validation Loss: 0.241\n",
      "Epoch: 3030, Train Loss: 0.342, Validation Loss: 0.240\n",
      "Epoch: 3031, Train Loss: 0.411, Validation Loss: 0.241\n",
      "Epoch: 3032, Train Loss: 0.242, Validation Loss: 0.242\n",
      "Epoch: 3033, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 3034, Train Loss: 0.280, Validation Loss: 0.245\n",
      "Epoch: 3035, Train Loss: 0.367, Validation Loss: 0.245\n",
      "Epoch: 3036, Train Loss: 0.216, Validation Loss: 0.240\n",
      "Epoch: 3037, Train Loss: 0.200, Validation Loss: 0.242\n",
      "Epoch: 3038, Train Loss: 0.298, Validation Loss: 0.240\n",
      "Epoch: 3039, Train Loss: 0.241, Validation Loss: 0.240\n",
      "Epoch: 3040, Train Loss: 0.311, Validation Loss: 0.241\n",
      "Epoch: 3041, Train Loss: 0.233, Validation Loss: 0.242\n",
      "Epoch: 3042, Train Loss: 0.218, Validation Loss: 0.240\n",
      "Epoch: 3043, Train Loss: 0.466, Validation Loss: 0.240\n",
      "Epoch: 3044, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 3045, Train Loss: 0.307, Validation Loss: 0.242\n",
      "Epoch: 3046, Train Loss: 0.236, Validation Loss: 0.240\n",
      "Epoch: 3047, Train Loss: 0.298, Validation Loss: 0.241\n",
      "Epoch: 3048, Train Loss: 0.300, Validation Loss: 0.238\n",
      "Epoch: 3049, Train Loss: 0.400, Validation Loss: 0.239\n",
      "Epoch: 3050, Train Loss: 0.269, Validation Loss: 0.239\n",
      "Epoch: 3051, Train Loss: 0.433, Validation Loss: 0.239\n",
      "Epoch: 3052, Train Loss: 0.225, Validation Loss: 0.241\n",
      "Epoch: 3053, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 3054, Train Loss: 0.288, Validation Loss: 0.238\n",
      "Epoch: 3055, Train Loss: 0.174, Validation Loss: 0.241\n",
      "Epoch: 3056, Train Loss: 0.328, Validation Loss: 0.244\n",
      "Epoch: 3057, Train Loss: 0.300, Validation Loss: 0.240\n",
      "Epoch: 3058, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 3059, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 3060, Train Loss: 0.466, Validation Loss: 0.244\n",
      "Epoch: 3061, Train Loss: 0.175, Validation Loss: 0.239\n",
      "Epoch: 3062, Train Loss: 0.209, Validation Loss: 0.241\n",
      "Epoch: 3063, Train Loss: 0.168, Validation Loss: 0.238\n",
      "Epoch: 3064, Train Loss: 0.191, Validation Loss: 0.239\n",
      "Epoch: 3065, Train Loss: 0.267, Validation Loss: 0.240\n",
      "Epoch: 3066, Train Loss: 0.181, Validation Loss: 0.238\n",
      "Epoch: 3067, Train Loss: 0.183, Validation Loss: 0.237\n",
      "Epoch: 3068, Train Loss: 0.165, Validation Loss: 0.239\n",
      "Epoch: 3069, Train Loss: 0.224, Validation Loss: 0.239\n",
      "Epoch: 3070, Train Loss: 0.498, Validation Loss: 0.244\n",
      "Epoch: 3071, Train Loss: 0.186, Validation Loss: 0.242\n",
      "Epoch: 3072, Train Loss: 0.364, Validation Loss: 0.241\n",
      "Epoch: 3073, Train Loss: 0.377, Validation Loss: 0.240\n",
      "Epoch: 3074, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 3075, Train Loss: 0.126, Validation Loss: 0.241\n",
      "Epoch: 3076, Train Loss: 0.236, Validation Loss: 0.240\n",
      "Epoch: 3077, Train Loss: 0.188, Validation Loss: 0.239\n",
      "Epoch: 3078, Train Loss: 0.331, Validation Loss: 0.238\n",
      "Epoch: 3079, Train Loss: 0.305, Validation Loss: 0.237\n",
      "Epoch: 3080, Train Loss: 0.213, Validation Loss: 0.237\n",
      "Epoch: 3081, Train Loss: 0.255, Validation Loss: 0.240\n",
      "Epoch: 3082, Train Loss: 0.225, Validation Loss: 0.245\n",
      "Epoch: 3083, Train Loss: 0.390, Validation Loss: 0.239\n",
      "Epoch: 3084, Train Loss: 0.326, Validation Loss: 0.238\n",
      "Epoch: 3085, Train Loss: 0.390, Validation Loss: 0.238\n",
      "Epoch: 3086, Train Loss: 0.321, Validation Loss: 0.241\n",
      "Epoch: 3087, Train Loss: 0.339, Validation Loss: 0.238\n",
      "Epoch: 3088, Train Loss: 0.299, Validation Loss: 0.238\n",
      "Epoch: 3089, Train Loss: 0.418, Validation Loss: 0.239\n",
      "Epoch: 3090, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 3091, Train Loss: 0.216, Validation Loss: 0.239\n",
      "Epoch: 3092, Train Loss: 0.206, Validation Loss: 0.239\n",
      "Epoch: 3093, Train Loss: 0.274, Validation Loss: 0.239\n",
      "Epoch: 3094, Train Loss: 0.342, Validation Loss: 0.240\n",
      "Epoch: 3095, Train Loss: 0.399, Validation Loss: 0.239\n",
      "Epoch: 3096, Train Loss: 0.203, Validation Loss: 0.240\n",
      "Epoch: 3097, Train Loss: 0.255, Validation Loss: 0.238\n",
      "Epoch: 3098, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 3099, Train Loss: 0.266, Validation Loss: 0.238\n",
      "Epoch: 3100, Train Loss: 0.217, Validation Loss: 0.239\n",
      "Epoch: 3101, Train Loss: 0.214, Validation Loss: 0.237\n",
      "Epoch: 3102, Train Loss: 0.363, Validation Loss: 0.242\n",
      "Epoch: 3103, Train Loss: 0.346, Validation Loss: 0.238\n",
      "Epoch: 3104, Train Loss: 0.240, Validation Loss: 0.236\n",
      "Epoch: 3105, Train Loss: 0.438, Validation Loss: 0.236\n",
      "Epoch: 3106, Train Loss: 0.301, Validation Loss: 0.240\n",
      "Epoch: 3107, Train Loss: 0.302, Validation Loss: 0.239\n",
      "Epoch: 3108, Train Loss: 0.262, Validation Loss: 0.239\n",
      "Epoch: 3109, Train Loss: 0.364, Validation Loss: 0.237\n",
      "Epoch: 3110, Train Loss: 0.277, Validation Loss: 0.237\n",
      "Epoch: 3111, Train Loss: 0.329, Validation Loss: 0.238\n",
      "Epoch: 3112, Train Loss: 0.172, Validation Loss: 0.239\n",
      "Epoch: 3113, Train Loss: 0.253, Validation Loss: 0.243\n",
      "Epoch: 3114, Train Loss: 0.296, Validation Loss: 0.247\n",
      "Epoch: 3115, Train Loss: 0.268, Validation Loss: 0.240\n",
      "Epoch: 3116, Train Loss: 0.311, Validation Loss: 0.238\n",
      "Epoch: 3117, Train Loss: 0.187, Validation Loss: 0.237\n",
      "Epoch: 3118, Train Loss: 0.217, Validation Loss: 0.237\n",
      "Epoch: 3119, Train Loss: 0.239, Validation Loss: 0.239\n",
      "Epoch: 3120, Train Loss: 0.346, Validation Loss: 0.239\n",
      "Epoch: 3121, Train Loss: 0.299, Validation Loss: 0.241\n",
      "Epoch: 3122, Train Loss: 0.204, Validation Loss: 0.239\n",
      "Epoch: 3123, Train Loss: 0.303, Validation Loss: 0.238\n",
      "Epoch: 3124, Train Loss: 0.315, Validation Loss: 0.241\n",
      "Epoch: 3125, Train Loss: 0.237, Validation Loss: 0.239\n",
      "Epoch: 3126, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 3127, Train Loss: 0.220, Validation Loss: 0.241\n",
      "Epoch: 3128, Train Loss: 0.356, Validation Loss: 0.239\n",
      "Epoch: 3129, Train Loss: 0.363, Validation Loss: 0.242\n",
      "Epoch: 3130, Train Loss: 0.212, Validation Loss: 0.240\n",
      "Epoch: 3131, Train Loss: 0.208, Validation Loss: 0.239\n",
      "Epoch: 3132, Train Loss: 0.295, Validation Loss: 0.239\n",
      "Epoch: 3133, Train Loss: 0.257, Validation Loss: 0.240\n",
      "Epoch: 3134, Train Loss: 0.184, Validation Loss: 0.239\n",
      "Epoch: 3135, Train Loss: 0.387, Validation Loss: 0.240\n",
      "Epoch: 3136, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 3137, Train Loss: 0.353, Validation Loss: 0.240\n",
      "Epoch: 3138, Train Loss: 0.357, Validation Loss: 0.242\n",
      "Epoch: 3139, Train Loss: 0.163, Validation Loss: 0.239\n",
      "Epoch: 3140, Train Loss: 0.191, Validation Loss: 0.240\n",
      "Epoch: 3141, Train Loss: 0.499, Validation Loss: 0.242\n",
      "Epoch: 3142, Train Loss: 0.194, Validation Loss: 0.241\n",
      "Epoch: 3143, Train Loss: 0.386, Validation Loss: 0.245\n",
      "Epoch: 3144, Train Loss: 0.201, Validation Loss: 0.239\n",
      "Epoch: 3145, Train Loss: 0.246, Validation Loss: 0.238\n",
      "Epoch: 3146, Train Loss: 0.360, Validation Loss: 0.239\n",
      "Epoch: 3147, Train Loss: 0.209, Validation Loss: 0.241\n",
      "Epoch: 3148, Train Loss: 0.308, Validation Loss: 0.241\n",
      "Epoch: 3149, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 3150, Train Loss: 0.222, Validation Loss: 0.239\n",
      "Epoch: 3151, Train Loss: 0.218, Validation Loss: 0.238\n",
      "Epoch: 3152, Train Loss: 0.282, Validation Loss: 0.245\n",
      "Epoch: 3153, Train Loss: 0.286, Validation Loss: 0.243\n",
      "Epoch: 3154, Train Loss: 0.393, Validation Loss: 0.242\n",
      "Epoch: 3155, Train Loss: 0.307, Validation Loss: 0.238\n",
      "Epoch: 3156, Train Loss: 0.216, Validation Loss: 0.238\n",
      "Epoch: 3157, Train Loss: 0.449, Validation Loss: 0.238\n",
      "Epoch: 3158, Train Loss: 0.347, Validation Loss: 0.239\n",
      "Epoch: 3159, Train Loss: 0.332, Validation Loss: 0.246\n",
      "Epoch: 3160, Train Loss: 0.224, Validation Loss: 0.238\n",
      "Epoch: 3161, Train Loss: 0.256, Validation Loss: 0.239\n",
      "Epoch: 3162, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 3163, Train Loss: 0.335, Validation Loss: 0.242\n",
      "Epoch: 3164, Train Loss: 0.289, Validation Loss: 0.245\n",
      "Epoch: 3165, Train Loss: 0.360, Validation Loss: 0.240\n",
      "Epoch: 3166, Train Loss: 0.218, Validation Loss: 0.241\n",
      "Epoch: 3167, Train Loss: 0.321, Validation Loss: 0.245\n",
      "Epoch: 3168, Train Loss: 0.201, Validation Loss: 0.238\n",
      "Epoch: 3169, Train Loss: 0.244, Validation Loss: 0.238\n",
      "Epoch: 3170, Train Loss: 0.215, Validation Loss: 0.239\n",
      "Epoch: 3171, Train Loss: 0.249, Validation Loss: 0.237\n",
      "Epoch: 3172, Train Loss: 0.236, Validation Loss: 0.241\n",
      "Epoch: 3173, Train Loss: 0.184, Validation Loss: 0.237\n",
      "Epoch: 3174, Train Loss: 0.267, Validation Loss: 0.238\n",
      "Epoch: 3175, Train Loss: 0.414, Validation Loss: 0.238\n",
      "Epoch: 3176, Train Loss: 0.190, Validation Loss: 0.237\n",
      "Epoch: 3177, Train Loss: 0.265, Validation Loss: 0.238\n",
      "Epoch: 3178, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 3179, Train Loss: 0.200, Validation Loss: 0.239\n",
      "Epoch: 3180, Train Loss: 0.197, Validation Loss: 0.239\n",
      "Epoch: 3181, Train Loss: 0.288, Validation Loss: 0.237\n",
      "Epoch: 3182, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 3183, Train Loss: 0.188, Validation Loss: 0.239\n",
      "Epoch: 3184, Train Loss: 0.299, Validation Loss: 0.240\n",
      "Epoch: 3185, Train Loss: 0.291, Validation Loss: 0.240\n",
      "Epoch: 3186, Train Loss: 0.314, Validation Loss: 0.238\n",
      "Epoch: 3187, Train Loss: 0.404, Validation Loss: 0.237\n",
      "Epoch: 3188, Train Loss: 0.218, Validation Loss: 0.237\n",
      "Epoch: 3189, Train Loss: 0.210, Validation Loss: 0.238\n",
      "Epoch: 3190, Train Loss: 0.321, Validation Loss: 0.242\n",
      "Epoch: 3191, Train Loss: 0.433, Validation Loss: 0.241\n",
      "Epoch: 3192, Train Loss: 0.313, Validation Loss: 0.238\n",
      "Epoch: 3193, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 3194, Train Loss: 0.230, Validation Loss: 0.245\n",
      "Epoch: 3195, Train Loss: 0.204, Validation Loss: 0.240\n",
      "Epoch: 3196, Train Loss: 0.432, Validation Loss: 0.240\n",
      "Epoch: 3197, Train Loss: 0.248, Validation Loss: 0.240\n",
      "Epoch: 3198, Train Loss: 0.441, Validation Loss: 0.241\n",
      "Epoch: 3199, Train Loss: 0.367, Validation Loss: 0.240\n",
      "Epoch: 3200, Train Loss: 0.290, Validation Loss: 0.242\n",
      "Epoch: 3201, Train Loss: 0.325, Validation Loss: 0.248\n",
      "Epoch: 3202, Train Loss: 0.255, Validation Loss: 0.241\n",
      "Epoch: 3203, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 3204, Train Loss: 0.226, Validation Loss: 0.239\n",
      "Epoch: 3205, Train Loss: 0.270, Validation Loss: 0.239\n",
      "Epoch: 3206, Train Loss: 0.390, Validation Loss: 0.240\n",
      "Epoch: 3207, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 3208, Train Loss: 0.233, Validation Loss: 0.241\n",
      "Epoch: 3209, Train Loss: 0.211, Validation Loss: 0.240\n",
      "Epoch: 3210, Train Loss: 0.330, Validation Loss: 0.243\n",
      "Epoch: 3211, Train Loss: 0.295, Validation Loss: 0.242\n",
      "Epoch: 3212, Train Loss: 0.229, Validation Loss: 0.243\n",
      "Epoch: 3213, Train Loss: 0.404, Validation Loss: 0.239\n",
      "Epoch: 3214, Train Loss: 0.238, Validation Loss: 0.242\n",
      "Epoch: 3215, Train Loss: 0.225, Validation Loss: 0.249\n",
      "Epoch: 3216, Train Loss: 0.305, Validation Loss: 0.247\n",
      "Epoch: 3217, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 3218, Train Loss: 0.504, Validation Loss: 0.244\n",
      "Epoch: 3219, Train Loss: 0.218, Validation Loss: 0.242\n",
      "Epoch: 3220, Train Loss: 0.259, Validation Loss: 0.246\n",
      "Epoch: 3221, Train Loss: 0.174, Validation Loss: 0.241\n",
      "Epoch: 3222, Train Loss: 0.258, Validation Loss: 0.241\n",
      "Epoch: 3223, Train Loss: 0.309, Validation Loss: 0.242\n",
      "Epoch: 3224, Train Loss: 0.163, Validation Loss: 0.241\n",
      "Epoch: 3225, Train Loss: 0.218, Validation Loss: 0.241\n",
      "Epoch: 3226, Train Loss: 0.255, Validation Loss: 0.243\n",
      "Epoch: 3227, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 3228, Train Loss: 0.264, Validation Loss: 0.241\n",
      "Epoch: 3229, Train Loss: 0.305, Validation Loss: 0.242\n",
      "Epoch: 3230, Train Loss: 0.212, Validation Loss: 0.247\n",
      "Epoch: 3231, Train Loss: 0.264, Validation Loss: 0.245\n",
      "Epoch: 3232, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 3233, Train Loss: 0.217, Validation Loss: 0.240\n",
      "Epoch: 3234, Train Loss: 0.348, Validation Loss: 0.244\n",
      "Epoch: 3235, Train Loss: 0.208, Validation Loss: 0.239\n",
      "Epoch: 3236, Train Loss: 0.396, Validation Loss: 0.244\n",
      "Epoch: 3237, Train Loss: 0.292, Validation Loss: 0.238\n",
      "Epoch: 3238, Train Loss: 0.282, Validation Loss: 0.240\n",
      "Epoch: 3239, Train Loss: 0.235, Validation Loss: 0.244\n",
      "Epoch: 3240, Train Loss: 0.246, Validation Loss: 0.249\n",
      "Epoch: 3241, Train Loss: 0.289, Validation Loss: 0.242\n",
      "Epoch: 3242, Train Loss: 0.372, Validation Loss: 0.238\n",
      "Epoch: 3243, Train Loss: 0.305, Validation Loss: 0.239\n",
      "Epoch: 3244, Train Loss: 0.223, Validation Loss: 0.244\n",
      "Epoch: 3245, Train Loss: 0.279, Validation Loss: 0.239\n",
      "Epoch: 3246, Train Loss: 0.276, Validation Loss: 0.242\n",
      "Epoch: 3247, Train Loss: 0.212, Validation Loss: 0.243\n",
      "Epoch: 3248, Train Loss: 0.160, Validation Loss: 0.241\n",
      "Epoch: 3249, Train Loss: 0.219, Validation Loss: 0.241\n",
      "Epoch: 3250, Train Loss: 0.232, Validation Loss: 0.241\n",
      "Epoch: 3251, Train Loss: 0.186, Validation Loss: 0.241\n",
      "Epoch: 3252, Train Loss: 0.256, Validation Loss: 0.239\n",
      "Epoch: 3253, Train Loss: 0.335, Validation Loss: 0.239\n",
      "Epoch: 3254, Train Loss: 0.239, Validation Loss: 0.244\n",
      "Epoch: 3255, Train Loss: 0.256, Validation Loss: 0.242\n",
      "Epoch: 3256, Train Loss: 0.302, Validation Loss: 0.243\n",
      "Epoch: 3257, Train Loss: 0.177, Validation Loss: 0.240\n",
      "Epoch: 3258, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 3259, Train Loss: 0.301, Validation Loss: 0.240\n",
      "Epoch: 3260, Train Loss: 0.493, Validation Loss: 0.240\n",
      "Epoch: 3261, Train Loss: 0.254, Validation Loss: 0.242\n",
      "Epoch: 3262, Train Loss: 0.263, Validation Loss: 0.241\n",
      "Epoch: 3263, Train Loss: 0.246, Validation Loss: 0.241\n",
      "Epoch: 3264, Train Loss: 0.178, Validation Loss: 0.241\n",
      "Epoch: 3265, Train Loss: 0.207, Validation Loss: 0.242\n",
      "Epoch: 3266, Train Loss: 0.447, Validation Loss: 0.251\n",
      "Epoch: 3267, Train Loss: 0.281, Validation Loss: 0.243\n",
      "Epoch: 3268, Train Loss: 0.267, Validation Loss: 0.242\n",
      "Epoch: 3269, Train Loss: 0.328, Validation Loss: 0.248\n",
      "Epoch: 3270, Train Loss: 0.220, Validation Loss: 0.239\n",
      "Epoch: 3271, Train Loss: 0.296, Validation Loss: 0.239\n",
      "Epoch: 3272, Train Loss: 0.279, Validation Loss: 0.244\n",
      "Epoch: 3273, Train Loss: 0.284, Validation Loss: 0.243\n",
      "Epoch: 3274, Train Loss: 0.248, Validation Loss: 0.244\n",
      "Epoch: 3275, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 3276, Train Loss: 0.357, Validation Loss: 0.245\n",
      "Epoch: 3277, Train Loss: 0.250, Validation Loss: 0.240\n",
      "Epoch: 3278, Train Loss: 0.224, Validation Loss: 0.243\n",
      "Epoch: 3279, Train Loss: 0.208, Validation Loss: 0.240\n",
      "Epoch: 3280, Train Loss: 0.208, Validation Loss: 0.244\n",
      "Epoch: 3281, Train Loss: 0.226, Validation Loss: 0.240\n",
      "Epoch: 3282, Train Loss: 0.205, Validation Loss: 0.244\n",
      "Epoch: 3283, Train Loss: 0.294, Validation Loss: 0.244\n",
      "Epoch: 3284, Train Loss: 0.351, Validation Loss: 0.241\n",
      "Epoch: 3285, Train Loss: 0.277, Validation Loss: 0.242\n",
      "Epoch: 3286, Train Loss: 0.613, Validation Loss: 0.246\n",
      "Epoch: 3287, Train Loss: 0.194, Validation Loss: 0.243\n",
      "Epoch: 3288, Train Loss: 0.338, Validation Loss: 0.241\n",
      "Epoch: 3289, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 3290, Train Loss: 0.204, Validation Loss: 0.244\n",
      "Epoch: 3291, Train Loss: 0.172, Validation Loss: 0.242\n",
      "Epoch: 3292, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 3293, Train Loss: 0.378, Validation Loss: 0.247\n",
      "Epoch: 3294, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 3295, Train Loss: 0.221, Validation Loss: 0.239\n",
      "Epoch: 3296, Train Loss: 0.230, Validation Loss: 0.238\n",
      "Epoch: 3297, Train Loss: 0.317, Validation Loss: 0.239\n",
      "Epoch: 3298, Train Loss: 0.234, Validation Loss: 0.240\n",
      "Epoch: 3299, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 3300, Train Loss: 0.205, Validation Loss: 0.243\n",
      "Epoch: 3301, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 3302, Train Loss: 0.414, Validation Loss: 0.242\n",
      "Epoch: 3303, Train Loss: 0.288, Validation Loss: 0.241\n",
      "Epoch: 3304, Train Loss: 0.190, Validation Loss: 0.243\n",
      "Epoch: 3305, Train Loss: 0.202, Validation Loss: 0.240\n",
      "Epoch: 3306, Train Loss: 0.197, Validation Loss: 0.239\n",
      "Epoch: 3307, Train Loss: 0.491, Validation Loss: 0.240\n",
      "Epoch: 3308, Train Loss: 0.379, Validation Loss: 0.241\n",
      "Epoch: 3309, Train Loss: 0.205, Validation Loss: 0.245\n",
      "Epoch: 3310, Train Loss: 0.176, Validation Loss: 0.241\n",
      "Epoch: 3311, Train Loss: 0.347, Validation Loss: 0.241\n",
      "Epoch: 3312, Train Loss: 0.393, Validation Loss: 0.245\n",
      "Epoch: 3313, Train Loss: 0.284, Validation Loss: 0.241\n",
      "Epoch: 3314, Train Loss: 0.468, Validation Loss: 0.250\n",
      "Epoch: 3315, Train Loss: 0.268, Validation Loss: 0.243\n",
      "Epoch: 3316, Train Loss: 0.244, Validation Loss: 0.246\n",
      "Epoch: 3317, Train Loss: 0.139, Validation Loss: 0.243\n",
      "Epoch: 3318, Train Loss: 0.267, Validation Loss: 0.243\n",
      "Epoch: 3319, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 3320, Train Loss: 0.460, Validation Loss: 0.245\n",
      "Epoch: 3321, Train Loss: 0.250, Validation Loss: 0.243\n",
      "Epoch: 3322, Train Loss: 0.427, Validation Loss: 0.254\n",
      "Epoch: 3323, Train Loss: 0.310, Validation Loss: 0.244\n",
      "Epoch: 3324, Train Loss: 0.417, Validation Loss: 0.242\n",
      "Epoch: 3325, Train Loss: 0.325, Validation Loss: 0.241\n",
      "Epoch: 3326, Train Loss: 0.191, Validation Loss: 0.245\n",
      "Epoch: 3327, Train Loss: 0.521, Validation Loss: 0.241\n",
      "Epoch: 3328, Train Loss: 0.351, Validation Loss: 0.248\n",
      "Epoch: 3329, Train Loss: 0.180, Validation Loss: 0.247\n",
      "Epoch: 3330, Train Loss: 0.264, Validation Loss: 0.240\n",
      "Epoch: 3331, Train Loss: 0.177, Validation Loss: 0.242\n",
      "Epoch: 3332, Train Loss: 0.243, Validation Loss: 0.245\n",
      "Epoch: 3333, Train Loss: 0.261, Validation Loss: 0.243\n",
      "Epoch: 3334, Train Loss: 0.349, Validation Loss: 0.240\n",
      "Epoch: 3335, Train Loss: 0.257, Validation Loss: 0.242\n",
      "Epoch: 3336, Train Loss: 0.168, Validation Loss: 0.246\n",
      "Epoch: 3337, Train Loss: 0.214, Validation Loss: 0.244\n",
      "Epoch: 3338, Train Loss: 0.208, Validation Loss: 0.243\n",
      "Epoch: 3339, Train Loss: 0.170, Validation Loss: 0.241\n",
      "Epoch: 3340, Train Loss: 0.463, Validation Loss: 0.243\n",
      "Epoch: 3341, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 3342, Train Loss: 0.317, Validation Loss: 0.244\n",
      "Epoch: 3343, Train Loss: 0.229, Validation Loss: 0.244\n",
      "Epoch: 3344, Train Loss: 0.252, Validation Loss: 0.244\n",
      "Epoch: 3345, Train Loss: 0.234, Validation Loss: 0.244\n",
      "Epoch: 3346, Train Loss: 0.252, Validation Loss: 0.241\n",
      "Epoch: 3347, Train Loss: 0.239, Validation Loss: 0.241\n",
      "Epoch: 3348, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 3349, Train Loss: 0.312, Validation Loss: 0.244\n",
      "Epoch: 3350, Train Loss: 0.251, Validation Loss: 0.240\n",
      "Epoch: 3351, Train Loss: 0.269, Validation Loss: 0.241\n",
      "Epoch: 3352, Train Loss: 0.580, Validation Loss: 0.248\n",
      "Epoch: 3353, Train Loss: 0.187, Validation Loss: 0.243\n",
      "Epoch: 3354, Train Loss: 0.205, Validation Loss: 0.241\n",
      "Epoch: 3355, Train Loss: 0.260, Validation Loss: 0.243\n",
      "Epoch: 3356, Train Loss: 0.392, Validation Loss: 0.242\n",
      "Epoch: 3357, Train Loss: 0.486, Validation Loss: 0.245\n",
      "Epoch: 3358, Train Loss: 0.244, Validation Loss: 0.247\n",
      "Epoch: 3359, Train Loss: 0.233, Validation Loss: 0.250\n",
      "Epoch: 3360, Train Loss: 0.357, Validation Loss: 0.241\n",
      "Epoch: 3361, Train Loss: 0.328, Validation Loss: 0.242\n",
      "Epoch: 3362, Train Loss: 0.191, Validation Loss: 0.244\n",
      "Epoch: 3363, Train Loss: 0.242, Validation Loss: 0.246\n",
      "Epoch: 3364, Train Loss: 0.261, Validation Loss: 0.242\n",
      "Epoch: 3365, Train Loss: 0.313, Validation Loss: 0.240\n",
      "Epoch: 3366, Train Loss: 0.261, Validation Loss: 0.242\n",
      "Epoch: 3367, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 3368, Train Loss: 0.248, Validation Loss: 0.242\n",
      "Epoch: 3369, Train Loss: 0.278, Validation Loss: 0.241\n",
      "Epoch: 3370, Train Loss: 0.513, Validation Loss: 0.245\n",
      "Epoch: 3371, Train Loss: 0.262, Validation Loss: 0.241\n",
      "Epoch: 3372, Train Loss: 0.280, Validation Loss: 0.243\n",
      "Epoch: 3373, Train Loss: 0.357, Validation Loss: 0.241\n",
      "Epoch: 3374, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 3375, Train Loss: 0.349, Validation Loss: 0.242\n",
      "Epoch: 3376, Train Loss: 0.291, Validation Loss: 0.248\n",
      "Epoch: 3377, Train Loss: 0.147, Validation Loss: 0.244\n",
      "Epoch: 3378, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 3379, Train Loss: 0.268, Validation Loss: 0.240\n",
      "Epoch: 3380, Train Loss: 0.228, Validation Loss: 0.239\n",
      "Epoch: 3381, Train Loss: 0.263, Validation Loss: 0.241\n",
      "Epoch: 3382, Train Loss: 0.379, Validation Loss: 0.242\n",
      "Epoch: 3383, Train Loss: 0.279, Validation Loss: 0.243\n",
      "Epoch: 3384, Train Loss: 0.253, Validation Loss: 0.246\n",
      "Epoch: 3385, Train Loss: 0.267, Validation Loss: 0.244\n",
      "Epoch: 3386, Train Loss: 0.203, Validation Loss: 0.240\n",
      "Epoch: 3387, Train Loss: 0.261, Validation Loss: 0.239\n",
      "Epoch: 3388, Train Loss: 0.250, Validation Loss: 0.240\n",
      "Epoch: 3389, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 3390, Train Loss: 0.351, Validation Loss: 0.243\n",
      "Epoch: 3391, Train Loss: 0.292, Validation Loss: 0.245\n",
      "Epoch: 3392, Train Loss: 0.406, Validation Loss: 0.240\n",
      "Epoch: 3393, Train Loss: 0.197, Validation Loss: 0.242\n",
      "Epoch: 3394, Train Loss: 0.206, Validation Loss: 0.241\n",
      "Epoch: 3395, Train Loss: 0.205, Validation Loss: 0.243\n",
      "Epoch: 3396, Train Loss: 0.306, Validation Loss: 0.246\n",
      "Epoch: 3397, Train Loss: 0.242, Validation Loss: 0.243\n",
      "Epoch: 3398, Train Loss: 0.497, Validation Loss: 0.239\n",
      "Epoch: 3399, Train Loss: 0.248, Validation Loss: 0.239\n",
      "Epoch: 3400, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 3401, Train Loss: 0.211, Validation Loss: 0.242\n",
      "Epoch: 3402, Train Loss: 0.303, Validation Loss: 0.241\n",
      "Epoch: 3403, Train Loss: 0.252, Validation Loss: 0.247\n",
      "Epoch: 3404, Train Loss: 0.248, Validation Loss: 0.245\n",
      "Epoch: 3405, Train Loss: 0.196, Validation Loss: 0.246\n",
      "Epoch: 3406, Train Loss: 0.180, Validation Loss: 0.241\n",
      "Epoch: 3407, Train Loss: 0.260, Validation Loss: 0.244\n",
      "Epoch: 3408, Train Loss: 0.256, Validation Loss: 0.242\n",
      "Epoch: 3409, Train Loss: 0.190, Validation Loss: 0.243\n",
      "Epoch: 3410, Train Loss: 0.309, Validation Loss: 0.241\n",
      "Epoch: 3411, Train Loss: 0.238, Validation Loss: 0.245\n",
      "Epoch: 3412, Train Loss: 0.211, Validation Loss: 0.245\n",
      "Epoch: 3413, Train Loss: 0.212, Validation Loss: 0.245\n",
      "Epoch: 3414, Train Loss: 0.237, Validation Loss: 0.244\n",
      "Epoch: 3415, Train Loss: 0.212, Validation Loss: 0.244\n",
      "Epoch: 3416, Train Loss: 0.253, Validation Loss: 0.242\n",
      "Epoch: 3417, Train Loss: 0.299, Validation Loss: 0.242\n",
      "Epoch: 3418, Train Loss: 0.213, Validation Loss: 0.243\n",
      "Epoch: 3419, Train Loss: 0.557, Validation Loss: 0.243\n",
      "Epoch: 3420, Train Loss: 0.231, Validation Loss: 0.243\n",
      "Epoch: 3421, Train Loss: 0.271, Validation Loss: 0.246\n",
      "Epoch: 3422, Train Loss: 0.347, Validation Loss: 0.245\n",
      "Epoch: 3423, Train Loss: 0.319, Validation Loss: 0.244\n",
      "Epoch: 3424, Train Loss: 0.187, Validation Loss: 0.242\n",
      "Epoch: 3425, Train Loss: 0.252, Validation Loss: 0.243\n",
      "Epoch: 3426, Train Loss: 0.230, Validation Loss: 0.241\n",
      "Epoch: 3427, Train Loss: 0.524, Validation Loss: 0.245\n",
      "Epoch: 3428, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 3429, Train Loss: 0.383, Validation Loss: 0.243\n",
      "Epoch: 3430, Train Loss: 0.342, Validation Loss: 0.241\n",
      "Epoch: 3431, Train Loss: 0.288, Validation Loss: 0.241\n",
      "Epoch: 3432, Train Loss: 0.215, Validation Loss: 0.243\n",
      "Epoch: 3433, Train Loss: 0.248, Validation Loss: 0.242\n",
      "Epoch: 3434, Train Loss: 0.237, Validation Loss: 0.241\n",
      "Epoch: 3435, Train Loss: 0.367, Validation Loss: 0.241\n",
      "Epoch: 3436, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 3437, Train Loss: 0.206, Validation Loss: 0.242\n",
      "Epoch: 3438, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 3439, Train Loss: 0.212, Validation Loss: 0.245\n",
      "Epoch: 3440, Train Loss: 0.191, Validation Loss: 0.242\n",
      "Epoch: 3441, Train Loss: 0.154, Validation Loss: 0.240\n",
      "Epoch: 3442, Train Loss: 0.353, Validation Loss: 0.245\n",
      "Epoch: 3443, Train Loss: 0.271, Validation Loss: 0.242\n",
      "Epoch: 3444, Train Loss: 0.498, Validation Loss: 0.239\n",
      "Epoch: 3445, Train Loss: 0.181, Validation Loss: 0.240\n",
      "Epoch: 3446, Train Loss: 0.168, Validation Loss: 0.241\n",
      "Epoch: 3447, Train Loss: 0.204, Validation Loss: 0.244\n",
      "Epoch: 3448, Train Loss: 0.596, Validation Loss: 0.241\n",
      "Epoch: 3449, Train Loss: 0.228, Validation Loss: 0.241\n",
      "Epoch: 3450, Train Loss: 0.247, Validation Loss: 0.239\n",
      "Epoch: 3451, Train Loss: 0.219, Validation Loss: 0.239\n",
      "Epoch: 3452, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 3453, Train Loss: 0.192, Validation Loss: 0.242\n",
      "Epoch: 3454, Train Loss: 0.165, Validation Loss: 0.245\n",
      "Epoch: 3455, Train Loss: 0.232, Validation Loss: 0.245\n",
      "Epoch: 3456, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 3457, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 3458, Train Loss: 0.271, Validation Loss: 0.242\n",
      "Epoch: 3459, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 3460, Train Loss: 0.229, Validation Loss: 0.240\n",
      "Epoch: 3461, Train Loss: 0.276, Validation Loss: 0.240\n",
      "Epoch: 3462, Train Loss: 0.347, Validation Loss: 0.240\n",
      "Epoch: 3463, Train Loss: 0.597, Validation Loss: 0.243\n",
      "Epoch: 3464, Train Loss: 0.207, Validation Loss: 0.239\n",
      "Epoch: 3465, Train Loss: 0.201, Validation Loss: 0.240\n",
      "Epoch: 3466, Train Loss: 0.479, Validation Loss: 0.243\n",
      "Epoch: 3467, Train Loss: 0.321, Validation Loss: 0.240\n",
      "Epoch: 3468, Train Loss: 0.348, Validation Loss: 0.242\n",
      "Epoch: 3469, Train Loss: 0.221, Validation Loss: 0.243\n",
      "Epoch: 3470, Train Loss: 0.182, Validation Loss: 0.241\n",
      "Epoch: 3471, Train Loss: 0.208, Validation Loss: 0.242\n",
      "Epoch: 3472, Train Loss: 0.230, Validation Loss: 0.244\n",
      "Epoch: 3473, Train Loss: 0.197, Validation Loss: 0.241\n",
      "Epoch: 3474, Train Loss: 0.268, Validation Loss: 0.241\n",
      "Epoch: 3475, Train Loss: 0.377, Validation Loss: 0.247\n",
      "Epoch: 3476, Train Loss: 0.227, Validation Loss: 0.239\n",
      "Epoch: 3477, Train Loss: 0.340, Validation Loss: 0.242\n",
      "Epoch: 3478, Train Loss: 0.405, Validation Loss: 0.243\n",
      "Epoch: 3479, Train Loss: 0.242, Validation Loss: 0.243\n",
      "Epoch: 3480, Train Loss: 0.588, Validation Loss: 0.241\n",
      "Epoch: 3481, Train Loss: 0.309, Validation Loss: 0.242\n",
      "Epoch: 3482, Train Loss: 0.231, Validation Loss: 0.243\n",
      "Epoch: 3483, Train Loss: 0.230, Validation Loss: 0.240\n",
      "Epoch: 3484, Train Loss: 0.419, Validation Loss: 0.245\n",
      "Epoch: 3485, Train Loss: 0.685, Validation Loss: 0.245\n",
      "Epoch: 3486, Train Loss: 0.244, Validation Loss: 0.241\n",
      "Epoch: 3487, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 3488, Train Loss: 0.430, Validation Loss: 0.241\n",
      "Epoch: 3489, Train Loss: 0.270, Validation Loss: 0.240\n",
      "Epoch: 3490, Train Loss: 0.223, Validation Loss: 0.244\n",
      "Epoch: 3491, Train Loss: 0.229, Validation Loss: 0.243\n",
      "Epoch: 3492, Train Loss: 0.182, Validation Loss: 0.241\n",
      "Epoch: 3493, Train Loss: 0.262, Validation Loss: 0.238\n",
      "Epoch: 3494, Train Loss: 0.426, Validation Loss: 0.240\n",
      "Epoch: 3495, Train Loss: 0.208, Validation Loss: 0.237\n",
      "Epoch: 3496, Train Loss: 0.254, Validation Loss: 0.238\n",
      "Epoch: 3497, Train Loss: 0.299, Validation Loss: 0.245\n",
      "Epoch: 3498, Train Loss: 0.213, Validation Loss: 0.242\n",
      "Epoch: 3499, Train Loss: 0.116, Validation Loss: 0.238\n",
      "Epoch: 3500, Train Loss: 0.233, Validation Loss: 0.239\n",
      "Epoch: 3501, Train Loss: 0.264, Validation Loss: 0.238\n",
      "Epoch: 3502, Train Loss: 0.291, Validation Loss: 0.243\n",
      "Epoch: 3503, Train Loss: 0.275, Validation Loss: 0.244\n",
      "Epoch: 3504, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 3505, Train Loss: 0.233, Validation Loss: 0.241\n",
      "Epoch: 3506, Train Loss: 0.231, Validation Loss: 0.243\n",
      "Epoch: 3507, Train Loss: 0.167, Validation Loss: 0.243\n",
      "Epoch: 3508, Train Loss: 0.309, Validation Loss: 0.248\n",
      "Epoch: 3509, Train Loss: 0.241, Validation Loss: 0.245\n",
      "Epoch: 3510, Train Loss: 0.379, Validation Loss: 0.243\n",
      "Epoch: 3511, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 3512, Train Loss: 0.269, Validation Loss: 0.241\n",
      "Epoch: 3513, Train Loss: 0.330, Validation Loss: 0.240\n",
      "Epoch: 3514, Train Loss: 0.306, Validation Loss: 0.241\n",
      "Epoch: 3515, Train Loss: 0.195, Validation Loss: 0.241\n",
      "Epoch: 3516, Train Loss: 0.562, Validation Loss: 0.241\n",
      "Epoch: 3517, Train Loss: 0.184, Validation Loss: 0.245\n",
      "Epoch: 3518, Train Loss: 0.417, Validation Loss: 0.240\n",
      "Epoch: 3519, Train Loss: 0.512, Validation Loss: 0.244\n",
      "Epoch: 3520, Train Loss: 0.259, Validation Loss: 0.247\n",
      "Epoch: 3521, Train Loss: 0.231, Validation Loss: 0.242\n",
      "Epoch: 3522, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 3523, Train Loss: 0.241, Validation Loss: 0.245\n",
      "Epoch: 3524, Train Loss: 0.422, Validation Loss: 0.246\n",
      "Epoch: 3525, Train Loss: 0.270, Validation Loss: 0.247\n",
      "Epoch: 3526, Train Loss: 0.314, Validation Loss: 0.241\n",
      "Epoch: 3527, Train Loss: 0.198, Validation Loss: 0.243\n",
      "Epoch: 3528, Train Loss: 0.399, Validation Loss: 0.242\n",
      "Epoch: 3529, Train Loss: 0.360, Validation Loss: 0.242\n",
      "Epoch: 3530, Train Loss: 0.227, Validation Loss: 0.244\n",
      "Epoch: 3531, Train Loss: 0.234, Validation Loss: 0.243\n",
      "Epoch: 3532, Train Loss: 0.289, Validation Loss: 0.244\n",
      "Epoch: 3533, Train Loss: 0.229, Validation Loss: 0.244\n",
      "Epoch: 3534, Train Loss: 0.331, Validation Loss: 0.244\n",
      "Epoch: 3535, Train Loss: 0.425, Validation Loss: 0.243\n",
      "Epoch: 3536, Train Loss: 0.204, Validation Loss: 0.242\n",
      "Epoch: 3537, Train Loss: 0.221, Validation Loss: 0.240\n",
      "Epoch: 3538, Train Loss: 0.187, Validation Loss: 0.240\n",
      "Epoch: 3539, Train Loss: 0.478, Validation Loss: 0.243\n",
      "Epoch: 3540, Train Loss: 0.298, Validation Loss: 0.242\n",
      "Epoch: 3541, Train Loss: 0.352, Validation Loss: 0.241\n",
      "Epoch: 3542, Train Loss: 0.207, Validation Loss: 0.241\n",
      "Epoch: 3543, Train Loss: 0.248, Validation Loss: 0.243\n",
      "Epoch: 3544, Train Loss: 0.209, Validation Loss: 0.242\n",
      "Epoch: 3545, Train Loss: 0.250, Validation Loss: 0.245\n",
      "Epoch: 3546, Train Loss: 0.319, Validation Loss: 0.243\n",
      "Epoch: 3547, Train Loss: 0.202, Validation Loss: 0.245\n",
      "Epoch: 3548, Train Loss: 0.192, Validation Loss: 0.246\n",
      "Epoch: 3549, Train Loss: 0.155, Validation Loss: 0.242\n",
      "Epoch: 3550, Train Loss: 0.259, Validation Loss: 0.243\n",
      "Epoch: 3551, Train Loss: 0.204, Validation Loss: 0.243\n",
      "Epoch: 3552, Train Loss: 0.210, Validation Loss: 0.242\n",
      "Epoch: 3553, Train Loss: 0.229, Validation Loss: 0.242\n",
      "Epoch: 3554, Train Loss: 0.220, Validation Loss: 0.240\n",
      "Epoch: 3555, Train Loss: 0.207, Validation Loss: 0.244\n",
      "Epoch: 3556, Train Loss: 0.181, Validation Loss: 0.241\n",
      "Epoch: 3557, Train Loss: 0.219, Validation Loss: 0.242\n",
      "Epoch: 3558, Train Loss: 0.211, Validation Loss: 0.244\n",
      "Epoch: 3559, Train Loss: 0.208, Validation Loss: 0.244\n",
      "Epoch: 3560, Train Loss: 0.212, Validation Loss: 0.242\n",
      "Epoch: 3561, Train Loss: 0.261, Validation Loss: 0.244\n",
      "Epoch: 3562, Train Loss: 0.317, Validation Loss: 0.246\n",
      "Epoch: 3563, Train Loss: 0.272, Validation Loss: 0.246\n",
      "Epoch: 3564, Train Loss: 0.192, Validation Loss: 0.242\n",
      "Epoch: 3565, Train Loss: 0.181, Validation Loss: 0.242\n",
      "Epoch: 3566, Train Loss: 0.244, Validation Loss: 0.244\n",
      "Epoch: 3567, Train Loss: 0.285, Validation Loss: 0.244\n",
      "Epoch: 3568, Train Loss: 0.539, Validation Loss: 0.247\n",
      "Epoch: 3569, Train Loss: 0.236, Validation Loss: 0.243\n",
      "Epoch: 3570, Train Loss: 0.295, Validation Loss: 0.242\n",
      "Epoch: 3571, Train Loss: 0.324, Validation Loss: 0.241\n",
      "Epoch: 3572, Train Loss: 0.201, Validation Loss: 0.242\n",
      "Epoch: 3573, Train Loss: 0.285, Validation Loss: 0.244\n",
      "Epoch: 3574, Train Loss: 0.221, Validation Loss: 0.242\n",
      "Epoch: 3575, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 3576, Train Loss: 0.252, Validation Loss: 0.240\n",
      "Epoch: 3577, Train Loss: 0.270, Validation Loss: 0.241\n",
      "Epoch: 3578, Train Loss: 0.197, Validation Loss: 0.245\n",
      "Epoch: 3579, Train Loss: 0.196, Validation Loss: 0.243\n",
      "Epoch: 3580, Train Loss: 0.238, Validation Loss: 0.242\n",
      "Epoch: 3581, Train Loss: 0.289, Validation Loss: 0.241\n",
      "Epoch: 3582, Train Loss: 0.280, Validation Loss: 0.245\n",
      "Epoch: 3583, Train Loss: 0.690, Validation Loss: 0.243\n",
      "Epoch: 3584, Train Loss: 0.185, Validation Loss: 0.240\n",
      "Epoch: 3585, Train Loss: 0.229, Validation Loss: 0.242\n",
      "Epoch: 3586, Train Loss: 0.284, Validation Loss: 0.243\n",
      "Epoch: 3587, Train Loss: 0.201, Validation Loss: 0.241\n",
      "Epoch: 3588, Train Loss: 0.203, Validation Loss: 0.241\n",
      "Epoch: 3589, Train Loss: 0.204, Validation Loss: 0.243\n",
      "Epoch: 3590, Train Loss: 0.179, Validation Loss: 0.243\n",
      "Epoch: 3591, Train Loss: 0.339, Validation Loss: 0.248\n",
      "Epoch: 3592, Train Loss: 0.221, Validation Loss: 0.243\n",
      "Epoch: 3593, Train Loss: 0.271, Validation Loss: 0.246\n",
      "Epoch: 3594, Train Loss: 0.239, Validation Loss: 0.244\n",
      "Epoch: 3595, Train Loss: 0.203, Validation Loss: 0.243\n",
      "Epoch: 3596, Train Loss: 0.310, Validation Loss: 0.245\n",
      "Epoch: 3597, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 3598, Train Loss: 0.466, Validation Loss: 0.243\n",
      "Epoch: 3599, Train Loss: 0.311, Validation Loss: 0.242\n",
      "Epoch: 3600, Train Loss: 0.252, Validation Loss: 0.246\n",
      "Epoch: 3601, Train Loss: 0.357, Validation Loss: 0.241\n",
      "Epoch: 3602, Train Loss: 0.321, Validation Loss: 0.245\n",
      "Epoch: 3603, Train Loss: 0.480, Validation Loss: 0.241\n",
      "Epoch: 3604, Train Loss: 0.209, Validation Loss: 0.244\n",
      "Epoch: 3605, Train Loss: 0.511, Validation Loss: 0.248\n",
      "Epoch: 3606, Train Loss: 0.178, Validation Loss: 0.242\n",
      "Epoch: 3607, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 3608, Train Loss: 0.396, Validation Loss: 0.242\n",
      "Epoch: 3609, Train Loss: 0.270, Validation Loss: 0.244\n",
      "Epoch: 3610, Train Loss: 0.236, Validation Loss: 0.245\n",
      "Epoch: 3611, Train Loss: 0.213, Validation Loss: 0.241\n",
      "Epoch: 3612, Train Loss: 0.196, Validation Loss: 0.244\n",
      "Epoch: 3613, Train Loss: 0.248, Validation Loss: 0.245\n",
      "Epoch: 3614, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 3615, Train Loss: 0.178, Validation Loss: 0.245\n",
      "Epoch: 3616, Train Loss: 0.238, Validation Loss: 0.245\n",
      "Epoch: 3617, Train Loss: 0.285, Validation Loss: 0.243\n",
      "Epoch: 3618, Train Loss: 0.284, Validation Loss: 0.244\n",
      "Epoch: 3619, Train Loss: 0.203, Validation Loss: 0.240\n",
      "Epoch: 3620, Train Loss: 0.238, Validation Loss: 0.240\n",
      "Epoch: 3621, Train Loss: 0.243, Validation Loss: 0.244\n",
      "Epoch: 3622, Train Loss: 0.282, Validation Loss: 0.243\n",
      "Epoch: 3623, Train Loss: 0.253, Validation Loss: 0.240\n",
      "Epoch: 3624, Train Loss: 0.267, Validation Loss: 0.241\n",
      "Epoch: 3625, Train Loss: 0.249, Validation Loss: 0.243\n",
      "Epoch: 3626, Train Loss: 0.204, Validation Loss: 0.240\n",
      "Epoch: 3627, Train Loss: 0.217, Validation Loss: 0.242\n",
      "Epoch: 3628, Train Loss: 0.211, Validation Loss: 0.242\n",
      "Epoch: 3629, Train Loss: 0.266, Validation Loss: 0.240\n",
      "Epoch: 3630, Train Loss: 0.215, Validation Loss: 0.240\n",
      "Epoch: 3631, Train Loss: 0.258, Validation Loss: 0.243\n",
      "Epoch: 3632, Train Loss: 0.487, Validation Loss: 0.239\n",
      "Epoch: 3633, Train Loss: 0.325, Validation Loss: 0.241\n",
      "Epoch: 3634, Train Loss: 0.181, Validation Loss: 0.241\n",
      "Epoch: 3635, Train Loss: 0.193, Validation Loss: 0.240\n",
      "Epoch: 3636, Train Loss: 0.249, Validation Loss: 0.242\n",
      "Epoch: 3637, Train Loss: 0.224, Validation Loss: 0.241\n",
      "Epoch: 3638, Train Loss: 0.280, Validation Loss: 0.239\n",
      "Epoch: 3639, Train Loss: 0.384, Validation Loss: 0.240\n",
      "Epoch: 3640, Train Loss: 0.383, Validation Loss: 0.243\n",
      "Epoch: 3641, Train Loss: 0.172, Validation Loss: 0.241\n",
      "Epoch: 3642, Train Loss: 0.207, Validation Loss: 0.243\n",
      "Epoch: 3643, Train Loss: 0.186, Validation Loss: 0.244\n",
      "Epoch: 3644, Train Loss: 0.673, Validation Loss: 0.246\n",
      "Epoch: 3645, Train Loss: 0.435, Validation Loss: 0.241\n",
      "Epoch: 3646, Train Loss: 0.271, Validation Loss: 0.243\n",
      "Epoch: 3647, Train Loss: 0.248, Validation Loss: 0.242\n",
      "Epoch: 3648, Train Loss: 0.486, Validation Loss: 0.244\n",
      "Epoch: 3649, Train Loss: 0.276, Validation Loss: 0.241\n",
      "Epoch: 3650, Train Loss: 0.168, Validation Loss: 0.240\n",
      "Epoch: 3651, Train Loss: 0.269, Validation Loss: 0.241\n",
      "Epoch: 3652, Train Loss: 0.360, Validation Loss: 0.241\n",
      "Epoch: 3653, Train Loss: 0.445, Validation Loss: 0.242\n",
      "Epoch: 3654, Train Loss: 0.234, Validation Loss: 0.245\n",
      "Epoch: 3655, Train Loss: 0.232, Validation Loss: 0.241\n",
      "Epoch: 3656, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 3657, Train Loss: 0.300, Validation Loss: 0.240\n",
      "Epoch: 3658, Train Loss: 0.260, Validation Loss: 0.240\n",
      "Epoch: 3659, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 3660, Train Loss: 0.277, Validation Loss: 0.242\n",
      "Epoch: 3661, Train Loss: 0.263, Validation Loss: 0.241\n",
      "Epoch: 3662, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 3663, Train Loss: 0.184, Validation Loss: 0.241\n",
      "Epoch: 3664, Train Loss: 0.229, Validation Loss: 0.240\n",
      "Epoch: 3665, Train Loss: 0.315, Validation Loss: 0.245\n",
      "Epoch: 3666, Train Loss: 0.201, Validation Loss: 0.242\n",
      "Epoch: 3667, Train Loss: 0.213, Validation Loss: 0.242\n",
      "Epoch: 3668, Train Loss: 0.231, Validation Loss: 0.240\n",
      "Epoch: 3669, Train Loss: 0.274, Validation Loss: 0.241\n",
      "Epoch: 3670, Train Loss: 0.185, Validation Loss: 0.242\n",
      "Epoch: 3671, Train Loss: 0.206, Validation Loss: 0.242\n",
      "Epoch: 3672, Train Loss: 0.291, Validation Loss: 0.240\n",
      "Epoch: 3673, Train Loss: 0.277, Validation Loss: 0.240\n",
      "Epoch: 3674, Train Loss: 0.343, Validation Loss: 0.242\n",
      "Epoch: 3675, Train Loss: 0.278, Validation Loss: 0.247\n",
      "Epoch: 3676, Train Loss: 0.194, Validation Loss: 0.243\n",
      "Epoch: 3677, Train Loss: 0.256, Validation Loss: 0.241\n",
      "Epoch: 3678, Train Loss: 0.317, Validation Loss: 0.246\n",
      "Epoch: 3679, Train Loss: 0.270, Validation Loss: 0.240\n",
      "Epoch: 3680, Train Loss: 0.214, Validation Loss: 0.240\n",
      "Epoch: 3681, Train Loss: 0.295, Validation Loss: 0.239\n",
      "Epoch: 3682, Train Loss: 0.211, Validation Loss: 0.243\n",
      "Epoch: 3683, Train Loss: 0.228, Validation Loss: 0.244\n",
      "Epoch: 3684, Train Loss: 0.217, Validation Loss: 0.246\n",
      "Epoch: 3685, Train Loss: 0.483, Validation Loss: 0.245\n",
      "Epoch: 3686, Train Loss: 0.169, Validation Loss: 0.241\n",
      "Epoch: 3687, Train Loss: 0.421, Validation Loss: 0.241\n",
      "Epoch: 3688, Train Loss: 0.185, Validation Loss: 0.244\n",
      "Epoch: 3689, Train Loss: 0.256, Validation Loss: 0.240\n",
      "Epoch: 3690, Train Loss: 0.339, Validation Loss: 0.241\n",
      "Epoch: 3691, Train Loss: 0.461, Validation Loss: 0.243\n",
      "Epoch: 3692, Train Loss: 0.213, Validation Loss: 0.242\n",
      "Epoch: 3693, Train Loss: 0.354, Validation Loss: 0.242\n",
      "Epoch: 3694, Train Loss: 0.195, Validation Loss: 0.244\n",
      "Epoch: 3695, Train Loss: 0.246, Validation Loss: 0.244\n",
      "Epoch: 3696, Train Loss: 0.267, Validation Loss: 0.247\n",
      "Epoch: 3697, Train Loss: 0.254, Validation Loss: 0.244\n",
      "Epoch: 3698, Train Loss: 0.234, Validation Loss: 0.243\n",
      "Epoch: 3699, Train Loss: 0.164, Validation Loss: 0.242\n",
      "Epoch: 3700, Train Loss: 0.200, Validation Loss: 0.242\n",
      "Epoch: 3701, Train Loss: 0.519, Validation Loss: 0.246\n",
      "Epoch: 3702, Train Loss: 0.428, Validation Loss: 0.244\n",
      "Epoch: 3703, Train Loss: 0.383, Validation Loss: 0.244\n",
      "Epoch: 3704, Train Loss: 0.222, Validation Loss: 0.244\n",
      "Epoch: 3705, Train Loss: 0.215, Validation Loss: 0.243\n",
      "Epoch: 3706, Train Loss: 0.201, Validation Loss: 0.245\n",
      "Epoch: 3707, Train Loss: 0.236, Validation Loss: 0.243\n",
      "Epoch: 3708, Train Loss: 0.331, Validation Loss: 0.246\n",
      "Epoch: 3709, Train Loss: 0.241, Validation Loss: 0.243\n",
      "Epoch: 3710, Train Loss: 0.257, Validation Loss: 0.243\n",
      "Epoch: 3711, Train Loss: 0.197, Validation Loss: 0.244\n",
      "Epoch: 3712, Train Loss: 0.264, Validation Loss: 0.247\n",
      "Epoch: 3713, Train Loss: 0.228, Validation Loss: 0.244\n",
      "Epoch: 3714, Train Loss: 0.228, Validation Loss: 0.243\n",
      "Epoch: 3715, Train Loss: 0.190, Validation Loss: 0.248\n",
      "Epoch: 3716, Train Loss: 0.199, Validation Loss: 0.243\n",
      "Epoch: 3717, Train Loss: 0.282, Validation Loss: 0.243\n",
      "Epoch: 3718, Train Loss: 0.324, Validation Loss: 0.240\n",
      "Epoch: 3719, Train Loss: 0.270, Validation Loss: 0.240\n",
      "Epoch: 3720, Train Loss: 0.201, Validation Loss: 0.246\n",
      "Epoch: 3721, Train Loss: 0.205, Validation Loss: 0.242\n",
      "Epoch: 3722, Train Loss: 0.193, Validation Loss: 0.245\n",
      "Epoch: 3723, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 3724, Train Loss: 0.242, Validation Loss: 0.240\n",
      "Epoch: 3725, Train Loss: 0.241, Validation Loss: 0.239\n",
      "Epoch: 3726, Train Loss: 0.179, Validation Loss: 0.239\n",
      "Epoch: 3727, Train Loss: 0.260, Validation Loss: 0.240\n",
      "Epoch: 3728, Train Loss: 0.284, Validation Loss: 0.242\n",
      "Epoch: 3729, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 3730, Train Loss: 0.254, Validation Loss: 0.242\n",
      "Epoch: 3731, Train Loss: 0.349, Validation Loss: 0.247\n",
      "Epoch: 3732, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 3733, Train Loss: 0.295, Validation Loss: 0.243\n",
      "Epoch: 3734, Train Loss: 0.190, Validation Loss: 0.244\n",
      "Epoch: 3735, Train Loss: 0.331, Validation Loss: 0.243\n",
      "Epoch: 3736, Train Loss: 0.272, Validation Loss: 0.244\n",
      "Epoch: 3737, Train Loss: 0.202, Validation Loss: 0.242\n",
      "Epoch: 3738, Train Loss: 0.183, Validation Loss: 0.243\n",
      "Epoch: 3739, Train Loss: 0.254, Validation Loss: 0.245\n",
      "Epoch: 3740, Train Loss: 0.267, Validation Loss: 0.243\n",
      "Epoch: 3741, Train Loss: 0.265, Validation Loss: 0.244\n",
      "Epoch: 3742, Train Loss: 0.215, Validation Loss: 0.246\n",
      "Epoch: 3743, Train Loss: 0.515, Validation Loss: 0.249\n",
      "Epoch: 3744, Train Loss: 0.329, Validation Loss: 0.247\n",
      "Epoch: 3745, Train Loss: 0.238, Validation Loss: 0.243\n",
      "Epoch: 3746, Train Loss: 0.223, Validation Loss: 0.243\n",
      "Epoch: 3747, Train Loss: 0.292, Validation Loss: 0.244\n",
      "Epoch: 3748, Train Loss: 0.228, Validation Loss: 0.243\n",
      "Epoch: 3749, Train Loss: 0.209, Validation Loss: 0.243\n",
      "Epoch: 3750, Train Loss: 0.219, Validation Loss: 0.243\n",
      "Epoch: 3751, Train Loss: 0.240, Validation Loss: 0.243\n",
      "Epoch: 3752, Train Loss: 0.168, Validation Loss: 0.242\n",
      "Epoch: 3753, Train Loss: 0.298, Validation Loss: 0.244\n",
      "Epoch: 3754, Train Loss: 0.242, Validation Loss: 0.252\n",
      "Epoch: 3755, Train Loss: 0.240, Validation Loss: 0.244\n",
      "Epoch: 3756, Train Loss: 0.336, Validation Loss: 0.248\n",
      "Epoch: 3757, Train Loss: 0.285, Validation Loss: 0.242\n",
      "Epoch: 3758, Train Loss: 0.193, Validation Loss: 0.241\n",
      "Epoch: 3759, Train Loss: 0.427, Validation Loss: 0.242\n",
      "Epoch: 3760, Train Loss: 0.518, Validation Loss: 0.244\n",
      "Epoch: 3761, Train Loss: 0.264, Validation Loss: 0.244\n",
      "Epoch: 3762, Train Loss: 0.198, Validation Loss: 0.243\n",
      "Epoch: 3763, Train Loss: 0.172, Validation Loss: 0.247\n",
      "Epoch: 3764, Train Loss: 0.166, Validation Loss: 0.244\n",
      "Epoch: 3765, Train Loss: 0.410, Validation Loss: 0.241\n",
      "Epoch: 3766, Train Loss: 0.230, Validation Loss: 0.241\n",
      "Epoch: 3767, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 3768, Train Loss: 0.263, Validation Loss: 0.242\n",
      "Epoch: 3769, Train Loss: 0.266, Validation Loss: 0.242\n",
      "Epoch: 3770, Train Loss: 0.391, Validation Loss: 0.242\n",
      "Epoch: 3771, Train Loss: 0.182, Validation Loss: 0.245\n",
      "Epoch: 3772, Train Loss: 0.251, Validation Loss: 0.244\n",
      "Epoch: 3773, Train Loss: 0.221, Validation Loss: 0.245\n",
      "Epoch: 3774, Train Loss: 0.187, Validation Loss: 0.244\n",
      "Epoch: 3775, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 3776, Train Loss: 0.237, Validation Loss: 0.243\n",
      "Epoch: 3777, Train Loss: 0.245, Validation Loss: 0.241\n",
      "Epoch: 3778, Train Loss: 0.242, Validation Loss: 0.244\n",
      "Epoch: 3779, Train Loss: 0.175, Validation Loss: 0.242\n",
      "Epoch: 3780, Train Loss: 0.448, Validation Loss: 0.246\n",
      "Epoch: 3781, Train Loss: 0.213, Validation Loss: 0.242\n",
      "Epoch: 3782, Train Loss: 0.255, Validation Loss: 0.241\n",
      "Epoch: 3783, Train Loss: 0.624, Validation Loss: 0.245\n",
      "Epoch: 3784, Train Loss: 0.461, Validation Loss: 0.243\n",
      "Epoch: 3785, Train Loss: 0.233, Validation Loss: 0.245\n",
      "Epoch: 3786, Train Loss: 0.248, Validation Loss: 0.245\n",
      "Epoch: 3787, Train Loss: 0.217, Validation Loss: 0.243\n",
      "Epoch: 3788, Train Loss: 0.255, Validation Loss: 0.243\n",
      "Epoch: 3789, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 3790, Train Loss: 0.199, Validation Loss: 0.242\n",
      "Epoch: 3791, Train Loss: 0.282, Validation Loss: 0.245\n",
      "Epoch: 3792, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 3793, Train Loss: 0.334, Validation Loss: 0.244\n",
      "Epoch: 3794, Train Loss: 0.445, Validation Loss: 0.247\n",
      "Epoch: 3795, Train Loss: 0.289, Validation Loss: 0.248\n",
      "Epoch: 3796, Train Loss: 0.341, Validation Loss: 0.251\n",
      "Epoch: 3797, Train Loss: 0.286, Validation Loss: 0.246\n",
      "Epoch: 3798, Train Loss: 0.232, Validation Loss: 0.241\n",
      "Epoch: 3799, Train Loss: 0.539, Validation Loss: 0.246\n",
      "Epoch: 3800, Train Loss: 0.198, Validation Loss: 0.246\n",
      "Epoch: 3801, Train Loss: 0.261, Validation Loss: 0.243\n",
      "Epoch: 3802, Train Loss: 0.224, Validation Loss: 0.245\n",
      "Epoch: 3803, Train Loss: 0.214, Validation Loss: 0.245\n",
      "Epoch: 3804, Train Loss: 0.168, Validation Loss: 0.244\n",
      "Epoch: 3805, Train Loss: 0.263, Validation Loss: 0.249\n",
      "Epoch: 3806, Train Loss: 0.282, Validation Loss: 0.244\n",
      "Epoch: 3807, Train Loss: 0.258, Validation Loss: 0.246\n",
      "Epoch: 3808, Train Loss: 0.214, Validation Loss: 0.242\n",
      "Epoch: 3809, Train Loss: 0.214, Validation Loss: 0.241\n",
      "Epoch: 3810, Train Loss: 0.350, Validation Loss: 0.248\n",
      "Epoch: 3811, Train Loss: 0.279, Validation Loss: 0.248\n",
      "Epoch: 3812, Train Loss: 0.240, Validation Loss: 0.242\n",
      "Epoch: 3813, Train Loss: 0.242, Validation Loss: 0.243\n",
      "Epoch: 3814, Train Loss: 0.371, Validation Loss: 0.243\n",
      "Epoch: 3815, Train Loss: 0.196, Validation Loss: 0.245\n",
      "Epoch: 3816, Train Loss: 0.215, Validation Loss: 0.242\n",
      "Epoch: 3817, Train Loss: 0.373, Validation Loss: 0.242\n",
      "Epoch: 3818, Train Loss: 0.173, Validation Loss: 0.241\n",
      "Epoch: 3819, Train Loss: 0.538, Validation Loss: 0.246\n",
      "Epoch: 3820, Train Loss: 0.309, Validation Loss: 0.243\n",
      "Epoch: 3821, Train Loss: 0.360, Validation Loss: 0.240\n",
      "Epoch: 3822, Train Loss: 0.225, Validation Loss: 0.240\n",
      "Epoch: 3823, Train Loss: 0.249, Validation Loss: 0.243\n",
      "Epoch: 3824, Train Loss: 0.241, Validation Loss: 0.243\n",
      "Epoch: 3825, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 3826, Train Loss: 0.376, Validation Loss: 0.242\n",
      "Epoch: 3827, Train Loss: 0.140, Validation Loss: 0.241\n",
      "Epoch: 3828, Train Loss: 0.283, Validation Loss: 0.241\n",
      "Epoch: 3829, Train Loss: 0.234, Validation Loss: 0.244\n",
      "Epoch: 3830, Train Loss: 0.238, Validation Loss: 0.243\n",
      "Epoch: 3831, Train Loss: 0.246, Validation Loss: 0.240\n",
      "Epoch: 3832, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 3833, Train Loss: 0.211, Validation Loss: 0.241\n",
      "Epoch: 3834, Train Loss: 0.384, Validation Loss: 0.241\n",
      "Epoch: 3835, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 3836, Train Loss: 0.328, Validation Loss: 0.241\n",
      "Epoch: 3837, Train Loss: 0.265, Validation Loss: 0.246\n",
      "Epoch: 3838, Train Loss: 0.264, Validation Loss: 0.248\n",
      "Epoch: 3839, Train Loss: 0.284, Validation Loss: 0.244\n",
      "Epoch: 3840, Train Loss: 0.233, Validation Loss: 0.242\n",
      "Epoch: 3841, Train Loss: 0.255, Validation Loss: 0.241\n",
      "Epoch: 3842, Train Loss: 0.231, Validation Loss: 0.242\n",
      "Epoch: 3843, Train Loss: 0.318, Validation Loss: 0.241\n",
      "Epoch: 3844, Train Loss: 0.217, Validation Loss: 0.241\n",
      "Epoch: 3845, Train Loss: 0.287, Validation Loss: 0.242\n",
      "Epoch: 3846, Train Loss: 0.228, Validation Loss: 0.242\n",
      "Epoch: 3847, Train Loss: 0.355, Validation Loss: 0.249\n",
      "Epoch: 3848, Train Loss: 0.298, Validation Loss: 0.244\n",
      "Epoch: 3849, Train Loss: 0.468, Validation Loss: 0.243\n",
      "Epoch: 3850, Train Loss: 0.255, Validation Loss: 0.242\n",
      "Epoch: 3851, Train Loss: 0.271, Validation Loss: 0.243\n",
      "Epoch: 3852, Train Loss: 0.302, Validation Loss: 0.242\n",
      "Epoch: 3853, Train Loss: 0.299, Validation Loss: 0.243\n",
      "Epoch: 3854, Train Loss: 0.226, Validation Loss: 0.243\n",
      "Epoch: 3855, Train Loss: 0.379, Validation Loss: 0.248\n",
      "Epoch: 3856, Train Loss: 0.270, Validation Loss: 0.245\n",
      "Epoch: 3857, Train Loss: 0.235, Validation Loss: 0.243\n",
      "Epoch: 3858, Train Loss: 0.192, Validation Loss: 0.241\n",
      "Epoch: 3859, Train Loss: 0.429, Validation Loss: 0.244\n",
      "Epoch: 3860, Train Loss: 0.376, Validation Loss: 0.246\n",
      "Epoch: 3861, Train Loss: 0.236, Validation Loss: 0.243\n",
      "Epoch: 3862, Train Loss: 0.256, Validation Loss: 0.243\n",
      "Epoch: 3863, Train Loss: 0.236, Validation Loss: 0.243\n",
      "Epoch: 3864, Train Loss: 0.286, Validation Loss: 0.245\n",
      "Epoch: 3865, Train Loss: 0.240, Validation Loss: 0.246\n",
      "Epoch: 3866, Train Loss: 0.225, Validation Loss: 0.243\n",
      "Epoch: 3867, Train Loss: 0.493, Validation Loss: 0.247\n",
      "Epoch: 3868, Train Loss: 0.325, Validation Loss: 0.250\n",
      "Epoch: 3869, Train Loss: 0.229, Validation Loss: 0.245\n",
      "Epoch: 3870, Train Loss: 0.242, Validation Loss: 0.247\n",
      "Epoch: 3871, Train Loss: 0.231, Validation Loss: 0.244\n",
      "Epoch: 3872, Train Loss: 0.215, Validation Loss: 0.242\n",
      "Epoch: 3873, Train Loss: 0.289, Validation Loss: 0.245\n",
      "Epoch: 3874, Train Loss: 0.226, Validation Loss: 0.244\n",
      "Epoch: 3875, Train Loss: 0.205, Validation Loss: 0.245\n",
      "Epoch: 3876, Train Loss: 0.262, Validation Loss: 0.246\n",
      "Epoch: 3877, Train Loss: 0.285, Validation Loss: 0.241\n",
      "Epoch: 3878, Train Loss: 0.249, Validation Loss: 0.242\n",
      "Epoch: 3879, Train Loss: 0.249, Validation Loss: 0.243\n",
      "Epoch: 3880, Train Loss: 0.269, Validation Loss: 0.245\n",
      "Epoch: 3881, Train Loss: 0.287, Validation Loss: 0.242\n",
      "Epoch: 3882, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 3883, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 3884, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 3885, Train Loss: 0.225, Validation Loss: 0.246\n",
      "Epoch: 3886, Train Loss: 0.177, Validation Loss: 0.243\n",
      "Epoch: 3887, Train Loss: 0.314, Validation Loss: 0.242\n",
      "Epoch: 3888, Train Loss: 0.190, Validation Loss: 0.243\n",
      "Epoch: 3889, Train Loss: 0.300, Validation Loss: 0.242\n",
      "Epoch: 3890, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 3891, Train Loss: 0.315, Validation Loss: 0.242\n",
      "Epoch: 3892, Train Loss: 0.684, Validation Loss: 0.244\n",
      "Epoch: 3893, Train Loss: 0.235, Validation Loss: 0.241\n",
      "Epoch: 3894, Train Loss: 0.231, Validation Loss: 0.241\n",
      "Epoch: 3895, Train Loss: 0.202, Validation Loss: 0.239\n",
      "Epoch: 3896, Train Loss: 0.158, Validation Loss: 0.240\n",
      "Epoch: 3897, Train Loss: 0.243, Validation Loss: 0.240\n",
      "Epoch: 3898, Train Loss: 0.343, Validation Loss: 0.241\n",
      "Epoch: 3899, Train Loss: 0.630, Validation Loss: 0.246\n",
      "Epoch: 3900, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 3901, Train Loss: 0.313, Validation Loss: 0.242\n",
      "Epoch: 3902, Train Loss: 0.422, Validation Loss: 0.243\n",
      "Epoch: 3903, Train Loss: 0.264, Validation Loss: 0.241\n",
      "Epoch: 3904, Train Loss: 0.250, Validation Loss: 0.243\n",
      "Epoch: 3905, Train Loss: 0.208, Validation Loss: 0.242\n",
      "Epoch: 3906, Train Loss: 0.435, Validation Loss: 0.240\n",
      "Epoch: 3907, Train Loss: 0.261, Validation Loss: 0.242\n",
      "Epoch: 3908, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 3909, Train Loss: 0.193, Validation Loss: 0.241\n",
      "Epoch: 3910, Train Loss: 0.172, Validation Loss: 0.243\n",
      "Epoch: 3911, Train Loss: 0.150, Validation Loss: 0.241\n",
      "Epoch: 3912, Train Loss: 0.160, Validation Loss: 0.242\n",
      "Epoch: 3913, Train Loss: 0.197, Validation Loss: 0.244\n",
      "Epoch: 3914, Train Loss: 0.266, Validation Loss: 0.243\n",
      "Epoch: 3915, Train Loss: 0.169, Validation Loss: 0.242\n",
      "Epoch: 3916, Train Loss: 0.225, Validation Loss: 0.245\n",
      "Epoch: 3917, Train Loss: 0.287, Validation Loss: 0.246\n",
      "Epoch: 3918, Train Loss: 0.249, Validation Loss: 0.242\n",
      "Epoch: 3919, Train Loss: 0.192, Validation Loss: 0.241\n",
      "Epoch: 3920, Train Loss: 0.426, Validation Loss: 0.241\n",
      "Epoch: 3921, Train Loss: 0.208, Validation Loss: 0.242\n",
      "Epoch: 3922, Train Loss: 0.226, Validation Loss: 0.243\n",
      "Epoch: 3923, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 3924, Train Loss: 0.171, Validation Loss: 0.247\n",
      "Epoch: 3925, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 3926, Train Loss: 0.186, Validation Loss: 0.243\n",
      "Epoch: 3927, Train Loss: 0.222, Validation Loss: 0.243\n",
      "Epoch: 3928, Train Loss: 0.244, Validation Loss: 0.243\n",
      "Epoch: 3929, Train Loss: 0.316, Validation Loss: 0.241\n",
      "Epoch: 3930, Train Loss: 0.188, Validation Loss: 0.241\n",
      "Epoch: 3931, Train Loss: 0.188, Validation Loss: 0.242\n",
      "Epoch: 3932, Train Loss: 0.320, Validation Loss: 0.242\n",
      "Epoch: 3933, Train Loss: 0.213, Validation Loss: 0.243\n",
      "Epoch: 3934, Train Loss: 0.241, Validation Loss: 0.249\n",
      "Epoch: 3935, Train Loss: 0.210, Validation Loss: 0.242\n",
      "Epoch: 3936, Train Loss: 0.318, Validation Loss: 0.243\n",
      "Epoch: 3937, Train Loss: 0.339, Validation Loss: 0.241\n",
      "Epoch: 3938, Train Loss: 0.208, Validation Loss: 0.241\n",
      "Epoch: 3939, Train Loss: 0.251, Validation Loss: 0.242\n",
      "Epoch: 3940, Train Loss: 0.274, Validation Loss: 0.241\n",
      "Epoch: 3941, Train Loss: 0.359, Validation Loss: 0.248\n",
      "Epoch: 3942, Train Loss: 0.150, Validation Loss: 0.243\n",
      "Epoch: 3943, Train Loss: 0.409, Validation Loss: 0.244\n",
      "Epoch: 3944, Train Loss: 0.297, Validation Loss: 0.242\n",
      "Epoch: 3945, Train Loss: 0.265, Validation Loss: 0.241\n",
      "Epoch: 3946, Train Loss: 0.362, Validation Loss: 0.241\n",
      "Epoch: 3947, Train Loss: 0.284, Validation Loss: 0.243\n",
      "Epoch: 3948, Train Loss: 0.236, Validation Loss: 0.240\n",
      "Epoch: 3949, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 3950, Train Loss: 0.246, Validation Loss: 0.241\n",
      "Epoch: 3951, Train Loss: 0.231, Validation Loss: 0.245\n",
      "Epoch: 3952, Train Loss: 0.218, Validation Loss: 0.256\n",
      "Epoch: 3953, Train Loss: 0.354, Validation Loss: 0.248\n",
      "Epoch: 3954, Train Loss: 0.400, Validation Loss: 0.241\n",
      "Epoch: 3955, Train Loss: 0.242, Validation Loss: 0.241\n",
      "Epoch: 3956, Train Loss: 0.328, Validation Loss: 0.245\n",
      "Epoch: 3957, Train Loss: 0.241, Validation Loss: 0.242\n",
      "Epoch: 3958, Train Loss: 0.243, Validation Loss: 0.238\n",
      "Epoch: 3959, Train Loss: 0.235, Validation Loss: 0.239\n",
      "Epoch: 3960, Train Loss: 0.222, Validation Loss: 0.240\n",
      "Epoch: 3961, Train Loss: 0.252, Validation Loss: 0.239\n",
      "Epoch: 3962, Train Loss: 0.216, Validation Loss: 0.239\n",
      "Epoch: 3963, Train Loss: 0.193, Validation Loss: 0.241\n",
      "Epoch: 3964, Train Loss: 0.204, Validation Loss: 0.240\n",
      "Epoch: 3965, Train Loss: 0.271, Validation Loss: 0.241\n",
      "Epoch: 3966, Train Loss: 0.272, Validation Loss: 0.242\n",
      "Epoch: 3967, Train Loss: 0.225, Validation Loss: 0.242\n",
      "Epoch: 3968, Train Loss: 0.301, Validation Loss: 0.244\n",
      "Epoch: 3969, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 3970, Train Loss: 0.283, Validation Loss: 0.240\n",
      "Epoch: 3971, Train Loss: 0.340, Validation Loss: 0.240\n",
      "Epoch: 3972, Train Loss: 0.305, Validation Loss: 0.240\n",
      "Epoch: 3973, Train Loss: 0.259, Validation Loss: 0.244\n",
      "Epoch: 3974, Train Loss: 0.297, Validation Loss: 0.241\n",
      "Epoch: 3975, Train Loss: 0.322, Validation Loss: 0.242\n",
      "Epoch: 3976, Train Loss: 0.279, Validation Loss: 0.243\n",
      "Epoch: 3977, Train Loss: 0.192, Validation Loss: 0.242\n",
      "Epoch: 3978, Train Loss: 0.199, Validation Loss: 0.244\n",
      "Epoch: 3979, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 3980, Train Loss: 0.234, Validation Loss: 0.242\n",
      "Epoch: 3981, Train Loss: 0.240, Validation Loss: 0.244\n",
      "Epoch: 3982, Train Loss: 0.329, Validation Loss: 0.242\n",
      "Epoch: 3983, Train Loss: 0.210, Validation Loss: 0.245\n",
      "Epoch: 3984, Train Loss: 0.451, Validation Loss: 0.243\n",
      "Epoch: 3985, Train Loss: 0.234, Validation Loss: 0.243\n",
      "Epoch: 3986, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 3987, Train Loss: 0.269, Validation Loss: 0.247\n",
      "Epoch: 3988, Train Loss: 0.237, Validation Loss: 0.244\n",
      "Epoch: 3989, Train Loss: 0.267, Validation Loss: 0.240\n",
      "Epoch: 3990, Train Loss: 0.283, Validation Loss: 0.242\n",
      "Epoch: 3991, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 3992, Train Loss: 0.292, Validation Loss: 0.247\n",
      "Epoch: 3993, Train Loss: 0.195, Validation Loss: 0.243\n",
      "Epoch: 3994, Train Loss: 0.232, Validation Loss: 0.240\n",
      "Epoch: 3995, Train Loss: 0.210, Validation Loss: 0.243\n",
      "Epoch: 3996, Train Loss: 0.265, Validation Loss: 0.242\n",
      "Epoch: 3997, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 3998, Train Loss: 0.337, Validation Loss: 0.244\n",
      "Epoch: 3999, Train Loss: 0.158, Validation Loss: 0.240\n",
      "Epoch: 4000, Train Loss: 0.331, Validation Loss: 0.240\n",
      "Epoch: 4001, Train Loss: 0.283, Validation Loss: 0.241\n",
      "Epoch: 4002, Train Loss: 0.241, Validation Loss: 0.243\n",
      "Epoch: 4003, Train Loss: 0.247, Validation Loss: 0.240\n",
      "Epoch: 4004, Train Loss: 0.240, Validation Loss: 0.244\n",
      "Epoch: 4005, Train Loss: 0.321, Validation Loss: 0.243\n",
      "Epoch: 4006, Train Loss: 0.288, Validation Loss: 0.241\n",
      "Epoch: 4007, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 4008, Train Loss: 0.251, Validation Loss: 0.242\n",
      "Epoch: 4009, Train Loss: 0.373, Validation Loss: 0.249\n",
      "Epoch: 4010, Train Loss: 0.272, Validation Loss: 0.240\n",
      "Epoch: 4011, Train Loss: 0.270, Validation Loss: 0.242\n",
      "Epoch: 4012, Train Loss: 0.538, Validation Loss: 0.248\n",
      "Epoch: 4013, Train Loss: 0.216, Validation Loss: 0.243\n",
      "Epoch: 4014, Train Loss: 0.288, Validation Loss: 0.242\n",
      "Epoch: 4015, Train Loss: 0.237, Validation Loss: 0.243\n",
      "Epoch: 4016, Train Loss: 0.335, Validation Loss: 0.246\n",
      "Epoch: 4017, Train Loss: 0.269, Validation Loss: 0.243\n",
      "Epoch: 4018, Train Loss: 0.263, Validation Loss: 0.240\n",
      "Epoch: 4019, Train Loss: 0.206, Validation Loss: 0.240\n",
      "Epoch: 4020, Train Loss: 0.320, Validation Loss: 0.241\n",
      "Epoch: 4021, Train Loss: 0.203, Validation Loss: 0.241\n",
      "Epoch: 4022, Train Loss: 0.156, Validation Loss: 0.240\n",
      "Epoch: 4023, Train Loss: 0.210, Validation Loss: 0.240\n",
      "Epoch: 4024, Train Loss: 0.338, Validation Loss: 0.240\n",
      "Epoch: 4025, Train Loss: 0.200, Validation Loss: 0.240\n",
      "Epoch: 4026, Train Loss: 0.221, Validation Loss: 0.240\n",
      "Epoch: 4027, Train Loss: 0.237, Validation Loss: 0.240\n",
      "Epoch: 4028, Train Loss: 0.270, Validation Loss: 0.242\n",
      "Epoch: 4029, Train Loss: 0.194, Validation Loss: 0.240\n",
      "Epoch: 4030, Train Loss: 0.223, Validation Loss: 0.241\n",
      "Epoch: 4031, Train Loss: 0.267, Validation Loss: 0.242\n",
      "Epoch: 4032, Train Loss: 0.204, Validation Loss: 0.241\n",
      "Epoch: 4033, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 4034, Train Loss: 0.415, Validation Loss: 0.245\n",
      "Epoch: 4035, Train Loss: 0.265, Validation Loss: 0.239\n",
      "Epoch: 4036, Train Loss: 0.236, Validation Loss: 0.241\n",
      "Epoch: 4037, Train Loss: 0.223, Validation Loss: 0.240\n",
      "Epoch: 4038, Train Loss: 0.356, Validation Loss: 0.241\n",
      "Epoch: 4039, Train Loss: 0.281, Validation Loss: 0.240\n",
      "Epoch: 4040, Train Loss: 0.239, Validation Loss: 0.240\n",
      "Epoch: 4041, Train Loss: 0.260, Validation Loss: 0.241\n",
      "Epoch: 4042, Train Loss: 0.244, Validation Loss: 0.243\n",
      "Epoch: 4043, Train Loss: 0.245, Validation Loss: 0.242\n",
      "Epoch: 4044, Train Loss: 0.242, Validation Loss: 0.242\n",
      "Epoch: 4045, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 4046, Train Loss: 0.243, Validation Loss: 0.243\n",
      "Epoch: 4047, Train Loss: 0.495, Validation Loss: 0.240\n",
      "Epoch: 4048, Train Loss: 0.239, Validation Loss: 0.241\n",
      "Epoch: 4049, Train Loss: 0.438, Validation Loss: 0.241\n",
      "Epoch: 4050, Train Loss: 0.310, Validation Loss: 0.246\n",
      "Epoch: 4051, Train Loss: 0.176, Validation Loss: 0.239\n",
      "Epoch: 4052, Train Loss: 0.563, Validation Loss: 0.240\n",
      "Epoch: 4053, Train Loss: 0.514, Validation Loss: 0.246\n",
      "Epoch: 4054, Train Loss: 0.240, Validation Loss: 0.244\n",
      "Epoch: 4055, Train Loss: 0.585, Validation Loss: 0.246\n",
      "Epoch: 4056, Train Loss: 0.166, Validation Loss: 0.244\n",
      "Epoch: 4057, Train Loss: 0.252, Validation Loss: 0.242\n",
      "Epoch: 4058, Train Loss: 0.208, Validation Loss: 0.244\n",
      "Epoch: 4059, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 4060, Train Loss: 0.518, Validation Loss: 0.248\n",
      "Epoch: 4061, Train Loss: 0.460, Validation Loss: 0.244\n",
      "Epoch: 4062, Train Loss: 0.347, Validation Loss: 0.242\n",
      "Epoch: 4063, Train Loss: 0.220, Validation Loss: 0.242\n",
      "Epoch: 4064, Train Loss: 0.375, Validation Loss: 0.244\n",
      "Epoch: 4065, Train Loss: 0.229, Validation Loss: 0.246\n",
      "Epoch: 4066, Train Loss: 0.246, Validation Loss: 0.244\n",
      "Epoch: 4067, Train Loss: 0.281, Validation Loss: 0.246\n",
      "Epoch: 4068, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 4069, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 4070, Train Loss: 0.262, Validation Loss: 0.244\n",
      "Epoch: 4071, Train Loss: 0.376, Validation Loss: 0.242\n",
      "Epoch: 4072, Train Loss: 0.437, Validation Loss: 0.241\n",
      "Epoch: 4073, Train Loss: 0.224, Validation Loss: 0.241\n",
      "Epoch: 4074, Train Loss: 0.322, Validation Loss: 0.245\n",
      "Epoch: 4075, Train Loss: 0.271, Validation Loss: 0.242\n",
      "Epoch: 4076, Train Loss: 0.260, Validation Loss: 0.242\n",
      "Epoch: 4077, Train Loss: 0.252, Validation Loss: 0.241\n",
      "Epoch: 4078, Train Loss: 0.348, Validation Loss: 0.239\n",
      "Epoch: 4079, Train Loss: 0.244, Validation Loss: 0.241\n",
      "Epoch: 4080, Train Loss: 0.274, Validation Loss: 0.252\n",
      "Epoch: 4081, Train Loss: 0.257, Validation Loss: 0.242\n",
      "Epoch: 4082, Train Loss: 0.233, Validation Loss: 0.241\n",
      "Epoch: 4083, Train Loss: 0.164, Validation Loss: 0.246\n",
      "Epoch: 4084, Train Loss: 0.251, Validation Loss: 0.240\n",
      "Epoch: 4085, Train Loss: 0.203, Validation Loss: 0.243\n",
      "Epoch: 4086, Train Loss: 0.291, Validation Loss: 0.242\n",
      "Epoch: 4087, Train Loss: 0.203, Validation Loss: 0.242\n",
      "Epoch: 4088, Train Loss: 0.159, Validation Loss: 0.245\n",
      "Epoch: 4089, Train Loss: 0.269, Validation Loss: 0.245\n",
      "Epoch: 4090, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 4091, Train Loss: 0.312, Validation Loss: 0.240\n",
      "Epoch: 4092, Train Loss: 0.397, Validation Loss: 0.240\n",
      "Epoch: 4093, Train Loss: 0.260, Validation Loss: 0.244\n",
      "Epoch: 4094, Train Loss: 0.197, Validation Loss: 0.242\n",
      "Epoch: 4095, Train Loss: 0.238, Validation Loss: 0.241\n",
      "Epoch: 4096, Train Loss: 0.305, Validation Loss: 0.243\n",
      "Epoch: 4097, Train Loss: 0.236, Validation Loss: 0.244\n",
      "Epoch: 4098, Train Loss: 0.233, Validation Loss: 0.245\n",
      "Epoch: 4099, Train Loss: 0.239, Validation Loss: 0.243\n",
      "Epoch: 4100, Train Loss: 0.298, Validation Loss: 0.245\n",
      "Epoch: 4101, Train Loss: 0.223, Validation Loss: 0.246\n",
      "Epoch: 4102, Train Loss: 0.220, Validation Loss: 0.244\n",
      "Epoch: 4103, Train Loss: 0.221, Validation Loss: 0.243\n",
      "Epoch: 4104, Train Loss: 0.194, Validation Loss: 0.244\n",
      "Epoch: 4105, Train Loss: 0.477, Validation Loss: 0.251\n",
      "Epoch: 4106, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 4107, Train Loss: 0.391, Validation Loss: 0.245\n",
      "Epoch: 4108, Train Loss: 0.243, Validation Loss: 0.243\n",
      "Epoch: 4109, Train Loss: 0.165, Validation Loss: 0.243\n",
      "Epoch: 4110, Train Loss: 0.264, Validation Loss: 0.242\n",
      "Epoch: 4111, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 4112, Train Loss: 0.495, Validation Loss: 0.247\n",
      "Epoch: 4113, Train Loss: 0.175, Validation Loss: 0.243\n",
      "Epoch: 4114, Train Loss: 0.306, Validation Loss: 0.245\n",
      "Epoch: 4115, Train Loss: 0.264, Validation Loss: 0.241\n",
      "Epoch: 4116, Train Loss: 0.240, Validation Loss: 0.241\n",
      "Epoch: 4117, Train Loss: 0.360, Validation Loss: 0.243\n",
      "Epoch: 4118, Train Loss: 0.253, Validation Loss: 0.244\n",
      "Epoch: 4119, Train Loss: 0.534, Validation Loss: 0.245\n",
      "Epoch: 4120, Train Loss: 0.178, Validation Loss: 0.244\n",
      "Epoch: 4121, Train Loss: 0.246, Validation Loss: 0.243\n",
      "Epoch: 4122, Train Loss: 0.330, Validation Loss: 0.243\n",
      "Epoch: 4123, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 4124, Train Loss: 0.213, Validation Loss: 0.248\n",
      "Epoch: 4125, Train Loss: 0.264, Validation Loss: 0.244\n",
      "Epoch: 4126, Train Loss: 0.206, Validation Loss: 0.245\n",
      "Epoch: 4127, Train Loss: 0.188, Validation Loss: 0.245\n",
      "Epoch: 4128, Train Loss: 0.220, Validation Loss: 0.244\n",
      "Epoch: 4129, Train Loss: 0.580, Validation Loss: 0.244\n",
      "Epoch: 4130, Train Loss: 0.437, Validation Loss: 0.247\n",
      "Epoch: 4131, Train Loss: 0.266, Validation Loss: 0.245\n",
      "Epoch: 4132, Train Loss: 0.280, Validation Loss: 0.242\n",
      "Epoch: 4133, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 4134, Train Loss: 0.185, Validation Loss: 0.244\n",
      "Epoch: 4135, Train Loss: 0.264, Validation Loss: 0.242\n",
      "Epoch: 4136, Train Loss: 0.212, Validation Loss: 0.244\n",
      "Epoch: 4137, Train Loss: 0.258, Validation Loss: 0.244\n",
      "Epoch: 4138, Train Loss: 0.266, Validation Loss: 0.244\n",
      "Epoch: 4139, Train Loss: 0.220, Validation Loss: 0.244\n",
      "Epoch: 4140, Train Loss: 0.252, Validation Loss: 0.242\n",
      "Epoch: 4141, Train Loss: 0.361, Validation Loss: 0.241\n",
      "Epoch: 4142, Train Loss: 0.267, Validation Loss: 0.241\n",
      "Epoch: 4143, Train Loss: 0.258, Validation Loss: 0.244\n",
      "Epoch: 4144, Train Loss: 0.328, Validation Loss: 0.247\n",
      "Epoch: 4145, Train Loss: 0.192, Validation Loss: 0.246\n",
      "Epoch: 4146, Train Loss: 0.210, Validation Loss: 0.243\n",
      "Epoch: 4147, Train Loss: 0.210, Validation Loss: 0.242\n",
      "Epoch: 4148, Train Loss: 0.229, Validation Loss: 0.241\n",
      "Epoch: 4149, Train Loss: 0.171, Validation Loss: 0.244\n",
      "Epoch: 4150, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 4151, Train Loss: 0.359, Validation Loss: 0.247\n",
      "Epoch: 4152, Train Loss: 0.214, Validation Loss: 0.243\n",
      "Epoch: 4153, Train Loss: 0.186, Validation Loss: 0.241\n",
      "Epoch: 4154, Train Loss: 0.163, Validation Loss: 0.243\n",
      "Epoch: 4155, Train Loss: 0.332, Validation Loss: 0.241\n",
      "Epoch: 4156, Train Loss: 0.197, Validation Loss: 0.244\n",
      "Epoch: 4157, Train Loss: 0.260, Validation Loss: 0.242\n",
      "Epoch: 4158, Train Loss: 0.244, Validation Loss: 0.239\n",
      "Epoch: 4159, Train Loss: 0.441, Validation Loss: 0.241\n",
      "Epoch: 4160, Train Loss: 0.181, Validation Loss: 0.239\n",
      "Epoch: 4161, Train Loss: 0.279, Validation Loss: 0.245\n",
      "Epoch: 4162, Train Loss: 0.294, Validation Loss: 0.245\n",
      "Epoch: 4163, Train Loss: 0.244, Validation Loss: 0.242\n",
      "Epoch: 4164, Train Loss: 0.252, Validation Loss: 0.243\n",
      "Epoch: 4165, Train Loss: 0.219, Validation Loss: 0.244\n",
      "Epoch: 4166, Train Loss: 0.468, Validation Loss: 0.241\n",
      "Epoch: 4167, Train Loss: 0.531, Validation Loss: 0.244\n",
      "Epoch: 4168, Train Loss: 0.242, Validation Loss: 0.241\n",
      "Epoch: 4169, Train Loss: 0.318, Validation Loss: 0.243\n",
      "Epoch: 4170, Train Loss: 0.286, Validation Loss: 0.243\n",
      "Epoch: 4171, Train Loss: 0.213, Validation Loss: 0.242\n",
      "Epoch: 4172, Train Loss: 0.238, Validation Loss: 0.242\n",
      "Epoch: 4173, Train Loss: 0.234, Validation Loss: 0.243\n",
      "Epoch: 4174, Train Loss: 0.261, Validation Loss: 0.241\n",
      "Epoch: 4175, Train Loss: 0.259, Validation Loss: 0.241\n",
      "Epoch: 4176, Train Loss: 0.406, Validation Loss: 0.243\n",
      "Epoch: 4177, Train Loss: 0.331, Validation Loss: 0.243\n",
      "Epoch: 4178, Train Loss: 0.225, Validation Loss: 0.244\n",
      "Epoch: 4179, Train Loss: 0.220, Validation Loss: 0.247\n",
      "Epoch: 4180, Train Loss: 0.253, Validation Loss: 0.245\n",
      "Epoch: 4181, Train Loss: 0.244, Validation Loss: 0.248\n",
      "Epoch: 4182, Train Loss: 0.224, Validation Loss: 0.246\n",
      "Epoch: 4183, Train Loss: 0.243, Validation Loss: 0.243\n",
      "Epoch: 4184, Train Loss: 0.289, Validation Loss: 0.242\n",
      "Epoch: 4185, Train Loss: 0.215, Validation Loss: 0.244\n",
      "Epoch: 4186, Train Loss: 0.203, Validation Loss: 0.244\n",
      "Epoch: 4187, Train Loss: 0.268, Validation Loss: 0.245\n",
      "Epoch: 4188, Train Loss: 0.206, Validation Loss: 0.241\n",
      "Epoch: 4189, Train Loss: 0.258, Validation Loss: 0.242\n",
      "Epoch: 4190, Train Loss: 0.222, Validation Loss: 0.244\n",
      "Epoch: 4191, Train Loss: 0.480, Validation Loss: 0.247\n",
      "Epoch: 4192, Train Loss: 0.226, Validation Loss: 0.244\n",
      "Epoch: 4193, Train Loss: 0.248, Validation Loss: 0.243\n",
      "Epoch: 4194, Train Loss: 0.279, Validation Loss: 0.243\n",
      "Epoch: 4195, Train Loss: 0.684, Validation Loss: 0.247\n",
      "Epoch: 4196, Train Loss: 0.218, Validation Loss: 0.244\n",
      "Epoch: 4197, Train Loss: 0.242, Validation Loss: 0.243\n",
      "Epoch: 4198, Train Loss: 0.170, Validation Loss: 0.243\n",
      "Epoch: 4199, Train Loss: 0.263, Validation Loss: 0.244\n",
      "Epoch: 4200, Train Loss: 0.228, Validation Loss: 0.242\n",
      "Epoch: 4201, Train Loss: 0.373, Validation Loss: 0.244\n",
      "Epoch: 4202, Train Loss: 0.215, Validation Loss: 0.245\n",
      "Epoch: 4203, Train Loss: 0.238, Validation Loss: 0.242\n",
      "Epoch: 4204, Train Loss: 0.192, Validation Loss: 0.241\n",
      "Epoch: 4205, Train Loss: 0.174, Validation Loss: 0.241\n",
      "Epoch: 4206, Train Loss: 0.243, Validation Loss: 0.241\n",
      "Epoch: 4207, Train Loss: 0.216, Validation Loss: 0.242\n",
      "Epoch: 4208, Train Loss: 0.368, Validation Loss: 0.243\n",
      "Epoch: 4209, Train Loss: 0.254, Validation Loss: 0.241\n",
      "Epoch: 4210, Train Loss: 0.360, Validation Loss: 0.242\n",
      "Epoch: 4211, Train Loss: 0.237, Validation Loss: 0.242\n",
      "Epoch: 4212, Train Loss: 0.246, Validation Loss: 0.242\n",
      "Epoch: 4213, Train Loss: 0.289, Validation Loss: 0.242\n",
      "Epoch: 4214, Train Loss: 0.436, Validation Loss: 0.242\n",
      "Epoch: 4215, Train Loss: 0.264, Validation Loss: 0.242\n",
      "Epoch: 4216, Train Loss: 0.313, Validation Loss: 0.242\n",
      "Epoch: 4217, Train Loss: 0.379, Validation Loss: 0.245\n",
      "Epoch: 4218, Train Loss: 0.192, Validation Loss: 0.243\n",
      "Epoch: 4219, Train Loss: 0.438, Validation Loss: 0.242\n",
      "Epoch: 4220, Train Loss: 0.319, Validation Loss: 0.245\n",
      "Epoch: 4221, Train Loss: 0.253, Validation Loss: 0.245\n",
      "Epoch: 4222, Train Loss: 0.235, Validation Loss: 0.244\n",
      "Epoch: 4223, Train Loss: 0.250, Validation Loss: 0.241\n",
      "Epoch: 4224, Train Loss: 0.297, Validation Loss: 0.242\n",
      "Epoch: 4225, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 4226, Train Loss: 0.169, Validation Loss: 0.245\n",
      "Epoch: 4227, Train Loss: 0.307, Validation Loss: 0.242\n",
      "Epoch: 4228, Train Loss: 0.185, Validation Loss: 0.244\n",
      "Epoch: 4229, Train Loss: 0.261, Validation Loss: 0.247\n",
      "Epoch: 4230, Train Loss: 0.372, Validation Loss: 0.242\n",
      "Epoch: 4231, Train Loss: 0.192, Validation Loss: 0.244\n",
      "Epoch: 4232, Train Loss: 0.441, Validation Loss: 0.241\n",
      "Epoch: 4233, Train Loss: 0.210, Validation Loss: 0.242\n",
      "Epoch: 4234, Train Loss: 0.251, Validation Loss: 0.241\n",
      "Epoch: 4235, Train Loss: 0.190, Validation Loss: 0.242\n",
      "Epoch: 4236, Train Loss: 0.294, Validation Loss: 0.242\n",
      "Epoch: 4237, Train Loss: 0.331, Validation Loss: 0.247\n",
      "Epoch: 4238, Train Loss: 0.187, Validation Loss: 0.244\n",
      "Epoch: 4239, Train Loss: 0.193, Validation Loss: 0.244\n",
      "Epoch: 4240, Train Loss: 0.222, Validation Loss: 0.242\n",
      "Epoch: 4241, Train Loss: 0.247, Validation Loss: 0.241\n",
      "Epoch: 4242, Train Loss: 0.507, Validation Loss: 0.244\n",
      "Epoch: 4243, Train Loss: 0.238, Validation Loss: 0.243\n",
      "Epoch: 4244, Train Loss: 0.235, Validation Loss: 0.245\n",
      "Epoch: 4245, Train Loss: 0.253, Validation Loss: 0.244\n",
      "Epoch: 4246, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 4247, Train Loss: 0.252, Validation Loss: 0.242\n",
      "Epoch: 4248, Train Loss: 0.163, Validation Loss: 0.241\n",
      "Epoch: 4249, Train Loss: 0.213, Validation Loss: 0.241\n",
      "Epoch: 4250, Train Loss: 0.395, Validation Loss: 0.242\n",
      "Epoch: 4251, Train Loss: 0.216, Validation Loss: 0.244\n",
      "Epoch: 4252, Train Loss: 0.358, Validation Loss: 0.243\n",
      "Epoch: 4253, Train Loss: 0.229, Validation Loss: 0.243\n",
      "Epoch: 4254, Train Loss: 0.326, Validation Loss: 0.241\n",
      "Epoch: 4255, Train Loss: 0.361, Validation Loss: 0.250\n",
      "Epoch: 4256, Train Loss: 0.451, Validation Loss: 0.243\n",
      "Epoch: 4257, Train Loss: 0.232, Validation Loss: 0.246\n",
      "Epoch: 4258, Train Loss: 0.244, Validation Loss: 0.244\n",
      "Epoch: 4259, Train Loss: 0.312, Validation Loss: 0.244\n",
      "Epoch: 4260, Train Loss: 0.185, Validation Loss: 0.253\n",
      "Epoch: 4261, Train Loss: 0.229, Validation Loss: 0.246\n",
      "Epoch: 4262, Train Loss: 0.182, Validation Loss: 0.244\n",
      "Epoch: 4263, Train Loss: 0.203, Validation Loss: 0.242\n",
      "Epoch: 4264, Train Loss: 0.459, Validation Loss: 0.241\n",
      "Epoch: 4265, Train Loss: 0.207, Validation Loss: 0.243\n",
      "Epoch: 4266, Train Loss: 0.222, Validation Loss: 0.242\n",
      "Epoch: 4267, Train Loss: 0.227, Validation Loss: 0.241\n",
      "Epoch: 4268, Train Loss: 0.211, Validation Loss: 0.239\n",
      "Epoch: 4269, Train Loss: 0.288, Validation Loss: 0.241\n",
      "Epoch: 4270, Train Loss: 0.288, Validation Loss: 0.244\n",
      "Epoch: 4271, Train Loss: 0.287, Validation Loss: 0.244\n",
      "Epoch: 4272, Train Loss: 0.269, Validation Loss: 0.246\n",
      "Epoch: 4273, Train Loss: 0.232, Validation Loss: 0.243\n",
      "Epoch: 4274, Train Loss: 0.350, Validation Loss: 0.246\n",
      "Epoch: 4275, Train Loss: 0.216, Validation Loss: 0.241\n",
      "Epoch: 4276, Train Loss: 0.227, Validation Loss: 0.242\n",
      "Epoch: 4277, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 4278, Train Loss: 0.189, Validation Loss: 0.242\n",
      "Epoch: 4279, Train Loss: 0.247, Validation Loss: 0.243\n",
      "Epoch: 4280, Train Loss: 0.189, Validation Loss: 0.244\n",
      "Epoch: 4281, Train Loss: 0.224, Validation Loss: 0.243\n",
      "Epoch: 4282, Train Loss: 0.321, Validation Loss: 0.241\n",
      "Epoch: 4283, Train Loss: 0.383, Validation Loss: 0.241\n",
      "Epoch: 4284, Train Loss: 0.282, Validation Loss: 0.244\n",
      "Epoch: 4285, Train Loss: 0.268, Validation Loss: 0.248\n",
      "Epoch: 4286, Train Loss: 0.234, Validation Loss: 0.247\n",
      "Epoch: 4287, Train Loss: 0.185, Validation Loss: 0.242\n",
      "Epoch: 4288, Train Loss: 0.226, Validation Loss: 0.241\n",
      "Epoch: 4289, Train Loss: 0.275, Validation Loss: 0.241\n",
      "Epoch: 4290, Train Loss: 0.344, Validation Loss: 0.241\n",
      "Epoch: 4291, Train Loss: 0.308, Validation Loss: 0.243\n",
      "Epoch: 4292, Train Loss: 0.290, Validation Loss: 0.241\n",
      "Epoch: 4293, Train Loss: 0.245, Validation Loss: 0.240\n",
      "Epoch: 4294, Train Loss: 0.307, Validation Loss: 0.241\n",
      "Epoch: 4295, Train Loss: 0.243, Validation Loss: 0.245\n",
      "Epoch: 4296, Train Loss: 0.289, Validation Loss: 0.247\n",
      "Epoch: 4297, Train Loss: 0.255, Validation Loss: 0.242\n",
      "Epoch: 4298, Train Loss: 0.186, Validation Loss: 0.244\n",
      "Epoch: 4299, Train Loss: 0.278, Validation Loss: 0.242\n",
      "Epoch: 4300, Train Loss: 0.184, Validation Loss: 0.243\n",
      "Epoch: 4301, Train Loss: 0.310, Validation Loss: 0.245\n",
      "Epoch: 4302, Train Loss: 0.286, Validation Loss: 0.243\n",
      "Epoch: 4303, Train Loss: 0.301, Validation Loss: 0.245\n",
      "Epoch: 4304, Train Loss: 0.230, Validation Loss: 0.245\n",
      "Epoch: 4305, Train Loss: 0.277, Validation Loss: 0.245\n",
      "Epoch: 4306, Train Loss: 0.323, Validation Loss: 0.242\n",
      "Epoch: 4307, Train Loss: 0.301, Validation Loss: 0.243\n",
      "Epoch: 4308, Train Loss: 0.220, Validation Loss: 0.242\n",
      "Epoch: 4309, Train Loss: 0.205, Validation Loss: 0.242\n",
      "Epoch: 4310, Train Loss: 0.417, Validation Loss: 0.242\n",
      "Epoch: 4311, Train Loss: 0.219, Validation Loss: 0.244\n",
      "Epoch: 4312, Train Loss: 0.403, Validation Loss: 0.253\n",
      "Epoch: 4313, Train Loss: 0.224, Validation Loss: 0.245\n",
      "Epoch: 4314, Train Loss: 0.243, Validation Loss: 0.246\n",
      "Epoch: 4315, Train Loss: 0.280, Validation Loss: 0.244\n",
      "Epoch: 4316, Train Loss: 0.196, Validation Loss: 0.242\n",
      "Epoch: 4317, Train Loss: 0.181, Validation Loss: 0.244\n",
      "Epoch: 4318, Train Loss: 0.168, Validation Loss: 0.244\n",
      "Epoch: 4319, Train Loss: 0.317, Validation Loss: 0.244\n",
      "Epoch: 4320, Train Loss: 0.269, Validation Loss: 0.245\n",
      "Epoch: 4321, Train Loss: 0.191, Validation Loss: 0.245\n",
      "Epoch: 4322, Train Loss: 0.239, Validation Loss: 0.243\n",
      "Epoch: 4323, Train Loss: 0.219, Validation Loss: 0.244\n",
      "Epoch: 4324, Train Loss: 0.568, Validation Loss: 0.250\n",
      "Epoch: 4325, Train Loss: 0.217, Validation Loss: 0.246\n",
      "Epoch: 4326, Train Loss: 0.177, Validation Loss: 0.245\n",
      "Epoch: 4327, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 4328, Train Loss: 0.349, Validation Loss: 0.243\n",
      "Epoch: 4329, Train Loss: 0.284, Validation Loss: 0.247\n",
      "Epoch: 4330, Train Loss: 0.198, Validation Loss: 0.245\n",
      "Epoch: 4331, Train Loss: 0.185, Validation Loss: 0.245\n",
      "Epoch: 4332, Train Loss: 0.249, Validation Loss: 0.246\n",
      "Epoch: 4333, Train Loss: 0.222, Validation Loss: 0.244\n",
      "Epoch: 4334, Train Loss: 0.285, Validation Loss: 0.245\n",
      "Epoch: 4335, Train Loss: 0.260, Validation Loss: 0.245\n",
      "Epoch: 4336, Train Loss: 0.214, Validation Loss: 0.247\n",
      "Epoch: 4337, Train Loss: 0.698, Validation Loss: 0.245\n",
      "Epoch: 4338, Train Loss: 0.305, Validation Loss: 0.246\n",
      "Epoch: 4339, Train Loss: 0.251, Validation Loss: 0.250\n",
      "Epoch: 4340, Train Loss: 0.273, Validation Loss: 0.249\n",
      "Epoch: 4341, Train Loss: 0.239, Validation Loss: 0.244\n",
      "Epoch: 4342, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 4343, Train Loss: 0.187, Validation Loss: 0.245\n",
      "Epoch: 4344, Train Loss: 0.319, Validation Loss: 0.246\n",
      "Epoch: 4345, Train Loss: 0.267, Validation Loss: 0.245\n",
      "Epoch: 4346, Train Loss: 0.180, Validation Loss: 0.246\n",
      "Epoch: 4347, Train Loss: 0.145, Validation Loss: 0.244\n",
      "Epoch: 4348, Train Loss: 0.314, Validation Loss: 0.245\n",
      "Epoch: 4349, Train Loss: 0.209, Validation Loss: 0.247\n",
      "Epoch: 4350, Train Loss: 0.209, Validation Loss: 0.244\n",
      "Epoch: 4351, Train Loss: 0.293, Validation Loss: 0.245\n",
      "Epoch: 4352, Train Loss: 0.211, Validation Loss: 0.244\n",
      "Epoch: 4353, Train Loss: 0.250, Validation Loss: 0.245\n",
      "Epoch: 4354, Train Loss: 0.306, Validation Loss: 0.246\n",
      "Epoch: 4355, Train Loss: 0.209, Validation Loss: 0.244\n",
      "Epoch: 4356, Train Loss: 0.214, Validation Loss: 0.246\n",
      "Epoch: 4357, Train Loss: 0.367, Validation Loss: 0.243\n",
      "Epoch: 4358, Train Loss: 0.344, Validation Loss: 0.247\n",
      "Epoch: 4359, Train Loss: 0.232, Validation Loss: 0.244\n",
      "Epoch: 4360, Train Loss: 0.246, Validation Loss: 0.244\n",
      "Epoch: 4361, Train Loss: 0.189, Validation Loss: 0.244\n",
      "Epoch: 4362, Train Loss: 0.268, Validation Loss: 0.244\n",
      "Epoch: 4363, Train Loss: 0.235, Validation Loss: 0.244\n",
      "Epoch: 4364, Train Loss: 0.267, Validation Loss: 0.244\n",
      "Epoch: 4365, Train Loss: 0.283, Validation Loss: 0.244\n",
      "Epoch: 4366, Train Loss: 0.371, Validation Loss: 0.246\n",
      "Epoch: 4367, Train Loss: 0.239, Validation Loss: 0.246\n",
      "Epoch: 4368, Train Loss: 0.197, Validation Loss: 0.244\n",
      "Epoch: 4369, Train Loss: 0.190, Validation Loss: 0.244\n",
      "Epoch: 4370, Train Loss: 0.247, Validation Loss: 0.244\n",
      "Epoch: 4371, Train Loss: 0.274, Validation Loss: 0.247\n",
      "Epoch: 4372, Train Loss: 0.475, Validation Loss: 0.250\n",
      "Epoch: 4373, Train Loss: 0.387, Validation Loss: 0.246\n",
      "Epoch: 4374, Train Loss: 0.237, Validation Loss: 0.247\n",
      "Epoch: 4375, Train Loss: 0.282, Validation Loss: 0.246\n",
      "Epoch: 4376, Train Loss: 0.243, Validation Loss: 0.248\n",
      "Epoch: 4377, Train Loss: 0.417, Validation Loss: 0.248\n",
      "Epoch: 4378, Train Loss: 0.346, Validation Loss: 0.246\n",
      "Epoch: 4379, Train Loss: 0.243, Validation Loss: 0.248\n",
      "Epoch: 4380, Train Loss: 0.430, Validation Loss: 0.246\n",
      "Epoch: 4381, Train Loss: 0.224, Validation Loss: 0.246\n",
      "Epoch: 4382, Train Loss: 0.272, Validation Loss: 0.244\n",
      "Epoch: 4383, Train Loss: 0.479, Validation Loss: 0.244\n",
      "Epoch: 4384, Train Loss: 0.237, Validation Loss: 0.246\n",
      "Epoch: 4385, Train Loss: 0.209, Validation Loss: 0.244\n",
      "Epoch: 4386, Train Loss: 0.767, Validation Loss: 0.243\n",
      "Epoch: 4387, Train Loss: 0.221, Validation Loss: 0.246\n",
      "Epoch: 4388, Train Loss: 0.145, Validation Loss: 0.245\n",
      "Epoch: 4389, Train Loss: 0.289, Validation Loss: 0.247\n",
      "Epoch: 4390, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 4391, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 4392, Train Loss: 0.528, Validation Loss: 0.250\n",
      "Epoch: 4393, Train Loss: 0.227, Validation Loss: 0.245\n",
      "Epoch: 4394, Train Loss: 0.258, Validation Loss: 0.246\n",
      "Epoch: 4395, Train Loss: 0.295, Validation Loss: 0.244\n",
      "Epoch: 4396, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 4397, Train Loss: 0.394, Validation Loss: 0.245\n",
      "Epoch: 4398, Train Loss: 0.247, Validation Loss: 0.245\n",
      "Epoch: 4399, Train Loss: 0.382, Validation Loss: 0.249\n",
      "Epoch: 4400, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 4401, Train Loss: 0.247, Validation Loss: 0.245\n",
      "Epoch: 4402, Train Loss: 0.291, Validation Loss: 0.247\n",
      "Epoch: 4403, Train Loss: 0.316, Validation Loss: 0.245\n",
      "Epoch: 4404, Train Loss: 0.171, Validation Loss: 0.245\n",
      "Epoch: 4405, Train Loss: 0.187, Validation Loss: 0.248\n",
      "Epoch: 4406, Train Loss: 0.248, Validation Loss: 0.250\n",
      "Epoch: 4407, Train Loss: 0.181, Validation Loss: 0.247\n",
      "Epoch: 4408, Train Loss: 0.400, Validation Loss: 0.253\n",
      "Epoch: 4409, Train Loss: 0.207, Validation Loss: 0.249\n",
      "Epoch: 4410, Train Loss: 0.178, Validation Loss: 0.246\n",
      "Epoch: 4411, Train Loss: 0.452, Validation Loss: 0.247\n",
      "Epoch: 4412, Train Loss: 0.200, Validation Loss: 0.245\n",
      "Epoch: 4413, Train Loss: 0.392, Validation Loss: 0.245\n",
      "Epoch: 4414, Train Loss: 0.534, Validation Loss: 0.246\n",
      "Epoch: 4415, Train Loss: 0.204, Validation Loss: 0.247\n",
      "Epoch: 4416, Train Loss: 0.278, Validation Loss: 0.246\n",
      "Epoch: 4417, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 4418, Train Loss: 0.199, Validation Loss: 0.251\n",
      "Epoch: 4419, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 4420, Train Loss: 0.380, Validation Loss: 0.248\n",
      "Epoch: 4421, Train Loss: 0.206, Validation Loss: 0.247\n",
      "Epoch: 4422, Train Loss: 0.258, Validation Loss: 0.248\n",
      "Epoch: 4423, Train Loss: 0.210, Validation Loss: 0.247\n",
      "Epoch: 4424, Train Loss: 0.218, Validation Loss: 0.247\n",
      "Epoch: 4425, Train Loss: 0.314, Validation Loss: 0.247\n",
      "Epoch: 4426, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 4427, Train Loss: 0.181, Validation Loss: 0.247\n",
      "Epoch: 4428, Train Loss: 0.310, Validation Loss: 0.245\n",
      "Epoch: 4429, Train Loss: 0.247, Validation Loss: 0.251\n",
      "Epoch: 4430, Train Loss: 0.443, Validation Loss: 0.247\n",
      "Epoch: 4431, Train Loss: 0.204, Validation Loss: 0.246\n",
      "Epoch: 4432, Train Loss: 0.195, Validation Loss: 0.247\n",
      "Epoch: 4433, Train Loss: 0.674, Validation Loss: 0.251\n",
      "Epoch: 4434, Train Loss: 0.189, Validation Loss: 0.246\n",
      "Epoch: 4435, Train Loss: 0.315, Validation Loss: 0.251\n",
      "Epoch: 4436, Train Loss: 0.253, Validation Loss: 0.248\n",
      "Epoch: 4437, Train Loss: 0.321, Validation Loss: 0.247\n",
      "Epoch: 4438, Train Loss: 0.275, Validation Loss: 0.248\n",
      "Epoch: 4439, Train Loss: 0.197, Validation Loss: 0.247\n",
      "Epoch: 4440, Train Loss: 0.164, Validation Loss: 0.249\n",
      "Epoch: 4441, Train Loss: 0.443, Validation Loss: 0.248\n",
      "Epoch: 4442, Train Loss: 0.315, Validation Loss: 0.246\n",
      "Epoch: 4443, Train Loss: 0.384, Validation Loss: 0.248\n",
      "Epoch: 4444, Train Loss: 0.232, Validation Loss: 0.248\n",
      "Epoch: 4445, Train Loss: 0.252, Validation Loss: 0.247\n",
      "Epoch: 4446, Train Loss: 0.221, Validation Loss: 0.248\n",
      "Epoch: 4447, Train Loss: 0.266, Validation Loss: 0.247\n",
      "Epoch: 4448, Train Loss: 0.250, Validation Loss: 0.248\n",
      "Epoch: 4449, Train Loss: 0.315, Validation Loss: 0.248\n",
      "Epoch: 4450, Train Loss: 0.316, Validation Loss: 0.247\n",
      "Epoch: 4451, Train Loss: 0.291, Validation Loss: 0.247\n",
      "Epoch: 4452, Train Loss: 0.377, Validation Loss: 0.253\n",
      "Epoch: 4453, Train Loss: 0.225, Validation Loss: 0.248\n",
      "Epoch: 4454, Train Loss: 0.160, Validation Loss: 0.246\n",
      "Epoch: 4455, Train Loss: 0.329, Validation Loss: 0.246\n",
      "Epoch: 4456, Train Loss: 0.370, Validation Loss: 0.247\n",
      "Epoch: 4457, Train Loss: 0.435, Validation Loss: 0.247\n",
      "Epoch: 4458, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 4459, Train Loss: 0.205, Validation Loss: 0.246\n",
      "Epoch: 4460, Train Loss: 0.250, Validation Loss: 0.245\n",
      "Epoch: 4461, Train Loss: 0.185, Validation Loss: 0.244\n",
      "Epoch: 4462, Train Loss: 0.317, Validation Loss: 0.247\n",
      "Epoch: 4463, Train Loss: 0.196, Validation Loss: 0.248\n",
      "Epoch: 4464, Train Loss: 0.303, Validation Loss: 0.250\n",
      "Epoch: 4465, Train Loss: 0.215, Validation Loss: 0.249\n",
      "Epoch: 4466, Train Loss: 0.243, Validation Loss: 0.250\n",
      "Epoch: 4467, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 4468, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 4469, Train Loss: 0.278, Validation Loss: 0.245\n",
      "Epoch: 4470, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 4471, Train Loss: 0.238, Validation Loss: 0.249\n",
      "Epoch: 4472, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 4473, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 4474, Train Loss: 0.298, Validation Loss: 0.246\n",
      "Epoch: 4475, Train Loss: 0.147, Validation Loss: 0.246\n",
      "Epoch: 4476, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 4477, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 4478, Train Loss: 0.254, Validation Loss: 0.247\n",
      "Epoch: 4479, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 4480, Train Loss: 0.396, Validation Loss: 0.246\n",
      "Epoch: 4481, Train Loss: 0.517, Validation Loss: 0.246\n",
      "Epoch: 4482, Train Loss: 0.236, Validation Loss: 0.247\n",
      "Epoch: 4483, Train Loss: 0.145, Validation Loss: 0.251\n",
      "Epoch: 4484, Train Loss: 0.195, Validation Loss: 0.248\n",
      "Epoch: 4485, Train Loss: 0.387, Validation Loss: 0.246\n",
      "Epoch: 4486, Train Loss: 0.518, Validation Loss: 0.246\n",
      "Epoch: 4487, Train Loss: 0.156, Validation Loss: 0.246\n",
      "Epoch: 4488, Train Loss: 0.195, Validation Loss: 0.247\n",
      "Epoch: 4489, Train Loss: 0.360, Validation Loss: 0.246\n",
      "Epoch: 4490, Train Loss: 0.337, Validation Loss: 0.246\n",
      "Epoch: 4491, Train Loss: 0.181, Validation Loss: 0.246\n",
      "Epoch: 4492, Train Loss: 0.211, Validation Loss: 0.245\n",
      "Epoch: 4493, Train Loss: 0.342, Validation Loss: 0.244\n",
      "Epoch: 4494, Train Loss: 0.276, Validation Loss: 0.244\n",
      "Epoch: 4495, Train Loss: 0.362, Validation Loss: 0.245\n",
      "Epoch: 4496, Train Loss: 0.303, Validation Loss: 0.244\n",
      "Epoch: 4497, Train Loss: 0.196, Validation Loss: 0.244\n",
      "Epoch: 4498, Train Loss: 0.182, Validation Loss: 0.243\n",
      "Epoch: 4499, Train Loss: 0.278, Validation Loss: 0.244\n",
      "Epoch: 4500, Train Loss: 0.278, Validation Loss: 0.244\n",
      "Epoch: 4501, Train Loss: 0.188, Validation Loss: 0.248\n",
      "Epoch: 4502, Train Loss: 0.459, Validation Loss: 0.244\n",
      "Epoch: 4503, Train Loss: 0.226, Validation Loss: 0.246\n",
      "Epoch: 4504, Train Loss: 0.232, Validation Loss: 0.246\n",
      "Epoch: 4505, Train Loss: 0.282, Validation Loss: 0.243\n",
      "Epoch: 4506, Train Loss: 0.464, Validation Loss: 0.248\n",
      "Epoch: 4507, Train Loss: 0.241, Validation Loss: 0.243\n",
      "Epoch: 4508, Train Loss: 0.310, Validation Loss: 0.244\n",
      "Epoch: 4509, Train Loss: 0.234, Validation Loss: 0.244\n",
      "Epoch: 4510, Train Loss: 0.213, Validation Loss: 0.245\n",
      "Epoch: 4511, Train Loss: 0.194, Validation Loss: 0.245\n",
      "Epoch: 4512, Train Loss: 0.272, Validation Loss: 0.245\n",
      "Epoch: 4513, Train Loss: 0.296, Validation Loss: 0.247\n",
      "Epoch: 4514, Train Loss: 0.278, Validation Loss: 0.249\n",
      "Epoch: 4515, Train Loss: 0.261, Validation Loss: 0.252\n",
      "Epoch: 4516, Train Loss: 0.205, Validation Loss: 0.245\n",
      "Epoch: 4517, Train Loss: 0.373, Validation Loss: 0.245\n",
      "Epoch: 4518, Train Loss: 0.236, Validation Loss: 0.243\n",
      "Epoch: 4519, Train Loss: 0.461, Validation Loss: 0.248\n",
      "Epoch: 4520, Train Loss: 0.217, Validation Loss: 0.248\n",
      "Epoch: 4521, Train Loss: 0.228, Validation Loss: 0.249\n",
      "Epoch: 4522, Train Loss: 0.323, Validation Loss: 0.245\n",
      "Epoch: 4523, Train Loss: 0.295, Validation Loss: 0.244\n",
      "Epoch: 4524, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 4525, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 4526, Train Loss: 0.368, Validation Loss: 0.248\n",
      "Epoch: 4527, Train Loss: 0.189, Validation Loss: 0.246\n",
      "Epoch: 4528, Train Loss: 0.209, Validation Loss: 0.246\n",
      "Epoch: 4529, Train Loss: 0.171, Validation Loss: 0.247\n",
      "Epoch: 4530, Train Loss: 0.339, Validation Loss: 0.246\n",
      "Epoch: 4531, Train Loss: 0.317, Validation Loss: 0.244\n",
      "Epoch: 4532, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 4533, Train Loss: 0.185, Validation Loss: 0.245\n",
      "Epoch: 4534, Train Loss: 0.294, Validation Loss: 0.246\n",
      "Epoch: 4535, Train Loss: 0.231, Validation Loss: 0.247\n",
      "Epoch: 4536, Train Loss: 0.435, Validation Loss: 0.246\n",
      "Epoch: 4537, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 4538, Train Loss: 0.236, Validation Loss: 0.245\n",
      "Epoch: 4539, Train Loss: 0.256, Validation Loss: 0.245\n",
      "Epoch: 4540, Train Loss: 0.173, Validation Loss: 0.247\n",
      "Epoch: 4541, Train Loss: 0.218, Validation Loss: 0.245\n",
      "Epoch: 4542, Train Loss: 0.213, Validation Loss: 0.243\n",
      "Epoch: 4543, Train Loss: 0.449, Validation Loss: 0.246\n",
      "Epoch: 4544, Train Loss: 0.274, Validation Loss: 0.243\n",
      "Epoch: 4545, Train Loss: 0.304, Validation Loss: 0.242\n",
      "Epoch: 4546, Train Loss: 0.349, Validation Loss: 0.247\n",
      "Epoch: 4547, Train Loss: 0.180, Validation Loss: 0.244\n",
      "Epoch: 4548, Train Loss: 0.208, Validation Loss: 0.246\n",
      "Epoch: 4549, Train Loss: 0.327, Validation Loss: 0.248\n",
      "Epoch: 4550, Train Loss: 0.348, Validation Loss: 0.242\n",
      "Epoch: 4551, Train Loss: 0.208, Validation Loss: 0.243\n",
      "Epoch: 4552, Train Loss: 0.223, Validation Loss: 0.243\n",
      "Epoch: 4553, Train Loss: 0.272, Validation Loss: 0.247\n",
      "Epoch: 4554, Train Loss: 0.269, Validation Loss: 0.245\n",
      "Epoch: 4555, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 4556, Train Loss: 0.244, Validation Loss: 0.250\n",
      "Epoch: 4557, Train Loss: 0.221, Validation Loss: 0.244\n",
      "Epoch: 4558, Train Loss: 0.282, Validation Loss: 0.244\n",
      "Epoch: 4559, Train Loss: 0.225, Validation Loss: 0.244\n",
      "Epoch: 4560, Train Loss: 0.268, Validation Loss: 0.243\n",
      "Epoch: 4561, Train Loss: 0.242, Validation Loss: 0.242\n",
      "Epoch: 4562, Train Loss: 0.254, Validation Loss: 0.245\n",
      "Epoch: 4563, Train Loss: 0.230, Validation Loss: 0.246\n",
      "Epoch: 4564, Train Loss: 0.173, Validation Loss: 0.246\n",
      "Epoch: 4565, Train Loss: 0.225, Validation Loss: 0.246\n",
      "Epoch: 4566, Train Loss: 0.277, Validation Loss: 0.244\n",
      "Epoch: 4567, Train Loss: 0.292, Validation Loss: 0.250\n",
      "Epoch: 4568, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 4569, Train Loss: 0.412, Validation Loss: 0.245\n",
      "Epoch: 4570, Train Loss: 0.221, Validation Loss: 0.248\n",
      "Epoch: 4571, Train Loss: 0.217, Validation Loss: 0.245\n",
      "Epoch: 4572, Train Loss: 0.258, Validation Loss: 0.246\n",
      "Epoch: 4573, Train Loss: 0.409, Validation Loss: 0.247\n",
      "Epoch: 4574, Train Loss: 0.276, Validation Loss: 0.251\n",
      "Epoch: 4575, Train Loss: 0.224, Validation Loss: 0.246\n",
      "Epoch: 4576, Train Loss: 0.270, Validation Loss: 0.246\n",
      "Epoch: 4577, Train Loss: 0.203, Validation Loss: 0.247\n",
      "Epoch: 4578, Train Loss: 0.290, Validation Loss: 0.248\n",
      "Epoch: 4579, Train Loss: 0.314, Validation Loss: 0.248\n",
      "Epoch: 4580, Train Loss: 0.220, Validation Loss: 0.247\n",
      "Epoch: 4581, Train Loss: 0.239, Validation Loss: 0.246\n",
      "Epoch: 4582, Train Loss: 0.437, Validation Loss: 0.249\n",
      "Epoch: 4583, Train Loss: 0.267, Validation Loss: 0.250\n",
      "Epoch: 4584, Train Loss: 0.314, Validation Loss: 0.251\n",
      "Epoch: 4585, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 4586, Train Loss: 0.201, Validation Loss: 0.247\n",
      "Epoch: 4587, Train Loss: 0.297, Validation Loss: 0.247\n",
      "Epoch: 4588, Train Loss: 0.212, Validation Loss: 0.245\n",
      "Epoch: 4589, Train Loss: 0.324, Validation Loss: 0.249\n",
      "Epoch: 4590, Train Loss: 0.414, Validation Loss: 0.254\n",
      "Epoch: 4591, Train Loss: 0.210, Validation Loss: 0.248\n",
      "Epoch: 4592, Train Loss: 0.262, Validation Loss: 0.252\n",
      "Epoch: 4593, Train Loss: 0.181, Validation Loss: 0.252\n",
      "Epoch: 4594, Train Loss: 0.263, Validation Loss: 0.251\n",
      "Epoch: 4595, Train Loss: 0.229, Validation Loss: 0.247\n",
      "Epoch: 4596, Train Loss: 0.282, Validation Loss: 0.247\n",
      "Epoch: 4597, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 4598, Train Loss: 0.238, Validation Loss: 0.248\n",
      "Epoch: 4599, Train Loss: 0.200, Validation Loss: 0.246\n",
      "Epoch: 4600, Train Loss: 0.230, Validation Loss: 0.247\n",
      "Epoch: 4601, Train Loss: 0.253, Validation Loss: 0.251\n",
      "Epoch: 4602, Train Loss: 0.183, Validation Loss: 0.246\n",
      "Epoch: 4603, Train Loss: 0.301, Validation Loss: 0.247\n",
      "Epoch: 4604, Train Loss: 0.557, Validation Loss: 0.251\n",
      "Epoch: 4605, Train Loss: 0.287, Validation Loss: 0.248\n",
      "Epoch: 4606, Train Loss: 0.239, Validation Loss: 0.251\n",
      "Epoch: 4607, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 4608, Train Loss: 0.170, Validation Loss: 0.249\n",
      "Epoch: 4609, Train Loss: 0.206, Validation Loss: 0.247\n",
      "Epoch: 4610, Train Loss: 0.204, Validation Loss: 0.249\n",
      "Epoch: 4611, Train Loss: 0.187, Validation Loss: 0.248\n",
      "Epoch: 4612, Train Loss: 0.321, Validation Loss: 0.249\n",
      "Epoch: 4613, Train Loss: 0.399, Validation Loss: 0.245\n",
      "Epoch: 4614, Train Loss: 0.231, Validation Loss: 0.247\n",
      "Epoch: 4615, Train Loss: 0.675, Validation Loss: 0.245\n",
      "Epoch: 4616, Train Loss: 0.278, Validation Loss: 0.251\n",
      "Epoch: 4617, Train Loss: 0.233, Validation Loss: 0.248\n",
      "Epoch: 4618, Train Loss: 0.286, Validation Loss: 0.244\n",
      "Epoch: 4619, Train Loss: 0.163, Validation Loss: 0.244\n",
      "Epoch: 4620, Train Loss: 0.217, Validation Loss: 0.244\n",
      "Epoch: 4621, Train Loss: 0.197, Validation Loss: 0.247\n",
      "Epoch: 4622, Train Loss: 0.255, Validation Loss: 0.243\n",
      "Epoch: 4623, Train Loss: 0.264, Validation Loss: 0.243\n",
      "Epoch: 4624, Train Loss: 0.279, Validation Loss: 0.248\n",
      "Epoch: 4625, Train Loss: 0.197, Validation Loss: 0.245\n",
      "Epoch: 4626, Train Loss: 0.278, Validation Loss: 0.244\n",
      "Epoch: 4627, Train Loss: 0.426, Validation Loss: 0.248\n",
      "Epoch: 4628, Train Loss: 0.379, Validation Loss: 0.245\n",
      "Epoch: 4629, Train Loss: 0.268, Validation Loss: 0.245\n",
      "Epoch: 4630, Train Loss: 0.278, Validation Loss: 0.248\n",
      "Epoch: 4631, Train Loss: 0.290, Validation Loss: 0.248\n",
      "Epoch: 4632, Train Loss: 0.227, Validation Loss: 0.244\n",
      "Epoch: 4633, Train Loss: 0.290, Validation Loss: 0.249\n",
      "Epoch: 4634, Train Loss: 0.413, Validation Loss: 0.247\n",
      "Epoch: 4635, Train Loss: 0.240, Validation Loss: 0.247\n",
      "Epoch: 4636, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 4637, Train Loss: 0.238, Validation Loss: 0.250\n",
      "Epoch: 4638, Train Loss: 0.269, Validation Loss: 0.251\n",
      "Epoch: 4639, Train Loss: 0.193, Validation Loss: 0.245\n",
      "Epoch: 4640, Train Loss: 0.199, Validation Loss: 0.245\n",
      "Epoch: 4641, Train Loss: 0.278, Validation Loss: 0.246\n",
      "Epoch: 4642, Train Loss: 0.371, Validation Loss: 0.252\n",
      "Epoch: 4643, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 4644, Train Loss: 0.291, Validation Loss: 0.245\n",
      "Epoch: 4645, Train Loss: 0.294, Validation Loss: 0.247\n",
      "Epoch: 4646, Train Loss: 0.460, Validation Loss: 0.249\n",
      "Epoch: 4647, Train Loss: 0.233, Validation Loss: 0.247\n",
      "Epoch: 4648, Train Loss: 0.350, Validation Loss: 0.245\n",
      "Epoch: 4649, Train Loss: 0.224, Validation Loss: 0.247\n",
      "Epoch: 4650, Train Loss: 0.162, Validation Loss: 0.247\n",
      "Epoch: 4651, Train Loss: 0.171, Validation Loss: 0.245\n",
      "Epoch: 4652, Train Loss: 0.197, Validation Loss: 0.244\n",
      "Epoch: 4653, Train Loss: 0.254, Validation Loss: 0.246\n",
      "Epoch: 4654, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 4655, Train Loss: 0.235, Validation Loss: 0.248\n",
      "Epoch: 4656, Train Loss: 0.265, Validation Loss: 0.246\n",
      "Epoch: 4657, Train Loss: 0.255, Validation Loss: 0.246\n",
      "Epoch: 4658, Train Loss: 0.358, Validation Loss: 0.245\n",
      "Epoch: 4659, Train Loss: 0.331, Validation Loss: 0.248\n",
      "Epoch: 4660, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 4661, Train Loss: 0.250, Validation Loss: 0.246\n",
      "Epoch: 4662, Train Loss: 0.243, Validation Loss: 0.247\n",
      "Epoch: 4663, Train Loss: 0.289, Validation Loss: 0.245\n",
      "Epoch: 4664, Train Loss: 0.202, Validation Loss: 0.247\n",
      "Epoch: 4665, Train Loss: 0.206, Validation Loss: 0.248\n",
      "Epoch: 4666, Train Loss: 0.261, Validation Loss: 0.251\n",
      "Epoch: 4667, Train Loss: 0.568, Validation Loss: 0.250\n",
      "Epoch: 4668, Train Loss: 0.476, Validation Loss: 0.248\n",
      "Epoch: 4669, Train Loss: 0.296, Validation Loss: 0.246\n",
      "Epoch: 4670, Train Loss: 0.234, Validation Loss: 0.248\n",
      "Epoch: 4671, Train Loss: 0.396, Validation Loss: 0.249\n",
      "Epoch: 4672, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 4673, Train Loss: 0.419, Validation Loss: 0.249\n",
      "Epoch: 4674, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 4675, Train Loss: 0.289, Validation Loss: 0.250\n",
      "Epoch: 4676, Train Loss: 0.232, Validation Loss: 0.247\n",
      "Epoch: 4677, Train Loss: 0.267, Validation Loss: 0.247\n",
      "Epoch: 4678, Train Loss: 0.216, Validation Loss: 0.245\n",
      "Epoch: 4679, Train Loss: 0.289, Validation Loss: 0.245\n",
      "Epoch: 4680, Train Loss: 0.508, Validation Loss: 0.248\n",
      "Epoch: 4681, Train Loss: 0.345, Validation Loss: 0.248\n",
      "Epoch: 4682, Train Loss: 0.275, Validation Loss: 0.248\n",
      "Epoch: 4683, Train Loss: 0.484, Validation Loss: 0.245\n",
      "Epoch: 4684, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 4685, Train Loss: 0.245, Validation Loss: 0.247\n",
      "Epoch: 4686, Train Loss: 0.299, Validation Loss: 0.256\n",
      "Epoch: 4687, Train Loss: 0.421, Validation Loss: 0.243\n",
      "Epoch: 4688, Train Loss: 0.236, Validation Loss: 0.244\n",
      "Epoch: 4689, Train Loss: 0.214, Validation Loss: 0.246\n",
      "Epoch: 4690, Train Loss: 0.165, Validation Loss: 0.246\n",
      "Epoch: 4691, Train Loss: 0.296, Validation Loss: 0.246\n",
      "Epoch: 4692, Train Loss: 0.230, Validation Loss: 0.243\n",
      "Epoch: 4693, Train Loss: 0.335, Validation Loss: 0.243\n",
      "Epoch: 4694, Train Loss: 0.325, Validation Loss: 0.243\n",
      "Epoch: 4695, Train Loss: 0.248, Validation Loss: 0.246\n",
      "Epoch: 4696, Train Loss: 0.300, Validation Loss: 0.252\n",
      "Epoch: 4697, Train Loss: 0.233, Validation Loss: 0.245\n",
      "Epoch: 4698, Train Loss: 0.362, Validation Loss: 0.247\n",
      "Epoch: 4699, Train Loss: 0.224, Validation Loss: 0.251\n",
      "Epoch: 4700, Train Loss: 0.327, Validation Loss: 0.244\n",
      "Epoch: 4701, Train Loss: 0.239, Validation Loss: 0.246\n",
      "Epoch: 4702, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 4703, Train Loss: 0.307, Validation Loss: 0.252\n",
      "Epoch: 4704, Train Loss: 0.285, Validation Loss: 0.246\n",
      "Epoch: 4705, Train Loss: 0.598, Validation Loss: 0.247\n",
      "Epoch: 4706, Train Loss: 0.198, Validation Loss: 0.245\n",
      "Epoch: 4707, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 4708, Train Loss: 0.234, Validation Loss: 0.249\n",
      "Epoch: 4709, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 4710, Train Loss: 0.248, Validation Loss: 0.247\n",
      "Epoch: 4711, Train Loss: 0.191, Validation Loss: 0.249\n",
      "Epoch: 4712, Train Loss: 0.331, Validation Loss: 0.249\n",
      "Epoch: 4713, Train Loss: 0.172, Validation Loss: 0.249\n",
      "Epoch: 4714, Train Loss: 0.171, Validation Loss: 0.249\n",
      "Epoch: 4715, Train Loss: 0.355, Validation Loss: 0.252\n",
      "Epoch: 4716, Train Loss: 0.633, Validation Loss: 0.249\n",
      "Epoch: 4717, Train Loss: 0.174, Validation Loss: 0.246\n",
      "Epoch: 4718, Train Loss: 0.382, Validation Loss: 0.246\n",
      "Epoch: 4719, Train Loss: 0.335, Validation Loss: 0.245\n",
      "Epoch: 4720, Train Loss: 0.221, Validation Loss: 0.246\n",
      "Epoch: 4721, Train Loss: 0.288, Validation Loss: 0.252\n",
      "Epoch: 4722, Train Loss: 0.399, Validation Loss: 0.248\n",
      "Epoch: 4723, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 4724, Train Loss: 0.265, Validation Loss: 0.249\n",
      "Epoch: 4725, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 4726, Train Loss: 0.259, Validation Loss: 0.249\n",
      "Epoch: 4727, Train Loss: 0.522, Validation Loss: 0.246\n",
      "Epoch: 4728, Train Loss: 0.269, Validation Loss: 0.245\n",
      "Epoch: 4729, Train Loss: 0.269, Validation Loss: 0.251\n",
      "Epoch: 4730, Train Loss: 0.384, Validation Loss: 0.258\n",
      "Epoch: 4731, Train Loss: 0.258, Validation Loss: 0.250\n",
      "Epoch: 4732, Train Loss: 0.290, Validation Loss: 0.246\n",
      "Epoch: 4733, Train Loss: 0.301, Validation Loss: 0.246\n",
      "Epoch: 4734, Train Loss: 0.532, Validation Loss: 0.250\n",
      "Epoch: 4735, Train Loss: 0.205, Validation Loss: 0.251\n",
      "Epoch: 4736, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 4737, Train Loss: 0.443, Validation Loss: 0.245\n",
      "Epoch: 4738, Train Loss: 0.295, Validation Loss: 0.247\n",
      "Epoch: 4739, Train Loss: 0.215, Validation Loss: 0.248\n",
      "Epoch: 4740, Train Loss: 0.236, Validation Loss: 0.246\n",
      "Epoch: 4741, Train Loss: 0.382, Validation Loss: 0.247\n",
      "Epoch: 4742, Train Loss: 0.372, Validation Loss: 0.246\n",
      "Epoch: 4743, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 4744, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 4745, Train Loss: 0.391, Validation Loss: 0.251\n",
      "Epoch: 4746, Train Loss: 0.272, Validation Loss: 0.247\n",
      "Epoch: 4747, Train Loss: 0.208, Validation Loss: 0.246\n",
      "Epoch: 4748, Train Loss: 0.215, Validation Loss: 0.248\n",
      "Epoch: 4749, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 4750, Train Loss: 0.277, Validation Loss: 0.246\n",
      "Epoch: 4751, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 4752, Train Loss: 0.267, Validation Loss: 0.246\n",
      "Epoch: 4753, Train Loss: 0.153, Validation Loss: 0.247\n",
      "Epoch: 4754, Train Loss: 0.194, Validation Loss: 0.246\n",
      "Epoch: 4755, Train Loss: 0.175, Validation Loss: 0.246\n",
      "Epoch: 4756, Train Loss: 0.224, Validation Loss: 0.244\n",
      "Epoch: 4757, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 4758, Train Loss: 0.221, Validation Loss: 0.253\n",
      "Epoch: 4759, Train Loss: 0.209, Validation Loss: 0.246\n",
      "Epoch: 4760, Train Loss: 0.269, Validation Loss: 0.244\n",
      "Epoch: 4761, Train Loss: 0.327, Validation Loss: 0.245\n",
      "Epoch: 4762, Train Loss: 0.263, Validation Loss: 0.248\n",
      "Epoch: 4763, Train Loss: 0.277, Validation Loss: 0.246\n",
      "Epoch: 4764, Train Loss: 0.172, Validation Loss: 0.244\n",
      "Epoch: 4765, Train Loss: 0.161, Validation Loss: 0.244\n",
      "Epoch: 4766, Train Loss: 0.241, Validation Loss: 0.247\n",
      "Epoch: 4767, Train Loss: 0.267, Validation Loss: 0.246\n",
      "Epoch: 4768, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 4769, Train Loss: 0.227, Validation Loss: 0.247\n",
      "Epoch: 4770, Train Loss: 0.212, Validation Loss: 0.247\n",
      "Epoch: 4771, Train Loss: 0.236, Validation Loss: 0.246\n",
      "Epoch: 4772, Train Loss: 0.166, Validation Loss: 0.250\n",
      "Epoch: 4773, Train Loss: 0.251, Validation Loss: 0.247\n",
      "Epoch: 4774, Train Loss: 0.196, Validation Loss: 0.246\n",
      "Epoch: 4775, Train Loss: 0.434, Validation Loss: 0.249\n",
      "Epoch: 4776, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 4777, Train Loss: 0.295, Validation Loss: 0.246\n",
      "Epoch: 4778, Train Loss: 0.182, Validation Loss: 0.246\n",
      "Epoch: 4779, Train Loss: 0.322, Validation Loss: 0.250\n",
      "Epoch: 4780, Train Loss: 0.186, Validation Loss: 0.250\n",
      "Epoch: 4781, Train Loss: 0.192, Validation Loss: 0.247\n",
      "Epoch: 4782, Train Loss: 0.172, Validation Loss: 0.246\n",
      "Epoch: 4783, Train Loss: 0.252, Validation Loss: 0.247\n",
      "Epoch: 4784, Train Loss: 0.263, Validation Loss: 0.245\n",
      "Epoch: 4785, Train Loss: 0.230, Validation Loss: 0.245\n",
      "Epoch: 4786, Train Loss: 0.208, Validation Loss: 0.245\n",
      "Epoch: 4787, Train Loss: 0.257, Validation Loss: 0.250\n",
      "Epoch: 4788, Train Loss: 0.230, Validation Loss: 0.247\n",
      "Epoch: 4789, Train Loss: 0.190, Validation Loss: 0.245\n",
      "Epoch: 4790, Train Loss: 0.411, Validation Loss: 0.246\n",
      "Epoch: 4791, Train Loss: 0.223, Validation Loss: 0.246\n",
      "Epoch: 4792, Train Loss: 0.232, Validation Loss: 0.253\n",
      "Epoch: 4793, Train Loss: 0.192, Validation Loss: 0.246\n",
      "Epoch: 4794, Train Loss: 0.333, Validation Loss: 0.246\n",
      "Epoch: 4795, Train Loss: 0.229, Validation Loss: 0.247\n",
      "Epoch: 4796, Train Loss: 0.325, Validation Loss: 0.253\n",
      "Epoch: 4797, Train Loss: 0.324, Validation Loss: 0.254\n",
      "Epoch: 4798, Train Loss: 0.209, Validation Loss: 0.245\n",
      "Epoch: 4799, Train Loss: 0.225, Validation Loss: 0.244\n",
      "Epoch: 4800, Train Loss: 0.331, Validation Loss: 0.245\n",
      "Epoch: 4801, Train Loss: 0.315, Validation Loss: 0.247\n",
      "Epoch: 4802, Train Loss: 0.468, Validation Loss: 0.248\n",
      "Epoch: 4803, Train Loss: 0.298, Validation Loss: 0.248\n",
      "Epoch: 4804, Train Loss: 0.226, Validation Loss: 0.246\n",
      "Epoch: 4805, Train Loss: 0.279, Validation Loss: 0.247\n",
      "Epoch: 4806, Train Loss: 0.159, Validation Loss: 0.250\n",
      "Epoch: 4807, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 4808, Train Loss: 0.240, Validation Loss: 0.248\n",
      "Epoch: 4809, Train Loss: 0.594, Validation Loss: 0.247\n",
      "Epoch: 4810, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 4811, Train Loss: 0.245, Validation Loss: 0.246\n",
      "Epoch: 4812, Train Loss: 0.278, Validation Loss: 0.247\n",
      "Epoch: 4813, Train Loss: 0.255, Validation Loss: 0.247\n",
      "Epoch: 4814, Train Loss: 0.315, Validation Loss: 0.245\n",
      "Epoch: 4815, Train Loss: 0.230, Validation Loss: 0.249\n",
      "Epoch: 4816, Train Loss: 0.656, Validation Loss: 0.248\n",
      "Epoch: 4817, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 4818, Train Loss: 0.392, Validation Loss: 0.246\n",
      "Epoch: 4819, Train Loss: 0.290, Validation Loss: 0.245\n",
      "Epoch: 4820, Train Loss: 0.497, Validation Loss: 0.249\n",
      "Epoch: 4821, Train Loss: 0.209, Validation Loss: 0.248\n",
      "Epoch: 4822, Train Loss: 0.227, Validation Loss: 0.246\n",
      "Epoch: 4823, Train Loss: 0.315, Validation Loss: 0.246\n",
      "Epoch: 4824, Train Loss: 0.286, Validation Loss: 0.248\n",
      "Epoch: 4825, Train Loss: 0.188, Validation Loss: 0.248\n",
      "Epoch: 4826, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 4827, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 4828, Train Loss: 0.282, Validation Loss: 0.247\n",
      "Epoch: 4829, Train Loss: 0.311, Validation Loss: 0.245\n",
      "Epoch: 4830, Train Loss: 0.275, Validation Loss: 0.245\n",
      "Epoch: 4831, Train Loss: 0.313, Validation Loss: 0.245\n",
      "Epoch: 4832, Train Loss: 0.319, Validation Loss: 0.250\n",
      "Epoch: 4833, Train Loss: 0.250, Validation Loss: 0.245\n",
      "Epoch: 4834, Train Loss: 0.282, Validation Loss: 0.247\n",
      "Epoch: 4835, Train Loss: 0.311, Validation Loss: 0.250\n",
      "Epoch: 4836, Train Loss: 0.286, Validation Loss: 0.251\n",
      "Epoch: 4837, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 4838, Train Loss: 0.212, Validation Loss: 0.247\n",
      "Epoch: 4839, Train Loss: 0.415, Validation Loss: 0.247\n",
      "Epoch: 4840, Train Loss: 0.233, Validation Loss: 0.247\n",
      "Epoch: 4841, Train Loss: 0.372, Validation Loss: 0.246\n",
      "Epoch: 4842, Train Loss: 0.271, Validation Loss: 0.249\n",
      "Epoch: 4843, Train Loss: 0.257, Validation Loss: 0.247\n",
      "Epoch: 4844, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 4845, Train Loss: 0.237, Validation Loss: 0.247\n",
      "Epoch: 4846, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 4847, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 4848, Train Loss: 0.225, Validation Loss: 0.249\n",
      "Epoch: 4849, Train Loss: 0.388, Validation Loss: 0.248\n",
      "Epoch: 4850, Train Loss: 0.160, Validation Loss: 0.246\n",
      "Epoch: 4851, Train Loss: 0.384, Validation Loss: 0.246\n",
      "Epoch: 4852, Train Loss: 0.247, Validation Loss: 0.245\n",
      "Epoch: 4853, Train Loss: 0.434, Validation Loss: 0.247\n",
      "Epoch: 4854, Train Loss: 0.275, Validation Loss: 0.245\n",
      "Epoch: 4855, Train Loss: 0.188, Validation Loss: 0.247\n",
      "Epoch: 4856, Train Loss: 0.305, Validation Loss: 0.249\n",
      "Epoch: 4857, Train Loss: 0.295, Validation Loss: 0.250\n",
      "Epoch: 4858, Train Loss: 0.263, Validation Loss: 0.245\n",
      "Epoch: 4859, Train Loss: 0.303, Validation Loss: 0.243\n",
      "Epoch: 4860, Train Loss: 0.158, Validation Loss: 0.245\n",
      "Epoch: 4861, Train Loss: 0.297, Validation Loss: 0.247\n",
      "Epoch: 4862, Train Loss: 0.401, Validation Loss: 0.248\n",
      "Epoch: 4863, Train Loss: 0.191, Validation Loss: 0.245\n",
      "Epoch: 4864, Train Loss: 0.412, Validation Loss: 0.249\n",
      "Epoch: 4865, Train Loss: 0.271, Validation Loss: 0.252\n",
      "Epoch: 4866, Train Loss: 0.488, Validation Loss: 0.248\n",
      "Epoch: 4867, Train Loss: 0.210, Validation Loss: 0.246\n",
      "Epoch: 4868, Train Loss: 0.255, Validation Loss: 0.246\n",
      "Epoch: 4869, Train Loss: 0.192, Validation Loss: 0.246\n",
      "Epoch: 4870, Train Loss: 0.270, Validation Loss: 0.248\n",
      "Epoch: 4871, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 4872, Train Loss: 0.214, Validation Loss: 0.247\n",
      "Epoch: 4873, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 4874, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 4875, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 4876, Train Loss: 0.285, Validation Loss: 0.251\n",
      "Epoch: 4877, Train Loss: 0.294, Validation Loss: 0.246\n",
      "Epoch: 4878, Train Loss: 0.504, Validation Loss: 0.247\n",
      "Epoch: 4879, Train Loss: 0.430, Validation Loss: 0.254\n",
      "Epoch: 4880, Train Loss: 0.179, Validation Loss: 0.248\n",
      "Epoch: 4881, Train Loss: 0.418, Validation Loss: 0.247\n",
      "Epoch: 4882, Train Loss: 0.213, Validation Loss: 0.246\n",
      "Epoch: 4883, Train Loss: 0.389, Validation Loss: 0.246\n",
      "Epoch: 4884, Train Loss: 0.215, Validation Loss: 0.250\n",
      "Epoch: 4885, Train Loss: 0.438, Validation Loss: 0.245\n",
      "Epoch: 4886, Train Loss: 0.216, Validation Loss: 0.251\n",
      "Epoch: 4887, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 4888, Train Loss: 0.329, Validation Loss: 0.248\n",
      "Epoch: 4889, Train Loss: 0.274, Validation Loss: 0.250\n",
      "Epoch: 4890, Train Loss: 0.245, Validation Loss: 0.250\n",
      "Epoch: 4891, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 4892, Train Loss: 0.194, Validation Loss: 0.247\n",
      "Epoch: 4893, Train Loss: 0.222, Validation Loss: 0.245\n",
      "Epoch: 4894, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 4895, Train Loss: 0.164, Validation Loss: 0.245\n",
      "Epoch: 4896, Train Loss: 0.414, Validation Loss: 0.246\n",
      "Epoch: 4897, Train Loss: 0.412, Validation Loss: 0.250\n",
      "Epoch: 4898, Train Loss: 0.208, Validation Loss: 0.248\n",
      "Epoch: 4899, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 4900, Train Loss: 0.169, Validation Loss: 0.249\n",
      "Epoch: 4901, Train Loss: 0.385, Validation Loss: 0.252\n",
      "Epoch: 4902, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 4903, Train Loss: 0.377, Validation Loss: 0.247\n",
      "Epoch: 4904, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 4905, Train Loss: 0.185, Validation Loss: 0.250\n",
      "Epoch: 4906, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 4907, Train Loss: 0.231, Validation Loss: 0.249\n",
      "Epoch: 4908, Train Loss: 0.485, Validation Loss: 0.246\n",
      "Epoch: 4909, Train Loss: 0.283, Validation Loss: 0.247\n",
      "Epoch: 4910, Train Loss: 0.261, Validation Loss: 0.252\n",
      "Epoch: 4911, Train Loss: 0.212, Validation Loss: 0.254\n",
      "Epoch: 4912, Train Loss: 0.284, Validation Loss: 0.252\n",
      "Epoch: 4913, Train Loss: 0.235, Validation Loss: 0.248\n",
      "Epoch: 4914, Train Loss: 0.220, Validation Loss: 0.247\n",
      "Epoch: 4915, Train Loss: 0.237, Validation Loss: 0.247\n",
      "Epoch: 4916, Train Loss: 0.216, Validation Loss: 0.249\n",
      "Epoch: 4917, Train Loss: 0.185, Validation Loss: 0.251\n",
      "Epoch: 4918, Train Loss: 0.296, Validation Loss: 0.252\n",
      "Epoch: 4919, Train Loss: 0.251, Validation Loss: 0.248\n",
      "Epoch: 4920, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 4921, Train Loss: 0.249, Validation Loss: 0.248\n",
      "Epoch: 4922, Train Loss: 0.496, Validation Loss: 0.250\n",
      "Epoch: 4923, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 4924, Train Loss: 0.265, Validation Loss: 0.249\n",
      "Epoch: 4925, Train Loss: 0.261, Validation Loss: 0.247\n",
      "Epoch: 4926, Train Loss: 0.257, Validation Loss: 0.246\n",
      "Epoch: 4927, Train Loss: 0.242, Validation Loss: 0.245\n",
      "Epoch: 4928, Train Loss: 0.227, Validation Loss: 0.247\n",
      "Epoch: 4929, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 4930, Train Loss: 0.208, Validation Loss: 0.248\n",
      "Epoch: 4931, Train Loss: 0.393, Validation Loss: 0.251\n",
      "Epoch: 4932, Train Loss: 0.350, Validation Loss: 0.251\n",
      "Epoch: 4933, Train Loss: 0.275, Validation Loss: 0.247\n",
      "Epoch: 4934, Train Loss: 0.600, Validation Loss: 0.247\n",
      "Epoch: 4935, Train Loss: 0.289, Validation Loss: 0.248\n",
      "Epoch: 4936, Train Loss: 0.238, Validation Loss: 0.245\n",
      "Epoch: 4937, Train Loss: 0.396, Validation Loss: 0.246\n",
      "Epoch: 4938, Train Loss: 0.435, Validation Loss: 0.248\n",
      "Epoch: 4939, Train Loss: 0.288, Validation Loss: 0.249\n",
      "Epoch: 4940, Train Loss: 0.303, Validation Loss: 0.251\n",
      "Epoch: 4941, Train Loss: 0.171, Validation Loss: 0.249\n",
      "Epoch: 4942, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 4943, Train Loss: 0.254, Validation Loss: 0.247\n",
      "Epoch: 4944, Train Loss: 0.342, Validation Loss: 0.247\n",
      "Epoch: 4945, Train Loss: 0.229, Validation Loss: 0.246\n",
      "Epoch: 4946, Train Loss: 0.193, Validation Loss: 0.247\n",
      "Epoch: 4947, Train Loss: 0.213, Validation Loss: 0.248\n",
      "Epoch: 4948, Train Loss: 0.493, Validation Loss: 0.251\n",
      "Epoch: 4949, Train Loss: 0.255, Validation Loss: 0.247\n",
      "Epoch: 4950, Train Loss: 0.206, Validation Loss: 0.247\n",
      "Epoch: 4951, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 4952, Train Loss: 0.327, Validation Loss: 0.249\n",
      "Epoch: 4953, Train Loss: 0.419, Validation Loss: 0.249\n",
      "Epoch: 4954, Train Loss: 0.226, Validation Loss: 0.253\n",
      "Epoch: 4955, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 4956, Train Loss: 0.276, Validation Loss: 0.248\n",
      "Epoch: 4957, Train Loss: 0.183, Validation Loss: 0.248\n",
      "Epoch: 4958, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 4959, Train Loss: 0.304, Validation Loss: 0.252\n",
      "Epoch: 4960, Train Loss: 0.239, Validation Loss: 0.246\n",
      "Epoch: 4961, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 4962, Train Loss: 0.315, Validation Loss: 0.248\n",
      "Epoch: 4963, Train Loss: 0.436, Validation Loss: 0.246\n",
      "Epoch: 4964, Train Loss: 0.225, Validation Loss: 0.249\n",
      "Epoch: 4965, Train Loss: 0.348, Validation Loss: 0.248\n",
      "Epoch: 4966, Train Loss: 0.248, Validation Loss: 0.252\n",
      "Epoch: 4967, Train Loss: 0.211, Validation Loss: 0.250\n",
      "Epoch: 4968, Train Loss: 0.229, Validation Loss: 0.250\n",
      "Epoch: 4969, Train Loss: 0.249, Validation Loss: 0.249\n",
      "Epoch: 4970, Train Loss: 0.274, Validation Loss: 0.253\n",
      "Epoch: 4971, Train Loss: 0.393, Validation Loss: 0.249\n",
      "Epoch: 4972, Train Loss: 0.332, Validation Loss: 0.256\n",
      "Epoch: 4973, Train Loss: 0.307, Validation Loss: 0.255\n",
      "Epoch: 4974, Train Loss: 0.371, Validation Loss: 0.250\n",
      "Epoch: 4975, Train Loss: 0.373, Validation Loss: 0.251\n",
      "Epoch: 4976, Train Loss: 0.225, Validation Loss: 0.250\n",
      "Epoch: 4977, Train Loss: 0.291, Validation Loss: 0.252\n",
      "Epoch: 4978, Train Loss: 0.259, Validation Loss: 0.248\n",
      "Epoch: 4979, Train Loss: 0.216, Validation Loss: 0.248\n",
      "Epoch: 4980, Train Loss: 0.618, Validation Loss: 0.252\n",
      "Epoch: 4981, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 4982, Train Loss: 0.295, Validation Loss: 0.248\n",
      "Epoch: 4983, Train Loss: 0.282, Validation Loss: 0.248\n",
      "Epoch: 4984, Train Loss: 0.337, Validation Loss: 0.249\n",
      "Epoch: 4985, Train Loss: 0.201, Validation Loss: 0.248\n",
      "Epoch: 4986, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 4987, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 4988, Train Loss: 0.207, Validation Loss: 0.252\n",
      "Epoch: 4989, Train Loss: 0.271, Validation Loss: 0.250\n",
      "Epoch: 4990, Train Loss: 0.433, Validation Loss: 0.249\n",
      "Epoch: 4991, Train Loss: 0.262, Validation Loss: 0.251\n",
      "Epoch: 4992, Train Loss: 0.258, Validation Loss: 0.249\n",
      "Epoch: 4993, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 4994, Train Loss: 0.192, Validation Loss: 0.247\n",
      "Epoch: 4995, Train Loss: 0.186, Validation Loss: 0.247\n",
      "Epoch: 4996, Train Loss: 0.380, Validation Loss: 0.250\n",
      "Epoch: 4997, Train Loss: 0.272, Validation Loss: 0.251\n",
      "Epoch: 4998, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 4999, Train Loss: 0.225, Validation Loss: 0.248\n",
      "Epoch: 5000, Train Loss: 0.241, Validation Loss: 0.252\n",
      "Epoch: 5001, Train Loss: 0.234, Validation Loss: 0.253\n",
      "Epoch: 5002, Train Loss: 0.481, Validation Loss: 0.248\n",
      "Epoch: 5003, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 5004, Train Loss: 0.219, Validation Loss: 0.253\n",
      "Epoch: 5005, Train Loss: 0.217, Validation Loss: 0.251\n",
      "Epoch: 5006, Train Loss: 0.201, Validation Loss: 0.252\n",
      "Epoch: 5007, Train Loss: 0.251, Validation Loss: 0.252\n",
      "Epoch: 5008, Train Loss: 0.503, Validation Loss: 0.252\n",
      "Epoch: 5009, Train Loss: 0.204, Validation Loss: 0.250\n",
      "Epoch: 5010, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 5011, Train Loss: 0.206, Validation Loss: 0.249\n",
      "Epoch: 5012, Train Loss: 0.292, Validation Loss: 0.251\n",
      "Epoch: 5013, Train Loss: 0.212, Validation Loss: 0.253\n",
      "Epoch: 5014, Train Loss: 0.186, Validation Loss: 0.251\n",
      "Epoch: 5015, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 5016, Train Loss: 0.270, Validation Loss: 0.247\n",
      "Epoch: 5017, Train Loss: 0.203, Validation Loss: 0.248\n",
      "Epoch: 5018, Train Loss: 0.294, Validation Loss: 0.250\n",
      "Epoch: 5019, Train Loss: 0.266, Validation Loss: 0.247\n",
      "Epoch: 5020, Train Loss: 0.258, Validation Loss: 0.250\n",
      "Epoch: 5021, Train Loss: 0.296, Validation Loss: 0.250\n",
      "Epoch: 5022, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 5023, Train Loss: 0.205, Validation Loss: 0.251\n",
      "Epoch: 5024, Train Loss: 0.151, Validation Loss: 0.248\n",
      "Epoch: 5025, Train Loss: 0.268, Validation Loss: 0.248\n",
      "Epoch: 5026, Train Loss: 0.328, Validation Loss: 0.248\n",
      "Epoch: 5027, Train Loss: 0.277, Validation Loss: 0.251\n",
      "Epoch: 5028, Train Loss: 0.388, Validation Loss: 0.249\n",
      "Epoch: 5029, Train Loss: 0.230, Validation Loss: 0.249\n",
      "Epoch: 5030, Train Loss: 0.235, Validation Loss: 0.246\n",
      "Epoch: 5031, Train Loss: 0.262, Validation Loss: 0.247\n",
      "Epoch: 5032, Train Loss: 0.182, Validation Loss: 0.249\n",
      "Epoch: 5033, Train Loss: 0.437, Validation Loss: 0.255\n",
      "Epoch: 5034, Train Loss: 0.223, Validation Loss: 0.251\n",
      "Epoch: 5035, Train Loss: 0.314, Validation Loss: 0.254\n",
      "Epoch: 5036, Train Loss: 0.411, Validation Loss: 0.249\n",
      "Epoch: 5037, Train Loss: 0.259, Validation Loss: 0.246\n",
      "Epoch: 5038, Train Loss: 0.317, Validation Loss: 0.246\n",
      "Epoch: 5039, Train Loss: 0.327, Validation Loss: 0.248\n",
      "Epoch: 5040, Train Loss: 0.245, Validation Loss: 0.255\n",
      "Epoch: 5041, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 5042, Train Loss: 0.176, Validation Loss: 0.248\n",
      "Epoch: 5043, Train Loss: 0.315, Validation Loss: 0.247\n",
      "Epoch: 5044, Train Loss: 0.302, Validation Loss: 0.253\n",
      "Epoch: 5045, Train Loss: 0.356, Validation Loss: 0.249\n",
      "Epoch: 5046, Train Loss: 0.413, Validation Loss: 0.250\n",
      "Epoch: 5047, Train Loss: 0.242, Validation Loss: 0.251\n",
      "Epoch: 5048, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 5049, Train Loss: 0.303, Validation Loss: 0.248\n",
      "Epoch: 5050, Train Loss: 0.253, Validation Loss: 0.254\n",
      "Epoch: 5051, Train Loss: 0.366, Validation Loss: 0.249\n",
      "Epoch: 5052, Train Loss: 0.223, Validation Loss: 0.250\n",
      "Epoch: 5053, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 5054, Train Loss: 0.559, Validation Loss: 0.253\n",
      "Epoch: 5055, Train Loss: 0.203, Validation Loss: 0.252\n",
      "Epoch: 5056, Train Loss: 0.189, Validation Loss: 0.251\n",
      "Epoch: 5057, Train Loss: 0.275, Validation Loss: 0.251\n",
      "Epoch: 5058, Train Loss: 0.265, Validation Loss: 0.252\n",
      "Epoch: 5059, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 5060, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 5061, Train Loss: 0.238, Validation Loss: 0.249\n",
      "Epoch: 5062, Train Loss: 0.316, Validation Loss: 0.254\n",
      "Epoch: 5063, Train Loss: 0.231, Validation Loss: 0.251\n",
      "Epoch: 5064, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 5065, Train Loss: 0.179, Validation Loss: 0.252\n",
      "Epoch: 5066, Train Loss: 0.228, Validation Loss: 0.256\n",
      "Epoch: 5067, Train Loss: 0.173, Validation Loss: 0.253\n",
      "Epoch: 5068, Train Loss: 0.253, Validation Loss: 0.251\n",
      "Epoch: 5069, Train Loss: 0.349, Validation Loss: 0.249\n",
      "Epoch: 5070, Train Loss: 0.320, Validation Loss: 0.250\n",
      "Epoch: 5071, Train Loss: 0.193, Validation Loss: 0.249\n",
      "Epoch: 5072, Train Loss: 0.266, Validation Loss: 0.248\n",
      "Epoch: 5073, Train Loss: 0.301, Validation Loss: 0.248\n",
      "Epoch: 5074, Train Loss: 0.217, Validation Loss: 0.249\n",
      "Epoch: 5075, Train Loss: 0.485, Validation Loss: 0.253\n",
      "Epoch: 5076, Train Loss: 0.211, Validation Loss: 0.250\n",
      "Epoch: 5077, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 5078, Train Loss: 0.184, Validation Loss: 0.248\n",
      "Epoch: 5079, Train Loss: 0.352, Validation Loss: 0.252\n",
      "Epoch: 5080, Train Loss: 0.208, Validation Loss: 0.252\n",
      "Epoch: 5081, Train Loss: 0.214, Validation Loss: 0.250\n",
      "Epoch: 5082, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 5083, Train Loss: 0.350, Validation Loss: 0.252\n",
      "Epoch: 5084, Train Loss: 0.230, Validation Loss: 0.246\n",
      "Epoch: 5085, Train Loss: 0.368, Validation Loss: 0.247\n",
      "Epoch: 5086, Train Loss: 0.195, Validation Loss: 0.249\n",
      "Epoch: 5087, Train Loss: 0.197, Validation Loss: 0.249\n",
      "Epoch: 5088, Train Loss: 0.233, Validation Loss: 0.248\n",
      "Epoch: 5089, Train Loss: 0.240, Validation Loss: 0.246\n",
      "Epoch: 5090, Train Loss: 0.276, Validation Loss: 0.247\n",
      "Epoch: 5091, Train Loss: 0.211, Validation Loss: 0.249\n",
      "Epoch: 5092, Train Loss: 0.283, Validation Loss: 0.249\n",
      "Epoch: 5093, Train Loss: 0.333, Validation Loss: 0.246\n",
      "Epoch: 5094, Train Loss: 0.315, Validation Loss: 0.252\n",
      "Epoch: 5095, Train Loss: 0.368, Validation Loss: 0.247\n",
      "Epoch: 5096, Train Loss: 0.210, Validation Loss: 0.248\n",
      "Epoch: 5097, Train Loss: 0.216, Validation Loss: 0.246\n",
      "Epoch: 5098, Train Loss: 0.281, Validation Loss: 0.247\n",
      "Epoch: 5099, Train Loss: 0.458, Validation Loss: 0.247\n",
      "Epoch: 5100, Train Loss: 0.324, Validation Loss: 0.246\n",
      "Epoch: 5101, Train Loss: 0.169, Validation Loss: 0.248\n",
      "Epoch: 5102, Train Loss: 0.189, Validation Loss: 0.250\n",
      "Epoch: 5103, Train Loss: 0.347, Validation Loss: 0.248\n",
      "Epoch: 5104, Train Loss: 0.297, Validation Loss: 0.245\n",
      "Epoch: 5105, Train Loss: 0.240, Validation Loss: 0.248\n",
      "Epoch: 5106, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 5107, Train Loss: 0.253, Validation Loss: 0.247\n",
      "Epoch: 5108, Train Loss: 0.335, Validation Loss: 0.249\n",
      "Epoch: 5109, Train Loss: 0.374, Validation Loss: 0.249\n",
      "Epoch: 5110, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 5111, Train Loss: 0.252, Validation Loss: 0.251\n",
      "Epoch: 5112, Train Loss: 0.233, Validation Loss: 0.248\n",
      "Epoch: 5113, Train Loss: 0.277, Validation Loss: 0.247\n",
      "Epoch: 5114, Train Loss: 0.253, Validation Loss: 0.249\n",
      "Epoch: 5115, Train Loss: 0.288, Validation Loss: 0.251\n",
      "Epoch: 5116, Train Loss: 0.200, Validation Loss: 0.249\n",
      "Epoch: 5117, Train Loss: 0.186, Validation Loss: 0.245\n",
      "Epoch: 5118, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 5119, Train Loss: 0.332, Validation Loss: 0.247\n",
      "Epoch: 5120, Train Loss: 0.208, Validation Loss: 0.248\n",
      "Epoch: 5121, Train Loss: 0.346, Validation Loss: 0.248\n",
      "Epoch: 5122, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 5123, Train Loss: 0.267, Validation Loss: 0.253\n",
      "Epoch: 5124, Train Loss: 0.412, Validation Loss: 0.249\n",
      "Epoch: 5125, Train Loss: 0.164, Validation Loss: 0.248\n",
      "Epoch: 5126, Train Loss: 0.306, Validation Loss: 0.249\n",
      "Epoch: 5127, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 5128, Train Loss: 0.180, Validation Loss: 0.250\n",
      "Epoch: 5129, Train Loss: 0.255, Validation Loss: 0.250\n",
      "Epoch: 5130, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 5131, Train Loss: 0.232, Validation Loss: 0.250\n",
      "Epoch: 5132, Train Loss: 0.314, Validation Loss: 0.249\n",
      "Epoch: 5133, Train Loss: 0.221, Validation Loss: 0.250\n",
      "Epoch: 5134, Train Loss: 0.197, Validation Loss: 0.254\n",
      "Epoch: 5135, Train Loss: 0.368, Validation Loss: 0.254\n",
      "Epoch: 5136, Train Loss: 0.249, Validation Loss: 0.251\n",
      "Epoch: 5137, Train Loss: 0.279, Validation Loss: 0.255\n",
      "Epoch: 5138, Train Loss: 0.360, Validation Loss: 0.250\n",
      "Epoch: 5139, Train Loss: 0.251, Validation Loss: 0.249\n",
      "Epoch: 5140, Train Loss: 0.189, Validation Loss: 0.249\n",
      "Epoch: 5141, Train Loss: 0.352, Validation Loss: 0.249\n",
      "Epoch: 5142, Train Loss: 0.237, Validation Loss: 0.253\n",
      "Epoch: 5143, Train Loss: 0.313, Validation Loss: 0.248\n",
      "Epoch: 5144, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 5145, Train Loss: 0.206, Validation Loss: 0.251\n",
      "Epoch: 5146, Train Loss: 0.172, Validation Loss: 0.250\n",
      "Epoch: 5147, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 5148, Train Loss: 0.287, Validation Loss: 0.248\n",
      "Epoch: 5149, Train Loss: 0.382, Validation Loss: 0.249\n",
      "Epoch: 5150, Train Loss: 0.200, Validation Loss: 0.250\n",
      "Epoch: 5151, Train Loss: 0.168, Validation Loss: 0.246\n",
      "Epoch: 5152, Train Loss: 0.234, Validation Loss: 0.246\n",
      "Epoch: 5153, Train Loss: 0.336, Validation Loss: 0.247\n",
      "Epoch: 5154, Train Loss: 0.241, Validation Loss: 0.247\n",
      "Epoch: 5155, Train Loss: 0.190, Validation Loss: 0.249\n",
      "Epoch: 5156, Train Loss: 0.236, Validation Loss: 0.251\n",
      "Epoch: 5157, Train Loss: 0.211, Validation Loss: 0.251\n",
      "Epoch: 5158, Train Loss: 0.439, Validation Loss: 0.253\n",
      "Epoch: 5159, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 5160, Train Loss: 0.270, Validation Loss: 0.249\n",
      "Epoch: 5161, Train Loss: 0.262, Validation Loss: 0.252\n",
      "Epoch: 5162, Train Loss: 0.145, Validation Loss: 0.251\n",
      "Epoch: 5163, Train Loss: 0.262, Validation Loss: 0.251\n",
      "Epoch: 5164, Train Loss: 0.248, Validation Loss: 0.252\n",
      "Epoch: 5165, Train Loss: 0.313, Validation Loss: 0.250\n",
      "Epoch: 5166, Train Loss: 0.275, Validation Loss: 0.252\n",
      "Epoch: 5167, Train Loss: 0.171, Validation Loss: 0.251\n",
      "Epoch: 5168, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 5169, Train Loss: 0.184, Validation Loss: 0.249\n",
      "Epoch: 5170, Train Loss: 0.148, Validation Loss: 0.250\n",
      "Epoch: 5171, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 5172, Train Loss: 0.219, Validation Loss: 0.249\n",
      "Epoch: 5173, Train Loss: 0.257, Validation Loss: 0.251\n",
      "Epoch: 5174, Train Loss: 0.569, Validation Loss: 0.250\n",
      "Epoch: 5175, Train Loss: 0.298, Validation Loss: 0.248\n",
      "Epoch: 5176, Train Loss: 0.312, Validation Loss: 0.252\n",
      "Epoch: 5177, Train Loss: 0.220, Validation Loss: 0.254\n",
      "Epoch: 5178, Train Loss: 0.218, Validation Loss: 0.251\n",
      "Epoch: 5179, Train Loss: 0.232, Validation Loss: 0.249\n",
      "Epoch: 5180, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 5181, Train Loss: 0.215, Validation Loss: 0.251\n",
      "Epoch: 5182, Train Loss: 0.260, Validation Loss: 0.251\n",
      "Epoch: 5183, Train Loss: 0.296, Validation Loss: 0.254\n",
      "Epoch: 5184, Train Loss: 0.416, Validation Loss: 0.254\n",
      "Epoch: 5185, Train Loss: 0.204, Validation Loss: 0.246\n",
      "Epoch: 5186, Train Loss: 0.352, Validation Loss: 0.249\n",
      "Epoch: 5187, Train Loss: 0.333, Validation Loss: 0.246\n",
      "Epoch: 5188, Train Loss: 0.254, Validation Loss: 0.249\n",
      "Epoch: 5189, Train Loss: 0.289, Validation Loss: 0.249\n",
      "Epoch: 5190, Train Loss: 0.223, Validation Loss: 0.253\n",
      "Epoch: 5191, Train Loss: 0.277, Validation Loss: 0.249\n",
      "Epoch: 5192, Train Loss: 0.363, Validation Loss: 0.247\n",
      "Epoch: 5193, Train Loss: 0.274, Validation Loss: 0.254\n",
      "Epoch: 5194, Train Loss: 0.153, Validation Loss: 0.249\n",
      "Epoch: 5195, Train Loss: 0.283, Validation Loss: 0.247\n",
      "Epoch: 5196, Train Loss: 0.224, Validation Loss: 0.247\n",
      "Epoch: 5197, Train Loss: 0.246, Validation Loss: 0.249\n",
      "Epoch: 5198, Train Loss: 0.201, Validation Loss: 0.249\n",
      "Epoch: 5199, Train Loss: 0.325, Validation Loss: 0.248\n",
      "Epoch: 5200, Train Loss: 0.651, Validation Loss: 0.251\n",
      "Epoch: 5201, Train Loss: 0.235, Validation Loss: 0.247\n",
      "Epoch: 5202, Train Loss: 0.251, Validation Loss: 0.249\n",
      "Epoch: 5203, Train Loss: 0.270, Validation Loss: 0.247\n",
      "Epoch: 5204, Train Loss: 0.318, Validation Loss: 0.246\n",
      "Epoch: 5205, Train Loss: 0.238, Validation Loss: 0.251\n",
      "Epoch: 5206, Train Loss: 0.444, Validation Loss: 0.249\n",
      "Epoch: 5207, Train Loss: 0.388, Validation Loss: 0.251\n",
      "Epoch: 5208, Train Loss: 0.228, Validation Loss: 0.251\n",
      "Epoch: 5209, Train Loss: 0.359, Validation Loss: 0.249\n",
      "Epoch: 5210, Train Loss: 0.219, Validation Loss: 0.249\n",
      "Epoch: 5211, Train Loss: 0.312, Validation Loss: 0.251\n",
      "Epoch: 5212, Train Loss: 0.431, Validation Loss: 0.252\n",
      "Epoch: 5213, Train Loss: 0.354, Validation Loss: 0.250\n",
      "Epoch: 5214, Train Loss: 0.209, Validation Loss: 0.248\n",
      "Epoch: 5215, Train Loss: 0.206, Validation Loss: 0.249\n",
      "Epoch: 5216, Train Loss: 0.211, Validation Loss: 0.248\n",
      "Epoch: 5217, Train Loss: 0.377, Validation Loss: 0.246\n",
      "Epoch: 5218, Train Loss: 0.227, Validation Loss: 0.248\n",
      "Epoch: 5219, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 5220, Train Loss: 0.256, Validation Loss: 0.249\n",
      "Epoch: 5221, Train Loss: 0.276, Validation Loss: 0.249\n",
      "Epoch: 5222, Train Loss: 0.274, Validation Loss: 0.247\n",
      "Epoch: 5223, Train Loss: 0.257, Validation Loss: 0.246\n",
      "Epoch: 5224, Train Loss: 0.397, Validation Loss: 0.247\n",
      "Epoch: 5225, Train Loss: 0.317, Validation Loss: 0.251\n",
      "Epoch: 5226, Train Loss: 0.189, Validation Loss: 0.250\n",
      "Epoch: 5227, Train Loss: 0.298, Validation Loss: 0.251\n",
      "Epoch: 5228, Train Loss: 0.247, Validation Loss: 0.249\n",
      "Epoch: 5229, Train Loss: 0.222, Validation Loss: 0.248\n",
      "Epoch: 5230, Train Loss: 0.271, Validation Loss: 0.248\n",
      "Epoch: 5231, Train Loss: 0.180, Validation Loss: 0.248\n",
      "Epoch: 5232, Train Loss: 0.201, Validation Loss: 0.251\n",
      "Epoch: 5233, Train Loss: 0.266, Validation Loss: 0.250\n",
      "Epoch: 5234, Train Loss: 0.237, Validation Loss: 0.245\n",
      "Epoch: 5235, Train Loss: 0.270, Validation Loss: 0.246\n",
      "Epoch: 5236, Train Loss: 0.238, Validation Loss: 0.250\n",
      "Epoch: 5237, Train Loss: 0.515, Validation Loss: 0.249\n",
      "Epoch: 5238, Train Loss: 0.186, Validation Loss: 0.248\n",
      "Epoch: 5239, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 5240, Train Loss: 0.289, Validation Loss: 0.249\n",
      "Epoch: 5241, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 5242, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 5243, Train Loss: 0.284, Validation Loss: 0.248\n",
      "Epoch: 5244, Train Loss: 0.211, Validation Loss: 0.248\n",
      "Epoch: 5245, Train Loss: 0.787, Validation Loss: 0.251\n",
      "Epoch: 5246, Train Loss: 0.202, Validation Loss: 0.250\n",
      "Epoch: 5247, Train Loss: 0.241, Validation Loss: 0.245\n",
      "Epoch: 5248, Train Loss: 0.301, Validation Loss: 0.246\n",
      "Epoch: 5249, Train Loss: 0.285, Validation Loss: 0.248\n",
      "Epoch: 5250, Train Loss: 0.592, Validation Loss: 0.247\n",
      "Epoch: 5251, Train Loss: 0.179, Validation Loss: 0.251\n",
      "Epoch: 5252, Train Loss: 0.278, Validation Loss: 0.250\n",
      "Epoch: 5253, Train Loss: 0.239, Validation Loss: 0.249\n",
      "Epoch: 5254, Train Loss: 0.285, Validation Loss: 0.253\n",
      "Epoch: 5255, Train Loss: 0.344, Validation Loss: 0.255\n",
      "Epoch: 5256, Train Loss: 0.351, Validation Loss: 0.253\n",
      "Epoch: 5257, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 5258, Train Loss: 0.392, Validation Loss: 0.249\n",
      "Epoch: 5259, Train Loss: 0.188, Validation Loss: 0.250\n",
      "Epoch: 5260, Train Loss: 0.220, Validation Loss: 0.250\n",
      "Epoch: 5261, Train Loss: 0.170, Validation Loss: 0.251\n",
      "Epoch: 5262, Train Loss: 0.387, Validation Loss: 0.251\n",
      "Epoch: 5263, Train Loss: 0.396, Validation Loss: 0.251\n",
      "Epoch: 5264, Train Loss: 0.229, Validation Loss: 0.257\n",
      "Epoch: 5265, Train Loss: 0.197, Validation Loss: 0.253\n",
      "Epoch: 5266, Train Loss: 0.218, Validation Loss: 0.252\n",
      "Epoch: 5267, Train Loss: 0.181, Validation Loss: 0.251\n",
      "Epoch: 5268, Train Loss: 0.685, Validation Loss: 0.250\n",
      "Epoch: 5269, Train Loss: 0.258, Validation Loss: 0.251\n",
      "Epoch: 5270, Train Loss: 0.245, Validation Loss: 0.251\n",
      "Epoch: 5271, Train Loss: 0.213, Validation Loss: 0.256\n",
      "Epoch: 5272, Train Loss: 0.242, Validation Loss: 0.254\n",
      "Epoch: 5273, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 5274, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 5275, Train Loss: 0.320, Validation Loss: 0.254\n",
      "Epoch: 5276, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 5277, Train Loss: 0.209, Validation Loss: 0.249\n",
      "Epoch: 5278, Train Loss: 0.377, Validation Loss: 0.248\n",
      "Epoch: 5279, Train Loss: 0.245, Validation Loss: 0.251\n",
      "Epoch: 5280, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 5281, Train Loss: 0.302, Validation Loss: 0.249\n",
      "Epoch: 5282, Train Loss: 0.230, Validation Loss: 0.250\n",
      "Epoch: 5283, Train Loss: 0.638, Validation Loss: 0.252\n",
      "Epoch: 5284, Train Loss: 0.280, Validation Loss: 0.248\n",
      "Epoch: 5285, Train Loss: 0.221, Validation Loss: 0.250\n",
      "Epoch: 5286, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 5287, Train Loss: 0.216, Validation Loss: 0.249\n",
      "Epoch: 5288, Train Loss: 0.302, Validation Loss: 0.246\n",
      "Epoch: 5289, Train Loss: 0.252, Validation Loss: 0.251\n",
      "Epoch: 5290, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 5291, Train Loss: 0.340, Validation Loss: 0.250\n",
      "Epoch: 5292, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 5293, Train Loss: 0.280, Validation Loss: 0.249\n",
      "Epoch: 5294, Train Loss: 0.212, Validation Loss: 0.258\n",
      "Epoch: 5295, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 5296, Train Loss: 0.435, Validation Loss: 0.248\n",
      "Epoch: 5297, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 5298, Train Loss: 0.239, Validation Loss: 0.248\n",
      "Epoch: 5299, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 5300, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 5301, Train Loss: 0.339, Validation Loss: 0.248\n",
      "Epoch: 5302, Train Loss: 0.241, Validation Loss: 0.248\n",
      "Epoch: 5303, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 5304, Train Loss: 0.233, Validation Loss: 0.253\n",
      "Epoch: 5305, Train Loss: 0.198, Validation Loss: 0.254\n",
      "Epoch: 5306, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 5307, Train Loss: 0.272, Validation Loss: 0.248\n",
      "Epoch: 5308, Train Loss: 0.420, Validation Loss: 0.255\n",
      "Epoch: 5309, Train Loss: 0.185, Validation Loss: 0.254\n",
      "Epoch: 5310, Train Loss: 0.285, Validation Loss: 0.253\n",
      "Epoch: 5311, Train Loss: 0.319, Validation Loss: 0.246\n",
      "Epoch: 5312, Train Loss: 0.209, Validation Loss: 0.246\n",
      "Epoch: 5313, Train Loss: 0.194, Validation Loss: 0.245\n",
      "Epoch: 5314, Train Loss: 0.165, Validation Loss: 0.248\n",
      "Epoch: 5315, Train Loss: 0.322, Validation Loss: 0.248\n",
      "Epoch: 5316, Train Loss: 0.253, Validation Loss: 0.253\n",
      "Epoch: 5317, Train Loss: 0.267, Validation Loss: 0.251\n",
      "Epoch: 5318, Train Loss: 0.274, Validation Loss: 0.252\n",
      "Epoch: 5319, Train Loss: 0.252, Validation Loss: 0.255\n",
      "Epoch: 5320, Train Loss: 0.333, Validation Loss: 0.250\n",
      "Epoch: 5321, Train Loss: 0.234, Validation Loss: 0.247\n",
      "Epoch: 5322, Train Loss: 0.291, Validation Loss: 0.246\n",
      "Epoch: 5323, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 5324, Train Loss: 0.168, Validation Loss: 0.249\n",
      "Epoch: 5325, Train Loss: 0.461, Validation Loss: 0.248\n",
      "Epoch: 5326, Train Loss: 0.331, Validation Loss: 0.248\n",
      "Epoch: 5327, Train Loss: 0.216, Validation Loss: 0.248\n",
      "Epoch: 5328, Train Loss: 0.236, Validation Loss: 0.249\n",
      "Epoch: 5329, Train Loss: 0.280, Validation Loss: 0.248\n",
      "Epoch: 5330, Train Loss: 0.388, Validation Loss: 0.249\n",
      "Epoch: 5331, Train Loss: 0.238, Validation Loss: 0.248\n",
      "Epoch: 5332, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 5333, Train Loss: 0.421, Validation Loss: 0.250\n",
      "Epoch: 5334, Train Loss: 0.225, Validation Loss: 0.252\n",
      "Epoch: 5335, Train Loss: 0.418, Validation Loss: 0.249\n",
      "Epoch: 5336, Train Loss: 0.267, Validation Loss: 0.248\n",
      "Epoch: 5337, Train Loss: 0.261, Validation Loss: 0.252\n",
      "Epoch: 5338, Train Loss: 0.250, Validation Loss: 0.247\n",
      "Epoch: 5339, Train Loss: 0.250, Validation Loss: 0.251\n",
      "Epoch: 5340, Train Loss: 0.192, Validation Loss: 0.249\n",
      "Epoch: 5341, Train Loss: 0.319, Validation Loss: 0.249\n",
      "Epoch: 5342, Train Loss: 0.219, Validation Loss: 0.249\n",
      "Epoch: 5343, Train Loss: 0.276, Validation Loss: 0.250\n",
      "Epoch: 5344, Train Loss: 0.309, Validation Loss: 0.248\n",
      "Epoch: 5345, Train Loss: 0.303, Validation Loss: 0.252\n",
      "Epoch: 5346, Train Loss: 0.198, Validation Loss: 0.251\n",
      "Epoch: 5347, Train Loss: 0.267, Validation Loss: 0.250\n",
      "Epoch: 5348, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 5349, Train Loss: 0.283, Validation Loss: 0.249\n",
      "Epoch: 5350, Train Loss: 0.329, Validation Loss: 0.249\n",
      "Epoch: 5351, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 5352, Train Loss: 0.369, Validation Loss: 0.248\n",
      "Epoch: 5353, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 5354, Train Loss: 0.289, Validation Loss: 0.248\n",
      "Epoch: 5355, Train Loss: 0.210, Validation Loss: 0.249\n",
      "Epoch: 5356, Train Loss: 0.280, Validation Loss: 0.250\n",
      "Epoch: 5357, Train Loss: 0.202, Validation Loss: 0.250\n",
      "Epoch: 5358, Train Loss: 0.186, Validation Loss: 0.251\n",
      "Epoch: 5359, Train Loss: 0.200, Validation Loss: 0.252\n",
      "Epoch: 5360, Train Loss: 0.263, Validation Loss: 0.251\n",
      "Epoch: 5361, Train Loss: 0.209, Validation Loss: 0.249\n",
      "Epoch: 5362, Train Loss: 0.401, Validation Loss: 0.247\n",
      "Epoch: 5363, Train Loss: 0.458, Validation Loss: 0.251\n",
      "Epoch: 5364, Train Loss: 0.268, Validation Loss: 0.252\n",
      "Epoch: 5365, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 5366, Train Loss: 0.210, Validation Loss: 0.250\n",
      "Epoch: 5367, Train Loss: 0.303, Validation Loss: 0.250\n",
      "Epoch: 5368, Train Loss: 0.183, Validation Loss: 0.252\n",
      "Epoch: 5369, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 5370, Train Loss: 0.296, Validation Loss: 0.253\n",
      "Epoch: 5371, Train Loss: 0.197, Validation Loss: 0.250\n",
      "Epoch: 5372, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 5373, Train Loss: 0.349, Validation Loss: 0.257\n",
      "Epoch: 5374, Train Loss: 0.363, Validation Loss: 0.250\n",
      "Epoch: 5375, Train Loss: 0.319, Validation Loss: 0.250\n",
      "Epoch: 5376, Train Loss: 0.184, Validation Loss: 0.253\n",
      "Epoch: 5377, Train Loss: 0.259, Validation Loss: 0.252\n",
      "Epoch: 5378, Train Loss: 0.326, Validation Loss: 0.249\n",
      "Epoch: 5379, Train Loss: 0.551, Validation Loss: 0.249\n",
      "Epoch: 5380, Train Loss: 0.306, Validation Loss: 0.252\n",
      "Epoch: 5381, Train Loss: 0.237, Validation Loss: 0.249\n",
      "Epoch: 5382, Train Loss: 0.191, Validation Loss: 0.250\n",
      "Epoch: 5383, Train Loss: 0.467, Validation Loss: 0.249\n",
      "Epoch: 5384, Train Loss: 0.285, Validation Loss: 0.249\n",
      "Epoch: 5385, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 5386, Train Loss: 0.283, Validation Loss: 0.250\n",
      "Epoch: 5387, Train Loss: 0.209, Validation Loss: 0.250\n",
      "Epoch: 5388, Train Loss: 0.224, Validation Loss: 0.250\n",
      "Epoch: 5389, Train Loss: 0.132, Validation Loss: 0.250\n",
      "Epoch: 5390, Train Loss: 0.257, Validation Loss: 0.251\n",
      "Epoch: 5391, Train Loss: 0.206, Validation Loss: 0.250\n",
      "Epoch: 5392, Train Loss: 0.365, Validation Loss: 0.251\n",
      "Epoch: 5393, Train Loss: 0.298, Validation Loss: 0.253\n",
      "Epoch: 5394, Train Loss: 0.442, Validation Loss: 0.254\n",
      "Epoch: 5395, Train Loss: 0.191, Validation Loss: 0.253\n",
      "Epoch: 5396, Train Loss: 0.221, Validation Loss: 0.253\n",
      "Epoch: 5397, Train Loss: 0.230, Validation Loss: 0.250\n",
      "Epoch: 5398, Train Loss: 0.227, Validation Loss: 0.251\n",
      "Epoch: 5399, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 5400, Train Loss: 0.352, Validation Loss: 0.251\n",
      "Epoch: 5401, Train Loss: 0.300, Validation Loss: 0.256\n",
      "Epoch: 5402, Train Loss: 0.240, Validation Loss: 0.255\n",
      "Epoch: 5403, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 5404, Train Loss: 0.405, Validation Loss: 0.252\n",
      "Epoch: 5405, Train Loss: 0.221, Validation Loss: 0.253\n",
      "Epoch: 5406, Train Loss: 0.327, Validation Loss: 0.250\n",
      "Epoch: 5407, Train Loss: 0.234, Validation Loss: 0.250\n",
      "Epoch: 5408, Train Loss: 0.451, Validation Loss: 0.249\n",
      "Epoch: 5409, Train Loss: 0.350, Validation Loss: 0.251\n",
      "Epoch: 5410, Train Loss: 0.258, Validation Loss: 0.254\n",
      "Epoch: 5411, Train Loss: 0.420, Validation Loss: 0.257\n",
      "Epoch: 5412, Train Loss: 0.257, Validation Loss: 0.251\n",
      "Epoch: 5413, Train Loss: 0.240, Validation Loss: 0.250\n",
      "Epoch: 5414, Train Loss: 0.380, Validation Loss: 0.252\n",
      "Epoch: 5415, Train Loss: 0.263, Validation Loss: 0.249\n",
      "Epoch: 5416, Train Loss: 0.238, Validation Loss: 0.250\n",
      "Epoch: 5417, Train Loss: 0.287, Validation Loss: 0.248\n",
      "Epoch: 5418, Train Loss: 0.401, Validation Loss: 0.248\n",
      "Epoch: 5419, Train Loss: 0.178, Validation Loss: 0.250\n",
      "Epoch: 5420, Train Loss: 0.179, Validation Loss: 0.249\n",
      "Epoch: 5421, Train Loss: 0.234, Validation Loss: 0.250\n",
      "Epoch: 5422, Train Loss: 0.270, Validation Loss: 0.251\n",
      "Epoch: 5423, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 5424, Train Loss: 0.286, Validation Loss: 0.250\n",
      "Epoch: 5425, Train Loss: 0.362, Validation Loss: 0.249\n",
      "Epoch: 5426, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 5427, Train Loss: 0.276, Validation Loss: 0.250\n",
      "Epoch: 5428, Train Loss: 0.264, Validation Loss: 0.251\n",
      "Epoch: 5429, Train Loss: 0.223, Validation Loss: 0.250\n",
      "Epoch: 5430, Train Loss: 0.259, Validation Loss: 0.249\n",
      "Epoch: 5431, Train Loss: 0.228, Validation Loss: 0.247\n",
      "Epoch: 5432, Train Loss: 0.310, Validation Loss: 0.251\n",
      "Epoch: 5433, Train Loss: 0.215, Validation Loss: 0.249\n",
      "Epoch: 5434, Train Loss: 0.209, Validation Loss: 0.248\n",
      "Epoch: 5435, Train Loss: 0.260, Validation Loss: 0.248\n",
      "Epoch: 5436, Train Loss: 0.395, Validation Loss: 0.253\n",
      "Epoch: 5437, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 5438, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 5439, Train Loss: 0.487, Validation Loss: 0.248\n",
      "Epoch: 5440, Train Loss: 0.485, Validation Loss: 0.251\n",
      "Epoch: 5441, Train Loss: 0.175, Validation Loss: 0.250\n",
      "Epoch: 5442, Train Loss: 0.158, Validation Loss: 0.249\n",
      "Epoch: 5443, Train Loss: 0.242, Validation Loss: 0.249\n",
      "Epoch: 5444, Train Loss: 0.283, Validation Loss: 0.251\n",
      "Epoch: 5445, Train Loss: 0.251, Validation Loss: 0.256\n",
      "Epoch: 5446, Train Loss: 0.305, Validation Loss: 0.255\n",
      "Epoch: 5447, Train Loss: 0.566, Validation Loss: 0.253\n",
      "Epoch: 5448, Train Loss: 0.217, Validation Loss: 0.251\n",
      "Epoch: 5449, Train Loss: 0.249, Validation Loss: 0.249\n",
      "Epoch: 5450, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 5451, Train Loss: 0.228, Validation Loss: 0.255\n",
      "Epoch: 5452, Train Loss: 0.255, Validation Loss: 0.254\n",
      "Epoch: 5453, Train Loss: 0.198, Validation Loss: 0.250\n",
      "Epoch: 5454, Train Loss: 0.182, Validation Loss: 0.250\n",
      "Epoch: 5455, Train Loss: 0.449, Validation Loss: 0.254\n",
      "Epoch: 5456, Train Loss: 0.354, Validation Loss: 0.250\n",
      "Epoch: 5457, Train Loss: 0.173, Validation Loss: 0.250\n",
      "Epoch: 5458, Train Loss: 0.162, Validation Loss: 0.253\n",
      "Epoch: 5459, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 5460, Train Loss: 0.236, Validation Loss: 0.248\n",
      "Epoch: 5461, Train Loss: 0.203, Validation Loss: 0.247\n",
      "Epoch: 5462, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 5463, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 5464, Train Loss: 0.509, Validation Loss: 0.248\n",
      "Epoch: 5465, Train Loss: 0.231, Validation Loss: 0.249\n",
      "Epoch: 5466, Train Loss: 0.309, Validation Loss: 0.251\n",
      "Epoch: 5467, Train Loss: 0.262, Validation Loss: 0.246\n",
      "Epoch: 5468, Train Loss: 0.225, Validation Loss: 0.246\n",
      "Epoch: 5469, Train Loss: 0.362, Validation Loss: 0.249\n",
      "Epoch: 5470, Train Loss: 0.295, Validation Loss: 0.251\n",
      "Epoch: 5471, Train Loss: 0.199, Validation Loss: 0.248\n",
      "Epoch: 5472, Train Loss: 0.440, Validation Loss: 0.247\n",
      "Epoch: 5473, Train Loss: 0.195, Validation Loss: 0.249\n",
      "Epoch: 5474, Train Loss: 0.285, Validation Loss: 0.250\n",
      "Epoch: 5475, Train Loss: 0.238, Validation Loss: 0.252\n",
      "Epoch: 5476, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 5477, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 5478, Train Loss: 0.158, Validation Loss: 0.247\n",
      "Epoch: 5479, Train Loss: 0.211, Validation Loss: 0.246\n",
      "Epoch: 5480, Train Loss: 0.250, Validation Loss: 0.251\n",
      "Epoch: 5481, Train Loss: 0.290, Validation Loss: 0.252\n",
      "Epoch: 5482, Train Loss: 0.247, Validation Loss: 0.248\n",
      "Epoch: 5483, Train Loss: 0.322, Validation Loss: 0.248\n",
      "Epoch: 5484, Train Loss: 0.186, Validation Loss: 0.251\n",
      "Epoch: 5485, Train Loss: 0.305, Validation Loss: 0.247\n",
      "Epoch: 5486, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 5487, Train Loss: 0.285, Validation Loss: 0.252\n",
      "Epoch: 5488, Train Loss: 0.168, Validation Loss: 0.249\n",
      "Epoch: 5489, Train Loss: 0.245, Validation Loss: 0.249\n",
      "Epoch: 5490, Train Loss: 0.212, Validation Loss: 0.247\n",
      "Epoch: 5491, Train Loss: 0.341, Validation Loss: 0.249\n",
      "Epoch: 5492, Train Loss: 0.205, Validation Loss: 0.249\n",
      "Epoch: 5493, Train Loss: 0.314, Validation Loss: 0.250\n",
      "Epoch: 5494, Train Loss: 0.442, Validation Loss: 0.255\n",
      "Epoch: 5495, Train Loss: 0.220, Validation Loss: 0.253\n",
      "Epoch: 5496, Train Loss: 0.203, Validation Loss: 0.251\n",
      "Epoch: 5497, Train Loss: 0.188, Validation Loss: 0.247\n",
      "Epoch: 5498, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 5499, Train Loss: 0.236, Validation Loss: 0.254\n",
      "Epoch: 5500, Train Loss: 0.630, Validation Loss: 0.250\n",
      "Epoch: 5501, Train Loss: 0.189, Validation Loss: 0.248\n",
      "Epoch: 5502, Train Loss: 0.254, Validation Loss: 0.250\n",
      "Epoch: 5503, Train Loss: 0.379, Validation Loss: 0.250\n",
      "Epoch: 5504, Train Loss: 0.488, Validation Loss: 0.254\n",
      "Epoch: 5505, Train Loss: 0.223, Validation Loss: 0.250\n",
      "Epoch: 5506, Train Loss: 0.353, Validation Loss: 0.254\n",
      "Epoch: 5507, Train Loss: 0.227, Validation Loss: 0.252\n",
      "Epoch: 5508, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 5509, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 5510, Train Loss: 0.228, Validation Loss: 0.249\n",
      "Epoch: 5511, Train Loss: 0.253, Validation Loss: 0.252\n",
      "Epoch: 5512, Train Loss: 0.174, Validation Loss: 0.253\n",
      "Epoch: 5513, Train Loss: 0.231, Validation Loss: 0.247\n",
      "Epoch: 5514, Train Loss: 0.232, Validation Loss: 0.249\n",
      "Epoch: 5515, Train Loss: 0.266, Validation Loss: 0.250\n",
      "Epoch: 5516, Train Loss: 0.197, Validation Loss: 0.250\n",
      "Epoch: 5517, Train Loss: 0.240, Validation Loss: 0.249\n",
      "Epoch: 5518, Train Loss: 0.325, Validation Loss: 0.247\n",
      "Epoch: 5519, Train Loss: 0.251, Validation Loss: 0.254\n",
      "Epoch: 5520, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 5521, Train Loss: 0.204, Validation Loss: 0.250\n",
      "Epoch: 5522, Train Loss: 0.241, Validation Loss: 0.250\n",
      "Epoch: 5523, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 5524, Train Loss: 0.302, Validation Loss: 0.253\n",
      "Epoch: 5525, Train Loss: 0.263, Validation Loss: 0.249\n",
      "Epoch: 5526, Train Loss: 0.254, Validation Loss: 0.251\n",
      "Epoch: 5527, Train Loss: 0.257, Validation Loss: 0.248\n",
      "Epoch: 5528, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 5529, Train Loss: 0.182, Validation Loss: 0.252\n",
      "Epoch: 5530, Train Loss: 0.346, Validation Loss: 0.252\n",
      "Epoch: 5531, Train Loss: 0.274, Validation Loss: 0.250\n",
      "Epoch: 5532, Train Loss: 0.258, Validation Loss: 0.248\n",
      "Epoch: 5533, Train Loss: 0.180, Validation Loss: 0.250\n",
      "Epoch: 5534, Train Loss: 0.330, Validation Loss: 0.251\n",
      "Epoch: 5535, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 5536, Train Loss: 0.269, Validation Loss: 0.255\n",
      "Epoch: 5537, Train Loss: 0.293, Validation Loss: 0.251\n",
      "Epoch: 5538, Train Loss: 0.362, Validation Loss: 0.251\n",
      "Epoch: 5539, Train Loss: 0.372, Validation Loss: 0.250\n",
      "Epoch: 5540, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 5541, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 5542, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 5543, Train Loss: 0.371, Validation Loss: 0.247\n",
      "Epoch: 5544, Train Loss: 0.233, Validation Loss: 0.253\n",
      "Epoch: 5545, Train Loss: 0.159, Validation Loss: 0.251\n",
      "Epoch: 5546, Train Loss: 0.203, Validation Loss: 0.249\n",
      "Epoch: 5547, Train Loss: 0.314, Validation Loss: 0.250\n",
      "Epoch: 5548, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 5549, Train Loss: 0.178, Validation Loss: 0.254\n",
      "Epoch: 5550, Train Loss: 0.222, Validation Loss: 0.252\n",
      "Epoch: 5551, Train Loss: 0.411, Validation Loss: 0.253\n",
      "Epoch: 5552, Train Loss: 0.244, Validation Loss: 0.254\n",
      "Epoch: 5553, Train Loss: 0.237, Validation Loss: 0.249\n",
      "Epoch: 5554, Train Loss: 0.209, Validation Loss: 0.250\n",
      "Epoch: 5555, Train Loss: 0.387, Validation Loss: 0.248\n",
      "Epoch: 5556, Train Loss: 0.206, Validation Loss: 0.252\n",
      "Epoch: 5557, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 5558, Train Loss: 0.252, Validation Loss: 0.252\n",
      "Epoch: 5559, Train Loss: 0.193, Validation Loss: 0.249\n",
      "Epoch: 5560, Train Loss: 0.278, Validation Loss: 0.250\n",
      "Epoch: 5561, Train Loss: 0.302, Validation Loss: 0.248\n",
      "Epoch: 5562, Train Loss: 0.267, Validation Loss: 0.251\n",
      "Epoch: 5563, Train Loss: 0.293, Validation Loss: 0.247\n",
      "Epoch: 5564, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 5565, Train Loss: 0.260, Validation Loss: 0.247\n",
      "Epoch: 5566, Train Loss: 0.359, Validation Loss: 0.247\n",
      "Epoch: 5567, Train Loss: 0.206, Validation Loss: 0.252\n",
      "Epoch: 5568, Train Loss: 0.221, Validation Loss: 0.256\n",
      "Epoch: 5569, Train Loss: 0.266, Validation Loss: 0.256\n",
      "Epoch: 5570, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 5571, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 5572, Train Loss: 0.249, Validation Loss: 0.251\n",
      "Epoch: 5573, Train Loss: 0.213, Validation Loss: 0.254\n",
      "Epoch: 5574, Train Loss: 0.281, Validation Loss: 0.256\n",
      "Epoch: 5575, Train Loss: 0.336, Validation Loss: 0.254\n",
      "Epoch: 5576, Train Loss: 0.298, Validation Loss: 0.249\n",
      "Epoch: 5577, Train Loss: 0.336, Validation Loss: 0.253\n",
      "Epoch: 5578, Train Loss: 0.201, Validation Loss: 0.251\n",
      "Epoch: 5579, Train Loss: 0.501, Validation Loss: 0.250\n",
      "Epoch: 5580, Train Loss: 0.257, Validation Loss: 0.252\n",
      "Epoch: 5581, Train Loss: 0.458, Validation Loss: 0.253\n",
      "Epoch: 5582, Train Loss: 0.339, Validation Loss: 0.252\n",
      "Epoch: 5583, Train Loss: 0.342, Validation Loss: 0.253\n",
      "Epoch: 5584, Train Loss: 0.425, Validation Loss: 0.258\n",
      "Epoch: 5585, Train Loss: 0.442, Validation Loss: 0.249\n",
      "Epoch: 5586, Train Loss: 0.265, Validation Loss: 0.249\n",
      "Epoch: 5587, Train Loss: 0.345, Validation Loss: 0.255\n",
      "Epoch: 5588, Train Loss: 0.179, Validation Loss: 0.253\n",
      "Epoch: 5589, Train Loss: 0.209, Validation Loss: 0.251\n",
      "Epoch: 5590, Train Loss: 0.276, Validation Loss: 0.256\n",
      "Epoch: 5591, Train Loss: 0.272, Validation Loss: 0.248\n",
      "Epoch: 5592, Train Loss: 0.396, Validation Loss: 0.250\n",
      "Epoch: 5593, Train Loss: 0.317, Validation Loss: 0.253\n",
      "Epoch: 5594, Train Loss: 0.238, Validation Loss: 0.249\n",
      "Epoch: 5595, Train Loss: 0.333, Validation Loss: 0.253\n",
      "Epoch: 5596, Train Loss: 0.278, Validation Loss: 0.249\n",
      "Epoch: 5597, Train Loss: 0.190, Validation Loss: 0.249\n",
      "Epoch: 5598, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 5599, Train Loss: 0.278, Validation Loss: 0.250\n",
      "Epoch: 5600, Train Loss: 0.268, Validation Loss: 0.259\n",
      "Epoch: 5601, Train Loss: 0.268, Validation Loss: 0.249\n",
      "Epoch: 5602, Train Loss: 0.328, Validation Loss: 0.253\n",
      "Epoch: 5603, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 5604, Train Loss: 0.212, Validation Loss: 0.248\n",
      "Epoch: 5605, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 5606, Train Loss: 0.515, Validation Loss: 0.252\n",
      "Epoch: 5607, Train Loss: 0.306, Validation Loss: 0.248\n",
      "Epoch: 5608, Train Loss: 0.201, Validation Loss: 0.247\n",
      "Epoch: 5609, Train Loss: 0.268, Validation Loss: 0.246\n",
      "Epoch: 5610, Train Loss: 0.404, Validation Loss: 0.248\n",
      "Epoch: 5611, Train Loss: 0.255, Validation Loss: 0.249\n",
      "Epoch: 5612, Train Loss: 0.263, Validation Loss: 0.251\n",
      "Epoch: 5613, Train Loss: 0.185, Validation Loss: 0.247\n",
      "Epoch: 5614, Train Loss: 0.466, Validation Loss: 0.248\n",
      "Epoch: 5615, Train Loss: 0.405, Validation Loss: 0.247\n",
      "Epoch: 5616, Train Loss: 0.248, Validation Loss: 0.254\n",
      "Epoch: 5617, Train Loss: 0.493, Validation Loss: 0.247\n",
      "Epoch: 5618, Train Loss: 0.313, Validation Loss: 0.247\n",
      "Epoch: 5619, Train Loss: 0.229, Validation Loss: 0.254\n",
      "Epoch: 5620, Train Loss: 0.279, Validation Loss: 0.255\n",
      "Epoch: 5621, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 5622, Train Loss: 0.170, Validation Loss: 0.253\n",
      "Epoch: 5623, Train Loss: 0.254, Validation Loss: 0.253\n",
      "Epoch: 5624, Train Loss: 0.438, Validation Loss: 0.260\n",
      "Epoch: 5625, Train Loss: 0.156, Validation Loss: 0.249\n",
      "Epoch: 5626, Train Loss: 0.191, Validation Loss: 0.247\n",
      "Epoch: 5627, Train Loss: 0.179, Validation Loss: 0.249\n",
      "Epoch: 5628, Train Loss: 0.241, Validation Loss: 0.248\n",
      "Epoch: 5629, Train Loss: 0.204, Validation Loss: 0.250\n",
      "Epoch: 5630, Train Loss: 0.198, Validation Loss: 0.253\n",
      "Epoch: 5631, Train Loss: 0.233, Validation Loss: 0.250\n",
      "Epoch: 5632, Train Loss: 0.349, Validation Loss: 0.250\n",
      "Epoch: 5633, Train Loss: 0.164, Validation Loss: 0.250\n",
      "Epoch: 5634, Train Loss: 0.290, Validation Loss: 0.255\n",
      "Epoch: 5635, Train Loss: 0.235, Validation Loss: 0.256\n",
      "Epoch: 5636, Train Loss: 0.304, Validation Loss: 0.252\n",
      "Epoch: 5637, Train Loss: 0.242, Validation Loss: 0.252\n",
      "Epoch: 5638, Train Loss: 0.199, Validation Loss: 0.255\n",
      "Epoch: 5639, Train Loss: 0.223, Validation Loss: 0.252\n",
      "Epoch: 5640, Train Loss: 0.189, Validation Loss: 0.251\n",
      "Epoch: 5641, Train Loss: 0.187, Validation Loss: 0.255\n",
      "Epoch: 5642, Train Loss: 0.245, Validation Loss: 0.252\n",
      "Epoch: 5643, Train Loss: 0.619, Validation Loss: 0.253\n",
      "Epoch: 5644, Train Loss: 0.240, Validation Loss: 0.249\n",
      "Epoch: 5645, Train Loss: 0.189, Validation Loss: 0.247\n",
      "Epoch: 5646, Train Loss: 0.371, Validation Loss: 0.254\n",
      "Epoch: 5647, Train Loss: 0.189, Validation Loss: 0.249\n",
      "Epoch: 5648, Train Loss: 0.242, Validation Loss: 0.252\n",
      "Epoch: 5649, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 5650, Train Loss: 0.500, Validation Loss: 0.250\n",
      "Epoch: 5651, Train Loss: 0.288, Validation Loss: 0.249\n",
      "Epoch: 5652, Train Loss: 0.282, Validation Loss: 0.257\n",
      "Epoch: 5653, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 5654, Train Loss: 0.458, Validation Loss: 0.248\n",
      "Epoch: 5655, Train Loss: 0.351, Validation Loss: 0.251\n",
      "Epoch: 5656, Train Loss: 0.402, Validation Loss: 0.248\n",
      "Epoch: 5657, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 5658, Train Loss: 0.170, Validation Loss: 0.248\n",
      "Epoch: 5659, Train Loss: 0.242, Validation Loss: 0.247\n",
      "Epoch: 5660, Train Loss: 0.206, Validation Loss: 0.249\n",
      "Epoch: 5661, Train Loss: 0.277, Validation Loss: 0.250\n",
      "Epoch: 5662, Train Loss: 0.385, Validation Loss: 0.255\n",
      "Epoch: 5663, Train Loss: 0.262, Validation Loss: 0.248\n",
      "Epoch: 5664, Train Loss: 0.274, Validation Loss: 0.246\n",
      "Epoch: 5665, Train Loss: 0.226, Validation Loss: 0.247\n",
      "Epoch: 5666, Train Loss: 0.233, Validation Loss: 0.250\n",
      "Epoch: 5667, Train Loss: 0.271, Validation Loss: 0.246\n",
      "Epoch: 5668, Train Loss: 0.235, Validation Loss: 0.248\n",
      "Epoch: 5669, Train Loss: 0.266, Validation Loss: 0.248\n",
      "Epoch: 5670, Train Loss: 0.345, Validation Loss: 0.252\n",
      "Epoch: 5671, Train Loss: 0.268, Validation Loss: 0.251\n",
      "Epoch: 5672, Train Loss: 0.352, Validation Loss: 0.252\n",
      "Epoch: 5673, Train Loss: 0.422, Validation Loss: 0.250\n",
      "Epoch: 5674, Train Loss: 0.176, Validation Loss: 0.248\n",
      "Epoch: 5675, Train Loss: 0.180, Validation Loss: 0.252\n",
      "Epoch: 5676, Train Loss: 0.245, Validation Loss: 0.257\n",
      "Epoch: 5677, Train Loss: 0.146, Validation Loss: 0.250\n",
      "Epoch: 5678, Train Loss: 0.272, Validation Loss: 0.246\n",
      "Epoch: 5679, Train Loss: 0.204, Validation Loss: 0.246\n",
      "Epoch: 5680, Train Loss: 0.229, Validation Loss: 0.248\n",
      "Epoch: 5681, Train Loss: 0.238, Validation Loss: 0.247\n",
      "Epoch: 5682, Train Loss: 0.228, Validation Loss: 0.253\n",
      "Epoch: 5683, Train Loss: 0.426, Validation Loss: 0.247\n",
      "Epoch: 5684, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 5685, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 5686, Train Loss: 0.268, Validation Loss: 0.250\n",
      "Epoch: 5687, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 5688, Train Loss: 0.302, Validation Loss: 0.249\n",
      "Epoch: 5689, Train Loss: 0.258, Validation Loss: 0.248\n",
      "Epoch: 5690, Train Loss: 0.294, Validation Loss: 0.254\n",
      "Epoch: 5691, Train Loss: 0.247, Validation Loss: 0.255\n",
      "Epoch: 5692, Train Loss: 0.469, Validation Loss: 0.250\n",
      "Epoch: 5693, Train Loss: 0.443, Validation Loss: 0.252\n",
      "Epoch: 5694, Train Loss: 0.277, Validation Loss: 0.252\n",
      "Epoch: 5695, Train Loss: 0.212, Validation Loss: 0.251\n",
      "Epoch: 5696, Train Loss: 0.190, Validation Loss: 0.252\n",
      "Epoch: 5697, Train Loss: 0.347, Validation Loss: 0.252\n",
      "Epoch: 5698, Train Loss: 0.177, Validation Loss: 0.251\n",
      "Epoch: 5699, Train Loss: 0.211, Validation Loss: 0.249\n",
      "Epoch: 5700, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 5701, Train Loss: 0.258, Validation Loss: 0.252\n",
      "Epoch: 5702, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 5703, Train Loss: 0.262, Validation Loss: 0.255\n",
      "Epoch: 5704, Train Loss: 0.403, Validation Loss: 0.246\n",
      "Epoch: 5705, Train Loss: 0.212, Validation Loss: 0.247\n",
      "Epoch: 5706, Train Loss: 0.219, Validation Loss: 0.251\n",
      "Epoch: 5707, Train Loss: 0.275, Validation Loss: 0.249\n",
      "Epoch: 5708, Train Loss: 0.212, Validation Loss: 0.248\n",
      "Epoch: 5709, Train Loss: 0.324, Validation Loss: 0.254\n",
      "Epoch: 5710, Train Loss: 0.238, Validation Loss: 0.245\n",
      "Epoch: 5711, Train Loss: 0.276, Validation Loss: 0.248\n",
      "Epoch: 5712, Train Loss: 0.190, Validation Loss: 0.246\n",
      "Epoch: 5713, Train Loss: 0.371, Validation Loss: 0.249\n",
      "Epoch: 5714, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 5715, Train Loss: 0.213, Validation Loss: 0.252\n",
      "Epoch: 5716, Train Loss: 0.324, Validation Loss: 0.247\n",
      "Epoch: 5717, Train Loss: 0.143, Validation Loss: 0.250\n",
      "Epoch: 5718, Train Loss: 0.249, Validation Loss: 0.251\n",
      "Epoch: 5719, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 5720, Train Loss: 0.378, Validation Loss: 0.250\n",
      "Epoch: 5721, Train Loss: 0.188, Validation Loss: 0.251\n",
      "Epoch: 5722, Train Loss: 0.172, Validation Loss: 0.253\n",
      "Epoch: 5723, Train Loss: 0.488, Validation Loss: 0.250\n",
      "Epoch: 5724, Train Loss: 0.206, Validation Loss: 0.250\n",
      "Epoch: 5725, Train Loss: 0.231, Validation Loss: 0.251\n",
      "Epoch: 5726, Train Loss: 0.277, Validation Loss: 0.254\n",
      "Epoch: 5727, Train Loss: 0.282, Validation Loss: 0.257\n",
      "Epoch: 5728, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 5729, Train Loss: 0.210, Validation Loss: 0.250\n",
      "Epoch: 5730, Train Loss: 0.274, Validation Loss: 0.255\n",
      "Epoch: 5731, Train Loss: 0.205, Validation Loss: 0.253\n",
      "Epoch: 5732, Train Loss: 0.616, Validation Loss: 0.250\n",
      "Epoch: 5733, Train Loss: 0.240, Validation Loss: 0.248\n",
      "Epoch: 5734, Train Loss: 0.216, Validation Loss: 0.246\n",
      "Epoch: 5735, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 5736, Train Loss: 0.203, Validation Loss: 0.246\n",
      "Epoch: 5737, Train Loss: 0.596, Validation Loss: 0.247\n",
      "Epoch: 5738, Train Loss: 0.284, Validation Loss: 0.247\n",
      "Epoch: 5739, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 5740, Train Loss: 0.220, Validation Loss: 0.251\n",
      "Epoch: 5741, Train Loss: 0.225, Validation Loss: 0.255\n",
      "Epoch: 5742, Train Loss: 0.437, Validation Loss: 0.252\n",
      "Epoch: 5743, Train Loss: 0.272, Validation Loss: 0.250\n",
      "Epoch: 5744, Train Loss: 0.267, Validation Loss: 0.256\n",
      "Epoch: 5745, Train Loss: 0.346, Validation Loss: 0.249\n",
      "Epoch: 5746, Train Loss: 0.378, Validation Loss: 0.250\n",
      "Epoch: 5747, Train Loss: 0.190, Validation Loss: 0.250\n",
      "Epoch: 5748, Train Loss: 0.310, Validation Loss: 0.249\n",
      "Epoch: 5749, Train Loss: 0.224, Validation Loss: 0.252\n",
      "Epoch: 5750, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 5751, Train Loss: 0.248, Validation Loss: 0.249\n",
      "Epoch: 5752, Train Loss: 0.312, Validation Loss: 0.249\n",
      "Epoch: 5753, Train Loss: 0.255, Validation Loss: 0.249\n",
      "Epoch: 5754, Train Loss: 0.291, Validation Loss: 0.252\n",
      "Epoch: 5755, Train Loss: 0.235, Validation Loss: 0.250\n",
      "Epoch: 5756, Train Loss: 0.308, Validation Loss: 0.246\n",
      "Epoch: 5757, Train Loss: 0.240, Validation Loss: 0.252\n",
      "Epoch: 5758, Train Loss: 0.422, Validation Loss: 0.248\n",
      "Epoch: 5759, Train Loss: 0.217, Validation Loss: 0.250\n",
      "Epoch: 5760, Train Loss: 0.221, Validation Loss: 0.254\n",
      "Epoch: 5761, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 5762, Train Loss: 0.366, Validation Loss: 0.249\n",
      "Epoch: 5763, Train Loss: 0.186, Validation Loss: 0.251\n",
      "Epoch: 5764, Train Loss: 0.288, Validation Loss: 0.252\n",
      "Epoch: 5765, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 5766, Train Loss: 0.190, Validation Loss: 0.252\n",
      "Epoch: 5767, Train Loss: 0.341, Validation Loss: 0.254\n",
      "Epoch: 5768, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 5769, Train Loss: 0.452, Validation Loss: 0.249\n",
      "Epoch: 5770, Train Loss: 0.317, Validation Loss: 0.250\n",
      "Epoch: 5771, Train Loss: 0.229, Validation Loss: 0.253\n",
      "Epoch: 5772, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 5773, Train Loss: 0.209, Validation Loss: 0.253\n",
      "Epoch: 5774, Train Loss: 0.204, Validation Loss: 0.252\n",
      "Epoch: 5775, Train Loss: 0.239, Validation Loss: 0.256\n",
      "Epoch: 5776, Train Loss: 0.298, Validation Loss: 0.261\n",
      "Epoch: 5777, Train Loss: 0.249, Validation Loss: 0.256\n",
      "Epoch: 5778, Train Loss: 0.294, Validation Loss: 0.253\n",
      "Epoch: 5779, Train Loss: 0.453, Validation Loss: 0.250\n",
      "Epoch: 5780, Train Loss: 0.256, Validation Loss: 0.249\n",
      "Epoch: 5781, Train Loss: 0.317, Validation Loss: 0.249\n",
      "Epoch: 5782, Train Loss: 0.388, Validation Loss: 0.247\n",
      "Epoch: 5783, Train Loss: 0.235, Validation Loss: 0.251\n",
      "Epoch: 5784, Train Loss: 0.230, Validation Loss: 0.250\n",
      "Epoch: 5785, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 5786, Train Loss: 0.348, Validation Loss: 0.248\n",
      "Epoch: 5787, Train Loss: 0.294, Validation Loss: 0.251\n",
      "Epoch: 5788, Train Loss: 0.296, Validation Loss: 0.253\n",
      "Epoch: 5789, Train Loss: 0.255, Validation Loss: 0.253\n",
      "Epoch: 5790, Train Loss: 0.188, Validation Loss: 0.253\n",
      "Epoch: 5791, Train Loss: 0.195, Validation Loss: 0.250\n",
      "Epoch: 5792, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 5793, Train Loss: 0.288, Validation Loss: 0.251\n",
      "Epoch: 5794, Train Loss: 0.239, Validation Loss: 0.252\n",
      "Epoch: 5795, Train Loss: 0.220, Validation Loss: 0.254\n",
      "Epoch: 5796, Train Loss: 0.247, Validation Loss: 0.254\n",
      "Epoch: 5797, Train Loss: 0.221, Validation Loss: 0.251\n",
      "Epoch: 5798, Train Loss: 0.263, Validation Loss: 0.248\n",
      "Epoch: 5799, Train Loss: 0.354, Validation Loss: 0.249\n",
      "Epoch: 5800, Train Loss: 0.155, Validation Loss: 0.251\n",
      "Epoch: 5801, Train Loss: 0.399, Validation Loss: 0.249\n",
      "Epoch: 5802, Train Loss: 0.201, Validation Loss: 0.248\n",
      "Epoch: 5803, Train Loss: 0.329, Validation Loss: 0.246\n",
      "Epoch: 5804, Train Loss: 0.232, Validation Loss: 0.247\n",
      "Epoch: 5805, Train Loss: 0.281, Validation Loss: 0.250\n",
      "Epoch: 5806, Train Loss: 0.176, Validation Loss: 0.249\n",
      "Epoch: 5807, Train Loss: 0.183, Validation Loss: 0.249\n",
      "Epoch: 5808, Train Loss: 0.413, Validation Loss: 0.246\n",
      "Epoch: 5809, Train Loss: 0.217, Validation Loss: 0.248\n",
      "Epoch: 5810, Train Loss: 0.250, Validation Loss: 0.253\n",
      "Epoch: 5811, Train Loss: 0.277, Validation Loss: 0.251\n",
      "Epoch: 5812, Train Loss: 0.203, Validation Loss: 0.251\n",
      "Epoch: 5813, Train Loss: 0.614, Validation Loss: 0.248\n",
      "Epoch: 5814, Train Loss: 0.236, Validation Loss: 0.253\n",
      "Epoch: 5815, Train Loss: 0.312, Validation Loss: 0.253\n",
      "Epoch: 5816, Train Loss: 0.425, Validation Loss: 0.247\n",
      "Epoch: 5817, Train Loss: 0.313, Validation Loss: 0.257\n",
      "Epoch: 5818, Train Loss: 0.394, Validation Loss: 0.255\n",
      "Epoch: 5819, Train Loss: 0.195, Validation Loss: 0.251\n",
      "Epoch: 5820, Train Loss: 0.208, Validation Loss: 0.251\n",
      "Epoch: 5821, Train Loss: 0.487, Validation Loss: 0.254\n",
      "Epoch: 5822, Train Loss: 0.300, Validation Loss: 0.258\n",
      "Epoch: 5823, Train Loss: 0.473, Validation Loss: 0.251\n",
      "Epoch: 5824, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 5825, Train Loss: 0.280, Validation Loss: 0.252\n",
      "Epoch: 5826, Train Loss: 0.268, Validation Loss: 0.254\n",
      "Epoch: 5827, Train Loss: 0.297, Validation Loss: 0.249\n",
      "Epoch: 5828, Train Loss: 0.259, Validation Loss: 0.252\n",
      "Epoch: 5829, Train Loss: 0.222, Validation Loss: 0.253\n",
      "Epoch: 5830, Train Loss: 0.207, Validation Loss: 0.255\n",
      "Epoch: 5831, Train Loss: 0.253, Validation Loss: 0.255\n",
      "Epoch: 5832, Train Loss: 0.317, Validation Loss: 0.254\n",
      "Epoch: 5833, Train Loss: 0.249, Validation Loss: 0.253\n",
      "Epoch: 5834, Train Loss: 0.151, Validation Loss: 0.254\n",
      "Epoch: 5835, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 5836, Train Loss: 0.252, Validation Loss: 0.252\n",
      "Epoch: 5837, Train Loss: 0.271, Validation Loss: 0.253\n",
      "Epoch: 5838, Train Loss: 0.280, Validation Loss: 0.252\n",
      "Epoch: 5839, Train Loss: 0.400, Validation Loss: 0.251\n",
      "Epoch: 5840, Train Loss: 0.242, Validation Loss: 0.249\n",
      "Epoch: 5841, Train Loss: 0.281, Validation Loss: 0.250\n",
      "Epoch: 5842, Train Loss: 0.239, Validation Loss: 0.248\n",
      "Epoch: 5843, Train Loss: 0.494, Validation Loss: 0.250\n",
      "Epoch: 5844, Train Loss: 0.305, Validation Loss: 0.251\n",
      "Epoch: 5845, Train Loss: 0.209, Validation Loss: 0.251\n",
      "Epoch: 5846, Train Loss: 0.298, Validation Loss: 0.248\n",
      "Epoch: 5847, Train Loss: 0.240, Validation Loss: 0.247\n",
      "Epoch: 5848, Train Loss: 0.231, Validation Loss: 0.250\n",
      "Epoch: 5849, Train Loss: 0.287, Validation Loss: 0.247\n",
      "Epoch: 5850, Train Loss: 0.284, Validation Loss: 0.251\n",
      "Epoch: 5851, Train Loss: 0.307, Validation Loss: 0.250\n",
      "Epoch: 5852, Train Loss: 0.409, Validation Loss: 0.249\n",
      "Epoch: 5853, Train Loss: 0.190, Validation Loss: 0.252\n",
      "Epoch: 5854, Train Loss: 0.209, Validation Loss: 0.250\n",
      "Epoch: 5855, Train Loss: 0.361, Validation Loss: 0.255\n",
      "Epoch: 5856, Train Loss: 0.259, Validation Loss: 0.253\n",
      "Epoch: 5857, Train Loss: 0.387, Validation Loss: 0.248\n",
      "Epoch: 5858, Train Loss: 0.176, Validation Loss: 0.251\n",
      "Epoch: 5859, Train Loss: 0.346, Validation Loss: 0.255\n",
      "Epoch: 5860, Train Loss: 0.472, Validation Loss: 0.249\n",
      "Epoch: 5861, Train Loss: 0.406, Validation Loss: 0.249\n",
      "Epoch: 5862, Train Loss: 0.327, Validation Loss: 0.249\n",
      "Epoch: 5863, Train Loss: 0.529, Validation Loss: 0.249\n",
      "Epoch: 5864, Train Loss: 0.305, Validation Loss: 0.250\n",
      "Epoch: 5865, Train Loss: 0.209, Validation Loss: 0.249\n",
      "Epoch: 5866, Train Loss: 0.229, Validation Loss: 0.250\n",
      "Epoch: 5867, Train Loss: 0.162, Validation Loss: 0.249\n",
      "Epoch: 5868, Train Loss: 0.236, Validation Loss: 0.248\n",
      "Epoch: 5869, Train Loss: 0.186, Validation Loss: 0.249\n",
      "Epoch: 5870, Train Loss: 0.249, Validation Loss: 0.252\n",
      "Epoch: 5871, Train Loss: 0.296, Validation Loss: 0.248\n",
      "Epoch: 5872, Train Loss: 0.323, Validation Loss: 0.251\n",
      "Epoch: 5873, Train Loss: 0.265, Validation Loss: 0.261\n",
      "Epoch: 5874, Train Loss: 0.195, Validation Loss: 0.256\n",
      "Epoch: 5875, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 5876, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 5877, Train Loss: 0.344, Validation Loss: 0.257\n",
      "Epoch: 5878, Train Loss: 0.359, Validation Loss: 0.253\n",
      "Epoch: 5879, Train Loss: 0.361, Validation Loss: 0.255\n",
      "Epoch: 5880, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 5881, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 5882, Train Loss: 0.290, Validation Loss: 0.259\n",
      "Epoch: 5883, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 5884, Train Loss: 0.417, Validation Loss: 0.250\n",
      "Epoch: 5885, Train Loss: 0.424, Validation Loss: 0.250\n",
      "Epoch: 5886, Train Loss: 0.303, Validation Loss: 0.250\n",
      "Epoch: 5887, Train Loss: 0.180, Validation Loss: 0.258\n",
      "Epoch: 5888, Train Loss: 0.315, Validation Loss: 0.258\n",
      "Epoch: 5889, Train Loss: 0.257, Validation Loss: 0.249\n",
      "Epoch: 5890, Train Loss: 0.195, Validation Loss: 0.249\n",
      "Epoch: 5891, Train Loss: 0.381, Validation Loss: 0.248\n",
      "Epoch: 5892, Train Loss: 0.225, Validation Loss: 0.250\n",
      "Epoch: 5893, Train Loss: 0.178, Validation Loss: 0.257\n",
      "Epoch: 5894, Train Loss: 0.323, Validation Loss: 0.258\n",
      "Epoch: 5895, Train Loss: 0.295, Validation Loss: 0.251\n",
      "Epoch: 5896, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 5897, Train Loss: 0.195, Validation Loss: 0.248\n",
      "Epoch: 5898, Train Loss: 0.451, Validation Loss: 0.247\n",
      "Epoch: 5899, Train Loss: 0.383, Validation Loss: 0.247\n",
      "Epoch: 5900, Train Loss: 0.326, Validation Loss: 0.251\n",
      "Epoch: 5901, Train Loss: 0.408, Validation Loss: 0.247\n",
      "Epoch: 5902, Train Loss: 0.203, Validation Loss: 0.249\n",
      "Epoch: 5903, Train Loss: 0.336, Validation Loss: 0.248\n",
      "Epoch: 5904, Train Loss: 0.391, Validation Loss: 0.252\n",
      "Epoch: 5905, Train Loss: 0.224, Validation Loss: 0.249\n",
      "Epoch: 5906, Train Loss: 0.363, Validation Loss: 0.246\n",
      "Epoch: 5907, Train Loss: 0.291, Validation Loss: 0.246\n",
      "Epoch: 5908, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 5909, Train Loss: 0.374, Validation Loss: 0.256\n",
      "Epoch: 5910, Train Loss: 0.363, Validation Loss: 0.246\n",
      "Epoch: 5911, Train Loss: 0.269, Validation Loss: 0.250\n",
      "Epoch: 5912, Train Loss: 0.236, Validation Loss: 0.249\n",
      "Epoch: 5913, Train Loss: 0.265, Validation Loss: 0.250\n",
      "Epoch: 5914, Train Loss: 0.306, Validation Loss: 0.252\n",
      "Epoch: 5915, Train Loss: 0.361, Validation Loss: 0.257\n",
      "Epoch: 5916, Train Loss: 0.771, Validation Loss: 0.250\n",
      "Epoch: 5917, Train Loss: 0.239, Validation Loss: 0.248\n",
      "Epoch: 5918, Train Loss: 0.295, Validation Loss: 0.247\n",
      "Epoch: 5919, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 5920, Train Loss: 0.654, Validation Loss: 0.251\n",
      "Epoch: 5921, Train Loss: 0.330, Validation Loss: 0.250\n",
      "Epoch: 5922, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 5923, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 5924, Train Loss: 0.228, Validation Loss: 0.251\n",
      "Epoch: 5925, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 5926, Train Loss: 0.319, Validation Loss: 0.250\n",
      "Epoch: 5927, Train Loss: 0.373, Validation Loss: 0.254\n",
      "Epoch: 5928, Train Loss: 0.304, Validation Loss: 0.251\n",
      "Epoch: 5929, Train Loss: 0.350, Validation Loss: 0.251\n",
      "Epoch: 5930, Train Loss: 0.226, Validation Loss: 0.251\n",
      "Epoch: 5931, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 5932, Train Loss: 0.417, Validation Loss: 0.250\n",
      "Epoch: 5933, Train Loss: 0.361, Validation Loss: 0.253\n",
      "Epoch: 5934, Train Loss: 0.248, Validation Loss: 0.256\n",
      "Epoch: 5935, Train Loss: 0.240, Validation Loss: 0.255\n",
      "Epoch: 5936, Train Loss: 0.206, Validation Loss: 0.255\n",
      "Epoch: 5937, Train Loss: 0.233, Validation Loss: 0.254\n",
      "Epoch: 5938, Train Loss: 0.550, Validation Loss: 0.251\n",
      "Epoch: 5939, Train Loss: 0.354, Validation Loss: 0.251\n",
      "Epoch: 5940, Train Loss: 0.410, Validation Loss: 0.251\n",
      "Epoch: 5941, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 5942, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 5943, Train Loss: 0.223, Validation Loss: 0.250\n",
      "Epoch: 5944, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 5945, Train Loss: 0.214, Validation Loss: 0.255\n",
      "Epoch: 5946, Train Loss: 0.225, Validation Loss: 0.253\n",
      "Epoch: 5947, Train Loss: 0.238, Validation Loss: 0.250\n",
      "Epoch: 5948, Train Loss: 0.232, Validation Loss: 0.250\n",
      "Epoch: 5949, Train Loss: 0.527, Validation Loss: 0.252\n",
      "Epoch: 5950, Train Loss: 0.353, Validation Loss: 0.258\n",
      "Epoch: 5951, Train Loss: 0.359, Validation Loss: 0.255\n",
      "Epoch: 5952, Train Loss: 0.399, Validation Loss: 0.249\n",
      "Epoch: 5953, Train Loss: 0.258, Validation Loss: 0.255\n",
      "Epoch: 5954, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 5955, Train Loss: 0.233, Validation Loss: 0.255\n",
      "Epoch: 5956, Train Loss: 0.291, Validation Loss: 0.251\n",
      "Epoch: 5957, Train Loss: 0.267, Validation Loss: 0.256\n",
      "Epoch: 5958, Train Loss: 0.231, Validation Loss: 0.252\n",
      "Epoch: 5959, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 5960, Train Loss: 0.317, Validation Loss: 0.257\n",
      "Epoch: 5961, Train Loss: 0.216, Validation Loss: 0.251\n",
      "Epoch: 5962, Train Loss: 0.273, Validation Loss: 0.249\n",
      "Epoch: 5963, Train Loss: 0.206, Validation Loss: 0.250\n",
      "Epoch: 5964, Train Loss: 0.214, Validation Loss: 0.251\n",
      "Epoch: 5965, Train Loss: 0.275, Validation Loss: 0.248\n",
      "Epoch: 5966, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 5967, Train Loss: 0.160, Validation Loss: 0.249\n",
      "Epoch: 5968, Train Loss: 0.272, Validation Loss: 0.255\n",
      "Epoch: 5969, Train Loss: 0.223, Validation Loss: 0.255\n",
      "Epoch: 5970, Train Loss: 0.308, Validation Loss: 0.250\n",
      "Epoch: 5971, Train Loss: 0.391, Validation Loss: 0.253\n",
      "Epoch: 5972, Train Loss: 0.206, Validation Loss: 0.251\n",
      "Epoch: 5973, Train Loss: 0.524, Validation Loss: 0.253\n",
      "Epoch: 5974, Train Loss: 0.296, Validation Loss: 0.252\n",
      "Epoch: 5975, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 5976, Train Loss: 0.432, Validation Loss: 0.255\n",
      "Epoch: 5977, Train Loss: 0.262, Validation Loss: 0.256\n",
      "Epoch: 5978, Train Loss: 0.266, Validation Loss: 0.255\n",
      "Epoch: 5979, Train Loss: 0.289, Validation Loss: 0.252\n",
      "Epoch: 5980, Train Loss: 0.477, Validation Loss: 0.254\n",
      "Epoch: 5981, Train Loss: 0.261, Validation Loss: 0.253\n",
      "Epoch: 5982, Train Loss: 0.242, Validation Loss: 0.252\n",
      "Epoch: 5983, Train Loss: 0.436, Validation Loss: 0.248\n",
      "Epoch: 5984, Train Loss: 0.190, Validation Loss: 0.248\n",
      "Epoch: 5985, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 5986, Train Loss: 0.448, Validation Loss: 0.254\n",
      "Epoch: 5987, Train Loss: 0.368, Validation Loss: 0.248\n",
      "Epoch: 5988, Train Loss: 0.149, Validation Loss: 0.247\n",
      "Epoch: 5989, Train Loss: 0.381, Validation Loss: 0.248\n",
      "Epoch: 5990, Train Loss: 0.341, Validation Loss: 0.248\n",
      "Epoch: 5991, Train Loss: 0.221, Validation Loss: 0.250\n",
      "Epoch: 5992, Train Loss: 0.282, Validation Loss: 0.252\n",
      "Epoch: 5993, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 5994, Train Loss: 0.421, Validation Loss: 0.250\n",
      "Epoch: 5995, Train Loss: 0.242, Validation Loss: 0.247\n",
      "Epoch: 5996, Train Loss: 0.271, Validation Loss: 0.249\n",
      "Epoch: 5997, Train Loss: 0.234, Validation Loss: 0.254\n",
      "Epoch: 5998, Train Loss: 0.231, Validation Loss: 0.253\n",
      "Epoch: 5999, Train Loss: 0.399, Validation Loss: 0.252\n",
      "Epoch: 6000, Train Loss: 0.227, Validation Loss: 0.258\n",
      "Epoch: 6001, Train Loss: 0.204, Validation Loss: 0.255\n",
      "Epoch: 6002, Train Loss: 0.281, Validation Loss: 0.252\n",
      "Epoch: 6003, Train Loss: 0.256, Validation Loss: 0.256\n",
      "Epoch: 6004, Train Loss: 0.292, Validation Loss: 0.257\n",
      "Epoch: 6005, Train Loss: 0.221, Validation Loss: 0.254\n",
      "Epoch: 6006, Train Loss: 0.260, Validation Loss: 0.250\n",
      "Epoch: 6007, Train Loss: 0.228, Validation Loss: 0.248\n",
      "Epoch: 6008, Train Loss: 0.227, Validation Loss: 0.248\n",
      "Epoch: 6009, Train Loss: 0.363, Validation Loss: 0.248\n",
      "Epoch: 6010, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 6011, Train Loss: 0.187, Validation Loss: 0.249\n",
      "Epoch: 6012, Train Loss: 0.272, Validation Loss: 0.258\n",
      "Epoch: 6013, Train Loss: 0.253, Validation Loss: 0.255\n",
      "Epoch: 6014, Train Loss: 0.370, Validation Loss: 0.260\n",
      "Epoch: 6015, Train Loss: 0.298, Validation Loss: 0.250\n",
      "Epoch: 6016, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 6017, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 6018, Train Loss: 0.370, Validation Loss: 0.250\n",
      "Epoch: 6019, Train Loss: 0.234, Validation Loss: 0.248\n",
      "Epoch: 6020, Train Loss: 0.176, Validation Loss: 0.253\n",
      "Epoch: 6021, Train Loss: 0.375, Validation Loss: 0.257\n",
      "Epoch: 6022, Train Loss: 0.237, Validation Loss: 0.249\n",
      "Epoch: 6023, Train Loss: 0.271, Validation Loss: 0.254\n",
      "Epoch: 6024, Train Loss: 0.200, Validation Loss: 0.248\n",
      "Epoch: 6025, Train Loss: 0.333, Validation Loss: 0.249\n",
      "Epoch: 6026, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 6027, Train Loss: 0.315, Validation Loss: 0.258\n",
      "Epoch: 6028, Train Loss: 0.286, Validation Loss: 0.249\n",
      "Epoch: 6029, Train Loss: 0.186, Validation Loss: 0.248\n",
      "Epoch: 6030, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 6031, Train Loss: 0.281, Validation Loss: 0.251\n",
      "Epoch: 6032, Train Loss: 0.188, Validation Loss: 0.257\n",
      "Epoch: 6033, Train Loss: 0.230, Validation Loss: 0.254\n",
      "Epoch: 6034, Train Loss: 0.458, Validation Loss: 0.249\n",
      "Epoch: 6035, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 6036, Train Loss: 0.250, Validation Loss: 0.254\n",
      "Epoch: 6037, Train Loss: 0.333, Validation Loss: 0.249\n",
      "Epoch: 6038, Train Loss: 0.230, Validation Loss: 0.255\n",
      "Epoch: 6039, Train Loss: 0.307, Validation Loss: 0.253\n",
      "Epoch: 6040, Train Loss: 0.252, Validation Loss: 0.257\n",
      "Epoch: 6041, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 6042, Train Loss: 0.317, Validation Loss: 0.250\n",
      "Epoch: 6043, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 6044, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 6045, Train Loss: 0.230, Validation Loss: 0.252\n",
      "Epoch: 6046, Train Loss: 0.178, Validation Loss: 0.253\n",
      "Epoch: 6047, Train Loss: 0.465, Validation Loss: 0.254\n",
      "Epoch: 6048, Train Loss: 0.237, Validation Loss: 0.254\n",
      "Epoch: 6049, Train Loss: 0.549, Validation Loss: 0.255\n",
      "Epoch: 6050, Train Loss: 0.211, Validation Loss: 0.253\n",
      "Epoch: 6051, Train Loss: 0.218, Validation Loss: 0.255\n",
      "Epoch: 6052, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 6053, Train Loss: 0.226, Validation Loss: 0.251\n",
      "Epoch: 6054, Train Loss: 0.265, Validation Loss: 0.253\n",
      "Epoch: 6055, Train Loss: 0.242, Validation Loss: 0.253\n",
      "Epoch: 6056, Train Loss: 0.250, Validation Loss: 0.252\n",
      "Epoch: 6057, Train Loss: 0.196, Validation Loss: 0.252\n",
      "Epoch: 6058, Train Loss: 0.272, Validation Loss: 0.252\n",
      "Epoch: 6059, Train Loss: 0.185, Validation Loss: 0.254\n",
      "Epoch: 6060, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 6061, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 6062, Train Loss: 0.390, Validation Loss: 0.252\n",
      "Epoch: 6063, Train Loss: 0.217, Validation Loss: 0.253\n",
      "Epoch: 6064, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 6065, Train Loss: 0.262, Validation Loss: 0.257\n",
      "Epoch: 6066, Train Loss: 0.203, Validation Loss: 0.257\n",
      "Epoch: 6067, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 6068, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 6069, Train Loss: 0.272, Validation Loss: 0.257\n",
      "Epoch: 6070, Train Loss: 0.189, Validation Loss: 0.255\n",
      "Epoch: 6071, Train Loss: 0.262, Validation Loss: 0.249\n",
      "Epoch: 6072, Train Loss: 0.292, Validation Loss: 0.250\n",
      "Epoch: 6073, Train Loss: 0.363, Validation Loss: 0.251\n",
      "Epoch: 6074, Train Loss: 0.172, Validation Loss: 0.256\n",
      "Epoch: 6075, Train Loss: 0.249, Validation Loss: 0.257\n",
      "Epoch: 6076, Train Loss: 0.402, Validation Loss: 0.252\n",
      "Epoch: 6077, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 6078, Train Loss: 0.166, Validation Loss: 0.253\n",
      "Epoch: 6079, Train Loss: 0.558, Validation Loss: 0.251\n",
      "Epoch: 6080, Train Loss: 0.291, Validation Loss: 0.250\n",
      "Epoch: 6081, Train Loss: 0.241, Validation Loss: 0.253\n",
      "Epoch: 6082, Train Loss: 0.348, Validation Loss: 0.250\n",
      "Epoch: 6083, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 6084, Train Loss: 0.528, Validation Loss: 0.254\n",
      "Epoch: 6085, Train Loss: 0.182, Validation Loss: 0.251\n",
      "Epoch: 6086, Train Loss: 0.370, Validation Loss: 0.252\n",
      "Epoch: 6087, Train Loss: 0.340, Validation Loss: 0.248\n",
      "Epoch: 6088, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 6089, Train Loss: 0.238, Validation Loss: 0.252\n",
      "Epoch: 6090, Train Loss: 0.273, Validation Loss: 0.250\n",
      "Epoch: 6091, Train Loss: 0.213, Validation Loss: 0.248\n",
      "Epoch: 6092, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 6093, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 6094, Train Loss: 0.153, Validation Loss: 0.252\n",
      "Epoch: 6095, Train Loss: 0.235, Validation Loss: 0.253\n",
      "Epoch: 6096, Train Loss: 0.323, Validation Loss: 0.255\n",
      "Epoch: 6097, Train Loss: 0.570, Validation Loss: 0.252\n",
      "Epoch: 6098, Train Loss: 0.216, Validation Loss: 0.250\n",
      "Epoch: 6099, Train Loss: 0.211, Validation Loss: 0.251\n",
      "Epoch: 6100, Train Loss: 0.247, Validation Loss: 0.251\n",
      "Epoch: 6101, Train Loss: 0.252, Validation Loss: 0.249\n",
      "Epoch: 6102, Train Loss: 0.209, Validation Loss: 0.249\n",
      "Epoch: 6103, Train Loss: 0.270, Validation Loss: 0.256\n",
      "Epoch: 6104, Train Loss: 0.239, Validation Loss: 0.255\n",
      "Epoch: 6105, Train Loss: 0.221, Validation Loss: 0.251\n",
      "Epoch: 6106, Train Loss: 0.181, Validation Loss: 0.254\n",
      "Epoch: 6107, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 6108, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 6109, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 6110, Train Loss: 0.274, Validation Loss: 0.249\n",
      "Epoch: 6111, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 6112, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 6113, Train Loss: 0.255, Validation Loss: 0.251\n",
      "Epoch: 6114, Train Loss: 0.431, Validation Loss: 0.257\n",
      "Epoch: 6115, Train Loss: 0.293, Validation Loss: 0.253\n",
      "Epoch: 6116, Train Loss: 0.328, Validation Loss: 0.251\n",
      "Epoch: 6117, Train Loss: 0.190, Validation Loss: 0.251\n",
      "Epoch: 6118, Train Loss: 0.203, Validation Loss: 0.251\n",
      "Epoch: 6119, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 6120, Train Loss: 0.204, Validation Loss: 0.251\n",
      "Epoch: 6121, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 6122, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 6123, Train Loss: 0.236, Validation Loss: 0.254\n",
      "Epoch: 6124, Train Loss: 0.206, Validation Loss: 0.255\n",
      "Epoch: 6125, Train Loss: 0.418, Validation Loss: 0.256\n",
      "Epoch: 6126, Train Loss: 0.209, Validation Loss: 0.256\n",
      "Epoch: 6127, Train Loss: 0.682, Validation Loss: 0.254\n",
      "Epoch: 6128, Train Loss: 0.289, Validation Loss: 0.251\n",
      "Epoch: 6129, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 6130, Train Loss: 0.427, Validation Loss: 0.250\n",
      "Epoch: 6131, Train Loss: 0.739, Validation Loss: 0.253\n",
      "Epoch: 6132, Train Loss: 0.319, Validation Loss: 0.249\n",
      "Epoch: 6133, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 6134, Train Loss: 0.379, Validation Loss: 0.249\n",
      "Epoch: 6135, Train Loss: 0.247, Validation Loss: 0.252\n",
      "Epoch: 6136, Train Loss: 0.305, Validation Loss: 0.253\n",
      "Epoch: 6137, Train Loss: 0.325, Validation Loss: 0.250\n",
      "Epoch: 6138, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 6139, Train Loss: 0.232, Validation Loss: 0.250\n",
      "Epoch: 6140, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 6141, Train Loss: 0.267, Validation Loss: 0.253\n",
      "Epoch: 6142, Train Loss: 0.192, Validation Loss: 0.250\n",
      "Epoch: 6143, Train Loss: 0.213, Validation Loss: 0.252\n",
      "Epoch: 6144, Train Loss: 0.234, Validation Loss: 0.250\n",
      "Epoch: 6145, Train Loss: 0.181, Validation Loss: 0.252\n",
      "Epoch: 6146, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 6147, Train Loss: 0.255, Validation Loss: 0.250\n",
      "Epoch: 6148, Train Loss: 0.167, Validation Loss: 0.251\n",
      "Epoch: 6149, Train Loss: 0.340, Validation Loss: 0.248\n",
      "Epoch: 6150, Train Loss: 0.255, Validation Loss: 0.248\n",
      "Epoch: 6151, Train Loss: 0.569, Validation Loss: 0.247\n",
      "Epoch: 6152, Train Loss: 0.204, Validation Loss: 0.249\n",
      "Epoch: 6153, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 6154, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 6155, Train Loss: 0.216, Validation Loss: 0.248\n",
      "Epoch: 6156, Train Loss: 0.264, Validation Loss: 0.256\n",
      "Epoch: 6157, Train Loss: 0.210, Validation Loss: 0.252\n",
      "Epoch: 6158, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 6159, Train Loss: 0.227, Validation Loss: 0.249\n",
      "Epoch: 6160, Train Loss: 0.217, Validation Loss: 0.248\n",
      "Epoch: 6161, Train Loss: 0.186, Validation Loss: 0.250\n",
      "Epoch: 6162, Train Loss: 0.395, Validation Loss: 0.245\n",
      "Epoch: 6163, Train Loss: 0.280, Validation Loss: 0.248\n",
      "Epoch: 6164, Train Loss: 0.182, Validation Loss: 0.251\n",
      "Epoch: 6165, Train Loss: 0.212, Validation Loss: 0.253\n",
      "Epoch: 6166, Train Loss: 0.224, Validation Loss: 0.251\n",
      "Epoch: 6167, Train Loss: 0.278, Validation Loss: 0.253\n",
      "Epoch: 6168, Train Loss: 0.227, Validation Loss: 0.249\n",
      "Epoch: 6169, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 6170, Train Loss: 0.334, Validation Loss: 0.249\n",
      "Epoch: 6171, Train Loss: 0.428, Validation Loss: 0.250\n",
      "Epoch: 6172, Train Loss: 0.271, Validation Loss: 0.254\n",
      "Epoch: 6173, Train Loss: 0.200, Validation Loss: 0.253\n",
      "Epoch: 6174, Train Loss: 0.256, Validation Loss: 0.249\n",
      "Epoch: 6175, Train Loss: 0.329, Validation Loss: 0.254\n",
      "Epoch: 6176, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 6177, Train Loss: 0.282, Validation Loss: 0.250\n",
      "Epoch: 6178, Train Loss: 0.188, Validation Loss: 0.249\n",
      "Epoch: 6179, Train Loss: 0.206, Validation Loss: 0.251\n",
      "Epoch: 6180, Train Loss: 0.281, Validation Loss: 0.252\n",
      "Epoch: 6181, Train Loss: 0.268, Validation Loss: 0.256\n",
      "Epoch: 6182, Train Loss: 0.207, Validation Loss: 0.257\n",
      "Epoch: 6183, Train Loss: 0.188, Validation Loss: 0.251\n",
      "Epoch: 6184, Train Loss: 0.183, Validation Loss: 0.253\n",
      "Epoch: 6185, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 6186, Train Loss: 0.619, Validation Loss: 0.255\n",
      "Epoch: 6187, Train Loss: 0.218, Validation Loss: 0.253\n",
      "Epoch: 6188, Train Loss: 0.393, Validation Loss: 0.256\n",
      "Epoch: 6189, Train Loss: 0.225, Validation Loss: 0.252\n",
      "Epoch: 6190, Train Loss: 0.225, Validation Loss: 0.250\n",
      "Epoch: 6191, Train Loss: 0.346, Validation Loss: 0.250\n",
      "Epoch: 6192, Train Loss: 0.265, Validation Loss: 0.252\n",
      "Epoch: 6193, Train Loss: 0.264, Validation Loss: 0.250\n",
      "Epoch: 6194, Train Loss: 0.255, Validation Loss: 0.251\n",
      "Epoch: 6195, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 6196, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 6197, Train Loss: 0.370, Validation Loss: 0.258\n",
      "Epoch: 6198, Train Loss: 0.526, Validation Loss: 0.249\n",
      "Epoch: 6199, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 6200, Train Loss: 0.388, Validation Loss: 0.250\n",
      "Epoch: 6201, Train Loss: 0.361, Validation Loss: 0.252\n",
      "Epoch: 6202, Train Loss: 0.233, Validation Loss: 0.254\n",
      "Epoch: 6203, Train Loss: 0.251, Validation Loss: 0.254\n",
      "Epoch: 6204, Train Loss: 0.236, Validation Loss: 0.251\n",
      "Epoch: 6205, Train Loss: 0.265, Validation Loss: 0.250\n",
      "Epoch: 6206, Train Loss: 0.339, Validation Loss: 0.252\n",
      "Epoch: 6207, Train Loss: 0.257, Validation Loss: 0.251\n",
      "Epoch: 6208, Train Loss: 0.273, Validation Loss: 0.251\n",
      "Epoch: 6209, Train Loss: 0.305, Validation Loss: 0.250\n",
      "Epoch: 6210, Train Loss: 0.171, Validation Loss: 0.250\n",
      "Epoch: 6211, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 6212, Train Loss: 0.220, Validation Loss: 0.253\n",
      "Epoch: 6213, Train Loss: 0.183, Validation Loss: 0.252\n",
      "Epoch: 6214, Train Loss: 0.251, Validation Loss: 0.255\n",
      "Epoch: 6215, Train Loss: 0.228, Validation Loss: 0.253\n",
      "Epoch: 6216, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 6217, Train Loss: 0.518, Validation Loss: 0.254\n",
      "Epoch: 6218, Train Loss: 0.188, Validation Loss: 0.250\n",
      "Epoch: 6219, Train Loss: 0.155, Validation Loss: 0.251\n",
      "Epoch: 6220, Train Loss: 0.429, Validation Loss: 0.252\n",
      "Epoch: 6221, Train Loss: 0.428, Validation Loss: 0.253\n",
      "Epoch: 6222, Train Loss: 0.562, Validation Loss: 0.253\n",
      "Epoch: 6223, Train Loss: 0.273, Validation Loss: 0.253\n",
      "Epoch: 6224, Train Loss: 0.208, Validation Loss: 0.249\n",
      "Epoch: 6225, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 6226, Train Loss: 0.199, Validation Loss: 0.250\n",
      "Epoch: 6227, Train Loss: 0.315, Validation Loss: 0.250\n",
      "Epoch: 6228, Train Loss: 0.208, Validation Loss: 0.252\n",
      "Epoch: 6229, Train Loss: 0.169, Validation Loss: 0.253\n",
      "Epoch: 6230, Train Loss: 0.288, Validation Loss: 0.253\n",
      "Epoch: 6231, Train Loss: 0.281, Validation Loss: 0.254\n",
      "Epoch: 6232, Train Loss: 0.226, Validation Loss: 0.253\n",
      "Epoch: 6233, Train Loss: 0.329, Validation Loss: 0.248\n",
      "Epoch: 6234, Train Loss: 0.347, Validation Loss: 0.249\n",
      "Epoch: 6235, Train Loss: 0.584, Validation Loss: 0.255\n",
      "Epoch: 6236, Train Loss: 0.252, Validation Loss: 0.253\n",
      "Epoch: 6237, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 6238, Train Loss: 0.211, Validation Loss: 0.250\n",
      "Epoch: 6239, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 6240, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 6241, Train Loss: 0.375, Validation Loss: 0.252\n",
      "Epoch: 6242, Train Loss: 0.205, Validation Loss: 0.254\n",
      "Epoch: 6243, Train Loss: 0.407, Validation Loss: 0.252\n",
      "Epoch: 6244, Train Loss: 0.279, Validation Loss: 0.250\n",
      "Epoch: 6245, Train Loss: 0.196, Validation Loss: 0.251\n",
      "Epoch: 6246, Train Loss: 0.333, Validation Loss: 0.251\n",
      "Epoch: 6247, Train Loss: 0.263, Validation Loss: 0.251\n",
      "Epoch: 6248, Train Loss: 0.345, Validation Loss: 0.259\n",
      "Epoch: 6249, Train Loss: 0.292, Validation Loss: 0.253\n",
      "Epoch: 6250, Train Loss: 0.285, Validation Loss: 0.250\n",
      "Epoch: 6251, Train Loss: 0.235, Validation Loss: 0.250\n",
      "Epoch: 6252, Train Loss: 0.257, Validation Loss: 0.253\n",
      "Epoch: 6253, Train Loss: 0.182, Validation Loss: 0.255\n",
      "Epoch: 6254, Train Loss: 0.267, Validation Loss: 0.254\n",
      "Epoch: 6255, Train Loss: 0.217, Validation Loss: 0.252\n",
      "Epoch: 6256, Train Loss: 0.184, Validation Loss: 0.248\n",
      "Epoch: 6257, Train Loss: 0.324, Validation Loss: 0.247\n",
      "Epoch: 6258, Train Loss: 0.273, Validation Loss: 0.249\n",
      "Epoch: 6259, Train Loss: 0.324, Validation Loss: 0.250\n",
      "Epoch: 6260, Train Loss: 0.565, Validation Loss: 0.249\n",
      "Epoch: 6261, Train Loss: 0.271, Validation Loss: 0.253\n",
      "Epoch: 6262, Train Loss: 0.184, Validation Loss: 0.253\n",
      "Epoch: 6263, Train Loss: 0.218, Validation Loss: 0.250\n",
      "Epoch: 6264, Train Loss: 0.252, Validation Loss: 0.248\n",
      "Epoch: 6265, Train Loss: 0.224, Validation Loss: 0.249\n",
      "Epoch: 6266, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 6267, Train Loss: 0.185, Validation Loss: 0.254\n",
      "Epoch: 6268, Train Loss: 0.252, Validation Loss: 0.254\n",
      "Epoch: 6269, Train Loss: 0.327, Validation Loss: 0.254\n",
      "Epoch: 6270, Train Loss: 0.441, Validation Loss: 0.250\n",
      "Epoch: 6271, Train Loss: 0.284, Validation Loss: 0.251\n",
      "Epoch: 6272, Train Loss: 0.252, Validation Loss: 0.249\n",
      "Epoch: 6273, Train Loss: 0.541, Validation Loss: 0.253\n",
      "Epoch: 6274, Train Loss: 0.429, Validation Loss: 0.252\n",
      "Epoch: 6275, Train Loss: 0.328, Validation Loss: 0.249\n",
      "Epoch: 6276, Train Loss: 0.194, Validation Loss: 0.254\n",
      "Epoch: 6277, Train Loss: 0.190, Validation Loss: 0.254\n",
      "Epoch: 6278, Train Loss: 0.232, Validation Loss: 0.252\n",
      "Epoch: 6279, Train Loss: 0.443, Validation Loss: 0.250\n",
      "Epoch: 6280, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 6281, Train Loss: 0.199, Validation Loss: 0.253\n",
      "Epoch: 6282, Train Loss: 0.192, Validation Loss: 0.252\n",
      "Epoch: 6283, Train Loss: 0.280, Validation Loss: 0.252\n",
      "Epoch: 6284, Train Loss: 0.221, Validation Loss: 0.255\n",
      "Epoch: 6285, Train Loss: 0.208, Validation Loss: 0.256\n",
      "Epoch: 6286, Train Loss: 0.352, Validation Loss: 0.251\n",
      "Epoch: 6287, Train Loss: 0.493, Validation Loss: 0.256\n",
      "Epoch: 6288, Train Loss: 0.385, Validation Loss: 0.254\n",
      "Epoch: 6289, Train Loss: 0.249, Validation Loss: 0.257\n",
      "Epoch: 6290, Train Loss: 0.310, Validation Loss: 0.251\n",
      "Epoch: 6291, Train Loss: 0.192, Validation Loss: 0.259\n",
      "Epoch: 6292, Train Loss: 0.207, Validation Loss: 0.258\n",
      "Epoch: 6293, Train Loss: 0.238, Validation Loss: 0.254\n",
      "Epoch: 6294, Train Loss: 0.223, Validation Loss: 0.259\n",
      "Epoch: 6295, Train Loss: 0.176, Validation Loss: 0.257\n",
      "Epoch: 6296, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 6297, Train Loss: 0.290, Validation Loss: 0.255\n",
      "Epoch: 6298, Train Loss: 0.180, Validation Loss: 0.252\n",
      "Epoch: 6299, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 6300, Train Loss: 0.302, Validation Loss: 0.251\n",
      "Epoch: 6301, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 6302, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 6303, Train Loss: 0.308, Validation Loss: 0.251\n",
      "Epoch: 6304, Train Loss: 0.251, Validation Loss: 0.253\n",
      "Epoch: 6305, Train Loss: 0.267, Validation Loss: 0.256\n",
      "Epoch: 6306, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 6307, Train Loss: 0.166, Validation Loss: 0.250\n",
      "Epoch: 6308, Train Loss: 0.202, Validation Loss: 0.247\n",
      "Epoch: 6309, Train Loss: 0.353, Validation Loss: 0.256\n",
      "Epoch: 6310, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 6311, Train Loss: 0.204, Validation Loss: 0.254\n",
      "Epoch: 6312, Train Loss: 0.300, Validation Loss: 0.249\n",
      "Epoch: 6313, Train Loss: 0.217, Validation Loss: 0.252\n",
      "Epoch: 6314, Train Loss: 0.180, Validation Loss: 0.252\n",
      "Epoch: 6315, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 6316, Train Loss: 0.185, Validation Loss: 0.250\n",
      "Epoch: 6317, Train Loss: 0.190, Validation Loss: 0.251\n",
      "Epoch: 6318, Train Loss: 0.302, Validation Loss: 0.250\n",
      "Epoch: 6319, Train Loss: 0.254, Validation Loss: 0.251\n",
      "Epoch: 6320, Train Loss: 0.250, Validation Loss: 0.252\n",
      "Epoch: 6321, Train Loss: 0.439, Validation Loss: 0.250\n",
      "Epoch: 6322, Train Loss: 0.410, Validation Loss: 0.250\n",
      "Epoch: 6323, Train Loss: 0.706, Validation Loss: 0.255\n",
      "Epoch: 6324, Train Loss: 0.250, Validation Loss: 0.252\n",
      "Epoch: 6325, Train Loss: 0.178, Validation Loss: 0.250\n",
      "Epoch: 6326, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 6327, Train Loss: 0.275, Validation Loss: 0.251\n",
      "Epoch: 6328, Train Loss: 0.279, Validation Loss: 0.252\n",
      "Epoch: 6329, Train Loss: 0.280, Validation Loss: 0.252\n",
      "Epoch: 6330, Train Loss: 0.224, Validation Loss: 0.249\n",
      "Epoch: 6331, Train Loss: 0.329, Validation Loss: 0.255\n",
      "Epoch: 6332, Train Loss: 0.191, Validation Loss: 0.254\n",
      "Epoch: 6333, Train Loss: 0.158, Validation Loss: 0.252\n",
      "Epoch: 6334, Train Loss: 0.236, Validation Loss: 0.256\n",
      "Epoch: 6335, Train Loss: 0.176, Validation Loss: 0.258\n",
      "Epoch: 6336, Train Loss: 0.233, Validation Loss: 0.257\n",
      "Epoch: 6337, Train Loss: 0.323, Validation Loss: 0.249\n",
      "Epoch: 6338, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 6339, Train Loss: 0.322, Validation Loss: 0.249\n",
      "Epoch: 6340, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 6341, Train Loss: 0.166, Validation Loss: 0.249\n",
      "Epoch: 6342, Train Loss: 0.278, Validation Loss: 0.252\n",
      "Epoch: 6343, Train Loss: 0.393, Validation Loss: 0.257\n",
      "Epoch: 6344, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 6345, Train Loss: 0.268, Validation Loss: 0.253\n",
      "Epoch: 6346, Train Loss: 0.425, Validation Loss: 0.255\n",
      "Epoch: 6347, Train Loss: 0.265, Validation Loss: 0.256\n",
      "Epoch: 6348, Train Loss: 0.242, Validation Loss: 0.255\n",
      "Epoch: 6349, Train Loss: 0.245, Validation Loss: 0.254\n",
      "Epoch: 6350, Train Loss: 0.247, Validation Loss: 0.255\n",
      "Epoch: 6351, Train Loss: 0.366, Validation Loss: 0.255\n",
      "Epoch: 6352, Train Loss: 0.379, Validation Loss: 0.252\n",
      "Epoch: 6353, Train Loss: 0.277, Validation Loss: 0.253\n",
      "Epoch: 6354, Train Loss: 0.338, Validation Loss: 0.256\n",
      "Epoch: 6355, Train Loss: 0.425, Validation Loss: 0.251\n",
      "Epoch: 6356, Train Loss: 0.178, Validation Loss: 0.251\n",
      "Epoch: 6357, Train Loss: 0.227, Validation Loss: 0.255\n",
      "Epoch: 6358, Train Loss: 0.271, Validation Loss: 0.254\n",
      "Epoch: 6359, Train Loss: 0.205, Validation Loss: 0.257\n",
      "Epoch: 6360, Train Loss: 0.285, Validation Loss: 0.256\n",
      "Epoch: 6361, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 6362, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 6363, Train Loss: 0.204, Validation Loss: 0.253\n",
      "Epoch: 6364, Train Loss: 0.268, Validation Loss: 0.254\n",
      "Epoch: 6365, Train Loss: 0.185, Validation Loss: 0.253\n",
      "Epoch: 6366, Train Loss: 0.228, Validation Loss: 0.252\n",
      "Epoch: 6367, Train Loss: 0.365, Validation Loss: 0.251\n",
      "Epoch: 6368, Train Loss: 0.248, Validation Loss: 0.258\n",
      "Epoch: 6369, Train Loss: 0.326, Validation Loss: 0.255\n",
      "Epoch: 6370, Train Loss: 0.179, Validation Loss: 0.256\n",
      "Epoch: 6371, Train Loss: 0.259, Validation Loss: 0.258\n",
      "Epoch: 6372, Train Loss: 0.331, Validation Loss: 0.254\n",
      "Epoch: 6373, Train Loss: 0.340, Validation Loss: 0.259\n",
      "Epoch: 6374, Train Loss: 0.645, Validation Loss: 0.252\n",
      "Epoch: 6375, Train Loss: 0.283, Validation Loss: 0.250\n",
      "Epoch: 6376, Train Loss: 0.153, Validation Loss: 0.250\n",
      "Epoch: 6377, Train Loss: 0.219, Validation Loss: 0.248\n",
      "Epoch: 6378, Train Loss: 0.216, Validation Loss: 0.249\n",
      "Epoch: 6379, Train Loss: 0.370, Validation Loss: 0.250\n",
      "Epoch: 6380, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 6381, Train Loss: 0.350, Validation Loss: 0.257\n",
      "Epoch: 6382, Train Loss: 0.243, Validation Loss: 0.249\n",
      "Epoch: 6383, Train Loss: 0.334, Validation Loss: 0.248\n",
      "Epoch: 6384, Train Loss: 0.206, Validation Loss: 0.255\n",
      "Epoch: 6385, Train Loss: 0.213, Validation Loss: 0.253\n",
      "Epoch: 6386, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 6387, Train Loss: 0.197, Validation Loss: 0.253\n",
      "Epoch: 6388, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 6389, Train Loss: 0.230, Validation Loss: 0.250\n",
      "Epoch: 6390, Train Loss: 0.284, Validation Loss: 0.250\n",
      "Epoch: 6391, Train Loss: 0.276, Validation Loss: 0.252\n",
      "Epoch: 6392, Train Loss: 0.261, Validation Loss: 0.251\n",
      "Epoch: 6393, Train Loss: 0.191, Validation Loss: 0.251\n",
      "Epoch: 6394, Train Loss: 0.286, Validation Loss: 0.249\n",
      "Epoch: 6395, Train Loss: 0.200, Validation Loss: 0.250\n",
      "Epoch: 6396, Train Loss: 0.334, Validation Loss: 0.251\n",
      "Epoch: 6397, Train Loss: 0.247, Validation Loss: 0.255\n",
      "Epoch: 6398, Train Loss: 0.175, Validation Loss: 0.257\n",
      "Epoch: 6399, Train Loss: 0.166, Validation Loss: 0.252\n",
      "Epoch: 6400, Train Loss: 0.241, Validation Loss: 0.251\n",
      "Epoch: 6401, Train Loss: 0.358, Validation Loss: 0.252\n",
      "Epoch: 6402, Train Loss: 0.334, Validation Loss: 0.250\n",
      "Epoch: 6403, Train Loss: 0.273, Validation Loss: 0.254\n",
      "Epoch: 6404, Train Loss: 0.508, Validation Loss: 0.253\n",
      "Epoch: 6405, Train Loss: 0.270, Validation Loss: 0.250\n",
      "Epoch: 6406, Train Loss: 0.363, Validation Loss: 0.249\n",
      "Epoch: 6407, Train Loss: 0.194, Validation Loss: 0.247\n",
      "Epoch: 6408, Train Loss: 0.194, Validation Loss: 0.252\n",
      "Epoch: 6409, Train Loss: 0.209, Validation Loss: 0.251\n",
      "Epoch: 6410, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 6411, Train Loss: 0.178, Validation Loss: 0.250\n",
      "Epoch: 6412, Train Loss: 0.284, Validation Loss: 0.251\n",
      "Epoch: 6413, Train Loss: 0.235, Validation Loss: 0.248\n",
      "Epoch: 6414, Train Loss: 0.335, Validation Loss: 0.250\n",
      "Epoch: 6415, Train Loss: 0.172, Validation Loss: 0.249\n",
      "Epoch: 6416, Train Loss: 0.188, Validation Loss: 0.247\n",
      "Epoch: 6417, Train Loss: 0.337, Validation Loss: 0.254\n",
      "Epoch: 6418, Train Loss: 0.313, Validation Loss: 0.255\n",
      "Epoch: 6419, Train Loss: 0.373, Validation Loss: 0.247\n",
      "Epoch: 6420, Train Loss: 0.359, Validation Loss: 0.246\n",
      "Epoch: 6421, Train Loss: 0.252, Validation Loss: 0.246\n",
      "Epoch: 6422, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 6423, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 6424, Train Loss: 0.189, Validation Loss: 0.250\n",
      "Epoch: 6425, Train Loss: 0.239, Validation Loss: 0.247\n",
      "Epoch: 6426, Train Loss: 0.279, Validation Loss: 0.247\n",
      "Epoch: 6427, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 6428, Train Loss: 0.227, Validation Loss: 0.249\n",
      "Epoch: 6429, Train Loss: 0.372, Validation Loss: 0.247\n",
      "Epoch: 6430, Train Loss: 0.487, Validation Loss: 0.248\n",
      "Epoch: 6431, Train Loss: 0.152, Validation Loss: 0.249\n",
      "Epoch: 6432, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 6433, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 6434, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 6435, Train Loss: 0.181, Validation Loss: 0.251\n",
      "Epoch: 6436, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 6437, Train Loss: 0.193, Validation Loss: 0.255\n",
      "Epoch: 6438, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 6439, Train Loss: 0.239, Validation Loss: 0.251\n",
      "Epoch: 6440, Train Loss: 0.202, Validation Loss: 0.248\n",
      "Epoch: 6441, Train Loss: 0.251, Validation Loss: 0.248\n",
      "Epoch: 6442, Train Loss: 0.244, Validation Loss: 0.248\n",
      "Epoch: 6443, Train Loss: 0.277, Validation Loss: 0.250\n",
      "Epoch: 6444, Train Loss: 0.221, Validation Loss: 0.248\n",
      "Epoch: 6445, Train Loss: 0.340, Validation Loss: 0.248\n",
      "Epoch: 6446, Train Loss: 0.176, Validation Loss: 0.252\n",
      "Epoch: 6447, Train Loss: 0.266, Validation Loss: 0.251\n",
      "Epoch: 6448, Train Loss: 0.293, Validation Loss: 0.251\n",
      "Epoch: 6449, Train Loss: 0.312, Validation Loss: 0.252\n",
      "Epoch: 6450, Train Loss: 0.200, Validation Loss: 0.251\n",
      "Epoch: 6451, Train Loss: 0.251, Validation Loss: 0.249\n",
      "Epoch: 6452, Train Loss: 0.192, Validation Loss: 0.252\n",
      "Epoch: 6453, Train Loss: 0.195, Validation Loss: 0.255\n",
      "Epoch: 6454, Train Loss: 0.247, Validation Loss: 0.253\n",
      "Epoch: 6455, Train Loss: 0.231, Validation Loss: 0.250\n",
      "Epoch: 6456, Train Loss: 0.236, Validation Loss: 0.248\n",
      "Epoch: 6457, Train Loss: 0.235, Validation Loss: 0.250\n",
      "Epoch: 6458, Train Loss: 0.258, Validation Loss: 0.251\n",
      "Epoch: 6459, Train Loss: 0.269, Validation Loss: 0.250\n",
      "Epoch: 6460, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 6461, Train Loss: 0.173, Validation Loss: 0.253\n",
      "Epoch: 6462, Train Loss: 0.290, Validation Loss: 0.253\n",
      "Epoch: 6463, Train Loss: 0.194, Validation Loss: 0.252\n",
      "Epoch: 6464, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 6465, Train Loss: 0.520, Validation Loss: 0.251\n",
      "Epoch: 6466, Train Loss: 0.174, Validation Loss: 0.248\n",
      "Epoch: 6467, Train Loss: 0.375, Validation Loss: 0.252\n",
      "Epoch: 6468, Train Loss: 0.529, Validation Loss: 0.248\n",
      "Epoch: 6469, Train Loss: 0.191, Validation Loss: 0.249\n",
      "Epoch: 6470, Train Loss: 0.405, Validation Loss: 0.254\n",
      "Epoch: 6471, Train Loss: 0.316, Validation Loss: 0.249\n",
      "Epoch: 6472, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 6473, Train Loss: 0.273, Validation Loss: 0.252\n",
      "Epoch: 6474, Train Loss: 0.415, Validation Loss: 0.248\n",
      "Epoch: 6475, Train Loss: 0.208, Validation Loss: 0.247\n",
      "Epoch: 6476, Train Loss: 0.235, Validation Loss: 0.248\n",
      "Epoch: 6477, Train Loss: 0.282, Validation Loss: 0.254\n",
      "Epoch: 6478, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 6479, Train Loss: 0.224, Validation Loss: 0.252\n",
      "Epoch: 6480, Train Loss: 0.263, Validation Loss: 0.253\n",
      "Epoch: 6481, Train Loss: 0.484, Validation Loss: 0.254\n",
      "Epoch: 6482, Train Loss: 0.305, Validation Loss: 0.248\n",
      "Epoch: 6483, Train Loss: 0.273, Validation Loss: 0.252\n",
      "Epoch: 6484, Train Loss: 0.206, Validation Loss: 0.252\n",
      "Epoch: 6485, Train Loss: 0.375, Validation Loss: 0.250\n",
      "Epoch: 6486, Train Loss: 0.275, Validation Loss: 0.251\n",
      "Epoch: 6487, Train Loss: 0.308, Validation Loss: 0.254\n",
      "Epoch: 6488, Train Loss: 0.508, Validation Loss: 0.253\n",
      "Epoch: 6489, Train Loss: 0.343, Validation Loss: 0.249\n",
      "Epoch: 6490, Train Loss: 0.253, Validation Loss: 0.249\n",
      "Epoch: 6491, Train Loss: 0.284, Validation Loss: 0.251\n",
      "Epoch: 6492, Train Loss: 0.321, Validation Loss: 0.252\n",
      "Epoch: 6493, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 6494, Train Loss: 0.303, Validation Loss: 0.249\n",
      "Epoch: 6495, Train Loss: 0.276, Validation Loss: 0.250\n",
      "Epoch: 6496, Train Loss: 0.236, Validation Loss: 0.252\n",
      "Epoch: 6497, Train Loss: 0.191, Validation Loss: 0.255\n",
      "Epoch: 6498, Train Loss: 0.309, Validation Loss: 0.257\n",
      "Epoch: 6499, Train Loss: 0.325, Validation Loss: 0.254\n",
      "Epoch: 6500, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 6501, Train Loss: 0.286, Validation Loss: 0.252\n",
      "Epoch: 6502, Train Loss: 0.265, Validation Loss: 0.250\n",
      "Epoch: 6503, Train Loss: 0.247, Validation Loss: 0.252\n",
      "Epoch: 6504, Train Loss: 0.300, Validation Loss: 0.248\n",
      "Epoch: 6505, Train Loss: 0.324, Validation Loss: 0.248\n",
      "Epoch: 6506, Train Loss: 0.193, Validation Loss: 0.255\n",
      "Epoch: 6507, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 6508, Train Loss: 0.212, Validation Loss: 0.251\n",
      "Epoch: 6509, Train Loss: 0.338, Validation Loss: 0.254\n",
      "Epoch: 6510, Train Loss: 0.198, Validation Loss: 0.250\n",
      "Epoch: 6511, Train Loss: 0.194, Validation Loss: 0.251\n",
      "Epoch: 6512, Train Loss: 0.286, Validation Loss: 0.253\n",
      "Epoch: 6513, Train Loss: 0.408, Validation Loss: 0.254\n",
      "Epoch: 6514, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 6515, Train Loss: 0.202, Validation Loss: 0.248\n",
      "Epoch: 6516, Train Loss: 0.245, Validation Loss: 0.248\n",
      "Epoch: 6517, Train Loss: 0.451, Validation Loss: 0.253\n",
      "Epoch: 6518, Train Loss: 0.460, Validation Loss: 0.252\n",
      "Epoch: 6519, Train Loss: 0.399, Validation Loss: 0.250\n",
      "Epoch: 6520, Train Loss: 0.250, Validation Loss: 0.248\n",
      "Epoch: 6521, Train Loss: 0.455, Validation Loss: 0.249\n",
      "Epoch: 6522, Train Loss: 0.276, Validation Loss: 0.246\n",
      "Epoch: 6523, Train Loss: 0.263, Validation Loss: 0.249\n",
      "Epoch: 6524, Train Loss: 0.188, Validation Loss: 0.250\n",
      "Epoch: 6525, Train Loss: 0.204, Validation Loss: 0.249\n",
      "Epoch: 6526, Train Loss: 0.245, Validation Loss: 0.250\n",
      "Epoch: 6527, Train Loss: 0.230, Validation Loss: 0.255\n",
      "Epoch: 6528, Train Loss: 0.282, Validation Loss: 0.251\n",
      "Epoch: 6529, Train Loss: 0.245, Validation Loss: 0.248\n",
      "Epoch: 6530, Train Loss: 0.190, Validation Loss: 0.250\n",
      "Epoch: 6531, Train Loss: 0.204, Validation Loss: 0.253\n",
      "Epoch: 6532, Train Loss: 0.186, Validation Loss: 0.254\n",
      "Epoch: 6533, Train Loss: 0.183, Validation Loss: 0.253\n",
      "Epoch: 6534, Train Loss: 0.195, Validation Loss: 0.251\n",
      "Epoch: 6535, Train Loss: 0.324, Validation Loss: 0.248\n",
      "Epoch: 6536, Train Loss: 0.187, Validation Loss: 0.250\n",
      "Epoch: 6537, Train Loss: 0.276, Validation Loss: 0.250\n",
      "Epoch: 6538, Train Loss: 0.228, Validation Loss: 0.254\n",
      "Epoch: 6539, Train Loss: 0.415, Validation Loss: 0.255\n",
      "Epoch: 6540, Train Loss: 0.259, Validation Loss: 0.255\n",
      "Epoch: 6541, Train Loss: 0.398, Validation Loss: 0.257\n",
      "Epoch: 6542, Train Loss: 0.394, Validation Loss: 0.251\n",
      "Epoch: 6543, Train Loss: 0.320, Validation Loss: 0.252\n",
      "Epoch: 6544, Train Loss: 0.207, Validation Loss: 0.252\n",
      "Epoch: 6545, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 6546, Train Loss: 0.235, Validation Loss: 0.250\n",
      "Epoch: 6547, Train Loss: 0.238, Validation Loss: 0.251\n",
      "Epoch: 6548, Train Loss: 0.236, Validation Loss: 0.249\n",
      "Epoch: 6549, Train Loss: 0.232, Validation Loss: 0.248\n",
      "Epoch: 6550, Train Loss: 0.186, Validation Loss: 0.250\n",
      "Epoch: 6551, Train Loss: 0.248, Validation Loss: 0.248\n",
      "Epoch: 6552, Train Loss: 0.170, Validation Loss: 0.252\n",
      "Epoch: 6553, Train Loss: 0.311, Validation Loss: 0.249\n",
      "Epoch: 6554, Train Loss: 0.461, Validation Loss: 0.249\n",
      "Epoch: 6555, Train Loss: 0.276, Validation Loss: 0.256\n",
      "Epoch: 6556, Train Loss: 0.284, Validation Loss: 0.255\n",
      "Epoch: 6557, Train Loss: 0.262, Validation Loss: 0.253\n",
      "Epoch: 6558, Train Loss: 0.516, Validation Loss: 0.252\n",
      "Epoch: 6559, Train Loss: 0.278, Validation Loss: 0.252\n",
      "Epoch: 6560, Train Loss: 0.385, Validation Loss: 0.250\n",
      "Epoch: 6561, Train Loss: 0.194, Validation Loss: 0.250\n",
      "Epoch: 6562, Train Loss: 0.307, Validation Loss: 0.250\n",
      "Epoch: 6563, Train Loss: 0.435, Validation Loss: 0.252\n",
      "Epoch: 6564, Train Loss: 0.246, Validation Loss: 0.251\n",
      "Epoch: 6565, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 6566, Train Loss: 0.268, Validation Loss: 0.249\n",
      "Epoch: 6567, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 6568, Train Loss: 0.228, Validation Loss: 0.251\n",
      "Epoch: 6569, Train Loss: 0.312, Validation Loss: 0.254\n",
      "Epoch: 6570, Train Loss: 0.191, Validation Loss: 0.251\n",
      "Epoch: 6571, Train Loss: 0.392, Validation Loss: 0.250\n",
      "Epoch: 6572, Train Loss: 0.195, Validation Loss: 0.254\n",
      "Epoch: 6573, Train Loss: 0.286, Validation Loss: 0.257\n",
      "Epoch: 6574, Train Loss: 0.286, Validation Loss: 0.252\n",
      "Epoch: 6575, Train Loss: 0.250, Validation Loss: 0.255\n",
      "Epoch: 6576, Train Loss: 0.223, Validation Loss: 0.253\n",
      "Epoch: 6577, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 6578, Train Loss: 0.216, Validation Loss: 0.254\n",
      "Epoch: 6579, Train Loss: 0.378, Validation Loss: 0.251\n",
      "Epoch: 6580, Train Loss: 0.267, Validation Loss: 0.250\n",
      "Epoch: 6581, Train Loss: 0.186, Validation Loss: 0.257\n",
      "Epoch: 6582, Train Loss: 0.272, Validation Loss: 0.253\n",
      "Epoch: 6583, Train Loss: 0.286, Validation Loss: 0.253\n",
      "Epoch: 6584, Train Loss: 0.273, Validation Loss: 0.252\n",
      "Epoch: 6585, Train Loss: 0.196, Validation Loss: 0.255\n",
      "Epoch: 6586, Train Loss: 0.435, Validation Loss: 0.250\n",
      "Epoch: 6587, Train Loss: 0.202, Validation Loss: 0.250\n",
      "Epoch: 6588, Train Loss: 0.459, Validation Loss: 0.249\n",
      "Epoch: 6589, Train Loss: 0.254, Validation Loss: 0.248\n",
      "Epoch: 6590, Train Loss: 0.250, Validation Loss: 0.254\n",
      "Epoch: 6591, Train Loss: 0.288, Validation Loss: 0.258\n",
      "Epoch: 6592, Train Loss: 0.502, Validation Loss: 0.249\n",
      "Epoch: 6593, Train Loss: 0.234, Validation Loss: 0.247\n",
      "Epoch: 6594, Train Loss: 0.294, Validation Loss: 0.251\n",
      "Epoch: 6595, Train Loss: 0.196, Validation Loss: 0.251\n",
      "Epoch: 6596, Train Loss: 0.224, Validation Loss: 0.252\n",
      "Epoch: 6597, Train Loss: 0.347, Validation Loss: 0.251\n",
      "Epoch: 6598, Train Loss: 0.192, Validation Loss: 0.249\n",
      "Epoch: 6599, Train Loss: 0.262, Validation Loss: 0.251\n",
      "Epoch: 6600, Train Loss: 0.306, Validation Loss: 0.256\n",
      "Epoch: 6601, Train Loss: 0.290, Validation Loss: 0.248\n",
      "Epoch: 6602, Train Loss: 0.207, Validation Loss: 0.250\n",
      "Epoch: 6603, Train Loss: 0.183, Validation Loss: 0.249\n",
      "Epoch: 6604, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 6605, Train Loss: 0.296, Validation Loss: 0.255\n",
      "Epoch: 6606, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 6607, Train Loss: 0.150, Validation Loss: 0.251\n",
      "Epoch: 6608, Train Loss: 0.309, Validation Loss: 0.253\n",
      "Epoch: 6609, Train Loss: 0.283, Validation Loss: 0.254\n",
      "Epoch: 6610, Train Loss: 0.161, Validation Loss: 0.254\n",
      "Epoch: 6611, Train Loss: 0.219, Validation Loss: 0.251\n",
      "Epoch: 6612, Train Loss: 0.235, Validation Loss: 0.255\n",
      "Epoch: 6613, Train Loss: 0.303, Validation Loss: 0.251\n",
      "Epoch: 6614, Train Loss: 0.197, Validation Loss: 0.254\n",
      "Epoch: 6615, Train Loss: 0.197, Validation Loss: 0.256\n",
      "Epoch: 6616, Train Loss: 0.269, Validation Loss: 0.253\n",
      "Epoch: 6617, Train Loss: 0.283, Validation Loss: 0.252\n",
      "Epoch: 6618, Train Loss: 0.309, Validation Loss: 0.251\n",
      "Epoch: 6619, Train Loss: 0.224, Validation Loss: 0.253\n",
      "Epoch: 6620, Train Loss: 0.391, Validation Loss: 0.252\n",
      "Epoch: 6621, Train Loss: 0.220, Validation Loss: 0.253\n",
      "Epoch: 6622, Train Loss: 0.261, Validation Loss: 0.251\n",
      "Epoch: 6623, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 6624, Train Loss: 0.296, Validation Loss: 0.250\n",
      "Epoch: 6625, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 6626, Train Loss: 0.266, Validation Loss: 0.253\n",
      "Epoch: 6627, Train Loss: 0.161, Validation Loss: 0.257\n",
      "Epoch: 6628, Train Loss: 0.251, Validation Loss: 0.254\n",
      "Epoch: 6629, Train Loss: 0.376, Validation Loss: 0.253\n",
      "Epoch: 6630, Train Loss: 0.375, Validation Loss: 0.253\n",
      "Epoch: 6631, Train Loss: 0.178, Validation Loss: 0.255\n",
      "Epoch: 6632, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 6633, Train Loss: 0.203, Validation Loss: 0.252\n",
      "Epoch: 6634, Train Loss: 0.306, Validation Loss: 0.254\n",
      "Epoch: 6635, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 6636, Train Loss: 0.343, Validation Loss: 0.253\n",
      "Epoch: 6637, Train Loss: 0.319, Validation Loss: 0.257\n",
      "Epoch: 6638, Train Loss: 0.300, Validation Loss: 0.256\n",
      "Epoch: 6639, Train Loss: 0.219, Validation Loss: 0.255\n",
      "Epoch: 6640, Train Loss: 0.392, Validation Loss: 0.252\n",
      "Epoch: 6641, Train Loss: 0.496, Validation Loss: 0.257\n",
      "Epoch: 6642, Train Loss: 0.397, Validation Loss: 0.252\n",
      "Epoch: 6643, Train Loss: 0.209, Validation Loss: 0.253\n",
      "Epoch: 6644, Train Loss: 0.337, Validation Loss: 0.250\n",
      "Epoch: 6645, Train Loss: 0.292, Validation Loss: 0.252\n",
      "Epoch: 6646, Train Loss: 0.424, Validation Loss: 0.252\n",
      "Epoch: 6647, Train Loss: 0.225, Validation Loss: 0.253\n",
      "Epoch: 6648, Train Loss: 0.234, Validation Loss: 0.257\n",
      "Epoch: 6649, Train Loss: 0.237, Validation Loss: 0.255\n",
      "Epoch: 6650, Train Loss: 0.171, Validation Loss: 0.251\n",
      "Epoch: 6651, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 6652, Train Loss: 0.203, Validation Loss: 0.252\n",
      "Epoch: 6653, Train Loss: 0.204, Validation Loss: 0.252\n",
      "Epoch: 6654, Train Loss: 0.274, Validation Loss: 0.252\n",
      "Epoch: 6655, Train Loss: 0.264, Validation Loss: 0.256\n",
      "Epoch: 6656, Train Loss: 0.312, Validation Loss: 0.254\n",
      "Epoch: 6657, Train Loss: 0.212, Validation Loss: 0.258\n",
      "Epoch: 6658, Train Loss: 0.255, Validation Loss: 0.257\n",
      "Epoch: 6659, Train Loss: 0.170, Validation Loss: 0.252\n",
      "Epoch: 6660, Train Loss: 0.268, Validation Loss: 0.251\n",
      "Epoch: 6661, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 6662, Train Loss: 0.337, Validation Loss: 0.255\n",
      "Epoch: 6663, Train Loss: 0.240, Validation Loss: 0.250\n",
      "Epoch: 6664, Train Loss: 0.202, Validation Loss: 0.252\n",
      "Epoch: 6665, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 6666, Train Loss: 0.232, Validation Loss: 0.255\n",
      "Epoch: 6667, Train Loss: 0.397, Validation Loss: 0.250\n",
      "Epoch: 6668, Train Loss: 0.273, Validation Loss: 0.254\n",
      "Epoch: 6669, Train Loss: 0.245, Validation Loss: 0.256\n",
      "Epoch: 6670, Train Loss: 0.201, Validation Loss: 0.257\n",
      "Epoch: 6671, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 6672, Train Loss: 0.195, Validation Loss: 0.250\n",
      "Epoch: 6673, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 6674, Train Loss: 0.213, Validation Loss: 0.257\n",
      "Epoch: 6675, Train Loss: 0.226, Validation Loss: 0.258\n",
      "Epoch: 6676, Train Loss: 0.433, Validation Loss: 0.251\n",
      "Epoch: 6677, Train Loss: 0.466, Validation Loss: 0.253\n",
      "Epoch: 6678, Train Loss: 0.243, Validation Loss: 0.251\n",
      "Epoch: 6679, Train Loss: 0.335, Validation Loss: 0.249\n",
      "Epoch: 6680, Train Loss: 0.280, Validation Loss: 0.253\n",
      "Epoch: 6681, Train Loss: 0.195, Validation Loss: 0.254\n",
      "Epoch: 6682, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 6683, Train Loss: 0.405, Validation Loss: 0.250\n",
      "Epoch: 6684, Train Loss: 0.281, Validation Loss: 0.254\n",
      "Epoch: 6685, Train Loss: 0.285, Validation Loss: 0.249\n",
      "Epoch: 6686, Train Loss: 0.169, Validation Loss: 0.249\n",
      "Epoch: 6687, Train Loss: 0.222, Validation Loss: 0.249\n",
      "Epoch: 6688, Train Loss: 0.517, Validation Loss: 0.254\n",
      "Epoch: 6689, Train Loss: 0.272, Validation Loss: 0.253\n",
      "Epoch: 6690, Train Loss: 0.244, Validation Loss: 0.250\n",
      "Epoch: 6691, Train Loss: 0.182, Validation Loss: 0.251\n",
      "Epoch: 6692, Train Loss: 0.158, Validation Loss: 0.250\n",
      "Epoch: 6693, Train Loss: 0.256, Validation Loss: 0.249\n",
      "Epoch: 6694, Train Loss: 0.200, Validation Loss: 0.251\n",
      "Epoch: 6695, Train Loss: 0.175, Validation Loss: 0.251\n",
      "Epoch: 6696, Train Loss: 0.329, Validation Loss: 0.251\n",
      "Epoch: 6697, Train Loss: 0.479, Validation Loss: 0.253\n",
      "Epoch: 6698, Train Loss: 0.295, Validation Loss: 0.252\n",
      "Epoch: 6699, Train Loss: 0.636, Validation Loss: 0.252\n",
      "Epoch: 6700, Train Loss: 0.328, Validation Loss: 0.252\n",
      "Epoch: 6701, Train Loss: 0.218, Validation Loss: 0.252\n",
      "Epoch: 6702, Train Loss: 0.234, Validation Loss: 0.253\n",
      "Epoch: 6703, Train Loss: 0.273, Validation Loss: 0.250\n",
      "Epoch: 6704, Train Loss: 0.491, Validation Loss: 0.251\n",
      "Epoch: 6705, Train Loss: 0.247, Validation Loss: 0.253\n",
      "Epoch: 6706, Train Loss: 0.222, Validation Loss: 0.252\n",
      "Epoch: 6707, Train Loss: 0.193, Validation Loss: 0.251\n",
      "Epoch: 6708, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 6709, Train Loss: 0.284, Validation Loss: 0.255\n",
      "Epoch: 6710, Train Loss: 0.283, Validation Loss: 0.257\n",
      "Epoch: 6711, Train Loss: 0.348, Validation Loss: 0.253\n",
      "Epoch: 6712, Train Loss: 0.358, Validation Loss: 0.250\n",
      "Epoch: 6713, Train Loss: 0.305, Validation Loss: 0.250\n",
      "Epoch: 6714, Train Loss: 0.230, Validation Loss: 0.252\n",
      "Epoch: 6715, Train Loss: 0.232, Validation Loss: 0.255\n",
      "Epoch: 6716, Train Loss: 0.210, Validation Loss: 0.255\n",
      "Epoch: 6717, Train Loss: 0.370, Validation Loss: 0.251\n",
      "Epoch: 6718, Train Loss: 0.264, Validation Loss: 0.250\n",
      "Epoch: 6719, Train Loss: 0.271, Validation Loss: 0.253\n",
      "Epoch: 6720, Train Loss: 0.164, Validation Loss: 0.251\n",
      "Epoch: 6721, Train Loss: 0.264, Validation Loss: 0.259\n",
      "Epoch: 6722, Train Loss: 0.233, Validation Loss: 0.253\n",
      "Epoch: 6723, Train Loss: 0.168, Validation Loss: 0.252\n",
      "Epoch: 6724, Train Loss: 0.243, Validation Loss: 0.257\n",
      "Epoch: 6725, Train Loss: 0.230, Validation Loss: 0.257\n",
      "Epoch: 6726, Train Loss: 0.504, Validation Loss: 0.256\n",
      "Epoch: 6727, Train Loss: 0.258, Validation Loss: 0.252\n",
      "Epoch: 6728, Train Loss: 0.205, Validation Loss: 0.251\n",
      "Epoch: 6729, Train Loss: 0.525, Validation Loss: 0.256\n",
      "Epoch: 6730, Train Loss: 0.239, Validation Loss: 0.256\n",
      "Epoch: 6731, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 6732, Train Loss: 0.236, Validation Loss: 0.252\n",
      "Epoch: 6733, Train Loss: 0.314, Validation Loss: 0.257\n",
      "Epoch: 6734, Train Loss: 0.197, Validation Loss: 0.251\n",
      "Epoch: 6735, Train Loss: 0.306, Validation Loss: 0.250\n",
      "Epoch: 6736, Train Loss: 0.384, Validation Loss: 0.257\n",
      "Epoch: 6737, Train Loss: 0.251, Validation Loss: 0.247\n",
      "Epoch: 6738, Train Loss: 0.305, Validation Loss: 0.249\n",
      "Epoch: 6739, Train Loss: 0.225, Validation Loss: 0.249\n",
      "Epoch: 6740, Train Loss: 0.282, Validation Loss: 0.257\n",
      "Epoch: 6741, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 6742, Train Loss: 0.194, Validation Loss: 0.251\n",
      "Epoch: 6743, Train Loss: 0.262, Validation Loss: 0.256\n",
      "Epoch: 6744, Train Loss: 0.256, Validation Loss: 0.252\n",
      "Epoch: 6745, Train Loss: 0.167, Validation Loss: 0.249\n",
      "Epoch: 6746, Train Loss: 0.619, Validation Loss: 0.250\n",
      "Epoch: 6747, Train Loss: 0.223, Validation Loss: 0.249\n",
      "Epoch: 6748, Train Loss: 0.292, Validation Loss: 0.252\n",
      "Epoch: 6749, Train Loss: 0.183, Validation Loss: 0.252\n",
      "Epoch: 6750, Train Loss: 0.261, Validation Loss: 0.256\n",
      "Epoch: 6751, Train Loss: 0.206, Validation Loss: 0.250\n",
      "Epoch: 6752, Train Loss: 0.203, Validation Loss: 0.252\n",
      "Epoch: 6753, Train Loss: 0.346, Validation Loss: 0.251\n",
      "Epoch: 6754, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 6755, Train Loss: 0.190, Validation Loss: 0.250\n",
      "Epoch: 6756, Train Loss: 0.218, Validation Loss: 0.251\n",
      "Epoch: 6757, Train Loss: 0.269, Validation Loss: 0.254\n",
      "Epoch: 6758, Train Loss: 0.298, Validation Loss: 0.253\n",
      "Epoch: 6759, Train Loss: 0.300, Validation Loss: 0.255\n",
      "Epoch: 6760, Train Loss: 0.194, Validation Loss: 0.254\n",
      "Epoch: 6761, Train Loss: 0.260, Validation Loss: 0.251\n",
      "Epoch: 6762, Train Loss: 0.211, Validation Loss: 0.253\n",
      "Epoch: 6763, Train Loss: 0.302, Validation Loss: 0.252\n",
      "Epoch: 6764, Train Loss: 0.219, Validation Loss: 0.251\n",
      "Epoch: 6765, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 6766, Train Loss: 0.347, Validation Loss: 0.255\n",
      "Epoch: 6767, Train Loss: 0.350, Validation Loss: 0.252\n",
      "Epoch: 6768, Train Loss: 0.264, Validation Loss: 0.253\n",
      "Epoch: 6769, Train Loss: 0.368, Validation Loss: 0.255\n",
      "Epoch: 6770, Train Loss: 0.294, Validation Loss: 0.251\n",
      "Epoch: 6771, Train Loss: 0.531, Validation Loss: 0.253\n",
      "Epoch: 6772, Train Loss: 0.350, Validation Loss: 0.251\n",
      "Epoch: 6773, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 6774, Train Loss: 0.218, Validation Loss: 0.253\n",
      "Epoch: 6775, Train Loss: 0.253, Validation Loss: 0.251\n",
      "Epoch: 6776, Train Loss: 0.272, Validation Loss: 0.251\n",
      "Epoch: 6777, Train Loss: 0.271, Validation Loss: 0.255\n",
      "Epoch: 6778, Train Loss: 0.274, Validation Loss: 0.249\n",
      "Epoch: 6779, Train Loss: 0.175, Validation Loss: 0.251\n",
      "Epoch: 6780, Train Loss: 0.286, Validation Loss: 0.253\n",
      "Epoch: 6781, Train Loss: 0.526, Validation Loss: 0.251\n",
      "Epoch: 6782, Train Loss: 0.304, Validation Loss: 0.249\n",
      "Epoch: 6783, Train Loss: 0.153, Validation Loss: 0.249\n",
      "Epoch: 6784, Train Loss: 0.292, Validation Loss: 0.251\n",
      "Epoch: 6785, Train Loss: 0.487, Validation Loss: 0.249\n",
      "Epoch: 6786, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 6787, Train Loss: 0.184, Validation Loss: 0.251\n",
      "Epoch: 6788, Train Loss: 0.270, Validation Loss: 0.253\n",
      "Epoch: 6789, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 6790, Train Loss: 0.229, Validation Loss: 0.250\n",
      "Epoch: 6791, Train Loss: 0.308, Validation Loss: 0.250\n",
      "Epoch: 6792, Train Loss: 0.254, Validation Loss: 0.258\n",
      "Epoch: 6793, Train Loss: 0.278, Validation Loss: 0.258\n",
      "Epoch: 6794, Train Loss: 0.250, Validation Loss: 0.255\n",
      "Epoch: 6795, Train Loss: 0.338, Validation Loss: 0.255\n",
      "Epoch: 6796, Train Loss: 0.290, Validation Loss: 0.249\n",
      "Epoch: 6797, Train Loss: 0.249, Validation Loss: 0.249\n",
      "Epoch: 6798, Train Loss: 0.314, Validation Loss: 0.248\n",
      "Epoch: 6799, Train Loss: 0.513, Validation Loss: 0.251\n",
      "Epoch: 6800, Train Loss: 0.730, Validation Loss: 0.254\n",
      "Epoch: 6801, Train Loss: 0.325, Validation Loss: 0.251\n",
      "Epoch: 6802, Train Loss: 0.204, Validation Loss: 0.247\n",
      "Epoch: 6803, Train Loss: 0.304, Validation Loss: 0.248\n",
      "Epoch: 6804, Train Loss: 0.511, Validation Loss: 0.251\n",
      "Epoch: 6805, Train Loss: 0.252, Validation Loss: 0.249\n",
      "Epoch: 6806, Train Loss: 0.178, Validation Loss: 0.249\n",
      "Epoch: 6807, Train Loss: 0.279, Validation Loss: 0.256\n",
      "Epoch: 6808, Train Loss: 0.233, Validation Loss: 0.252\n",
      "Epoch: 6809, Train Loss: 0.303, Validation Loss: 0.251\n",
      "Epoch: 6810, Train Loss: 0.412, Validation Loss: 0.251\n",
      "Epoch: 6811, Train Loss: 0.252, Validation Loss: 0.259\n",
      "Epoch: 6812, Train Loss: 0.883, Validation Loss: 0.254\n",
      "Epoch: 6813, Train Loss: 0.188, Validation Loss: 0.250\n",
      "Epoch: 6814, Train Loss: 0.228, Validation Loss: 0.250\n",
      "Epoch: 6815, Train Loss: 0.212, Validation Loss: 0.249\n",
      "Epoch: 6816, Train Loss: 0.168, Validation Loss: 0.248\n",
      "Epoch: 6817, Train Loss: 0.219, Validation Loss: 0.248\n",
      "Epoch: 6818, Train Loss: 0.136, Validation Loss: 0.250\n",
      "Epoch: 6819, Train Loss: 0.247, Validation Loss: 0.249\n",
      "Epoch: 6820, Train Loss: 0.539, Validation Loss: 0.248\n",
      "Epoch: 6821, Train Loss: 0.314, Validation Loss: 0.249\n",
      "Epoch: 6822, Train Loss: 0.194, Validation Loss: 0.251\n",
      "Epoch: 6823, Train Loss: 0.175, Validation Loss: 0.251\n",
      "Epoch: 6824, Train Loss: 0.290, Validation Loss: 0.253\n",
      "Epoch: 6825, Train Loss: 0.215, Validation Loss: 0.250\n",
      "Epoch: 6826, Train Loss: 0.266, Validation Loss: 0.248\n",
      "Epoch: 6827, Train Loss: 0.343, Validation Loss: 0.249\n",
      "Epoch: 6828, Train Loss: 0.363, Validation Loss: 0.251\n",
      "Epoch: 6829, Train Loss: 0.311, Validation Loss: 0.254\n",
      "Epoch: 6830, Train Loss: 0.229, Validation Loss: 0.252\n",
      "Epoch: 6831, Train Loss: 0.165, Validation Loss: 0.253\n",
      "Epoch: 6832, Train Loss: 0.209, Validation Loss: 0.253\n",
      "Epoch: 6833, Train Loss: 0.170, Validation Loss: 0.252\n",
      "Epoch: 6834, Train Loss: 0.305, Validation Loss: 0.254\n",
      "Epoch: 6835, Train Loss: 0.288, Validation Loss: 0.249\n",
      "Epoch: 6836, Train Loss: 0.256, Validation Loss: 0.252\n",
      "Epoch: 6837, Train Loss: 0.192, Validation Loss: 0.252\n",
      "Epoch: 6838, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 6839, Train Loss: 0.261, Validation Loss: 0.250\n",
      "Epoch: 6840, Train Loss: 0.254, Validation Loss: 0.251\n",
      "Epoch: 6841, Train Loss: 0.308, Validation Loss: 0.251\n",
      "Epoch: 6842, Train Loss: 0.290, Validation Loss: 0.249\n",
      "Epoch: 6843, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 6844, Train Loss: 0.257, Validation Loss: 0.253\n",
      "Epoch: 6845, Train Loss: 0.381, Validation Loss: 0.259\n",
      "Epoch: 6846, Train Loss: 0.273, Validation Loss: 0.256\n",
      "Epoch: 6847, Train Loss: 0.249, Validation Loss: 0.248\n",
      "Epoch: 6848, Train Loss: 0.187, Validation Loss: 0.249\n",
      "Epoch: 6849, Train Loss: 0.448, Validation Loss: 0.250\n",
      "Epoch: 6850, Train Loss: 0.178, Validation Loss: 0.252\n",
      "Epoch: 6851, Train Loss: 0.259, Validation Loss: 0.250\n",
      "Epoch: 6852, Train Loss: 0.185, Validation Loss: 0.252\n",
      "Epoch: 6853, Train Loss: 0.562, Validation Loss: 0.253\n",
      "Epoch: 6854, Train Loss: 0.345, Validation Loss: 0.250\n",
      "Epoch: 6855, Train Loss: 0.274, Validation Loss: 0.252\n",
      "Epoch: 6856, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 6857, Train Loss: 0.277, Validation Loss: 0.249\n",
      "Epoch: 6858, Train Loss: 0.307, Validation Loss: 0.247\n",
      "Epoch: 6859, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 6860, Train Loss: 0.274, Validation Loss: 0.252\n",
      "Epoch: 6861, Train Loss: 0.481, Validation Loss: 0.253\n",
      "Epoch: 6862, Train Loss: 0.475, Validation Loss: 0.251\n",
      "Epoch: 6863, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 6864, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 6865, Train Loss: 0.255, Validation Loss: 0.252\n",
      "Epoch: 6866, Train Loss: 0.303, Validation Loss: 0.261\n",
      "Epoch: 6867, Train Loss: 0.332, Validation Loss: 0.251\n",
      "Epoch: 6868, Train Loss: 0.292, Validation Loss: 0.259\n",
      "Epoch: 6869, Train Loss: 0.195, Validation Loss: 0.255\n",
      "Epoch: 6870, Train Loss: 0.267, Validation Loss: 0.255\n",
      "Epoch: 6871, Train Loss: 0.374, Validation Loss: 0.255\n",
      "Epoch: 6872, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 6873, Train Loss: 0.216, Validation Loss: 0.250\n",
      "Epoch: 6874, Train Loss: 0.317, Validation Loss: 0.249\n",
      "Epoch: 6875, Train Loss: 0.186, Validation Loss: 0.252\n",
      "Epoch: 6876, Train Loss: 0.266, Validation Loss: 0.254\n",
      "Epoch: 6877, Train Loss: 0.278, Validation Loss: 0.252\n",
      "Epoch: 6878, Train Loss: 0.190, Validation Loss: 0.247\n",
      "Epoch: 6879, Train Loss: 0.194, Validation Loss: 0.248\n",
      "Epoch: 6880, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 6881, Train Loss: 0.400, Validation Loss: 0.252\n",
      "Epoch: 6882, Train Loss: 0.248, Validation Loss: 0.250\n",
      "Epoch: 6883, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 6884, Train Loss: 0.324, Validation Loss: 0.251\n",
      "Epoch: 6885, Train Loss: 0.206, Validation Loss: 0.248\n",
      "Epoch: 6886, Train Loss: 0.221, Validation Loss: 0.249\n",
      "Epoch: 6887, Train Loss: 0.217, Validation Loss: 0.252\n",
      "Epoch: 6888, Train Loss: 0.556, Validation Loss: 0.252\n",
      "Epoch: 6889, Train Loss: 0.350, Validation Loss: 0.250\n",
      "Epoch: 6890, Train Loss: 0.218, Validation Loss: 0.250\n",
      "Epoch: 6891, Train Loss: 0.289, Validation Loss: 0.249\n",
      "Epoch: 6892, Train Loss: 0.244, Validation Loss: 0.254\n",
      "Epoch: 6893, Train Loss: 0.360, Validation Loss: 0.249\n",
      "Epoch: 6894, Train Loss: 0.261, Validation Loss: 0.249\n",
      "Epoch: 6895, Train Loss: 0.292, Validation Loss: 0.250\n",
      "Epoch: 6896, Train Loss: 0.314, Validation Loss: 0.250\n",
      "Epoch: 6897, Train Loss: 0.250, Validation Loss: 0.250\n",
      "Epoch: 6898, Train Loss: 0.266, Validation Loss: 0.258\n",
      "Epoch: 6899, Train Loss: 0.232, Validation Loss: 0.258\n",
      "Epoch: 6900, Train Loss: 0.174, Validation Loss: 0.252\n",
      "Epoch: 6901, Train Loss: 0.211, Validation Loss: 0.255\n",
      "Epoch: 6902, Train Loss: 0.357, Validation Loss: 0.249\n",
      "Epoch: 6903, Train Loss: 0.328, Validation Loss: 0.249\n",
      "Epoch: 6904, Train Loss: 0.260, Validation Loss: 0.250\n",
      "Epoch: 6905, Train Loss: 0.468, Validation Loss: 0.256\n",
      "Epoch: 6906, Train Loss: 0.239, Validation Loss: 0.251\n",
      "Epoch: 6907, Train Loss: 0.201, Validation Loss: 0.256\n",
      "Epoch: 6908, Train Loss: 0.220, Validation Loss: 0.256\n",
      "Epoch: 6909, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 6910, Train Loss: 0.195, Validation Loss: 0.250\n",
      "Epoch: 6911, Train Loss: 0.307, Validation Loss: 0.251\n",
      "Epoch: 6912, Train Loss: 0.245, Validation Loss: 0.250\n",
      "Epoch: 6913, Train Loss: 0.243, Validation Loss: 0.251\n",
      "Epoch: 6914, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 6915, Train Loss: 0.522, Validation Loss: 0.252\n",
      "Epoch: 6916, Train Loss: 0.267, Validation Loss: 0.253\n",
      "Epoch: 6917, Train Loss: 0.289, Validation Loss: 0.255\n",
      "Epoch: 6918, Train Loss: 0.169, Validation Loss: 0.250\n",
      "Epoch: 6919, Train Loss: 0.262, Validation Loss: 0.249\n",
      "Epoch: 6920, Train Loss: 0.242, Validation Loss: 0.249\n",
      "Epoch: 6921, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 6922, Train Loss: 0.207, Validation Loss: 0.255\n",
      "Epoch: 6923, Train Loss: 0.259, Validation Loss: 0.255\n",
      "Epoch: 6924, Train Loss: 0.253, Validation Loss: 0.254\n",
      "Epoch: 6925, Train Loss: 0.240, Validation Loss: 0.253\n",
      "Epoch: 6926, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 6927, Train Loss: 0.253, Validation Loss: 0.251\n",
      "Epoch: 6928, Train Loss: 0.371, Validation Loss: 0.250\n",
      "Epoch: 6929, Train Loss: 0.305, Validation Loss: 0.251\n",
      "Epoch: 6930, Train Loss: 0.194, Validation Loss: 0.256\n",
      "Epoch: 6931, Train Loss: 0.179, Validation Loss: 0.253\n",
      "Epoch: 6932, Train Loss: 0.189, Validation Loss: 0.254\n",
      "Epoch: 6933, Train Loss: 0.191, Validation Loss: 0.255\n",
      "Epoch: 6934, Train Loss: 0.279, Validation Loss: 0.251\n",
      "Epoch: 6935, Train Loss: 0.218, Validation Loss: 0.250\n",
      "Epoch: 6936, Train Loss: 0.265, Validation Loss: 0.254\n",
      "Epoch: 6937, Train Loss: 0.251, Validation Loss: 0.251\n",
      "Epoch: 6938, Train Loss: 0.249, Validation Loss: 0.250\n",
      "Epoch: 6939, Train Loss: 0.214, Validation Loss: 0.250\n",
      "Epoch: 6940, Train Loss: 0.160, Validation Loss: 0.251\n",
      "Epoch: 6941, Train Loss: 0.225, Validation Loss: 0.252\n",
      "Epoch: 6942, Train Loss: 0.312, Validation Loss: 0.249\n",
      "Epoch: 6943, Train Loss: 0.320, Validation Loss: 0.250\n",
      "Epoch: 6944, Train Loss: 0.213, Validation Loss: 0.249\n",
      "Epoch: 6945, Train Loss: 0.311, Validation Loss: 0.249\n",
      "Epoch: 6946, Train Loss: 0.183, Validation Loss: 0.253\n",
      "Epoch: 6947, Train Loss: 0.420, Validation Loss: 0.259\n",
      "Epoch: 6948, Train Loss: 0.235, Validation Loss: 0.253\n",
      "Epoch: 6949, Train Loss: 0.287, Validation Loss: 0.254\n",
      "Epoch: 6950, Train Loss: 0.492, Validation Loss: 0.252\n",
      "Epoch: 6951, Train Loss: 0.276, Validation Loss: 0.254\n",
      "Epoch: 6952, Train Loss: 0.275, Validation Loss: 0.252\n",
      "Epoch: 6953, Train Loss: 0.302, Validation Loss: 0.258\n",
      "Epoch: 6954, Train Loss: 0.553, Validation Loss: 0.250\n",
      "Epoch: 6955, Train Loss: 0.446, Validation Loss: 0.249\n",
      "Epoch: 6956, Train Loss: 0.261, Validation Loss: 0.251\n",
      "Epoch: 6957, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 6958, Train Loss: 0.338, Validation Loss: 0.250\n",
      "Epoch: 6959, Train Loss: 0.264, Validation Loss: 0.255\n",
      "Epoch: 6960, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 6961, Train Loss: 0.311, Validation Loss: 0.249\n",
      "Epoch: 6962, Train Loss: 0.443, Validation Loss: 0.249\n",
      "Epoch: 6963, Train Loss: 0.266, Validation Loss: 0.255\n",
      "Epoch: 6964, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 6965, Train Loss: 0.299, Validation Loss: 0.255\n",
      "Epoch: 6966, Train Loss: 0.305, Validation Loss: 0.249\n",
      "Epoch: 6967, Train Loss: 0.232, Validation Loss: 0.252\n",
      "Epoch: 6968, Train Loss: 0.195, Validation Loss: 0.256\n",
      "Epoch: 6969, Train Loss: 0.238, Validation Loss: 0.260\n",
      "Epoch: 6970, Train Loss: 0.307, Validation Loss: 0.249\n",
      "Epoch: 6971, Train Loss: 0.232, Validation Loss: 0.253\n",
      "Epoch: 6972, Train Loss: 0.239, Validation Loss: 0.250\n",
      "Epoch: 6973, Train Loss: 0.235, Validation Loss: 0.251\n",
      "Epoch: 6974, Train Loss: 0.277, Validation Loss: 0.253\n",
      "Epoch: 6975, Train Loss: 0.173, Validation Loss: 0.251\n",
      "Epoch: 6976, Train Loss: 0.297, Validation Loss: 0.259\n",
      "Epoch: 6977, Train Loss: 0.366, Validation Loss: 0.251\n",
      "Epoch: 6978, Train Loss: 0.297, Validation Loss: 0.257\n",
      "Epoch: 6979, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 6980, Train Loss: 0.601, Validation Loss: 0.250\n",
      "Epoch: 6981, Train Loss: 0.193, Validation Loss: 0.249\n",
      "Epoch: 6982, Train Loss: 0.401, Validation Loss: 0.248\n",
      "Epoch: 6983, Train Loss: 0.237, Validation Loss: 0.249\n",
      "Epoch: 6984, Train Loss: 0.193, Validation Loss: 0.251\n",
      "Epoch: 6985, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 6986, Train Loss: 0.281, Validation Loss: 0.255\n",
      "Epoch: 6987, Train Loss: 0.306, Validation Loss: 0.255\n",
      "Epoch: 6988, Train Loss: 0.300, Validation Loss: 0.249\n",
      "Epoch: 6989, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 6990, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 6991, Train Loss: 0.288, Validation Loss: 0.253\n",
      "Epoch: 6992, Train Loss: 0.285, Validation Loss: 0.253\n",
      "Epoch: 6993, Train Loss: 0.205, Validation Loss: 0.253\n",
      "Epoch: 6994, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 6995, Train Loss: 0.226, Validation Loss: 0.255\n",
      "Epoch: 6996, Train Loss: 0.222, Validation Loss: 0.253\n",
      "Epoch: 6997, Train Loss: 0.393, Validation Loss: 0.250\n",
      "Epoch: 6998, Train Loss: 0.377, Validation Loss: 0.258\n",
      "Epoch: 6999, Train Loss: 0.229, Validation Loss: 0.252\n",
      "Epoch: 7000, Train Loss: 0.270, Validation Loss: 0.251\n",
      "Epoch: 7001, Train Loss: 0.198, Validation Loss: 0.252\n",
      "Epoch: 7002, Train Loss: 0.146, Validation Loss: 0.253\n",
      "Epoch: 7003, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 7004, Train Loss: 0.307, Validation Loss: 0.250\n",
      "Epoch: 7005, Train Loss: 0.309, Validation Loss: 0.255\n",
      "Epoch: 7006, Train Loss: 0.364, Validation Loss: 0.251\n",
      "Epoch: 7007, Train Loss: 0.442, Validation Loss: 0.252\n",
      "Epoch: 7008, Train Loss: 0.214, Validation Loss: 0.252\n",
      "Epoch: 7009, Train Loss: 0.281, Validation Loss: 0.253\n",
      "Epoch: 7010, Train Loss: 0.230, Validation Loss: 0.256\n",
      "Epoch: 7011, Train Loss: 0.281, Validation Loss: 0.250\n",
      "Epoch: 7012, Train Loss: 0.233, Validation Loss: 0.250\n",
      "Epoch: 7013, Train Loss: 0.235, Validation Loss: 0.251\n",
      "Epoch: 7014, Train Loss: 0.244, Validation Loss: 0.248\n",
      "Epoch: 7015, Train Loss: 0.192, Validation Loss: 0.251\n",
      "Epoch: 7016, Train Loss: 0.183, Validation Loss: 0.251\n",
      "Epoch: 7017, Train Loss: 0.269, Validation Loss: 0.252\n",
      "Epoch: 7018, Train Loss: 0.375, Validation Loss: 0.255\n",
      "Epoch: 7019, Train Loss: 0.231, Validation Loss: 0.252\n",
      "Epoch: 7020, Train Loss: 0.222, Validation Loss: 0.249\n",
      "Epoch: 7021, Train Loss: 0.355, Validation Loss: 0.249\n",
      "Epoch: 7022, Train Loss: 0.386, Validation Loss: 0.256\n",
      "Epoch: 7023, Train Loss: 0.287, Validation Loss: 0.253\n",
      "Epoch: 7024, Train Loss: 0.259, Validation Loss: 0.255\n",
      "Epoch: 7025, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 7026, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 7027, Train Loss: 0.332, Validation Loss: 0.251\n",
      "Epoch: 7028, Train Loss: 0.234, Validation Loss: 0.253\n",
      "Epoch: 7029, Train Loss: 0.205, Validation Loss: 0.255\n",
      "Epoch: 7030, Train Loss: 0.228, Validation Loss: 0.255\n",
      "Epoch: 7031, Train Loss: 0.320, Validation Loss: 0.250\n",
      "Epoch: 7032, Train Loss: 0.253, Validation Loss: 0.253\n",
      "Epoch: 7033, Train Loss: 0.205, Validation Loss: 0.251\n",
      "Epoch: 7034, Train Loss: 0.302, Validation Loss: 0.251\n",
      "Epoch: 7035, Train Loss: 0.327, Validation Loss: 0.254\n",
      "Epoch: 7036, Train Loss: 0.314, Validation Loss: 0.252\n",
      "Epoch: 7037, Train Loss: 0.478, Validation Loss: 0.250\n",
      "Epoch: 7038, Train Loss: 0.245, Validation Loss: 0.248\n",
      "Epoch: 7039, Train Loss: 0.468, Validation Loss: 0.250\n",
      "Epoch: 7040, Train Loss: 0.202, Validation Loss: 0.252\n",
      "Epoch: 7041, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 7042, Train Loss: 0.357, Validation Loss: 0.248\n",
      "Epoch: 7043, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 7044, Train Loss: 0.388, Validation Loss: 0.259\n",
      "Epoch: 7045, Train Loss: 0.529, Validation Loss: 0.251\n",
      "Epoch: 7046, Train Loss: 0.183, Validation Loss: 0.254\n",
      "Epoch: 7047, Train Loss: 0.262, Validation Loss: 0.250\n",
      "Epoch: 7048, Train Loss: 0.272, Validation Loss: 0.249\n",
      "Epoch: 7049, Train Loss: 0.217, Validation Loss: 0.249\n",
      "Epoch: 7050, Train Loss: 0.242, Validation Loss: 0.252\n",
      "Epoch: 7051, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 7052, Train Loss: 0.186, Validation Loss: 0.253\n",
      "Epoch: 7053, Train Loss: 0.353, Validation Loss: 0.254\n",
      "Epoch: 7054, Train Loss: 0.197, Validation Loss: 0.254\n",
      "Epoch: 7055, Train Loss: 0.292, Validation Loss: 0.254\n",
      "Epoch: 7056, Train Loss: 0.493, Validation Loss: 0.250\n",
      "Epoch: 7057, Train Loss: 0.259, Validation Loss: 0.251\n",
      "Epoch: 7058, Train Loss: 0.381, Validation Loss: 0.251\n",
      "Epoch: 7059, Train Loss: 0.323, Validation Loss: 0.249\n",
      "Epoch: 7060, Train Loss: 0.358, Validation Loss: 0.249\n",
      "Epoch: 7061, Train Loss: 0.525, Validation Loss: 0.251\n",
      "Epoch: 7062, Train Loss: 0.252, Validation Loss: 0.251\n",
      "Epoch: 7063, Train Loss: 0.406, Validation Loss: 0.249\n",
      "Epoch: 7064, Train Loss: 0.443, Validation Loss: 0.249\n",
      "Epoch: 7065, Train Loss: 0.183, Validation Loss: 0.251\n",
      "Epoch: 7066, Train Loss: 0.337, Validation Loss: 0.249\n",
      "Epoch: 7067, Train Loss: 0.377, Validation Loss: 0.255\n",
      "Epoch: 7068, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 7069, Train Loss: 0.186, Validation Loss: 0.253\n",
      "Epoch: 7070, Train Loss: 0.243, Validation Loss: 0.254\n",
      "Epoch: 7071, Train Loss: 0.293, Validation Loss: 0.253\n",
      "Epoch: 7072, Train Loss: 0.217, Validation Loss: 0.251\n",
      "Epoch: 7073, Train Loss: 0.464, Validation Loss: 0.256\n",
      "Epoch: 7074, Train Loss: 0.238, Validation Loss: 0.252\n",
      "Epoch: 7075, Train Loss: 0.238, Validation Loss: 0.251\n",
      "Epoch: 7076, Train Loss: 0.386, Validation Loss: 0.250\n",
      "Epoch: 7077, Train Loss: 0.449, Validation Loss: 0.250\n",
      "Epoch: 7078, Train Loss: 0.188, Validation Loss: 0.251\n",
      "Epoch: 7079, Train Loss: 0.287, Validation Loss: 0.251\n",
      "Epoch: 7080, Train Loss: 0.248, Validation Loss: 0.249\n",
      "Epoch: 7081, Train Loss: 0.574, Validation Loss: 0.251\n",
      "Epoch: 7082, Train Loss: 0.322, Validation Loss: 0.249\n",
      "Epoch: 7083, Train Loss: 0.209, Validation Loss: 0.248\n",
      "Epoch: 7084, Train Loss: 0.204, Validation Loss: 0.249\n",
      "Epoch: 7085, Train Loss: 0.326, Validation Loss: 0.248\n",
      "Epoch: 7086, Train Loss: 0.349, Validation Loss: 0.248\n",
      "Epoch: 7087, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 7088, Train Loss: 0.262, Validation Loss: 0.248\n",
      "Epoch: 7089, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 7090, Train Loss: 0.290, Validation Loss: 0.252\n",
      "Epoch: 7091, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 7092, Train Loss: 0.445, Validation Loss: 0.249\n",
      "Epoch: 7093, Train Loss: 0.169, Validation Loss: 0.249\n",
      "Epoch: 7094, Train Loss: 0.212, Validation Loss: 0.253\n",
      "Epoch: 7095, Train Loss: 0.193, Validation Loss: 0.256\n",
      "Epoch: 7096, Train Loss: 0.208, Validation Loss: 0.252\n",
      "Epoch: 7097, Train Loss: 0.406, Validation Loss: 0.250\n",
      "Epoch: 7098, Train Loss: 0.392, Validation Loss: 0.250\n",
      "Epoch: 7099, Train Loss: 0.200, Validation Loss: 0.255\n",
      "Epoch: 7100, Train Loss: 0.525, Validation Loss: 0.251\n",
      "Epoch: 7101, Train Loss: 0.202, Validation Loss: 0.252\n",
      "Epoch: 7102, Train Loss: 0.237, Validation Loss: 0.257\n",
      "Epoch: 7103, Train Loss: 0.167, Validation Loss: 0.256\n",
      "Epoch: 7104, Train Loss: 0.397, Validation Loss: 0.250\n",
      "Epoch: 7105, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 7106, Train Loss: 0.225, Validation Loss: 0.248\n",
      "Epoch: 7107, Train Loss: 0.197, Validation Loss: 0.251\n",
      "Epoch: 7108, Train Loss: 0.280, Validation Loss: 0.253\n",
      "Epoch: 7109, Train Loss: 0.362, Validation Loss: 0.253\n",
      "Epoch: 7110, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 7111, Train Loss: 0.375, Validation Loss: 0.248\n",
      "Epoch: 7112, Train Loss: 0.419, Validation Loss: 0.247\n",
      "Epoch: 7113, Train Loss: 0.354, Validation Loss: 0.248\n",
      "Epoch: 7114, Train Loss: 0.181, Validation Loss: 0.251\n",
      "Epoch: 7115, Train Loss: 0.177, Validation Loss: 0.249\n",
      "Epoch: 7116, Train Loss: 0.272, Validation Loss: 0.252\n",
      "Epoch: 7117, Train Loss: 0.183, Validation Loss: 0.247\n",
      "Epoch: 7118, Train Loss: 0.406, Validation Loss: 0.249\n",
      "Epoch: 7119, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 7120, Train Loss: 0.227, Validation Loss: 0.247\n",
      "Epoch: 7121, Train Loss: 0.311, Validation Loss: 0.247\n",
      "Epoch: 7122, Train Loss: 0.580, Validation Loss: 0.249\n",
      "Epoch: 7123, Train Loss: 0.259, Validation Loss: 0.250\n",
      "Epoch: 7124, Train Loss: 0.256, Validation Loss: 0.250\n",
      "Epoch: 7125, Train Loss: 0.510, Validation Loss: 0.249\n",
      "Epoch: 7126, Train Loss: 0.192, Validation Loss: 0.250\n",
      "Epoch: 7127, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 7128, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 7129, Train Loss: 0.413, Validation Loss: 0.246\n",
      "Epoch: 7130, Train Loss: 0.334, Validation Loss: 0.248\n",
      "Epoch: 7131, Train Loss: 0.217, Validation Loss: 0.250\n",
      "Epoch: 7132, Train Loss: 0.250, Validation Loss: 0.252\n",
      "Epoch: 7133, Train Loss: 0.572, Validation Loss: 0.248\n",
      "Epoch: 7134, Train Loss: 0.267, Validation Loss: 0.253\n",
      "Epoch: 7135, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 7136, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 7137, Train Loss: 0.203, Validation Loss: 0.255\n",
      "Epoch: 7138, Train Loss: 0.265, Validation Loss: 0.250\n",
      "Epoch: 7139, Train Loss: 0.336, Validation Loss: 0.254\n",
      "Epoch: 7140, Train Loss: 0.227, Validation Loss: 0.255\n",
      "Epoch: 7141, Train Loss: 0.185, Validation Loss: 0.255\n",
      "Epoch: 7142, Train Loss: 0.380, Validation Loss: 0.253\n",
      "Epoch: 7143, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 7144, Train Loss: 0.248, Validation Loss: 0.252\n",
      "Epoch: 7145, Train Loss: 0.311, Validation Loss: 0.249\n",
      "Epoch: 7146, Train Loss: 0.169, Validation Loss: 0.252\n",
      "Epoch: 7147, Train Loss: 0.399, Validation Loss: 0.250\n",
      "Epoch: 7148, Train Loss: 0.291, Validation Loss: 0.252\n",
      "Epoch: 7149, Train Loss: 0.230, Validation Loss: 0.249\n",
      "Epoch: 7150, Train Loss: 0.172, Validation Loss: 0.248\n",
      "Epoch: 7151, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 7152, Train Loss: 0.301, Validation Loss: 0.250\n",
      "Epoch: 7153, Train Loss: 0.199, Validation Loss: 0.250\n",
      "Epoch: 7154, Train Loss: 0.394, Validation Loss: 0.250\n",
      "Epoch: 7155, Train Loss: 0.327, Validation Loss: 0.250\n",
      "Epoch: 7156, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 7157, Train Loss: 0.284, Validation Loss: 0.251\n",
      "Epoch: 7158, Train Loss: 0.197, Validation Loss: 0.255\n",
      "Epoch: 7159, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 7160, Train Loss: 0.376, Validation Loss: 0.253\n",
      "Epoch: 7161, Train Loss: 0.234, Validation Loss: 0.248\n",
      "Epoch: 7162, Train Loss: 0.230, Validation Loss: 0.247\n",
      "Epoch: 7163, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 7164, Train Loss: 0.216, Validation Loss: 0.250\n",
      "Epoch: 7165, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 7166, Train Loss: 0.221, Validation Loss: 0.248\n",
      "Epoch: 7167, Train Loss: 0.247, Validation Loss: 0.252\n",
      "Epoch: 7168, Train Loss: 0.321, Validation Loss: 0.250\n",
      "Epoch: 7169, Train Loss: 0.258, Validation Loss: 0.247\n",
      "Epoch: 7170, Train Loss: 0.249, Validation Loss: 0.248\n",
      "Epoch: 7171, Train Loss: 0.249, Validation Loss: 0.253\n",
      "Epoch: 7172, Train Loss: 0.455, Validation Loss: 0.248\n",
      "Epoch: 7173, Train Loss: 0.212, Validation Loss: 0.248\n",
      "Epoch: 7174, Train Loss: 0.214, Validation Loss: 0.246\n",
      "Epoch: 7175, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 7176, Train Loss: 0.222, Validation Loss: 0.246\n",
      "Epoch: 7177, Train Loss: 0.196, Validation Loss: 0.250\n",
      "Epoch: 7178, Train Loss: 0.217, Validation Loss: 0.249\n",
      "Epoch: 7179, Train Loss: 0.239, Validation Loss: 0.251\n",
      "Epoch: 7180, Train Loss: 0.283, Validation Loss: 0.249\n",
      "Epoch: 7181, Train Loss: 0.240, Validation Loss: 0.250\n",
      "Epoch: 7182, Train Loss: 0.331, Validation Loss: 0.245\n",
      "Epoch: 7183, Train Loss: 0.257, Validation Loss: 0.249\n",
      "Epoch: 7184, Train Loss: 0.172, Validation Loss: 0.250\n",
      "Epoch: 7185, Train Loss: 0.486, Validation Loss: 0.252\n",
      "Epoch: 7186, Train Loss: 0.308, Validation Loss: 0.248\n",
      "Epoch: 7187, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 7188, Train Loss: 0.210, Validation Loss: 0.248\n",
      "Epoch: 7189, Train Loss: 0.183, Validation Loss: 0.249\n",
      "Epoch: 7190, Train Loss: 0.193, Validation Loss: 0.246\n",
      "Epoch: 7191, Train Loss: 0.255, Validation Loss: 0.247\n",
      "Epoch: 7192, Train Loss: 0.188, Validation Loss: 0.248\n",
      "Epoch: 7193, Train Loss: 0.290, Validation Loss: 0.252\n",
      "Epoch: 7194, Train Loss: 0.257, Validation Loss: 0.251\n",
      "Epoch: 7195, Train Loss: 0.338, Validation Loss: 0.250\n",
      "Epoch: 7196, Train Loss: 0.188, Validation Loss: 0.251\n",
      "Epoch: 7197, Train Loss: 0.211, Validation Loss: 0.251\n",
      "Epoch: 7198, Train Loss: 0.239, Validation Loss: 0.250\n",
      "Epoch: 7199, Train Loss: 0.231, Validation Loss: 0.246\n",
      "Epoch: 7200, Train Loss: 0.221, Validation Loss: 0.245\n",
      "Epoch: 7201, Train Loss: 0.197, Validation Loss: 0.247\n",
      "Epoch: 7202, Train Loss: 0.283, Validation Loss: 0.248\n",
      "Epoch: 7203, Train Loss: 0.321, Validation Loss: 0.247\n",
      "Epoch: 7204, Train Loss: 0.307, Validation Loss: 0.255\n",
      "Epoch: 7205, Train Loss: 0.210, Validation Loss: 0.249\n",
      "Epoch: 7206, Train Loss: 0.294, Validation Loss: 0.253\n",
      "Epoch: 7207, Train Loss: 0.249, Validation Loss: 0.249\n",
      "Epoch: 7208, Train Loss: 0.253, Validation Loss: 0.247\n",
      "Epoch: 7209, Train Loss: 0.213, Validation Loss: 0.248\n",
      "Epoch: 7210, Train Loss: 0.196, Validation Loss: 0.249\n",
      "Epoch: 7211, Train Loss: 0.201, Validation Loss: 0.251\n",
      "Epoch: 7212, Train Loss: 0.302, Validation Loss: 0.250\n",
      "Epoch: 7213, Train Loss: 0.326, Validation Loss: 0.251\n",
      "Epoch: 7214, Train Loss: 0.201, Validation Loss: 0.252\n",
      "Epoch: 7215, Train Loss: 0.190, Validation Loss: 0.252\n",
      "Epoch: 7216, Train Loss: 0.260, Validation Loss: 0.253\n",
      "Epoch: 7217, Train Loss: 0.268, Validation Loss: 0.252\n",
      "Epoch: 7218, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 7219, Train Loss: 0.387, Validation Loss: 0.261\n",
      "Epoch: 7220, Train Loss: 0.488, Validation Loss: 0.250\n",
      "Epoch: 7221, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 7222, Train Loss: 0.175, Validation Loss: 0.251\n",
      "Epoch: 7223, Train Loss: 0.137, Validation Loss: 0.253\n",
      "Epoch: 7224, Train Loss: 0.403, Validation Loss: 0.247\n",
      "Epoch: 7225, Train Loss: 0.308, Validation Loss: 0.248\n",
      "Epoch: 7226, Train Loss: 0.247, Validation Loss: 0.248\n",
      "Epoch: 7227, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 7228, Train Loss: 0.197, Validation Loss: 0.254\n",
      "Epoch: 7229, Train Loss: 0.256, Validation Loss: 0.248\n",
      "Epoch: 7230, Train Loss: 0.173, Validation Loss: 0.249\n",
      "Epoch: 7231, Train Loss: 0.217, Validation Loss: 0.252\n",
      "Epoch: 7232, Train Loss: 0.201, Validation Loss: 0.252\n",
      "Epoch: 7233, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 7234, Train Loss: 0.237, Validation Loss: 0.248\n",
      "Epoch: 7235, Train Loss: 0.308, Validation Loss: 0.253\n",
      "Epoch: 7236, Train Loss: 0.334, Validation Loss: 0.250\n",
      "Epoch: 7237, Train Loss: 0.207, Validation Loss: 0.254\n",
      "Epoch: 7238, Train Loss: 0.306, Validation Loss: 0.250\n",
      "Epoch: 7239, Train Loss: 0.480, Validation Loss: 0.248\n",
      "Epoch: 7240, Train Loss: 0.517, Validation Loss: 0.248\n",
      "Epoch: 7241, Train Loss: 0.191, Validation Loss: 0.247\n",
      "Epoch: 7242, Train Loss: 0.321, Validation Loss: 0.255\n",
      "Epoch: 7243, Train Loss: 0.252, Validation Loss: 0.251\n",
      "Epoch: 7244, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 7245, Train Loss: 0.218, Validation Loss: 0.253\n",
      "Epoch: 7246, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 7247, Train Loss: 0.161, Validation Loss: 0.256\n",
      "Epoch: 7248, Train Loss: 0.200, Validation Loss: 0.251\n",
      "Epoch: 7249, Train Loss: 0.178, Validation Loss: 0.249\n",
      "Epoch: 7250, Train Loss: 0.295, Validation Loss: 0.254\n",
      "Epoch: 7251, Train Loss: 0.395, Validation Loss: 0.247\n",
      "Epoch: 7252, Train Loss: 0.280, Validation Loss: 0.250\n",
      "Epoch: 7253, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 7254, Train Loss: 0.276, Validation Loss: 0.249\n",
      "Epoch: 7255, Train Loss: 0.224, Validation Loss: 0.253\n",
      "Epoch: 7256, Train Loss: 0.238, Validation Loss: 0.253\n",
      "Epoch: 7257, Train Loss: 0.170, Validation Loss: 0.256\n",
      "Epoch: 7258, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 7259, Train Loss: 0.347, Validation Loss: 0.245\n",
      "Epoch: 7260, Train Loss: 0.196, Validation Loss: 0.249\n",
      "Epoch: 7261, Train Loss: 0.197, Validation Loss: 0.250\n",
      "Epoch: 7262, Train Loss: 0.326, Validation Loss: 0.252\n",
      "Epoch: 7263, Train Loss: 0.322, Validation Loss: 0.250\n",
      "Epoch: 7264, Train Loss: 0.213, Validation Loss: 0.253\n",
      "Epoch: 7265, Train Loss: 0.368, Validation Loss: 0.250\n",
      "Epoch: 7266, Train Loss: 0.340, Validation Loss: 0.249\n",
      "Epoch: 7267, Train Loss: 0.596, Validation Loss: 0.250\n",
      "Epoch: 7268, Train Loss: 0.235, Validation Loss: 0.247\n",
      "Epoch: 7269, Train Loss: 0.215, Validation Loss: 0.248\n",
      "Epoch: 7270, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 7271, Train Loss: 0.198, Validation Loss: 0.251\n",
      "Epoch: 7272, Train Loss: 0.296, Validation Loss: 0.252\n",
      "Epoch: 7273, Train Loss: 0.275, Validation Loss: 0.248\n",
      "Epoch: 7274, Train Loss: 0.250, Validation Loss: 0.246\n",
      "Epoch: 7275, Train Loss: 0.180, Validation Loss: 0.246\n",
      "Epoch: 7276, Train Loss: 0.137, Validation Loss: 0.248\n",
      "Epoch: 7277, Train Loss: 0.239, Validation Loss: 0.256\n",
      "Epoch: 7278, Train Loss: 0.265, Validation Loss: 0.255\n",
      "Epoch: 7279, Train Loss: 0.238, Validation Loss: 0.249\n",
      "Epoch: 7280, Train Loss: 0.238, Validation Loss: 0.248\n",
      "Epoch: 7281, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 7282, Train Loss: 0.199, Validation Loss: 0.252\n",
      "Epoch: 7283, Train Loss: 0.249, Validation Loss: 0.248\n",
      "Epoch: 7284, Train Loss: 0.449, Validation Loss: 0.246\n",
      "Epoch: 7285, Train Loss: 0.198, Validation Loss: 0.246\n",
      "Epoch: 7286, Train Loss: 0.165, Validation Loss: 0.246\n",
      "Epoch: 7287, Train Loss: 0.353, Validation Loss: 0.246\n",
      "Epoch: 7288, Train Loss: 0.164, Validation Loss: 0.250\n",
      "Epoch: 7289, Train Loss: 0.229, Validation Loss: 0.250\n",
      "Epoch: 7290, Train Loss: 0.193, Validation Loss: 0.250\n",
      "Epoch: 7291, Train Loss: 0.283, Validation Loss: 0.246\n",
      "Epoch: 7292, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 7293, Train Loss: 0.261, Validation Loss: 0.248\n",
      "Epoch: 7294, Train Loss: 0.312, Validation Loss: 0.246\n",
      "Epoch: 7295, Train Loss: 0.198, Validation Loss: 0.249\n",
      "Epoch: 7296, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 7297, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 7298, Train Loss: 0.233, Validation Loss: 0.250\n",
      "Epoch: 7299, Train Loss: 0.290, Validation Loss: 0.245\n",
      "Epoch: 7300, Train Loss: 0.304, Validation Loss: 0.247\n",
      "Epoch: 7301, Train Loss: 0.250, Validation Loss: 0.250\n",
      "Epoch: 7302, Train Loss: 0.184, Validation Loss: 0.252\n",
      "Epoch: 7303, Train Loss: 0.309, Validation Loss: 0.249\n",
      "Epoch: 7304, Train Loss: 0.168, Validation Loss: 0.245\n",
      "Epoch: 7305, Train Loss: 0.576, Validation Loss: 0.247\n",
      "Epoch: 7306, Train Loss: 0.253, Validation Loss: 0.246\n",
      "Epoch: 7307, Train Loss: 0.284, Validation Loss: 0.246\n",
      "Epoch: 7308, Train Loss: 0.253, Validation Loss: 0.248\n",
      "Epoch: 7309, Train Loss: 0.236, Validation Loss: 0.247\n",
      "Epoch: 7310, Train Loss: 0.315, Validation Loss: 0.249\n",
      "Epoch: 7311, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 7312, Train Loss: 0.322, Validation Loss: 0.248\n",
      "Epoch: 7313, Train Loss: 0.272, Validation Loss: 0.251\n",
      "Epoch: 7314, Train Loss: 0.185, Validation Loss: 0.252\n",
      "Epoch: 7315, Train Loss: 0.460, Validation Loss: 0.247\n",
      "Epoch: 7316, Train Loss: 0.308, Validation Loss: 0.249\n",
      "Epoch: 7317, Train Loss: 0.237, Validation Loss: 0.246\n",
      "Epoch: 7318, Train Loss: 0.194, Validation Loss: 0.250\n",
      "Epoch: 7319, Train Loss: 0.221, Validation Loss: 0.247\n",
      "Epoch: 7320, Train Loss: 0.464, Validation Loss: 0.249\n",
      "Epoch: 7321, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 7322, Train Loss: 0.193, Validation Loss: 0.245\n",
      "Epoch: 7323, Train Loss: 0.248, Validation Loss: 0.248\n",
      "Epoch: 7324, Train Loss: 0.324, Validation Loss: 0.245\n",
      "Epoch: 7325, Train Loss: 0.248, Validation Loss: 0.248\n",
      "Epoch: 7326, Train Loss: 0.273, Validation Loss: 0.254\n",
      "Epoch: 7327, Train Loss: 0.275, Validation Loss: 0.250\n",
      "Epoch: 7328, Train Loss: 0.265, Validation Loss: 0.249\n",
      "Epoch: 7329, Train Loss: 0.221, Validation Loss: 0.246\n",
      "Epoch: 7330, Train Loss: 0.289, Validation Loss: 0.248\n",
      "Epoch: 7331, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 7332, Train Loss: 0.196, Validation Loss: 0.249\n",
      "Epoch: 7333, Train Loss: 0.261, Validation Loss: 0.247\n",
      "Epoch: 7334, Train Loss: 0.222, Validation Loss: 0.246\n",
      "Epoch: 7335, Train Loss: 0.189, Validation Loss: 0.251\n",
      "Epoch: 7336, Train Loss: 0.432, Validation Loss: 0.255\n",
      "Epoch: 7337, Train Loss: 0.215, Validation Loss: 0.251\n",
      "Epoch: 7338, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 7339, Train Loss: 0.429, Validation Loss: 0.247\n",
      "Epoch: 7340, Train Loss: 0.183, Validation Loss: 0.250\n",
      "Epoch: 7341, Train Loss: 0.225, Validation Loss: 0.250\n",
      "Epoch: 7342, Train Loss: 0.373, Validation Loss: 0.247\n",
      "Epoch: 7343, Train Loss: 0.327, Validation Loss: 0.251\n",
      "Epoch: 7344, Train Loss: 0.308, Validation Loss: 0.249\n",
      "Epoch: 7345, Train Loss: 0.201, Validation Loss: 0.248\n",
      "Epoch: 7346, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 7347, Train Loss: 0.224, Validation Loss: 0.253\n",
      "Epoch: 7348, Train Loss: 0.241, Validation Loss: 0.247\n",
      "Epoch: 7349, Train Loss: 0.285, Validation Loss: 0.250\n",
      "Epoch: 7350, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 7351, Train Loss: 0.270, Validation Loss: 0.245\n",
      "Epoch: 7352, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 7353, Train Loss: 0.214, Validation Loss: 0.246\n",
      "Epoch: 7354, Train Loss: 0.223, Validation Loss: 0.248\n",
      "Epoch: 7355, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 7356, Train Loss: 0.165, Validation Loss: 0.250\n",
      "Epoch: 7357, Train Loss: 0.248, Validation Loss: 0.248\n",
      "Epoch: 7358, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 7359, Train Loss: 0.202, Validation Loss: 0.247\n",
      "Epoch: 7360, Train Loss: 0.228, Validation Loss: 0.249\n",
      "Epoch: 7361, Train Loss: 0.247, Validation Loss: 0.251\n",
      "Epoch: 7362, Train Loss: 0.220, Validation Loss: 0.249\n",
      "Epoch: 7363, Train Loss: 0.295, Validation Loss: 0.254\n",
      "Epoch: 7364, Train Loss: 0.257, Validation Loss: 0.248\n",
      "Epoch: 7365, Train Loss: 0.274, Validation Loss: 0.247\n",
      "Epoch: 7366, Train Loss: 0.420, Validation Loss: 0.248\n",
      "Epoch: 7367, Train Loss: 0.360, Validation Loss: 0.248\n",
      "Epoch: 7368, Train Loss: 0.229, Validation Loss: 0.248\n",
      "Epoch: 7369, Train Loss: 0.298, Validation Loss: 0.246\n",
      "Epoch: 7370, Train Loss: 0.255, Validation Loss: 0.254\n",
      "Epoch: 7371, Train Loss: 0.269, Validation Loss: 0.252\n",
      "Epoch: 7372, Train Loss: 0.316, Validation Loss: 0.248\n",
      "Epoch: 7373, Train Loss: 0.342, Validation Loss: 0.245\n",
      "Epoch: 7374, Train Loss: 0.164, Validation Loss: 0.246\n",
      "Epoch: 7375, Train Loss: 0.434, Validation Loss: 0.244\n",
      "Epoch: 7376, Train Loss: 0.165, Validation Loss: 0.249\n",
      "Epoch: 7377, Train Loss: 0.219, Validation Loss: 0.249\n",
      "Epoch: 7378, Train Loss: 0.250, Validation Loss: 0.248\n",
      "Epoch: 7379, Train Loss: 0.291, Validation Loss: 0.249\n",
      "Epoch: 7380, Train Loss: 0.207, Validation Loss: 0.247\n",
      "Epoch: 7381, Train Loss: 0.144, Validation Loss: 0.246\n",
      "Epoch: 7382, Train Loss: 0.328, Validation Loss: 0.246\n",
      "Epoch: 7383, Train Loss: 0.225, Validation Loss: 0.249\n",
      "Epoch: 7384, Train Loss: 0.225, Validation Loss: 0.248\n",
      "Epoch: 7385, Train Loss: 0.295, Validation Loss: 0.245\n",
      "Epoch: 7386, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 7387, Train Loss: 0.269, Validation Loss: 0.248\n",
      "Epoch: 7388, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 7389, Train Loss: 0.268, Validation Loss: 0.249\n",
      "Epoch: 7390, Train Loss: 0.194, Validation Loss: 0.244\n",
      "Epoch: 7391, Train Loss: 0.404, Validation Loss: 0.245\n",
      "Epoch: 7392, Train Loss: 0.155, Validation Loss: 0.250\n",
      "Epoch: 7393, Train Loss: 0.255, Validation Loss: 0.250\n",
      "Epoch: 7394, Train Loss: 0.183, Validation Loss: 0.249\n",
      "Epoch: 7395, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 7396, Train Loss: 0.200, Validation Loss: 0.247\n",
      "Epoch: 7397, Train Loss: 0.253, Validation Loss: 0.248\n",
      "Epoch: 7398, Train Loss: 0.231, Validation Loss: 0.247\n",
      "Epoch: 7399, Train Loss: 0.177, Validation Loss: 0.245\n",
      "Epoch: 7400, Train Loss: 0.453, Validation Loss: 0.245\n",
      "Epoch: 7401, Train Loss: 0.213, Validation Loss: 0.245\n",
      "Epoch: 7402, Train Loss: 0.362, Validation Loss: 0.244\n",
      "Epoch: 7403, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 7404, Train Loss: 0.364, Validation Loss: 0.245\n",
      "Epoch: 7405, Train Loss: 0.246, Validation Loss: 0.246\n",
      "Epoch: 7406, Train Loss: 0.213, Validation Loss: 0.247\n",
      "Epoch: 7407, Train Loss: 0.401, Validation Loss: 0.249\n",
      "Epoch: 7408, Train Loss: 0.301, Validation Loss: 0.243\n",
      "Epoch: 7409, Train Loss: 0.243, Validation Loss: 0.244\n",
      "Epoch: 7410, Train Loss: 0.384, Validation Loss: 0.244\n",
      "Epoch: 7411, Train Loss: 0.192, Validation Loss: 0.245\n",
      "Epoch: 7412, Train Loss: 0.240, Validation Loss: 0.246\n",
      "Epoch: 7413, Train Loss: 0.199, Validation Loss: 0.247\n",
      "Epoch: 7414, Train Loss: 0.253, Validation Loss: 0.247\n",
      "Epoch: 7415, Train Loss: 0.246, Validation Loss: 0.254\n",
      "Epoch: 7416, Train Loss: 0.304, Validation Loss: 0.248\n",
      "Epoch: 7417, Train Loss: 0.180, Validation Loss: 0.250\n",
      "Epoch: 7418, Train Loss: 0.363, Validation Loss: 0.256\n",
      "Epoch: 7419, Train Loss: 0.278, Validation Loss: 0.254\n",
      "Epoch: 7420, Train Loss: 0.231, Validation Loss: 0.248\n",
      "Epoch: 7421, Train Loss: 0.308, Validation Loss: 0.246\n",
      "Epoch: 7422, Train Loss: 0.217, Validation Loss: 0.251\n",
      "Epoch: 7423, Train Loss: 0.421, Validation Loss: 0.250\n",
      "Epoch: 7424, Train Loss: 0.439, Validation Loss: 0.247\n",
      "Epoch: 7425, Train Loss: 0.301, Validation Loss: 0.247\n",
      "Epoch: 7426, Train Loss: 0.302, Validation Loss: 0.256\n",
      "Epoch: 7427, Train Loss: 0.297, Validation Loss: 0.248\n",
      "Epoch: 7428, Train Loss: 0.208, Validation Loss: 0.247\n",
      "Epoch: 7429, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 7430, Train Loss: 0.390, Validation Loss: 0.244\n",
      "Epoch: 7431, Train Loss: 0.248, Validation Loss: 0.248\n",
      "Epoch: 7432, Train Loss: 0.231, Validation Loss: 0.249\n",
      "Epoch: 7433, Train Loss: 0.275, Validation Loss: 0.251\n",
      "Epoch: 7434, Train Loss: 0.231, Validation Loss: 0.251\n",
      "Epoch: 7435, Train Loss: 0.185, Validation Loss: 0.247\n",
      "Epoch: 7436, Train Loss: 0.216, Validation Loss: 0.246\n",
      "Epoch: 7437, Train Loss: 0.211, Validation Loss: 0.246\n",
      "Epoch: 7438, Train Loss: 0.315, Validation Loss: 0.247\n",
      "Epoch: 7439, Train Loss: 0.153, Validation Loss: 0.247\n",
      "Epoch: 7440, Train Loss: 0.250, Validation Loss: 0.249\n",
      "Epoch: 7441, Train Loss: 0.243, Validation Loss: 0.247\n",
      "Epoch: 7442, Train Loss: 0.200, Validation Loss: 0.247\n",
      "Epoch: 7443, Train Loss: 0.272, Validation Loss: 0.246\n",
      "Epoch: 7444, Train Loss: 0.203, Validation Loss: 0.250\n",
      "Epoch: 7445, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 7446, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 7447, Train Loss: 0.377, Validation Loss: 0.246\n",
      "Epoch: 7448, Train Loss: 0.207, Validation Loss: 0.249\n",
      "Epoch: 7449, Train Loss: 0.168, Validation Loss: 0.248\n",
      "Epoch: 7450, Train Loss: 0.261, Validation Loss: 0.250\n",
      "Epoch: 7451, Train Loss: 0.382, Validation Loss: 0.251\n",
      "Epoch: 7452, Train Loss: 0.272, Validation Loss: 0.251\n",
      "Epoch: 7453, Train Loss: 0.342, Validation Loss: 0.247\n",
      "Epoch: 7454, Train Loss: 0.323, Validation Loss: 0.250\n",
      "Epoch: 7455, Train Loss: 0.245, Validation Loss: 0.249\n",
      "Epoch: 7456, Train Loss: 0.245, Validation Loss: 0.252\n",
      "Epoch: 7457, Train Loss: 0.197, Validation Loss: 0.249\n",
      "Epoch: 7458, Train Loss: 0.416, Validation Loss: 0.248\n",
      "Epoch: 7459, Train Loss: 0.273, Validation Loss: 0.250\n",
      "Epoch: 7460, Train Loss: 0.401, Validation Loss: 0.249\n",
      "Epoch: 7461, Train Loss: 0.480, Validation Loss: 0.248\n",
      "Epoch: 7462, Train Loss: 0.243, Validation Loss: 0.247\n",
      "Epoch: 7463, Train Loss: 0.182, Validation Loss: 0.248\n",
      "Epoch: 7464, Train Loss: 0.244, Validation Loss: 0.253\n",
      "Epoch: 7465, Train Loss: 0.291, Validation Loss: 0.249\n",
      "Epoch: 7466, Train Loss: 0.182, Validation Loss: 0.250\n",
      "Epoch: 7467, Train Loss: 0.229, Validation Loss: 0.247\n",
      "Epoch: 7468, Train Loss: 0.220, Validation Loss: 0.246\n",
      "Epoch: 7469, Train Loss: 0.178, Validation Loss: 0.246\n",
      "Epoch: 7470, Train Loss: 0.228, Validation Loss: 0.246\n",
      "Epoch: 7471, Train Loss: 0.252, Validation Loss: 0.245\n",
      "Epoch: 7472, Train Loss: 0.300, Validation Loss: 0.246\n",
      "Epoch: 7473, Train Loss: 0.346, Validation Loss: 0.253\n",
      "Epoch: 7474, Train Loss: 0.203, Validation Loss: 0.254\n",
      "Epoch: 7475, Train Loss: 0.289, Validation Loss: 0.246\n",
      "Epoch: 7476, Train Loss: 0.193, Validation Loss: 0.247\n",
      "Epoch: 7477, Train Loss: 0.309, Validation Loss: 0.252\n",
      "Epoch: 7478, Train Loss: 0.189, Validation Loss: 0.250\n",
      "Epoch: 7479, Train Loss: 0.433, Validation Loss: 0.258\n",
      "Epoch: 7480, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 7481, Train Loss: 0.448, Validation Loss: 0.249\n",
      "Epoch: 7482, Train Loss: 0.182, Validation Loss: 0.248\n",
      "Epoch: 7483, Train Loss: 0.234, Validation Loss: 0.248\n",
      "Epoch: 7484, Train Loss: 0.244, Validation Loss: 0.247\n",
      "Epoch: 7485, Train Loss: 0.211, Validation Loss: 0.245\n",
      "Epoch: 7486, Train Loss: 0.258, Validation Loss: 0.247\n",
      "Epoch: 7487, Train Loss: 0.279, Validation Loss: 0.248\n",
      "Epoch: 7488, Train Loss: 0.259, Validation Loss: 0.248\n",
      "Epoch: 7489, Train Loss: 0.388, Validation Loss: 0.255\n",
      "Epoch: 7490, Train Loss: 0.207, Validation Loss: 0.247\n",
      "Epoch: 7491, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 7492, Train Loss: 0.196, Validation Loss: 0.252\n",
      "Epoch: 7493, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 7494, Train Loss: 0.297, Validation Loss: 0.246\n",
      "Epoch: 7495, Train Loss: 0.281, Validation Loss: 0.251\n",
      "Epoch: 7496, Train Loss: 0.239, Validation Loss: 0.249\n",
      "Epoch: 7497, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 7498, Train Loss: 0.344, Validation Loss: 0.244\n",
      "Epoch: 7499, Train Loss: 0.177, Validation Loss: 0.244\n",
      "Epoch: 7500, Train Loss: 0.282, Validation Loss: 0.243\n",
      "Epoch: 7501, Train Loss: 0.297, Validation Loss: 0.251\n",
      "Epoch: 7502, Train Loss: 0.205, Validation Loss: 0.249\n",
      "Epoch: 7503, Train Loss: 0.400, Validation Loss: 0.254\n",
      "Epoch: 7504, Train Loss: 0.397, Validation Loss: 0.245\n",
      "Epoch: 7505, Train Loss: 0.281, Validation Loss: 0.248\n",
      "Epoch: 7506, Train Loss: 0.248, Validation Loss: 0.250\n",
      "Epoch: 7507, Train Loss: 0.245, Validation Loss: 0.246\n",
      "Epoch: 7508, Train Loss: 0.327, Validation Loss: 0.245\n",
      "Epoch: 7509, Train Loss: 0.318, Validation Loss: 0.248\n",
      "Epoch: 7510, Train Loss: 0.193, Validation Loss: 0.246\n",
      "Epoch: 7511, Train Loss: 0.216, Validation Loss: 0.248\n",
      "Epoch: 7512, Train Loss: 0.275, Validation Loss: 0.251\n",
      "Epoch: 7513, Train Loss: 0.281, Validation Loss: 0.251\n",
      "Epoch: 7514, Train Loss: 0.337, Validation Loss: 0.250\n",
      "Epoch: 7515, Train Loss: 0.202, Validation Loss: 0.250\n",
      "Epoch: 7516, Train Loss: 0.187, Validation Loss: 0.248\n",
      "Epoch: 7517, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 7518, Train Loss: 0.248, Validation Loss: 0.254\n",
      "Epoch: 7519, Train Loss: 0.227, Validation Loss: 0.250\n",
      "Epoch: 7520, Train Loss: 0.227, Validation Loss: 0.255\n",
      "Epoch: 7521, Train Loss: 0.214, Validation Loss: 0.255\n",
      "Epoch: 7522, Train Loss: 0.218, Validation Loss: 0.253\n",
      "Epoch: 7523, Train Loss: 0.208, Validation Loss: 0.251\n",
      "Epoch: 7524, Train Loss: 0.194, Validation Loss: 0.250\n",
      "Epoch: 7525, Train Loss: 0.287, Validation Loss: 0.252\n",
      "Epoch: 7526, Train Loss: 0.200, Validation Loss: 0.249\n",
      "Epoch: 7527, Train Loss: 0.201, Validation Loss: 0.248\n",
      "Epoch: 7528, Train Loss: 0.224, Validation Loss: 0.247\n",
      "Epoch: 7529, Train Loss: 0.272, Validation Loss: 0.250\n",
      "Epoch: 7530, Train Loss: 0.345, Validation Loss: 0.250\n",
      "Epoch: 7531, Train Loss: 0.185, Validation Loss: 0.246\n",
      "Epoch: 7532, Train Loss: 0.221, Validation Loss: 0.245\n",
      "Epoch: 7533, Train Loss: 0.179, Validation Loss: 0.247\n",
      "Epoch: 7534, Train Loss: 0.277, Validation Loss: 0.244\n",
      "Epoch: 7535, Train Loss: 0.306, Validation Loss: 0.254\n",
      "Epoch: 7536, Train Loss: 0.715, Validation Loss: 0.249\n",
      "Epoch: 7537, Train Loss: 0.395, Validation Loss: 0.247\n",
      "Epoch: 7538, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 7539, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 7540, Train Loss: 0.281, Validation Loss: 0.251\n",
      "Epoch: 7541, Train Loss: 0.532, Validation Loss: 0.249\n",
      "Epoch: 7542, Train Loss: 0.248, Validation Loss: 0.246\n",
      "Epoch: 7543, Train Loss: 0.335, Validation Loss: 0.247\n",
      "Epoch: 7544, Train Loss: 0.289, Validation Loss: 0.247\n",
      "Epoch: 7545, Train Loss: 0.244, Validation Loss: 0.254\n",
      "Epoch: 7546, Train Loss: 0.259, Validation Loss: 0.251\n",
      "Epoch: 7547, Train Loss: 0.161, Validation Loss: 0.252\n",
      "Epoch: 7548, Train Loss: 0.232, Validation Loss: 0.246\n",
      "Epoch: 7549, Train Loss: 0.261, Validation Loss: 0.246\n",
      "Epoch: 7550, Train Loss: 0.225, Validation Loss: 0.245\n",
      "Epoch: 7551, Train Loss: 0.205, Validation Loss: 0.247\n",
      "Epoch: 7552, Train Loss: 0.354, Validation Loss: 0.245\n",
      "Epoch: 7553, Train Loss: 0.187, Validation Loss: 0.250\n",
      "Epoch: 7554, Train Loss: 0.293, Validation Loss: 0.252\n",
      "Epoch: 7555, Train Loss: 0.458, Validation Loss: 0.248\n",
      "Epoch: 7556, Train Loss: 0.255, Validation Loss: 0.247\n",
      "Epoch: 7557, Train Loss: 0.263, Validation Loss: 0.247\n",
      "Epoch: 7558, Train Loss: 0.247, Validation Loss: 0.249\n",
      "Epoch: 7559, Train Loss: 0.185, Validation Loss: 0.248\n",
      "Epoch: 7560, Train Loss: 0.172, Validation Loss: 0.247\n",
      "Epoch: 7561, Train Loss: 0.260, Validation Loss: 0.254\n",
      "Epoch: 7562, Train Loss: 0.189, Validation Loss: 0.248\n",
      "Epoch: 7563, Train Loss: 0.133, Validation Loss: 0.246\n",
      "Epoch: 7564, Train Loss: 0.671, Validation Loss: 0.250\n",
      "Epoch: 7565, Train Loss: 0.258, Validation Loss: 0.245\n",
      "Epoch: 7566, Train Loss: 0.261, Validation Loss: 0.250\n",
      "Epoch: 7567, Train Loss: 0.269, Validation Loss: 0.247\n",
      "Epoch: 7568, Train Loss: 0.204, Validation Loss: 0.246\n",
      "Epoch: 7569, Train Loss: 0.219, Validation Loss: 0.246\n",
      "Epoch: 7570, Train Loss: 0.237, Validation Loss: 0.247\n",
      "Epoch: 7571, Train Loss: 0.220, Validation Loss: 0.249\n",
      "Epoch: 7572, Train Loss: 0.260, Validation Loss: 0.248\n",
      "Epoch: 7573, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 7574, Train Loss: 0.277, Validation Loss: 0.249\n",
      "Epoch: 7575, Train Loss: 0.263, Validation Loss: 0.247\n",
      "Epoch: 7576, Train Loss: 0.180, Validation Loss: 0.250\n",
      "Epoch: 7577, Train Loss: 0.238, Validation Loss: 0.248\n",
      "Epoch: 7578, Train Loss: 0.226, Validation Loss: 0.248\n",
      "Epoch: 7579, Train Loss: 0.252, Validation Loss: 0.248\n",
      "Epoch: 7580, Train Loss: 0.266, Validation Loss: 0.247\n",
      "Epoch: 7581, Train Loss: 0.239, Validation Loss: 0.247\n",
      "Epoch: 7582, Train Loss: 0.443, Validation Loss: 0.255\n",
      "Epoch: 7583, Train Loss: 0.233, Validation Loss: 0.247\n",
      "Epoch: 7584, Train Loss: 0.203, Validation Loss: 0.247\n",
      "Epoch: 7585, Train Loss: 0.250, Validation Loss: 0.248\n",
      "Epoch: 7586, Train Loss: 0.255, Validation Loss: 0.245\n",
      "Epoch: 7587, Train Loss: 0.196, Validation Loss: 0.245\n",
      "Epoch: 7588, Train Loss: 0.244, Validation Loss: 0.245\n",
      "Epoch: 7589, Train Loss: 0.241, Validation Loss: 0.249\n",
      "Epoch: 7590, Train Loss: 0.340, Validation Loss: 0.246\n",
      "Epoch: 7591, Train Loss: 0.479, Validation Loss: 0.248\n",
      "Epoch: 7592, Train Loss: 0.273, Validation Loss: 0.248\n",
      "Epoch: 7593, Train Loss: 0.300, Validation Loss: 0.252\n",
      "Epoch: 7594, Train Loss: 0.305, Validation Loss: 0.251\n",
      "Epoch: 7595, Train Loss: 0.218, Validation Loss: 0.248\n",
      "Epoch: 7596, Train Loss: 0.291, Validation Loss: 0.250\n",
      "Epoch: 7597, Train Loss: 0.322, Validation Loss: 0.251\n",
      "Epoch: 7598, Train Loss: 0.324, Validation Loss: 0.245\n",
      "Epoch: 7599, Train Loss: 0.192, Validation Loss: 0.245\n",
      "Epoch: 7600, Train Loss: 0.209, Validation Loss: 0.249\n",
      "Epoch: 7601, Train Loss: 0.279, Validation Loss: 0.247\n",
      "Epoch: 7602, Train Loss: 0.285, Validation Loss: 0.252\n",
      "Epoch: 7603, Train Loss: 0.356, Validation Loss: 0.247\n",
      "Epoch: 7604, Train Loss: 0.169, Validation Loss: 0.251\n",
      "Epoch: 7605, Train Loss: 0.176, Validation Loss: 0.256\n",
      "Epoch: 7606, Train Loss: 0.588, Validation Loss: 0.251\n",
      "Epoch: 7607, Train Loss: 0.622, Validation Loss: 0.247\n",
      "Epoch: 7608, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 7609, Train Loss: 0.264, Validation Loss: 0.248\n",
      "Epoch: 7610, Train Loss: 0.249, Validation Loss: 0.252\n",
      "Epoch: 7611, Train Loss: 0.181, Validation Loss: 0.247\n",
      "Epoch: 7612, Train Loss: 0.466, Validation Loss: 0.248\n",
      "Epoch: 7613, Train Loss: 0.262, Validation Loss: 0.245\n",
      "Epoch: 7614, Train Loss: 0.263, Validation Loss: 0.245\n",
      "Epoch: 7615, Train Loss: 0.218, Validation Loss: 0.247\n",
      "Epoch: 7616, Train Loss: 0.422, Validation Loss: 0.248\n",
      "Epoch: 7617, Train Loss: 0.278, Validation Loss: 0.249\n",
      "Epoch: 7618, Train Loss: 0.174, Validation Loss: 0.244\n",
      "Epoch: 7619, Train Loss: 0.477, Validation Loss: 0.247\n",
      "Epoch: 7620, Train Loss: 0.564, Validation Loss: 0.247\n",
      "Epoch: 7621, Train Loss: 0.228, Validation Loss: 0.246\n",
      "Epoch: 7622, Train Loss: 0.275, Validation Loss: 0.256\n",
      "Epoch: 7623, Train Loss: 0.277, Validation Loss: 0.257\n",
      "Epoch: 7624, Train Loss: 0.253, Validation Loss: 0.256\n",
      "Epoch: 7625, Train Loss: 0.238, Validation Loss: 0.248\n",
      "Epoch: 7626, Train Loss: 0.486, Validation Loss: 0.248\n",
      "Epoch: 7627, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 7628, Train Loss: 0.301, Validation Loss: 0.248\n",
      "Epoch: 7629, Train Loss: 0.202, Validation Loss: 0.254\n",
      "Epoch: 7630, Train Loss: 0.317, Validation Loss: 0.253\n",
      "Epoch: 7631, Train Loss: 0.158, Validation Loss: 0.251\n",
      "Epoch: 7632, Train Loss: 0.199, Validation Loss: 0.252\n",
      "Epoch: 7633, Train Loss: 0.260, Validation Loss: 0.256\n",
      "Epoch: 7634, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 7635, Train Loss: 0.264, Validation Loss: 0.251\n",
      "Epoch: 7636, Train Loss: 0.537, Validation Loss: 0.248\n",
      "Epoch: 7637, Train Loss: 0.267, Validation Loss: 0.254\n",
      "Epoch: 7638, Train Loss: 0.223, Validation Loss: 0.253\n",
      "Epoch: 7639, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 7640, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 7641, Train Loss: 0.188, Validation Loss: 0.250\n",
      "Epoch: 7642, Train Loss: 0.208, Validation Loss: 0.247\n",
      "Epoch: 7643, Train Loss: 0.294, Validation Loss: 0.246\n",
      "Epoch: 7644, Train Loss: 0.267, Validation Loss: 0.247\n",
      "Epoch: 7645, Train Loss: 0.268, Validation Loss: 0.250\n",
      "Epoch: 7646, Train Loss: 0.201, Validation Loss: 0.254\n",
      "Epoch: 7647, Train Loss: 0.287, Validation Loss: 0.253\n",
      "Epoch: 7648, Train Loss: 0.354, Validation Loss: 0.251\n",
      "Epoch: 7649, Train Loss: 0.389, Validation Loss: 0.245\n",
      "Epoch: 7650, Train Loss: 0.164, Validation Loss: 0.246\n",
      "Epoch: 7651, Train Loss: 0.254, Validation Loss: 0.246\n",
      "Epoch: 7652, Train Loss: 0.299, Validation Loss: 0.248\n",
      "Epoch: 7653, Train Loss: 0.234, Validation Loss: 0.251\n",
      "Epoch: 7654, Train Loss: 0.187, Validation Loss: 0.246\n",
      "Epoch: 7655, Train Loss: 0.232, Validation Loss: 0.246\n",
      "Epoch: 7656, Train Loss: 0.169, Validation Loss: 0.247\n",
      "Epoch: 7657, Train Loss: 0.475, Validation Loss: 0.244\n",
      "Epoch: 7658, Train Loss: 0.245, Validation Loss: 0.247\n",
      "Epoch: 7659, Train Loss: 0.467, Validation Loss: 0.248\n",
      "Epoch: 7660, Train Loss: 0.271, Validation Loss: 0.248\n",
      "Epoch: 7661, Train Loss: 0.309, Validation Loss: 0.249\n",
      "Epoch: 7662, Train Loss: 0.266, Validation Loss: 0.245\n",
      "Epoch: 7663, Train Loss: 0.352, Validation Loss: 0.244\n",
      "Epoch: 7664, Train Loss: 0.183, Validation Loss: 0.247\n",
      "Epoch: 7665, Train Loss: 0.313, Validation Loss: 0.251\n",
      "Epoch: 7666, Train Loss: 0.268, Validation Loss: 0.249\n",
      "Epoch: 7667, Train Loss: 0.232, Validation Loss: 0.247\n",
      "Epoch: 7668, Train Loss: 0.172, Validation Loss: 0.250\n",
      "Epoch: 7669, Train Loss: 0.271, Validation Loss: 0.247\n",
      "Epoch: 7670, Train Loss: 0.223, Validation Loss: 0.251\n",
      "Epoch: 7671, Train Loss: 0.246, Validation Loss: 0.244\n",
      "Epoch: 7672, Train Loss: 0.204, Validation Loss: 0.245\n",
      "Epoch: 7673, Train Loss: 0.301, Validation Loss: 0.244\n",
      "Epoch: 7674, Train Loss: 0.262, Validation Loss: 0.247\n",
      "Epoch: 7675, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 7676, Train Loss: 0.336, Validation Loss: 0.248\n",
      "Epoch: 7677, Train Loss: 0.179, Validation Loss: 0.250\n",
      "Epoch: 7678, Train Loss: 0.241, Validation Loss: 0.248\n",
      "Epoch: 7679, Train Loss: 0.210, Validation Loss: 0.244\n",
      "Epoch: 7680, Train Loss: 0.212, Validation Loss: 0.244\n",
      "Epoch: 7681, Train Loss: 0.239, Validation Loss: 0.249\n",
      "Epoch: 7682, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 7683, Train Loss: 0.258, Validation Loss: 0.250\n",
      "Epoch: 7684, Train Loss: 0.151, Validation Loss: 0.247\n",
      "Epoch: 7685, Train Loss: 0.242, Validation Loss: 0.245\n",
      "Epoch: 7686, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 7687, Train Loss: 0.315, Validation Loss: 0.248\n",
      "Epoch: 7688, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 7689, Train Loss: 0.155, Validation Loss: 0.247\n",
      "Epoch: 7690, Train Loss: 0.326, Validation Loss: 0.250\n",
      "Epoch: 7691, Train Loss: 0.631, Validation Loss: 0.249\n",
      "Epoch: 7692, Train Loss: 0.407, Validation Loss: 0.248\n",
      "Epoch: 7693, Train Loss: 0.371, Validation Loss: 0.247\n",
      "Epoch: 7694, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 7695, Train Loss: 0.267, Validation Loss: 0.252\n",
      "Epoch: 7696, Train Loss: 0.199, Validation Loss: 0.251\n",
      "Epoch: 7697, Train Loss: 0.292, Validation Loss: 0.256\n",
      "Epoch: 7698, Train Loss: 0.446, Validation Loss: 0.248\n",
      "Epoch: 7699, Train Loss: 0.180, Validation Loss: 0.247\n",
      "Epoch: 7700, Train Loss: 0.551, Validation Loss: 0.247\n",
      "Epoch: 7701, Train Loss: 0.196, Validation Loss: 0.250\n",
      "Epoch: 7702, Train Loss: 0.288, Validation Loss: 0.250\n",
      "Epoch: 7703, Train Loss: 0.257, Validation Loss: 0.249\n",
      "Epoch: 7704, Train Loss: 0.266, Validation Loss: 0.247\n",
      "Epoch: 7705, Train Loss: 0.191, Validation Loss: 0.248\n",
      "Epoch: 7706, Train Loss: 0.163, Validation Loss: 0.250\n",
      "Epoch: 7707, Train Loss: 0.305, Validation Loss: 0.248\n",
      "Epoch: 7708, Train Loss: 0.300, Validation Loss: 0.248\n",
      "Epoch: 7709, Train Loss: 0.419, Validation Loss: 0.247\n",
      "Epoch: 7710, Train Loss: 0.230, Validation Loss: 0.247\n",
      "Epoch: 7711, Train Loss: 0.727, Validation Loss: 0.248\n",
      "Epoch: 7712, Train Loss: 0.211, Validation Loss: 0.246\n",
      "Epoch: 7713, Train Loss: 0.211, Validation Loss: 0.248\n",
      "Epoch: 7714, Train Loss: 0.215, Validation Loss: 0.251\n",
      "Epoch: 7715, Train Loss: 0.241, Validation Loss: 0.245\n",
      "Epoch: 7716, Train Loss: 0.459, Validation Loss: 0.246\n",
      "Epoch: 7717, Train Loss: 0.230, Validation Loss: 0.246\n",
      "Epoch: 7718, Train Loss: 0.164, Validation Loss: 0.246\n",
      "Epoch: 7719, Train Loss: 0.217, Validation Loss: 0.247\n",
      "Epoch: 7720, Train Loss: 0.193, Validation Loss: 0.248\n",
      "Epoch: 7721, Train Loss: 0.295, Validation Loss: 0.246\n",
      "Epoch: 7722, Train Loss: 0.261, Validation Loss: 0.246\n",
      "Epoch: 7723, Train Loss: 0.177, Validation Loss: 0.251\n",
      "Epoch: 7724, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 7725, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 7726, Train Loss: 0.292, Validation Loss: 0.249\n",
      "Epoch: 7727, Train Loss: 0.267, Validation Loss: 0.248\n",
      "Epoch: 7728, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 7729, Train Loss: 0.270, Validation Loss: 0.247\n",
      "Epoch: 7730, Train Loss: 0.196, Validation Loss: 0.254\n",
      "Epoch: 7731, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 7732, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 7733, Train Loss: 0.187, Validation Loss: 0.250\n",
      "Epoch: 7734, Train Loss: 0.201, Validation Loss: 0.250\n",
      "Epoch: 7735, Train Loss: 0.616, Validation Loss: 0.246\n",
      "Epoch: 7736, Train Loss: 0.293, Validation Loss: 0.251\n",
      "Epoch: 7737, Train Loss: 0.155, Validation Loss: 0.250\n",
      "Epoch: 7738, Train Loss: 0.240, Validation Loss: 0.250\n",
      "Epoch: 7739, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 7740, Train Loss: 0.237, Validation Loss: 0.249\n",
      "Epoch: 7741, Train Loss: 0.254, Validation Loss: 0.248\n",
      "Epoch: 7742, Train Loss: 0.202, Validation Loss: 0.247\n",
      "Epoch: 7743, Train Loss: 0.265, Validation Loss: 0.255\n",
      "Epoch: 7744, Train Loss: 0.190, Validation Loss: 0.250\n",
      "Epoch: 7745, Train Loss: 0.270, Validation Loss: 0.248\n",
      "Epoch: 7746, Train Loss: 0.224, Validation Loss: 0.253\n",
      "Epoch: 7747, Train Loss: 0.297, Validation Loss: 0.258\n",
      "Epoch: 7748, Train Loss: 0.219, Validation Loss: 0.255\n",
      "Epoch: 7749, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 7750, Train Loss: 0.353, Validation Loss: 0.248\n",
      "Epoch: 7751, Train Loss: 0.268, Validation Loss: 0.248\n",
      "Epoch: 7752, Train Loss: 0.271, Validation Loss: 0.252\n",
      "Epoch: 7753, Train Loss: 0.129, Validation Loss: 0.245\n",
      "Epoch: 7754, Train Loss: 0.492, Validation Loss: 0.243\n",
      "Epoch: 7755, Train Loss: 0.540, Validation Loss: 0.244\n",
      "Epoch: 7756, Train Loss: 0.236, Validation Loss: 0.247\n",
      "Epoch: 7757, Train Loss: 0.223, Validation Loss: 0.250\n",
      "Epoch: 7758, Train Loss: 0.444, Validation Loss: 0.249\n",
      "Epoch: 7759, Train Loss: 0.300, Validation Loss: 0.247\n",
      "Epoch: 7760, Train Loss: 0.295, Validation Loss: 0.245\n",
      "Epoch: 7761, Train Loss: 0.283, Validation Loss: 0.248\n",
      "Epoch: 7762, Train Loss: 0.165, Validation Loss: 0.247\n",
      "Epoch: 7763, Train Loss: 0.270, Validation Loss: 0.246\n",
      "Epoch: 7764, Train Loss: 0.267, Validation Loss: 0.245\n",
      "Epoch: 7765, Train Loss: 0.234, Validation Loss: 0.250\n",
      "Epoch: 7766, Train Loss: 0.210, Validation Loss: 0.247\n",
      "Epoch: 7767, Train Loss: 0.244, Validation Loss: 0.244\n",
      "Epoch: 7768, Train Loss: 0.223, Validation Loss: 0.246\n",
      "Epoch: 7769, Train Loss: 0.216, Validation Loss: 0.250\n",
      "Epoch: 7770, Train Loss: 0.203, Validation Loss: 0.248\n",
      "Epoch: 7771, Train Loss: 0.566, Validation Loss: 0.245\n",
      "Epoch: 7772, Train Loss: 0.295, Validation Loss: 0.244\n",
      "Epoch: 7773, Train Loss: 0.487, Validation Loss: 0.247\n",
      "Epoch: 7774, Train Loss: 0.417, Validation Loss: 0.250\n",
      "Epoch: 7775, Train Loss: 0.262, Validation Loss: 0.245\n",
      "Epoch: 7776, Train Loss: 0.493, Validation Loss: 0.245\n",
      "Epoch: 7777, Train Loss: 0.276, Validation Loss: 0.245\n",
      "Epoch: 7778, Train Loss: 0.468, Validation Loss: 0.249\n",
      "Epoch: 7779, Train Loss: 0.255, Validation Loss: 0.248\n",
      "Epoch: 7780, Train Loss: 0.453, Validation Loss: 0.250\n",
      "Epoch: 7781, Train Loss: 0.212, Validation Loss: 0.245\n",
      "Epoch: 7782, Train Loss: 0.228, Validation Loss: 0.247\n",
      "Epoch: 7783, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 7784, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 7785, Train Loss: 0.278, Validation Loss: 0.250\n",
      "Epoch: 7786, Train Loss: 0.211, Validation Loss: 0.251\n",
      "Epoch: 7787, Train Loss: 0.239, Validation Loss: 0.249\n",
      "Epoch: 7788, Train Loss: 0.246, Validation Loss: 0.248\n",
      "Epoch: 7789, Train Loss: 0.249, Validation Loss: 0.247\n",
      "Epoch: 7790, Train Loss: 0.511, Validation Loss: 0.247\n",
      "Epoch: 7791, Train Loss: 0.374, Validation Loss: 0.250\n",
      "Epoch: 7792, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 7793, Train Loss: 0.364, Validation Loss: 0.248\n",
      "Epoch: 7794, Train Loss: 0.394, Validation Loss: 0.251\n",
      "Epoch: 7795, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 7796, Train Loss: 0.186, Validation Loss: 0.247\n",
      "Epoch: 7797, Train Loss: 0.285, Validation Loss: 0.250\n",
      "Epoch: 7798, Train Loss: 0.225, Validation Loss: 0.247\n",
      "Epoch: 7799, Train Loss: 0.215, Validation Loss: 0.250\n",
      "Epoch: 7800, Train Loss: 0.241, Validation Loss: 0.248\n",
      "Epoch: 7801, Train Loss: 0.198, Validation Loss: 0.248\n",
      "Epoch: 7802, Train Loss: 0.264, Validation Loss: 0.248\n",
      "Epoch: 7803, Train Loss: 0.294, Validation Loss: 0.247\n",
      "Epoch: 7804, Train Loss: 0.217, Validation Loss: 0.248\n",
      "Epoch: 7805, Train Loss: 0.331, Validation Loss: 0.249\n",
      "Epoch: 7806, Train Loss: 0.258, Validation Loss: 0.249\n",
      "Epoch: 7807, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 7808, Train Loss: 0.283, Validation Loss: 0.245\n",
      "Epoch: 7809, Train Loss: 0.292, Validation Loss: 0.249\n",
      "Epoch: 7810, Train Loss: 0.280, Validation Loss: 0.252\n",
      "Epoch: 7811, Train Loss: 0.315, Validation Loss: 0.253\n",
      "Epoch: 7812, Train Loss: 0.179, Validation Loss: 0.249\n",
      "Epoch: 7813, Train Loss: 0.204, Validation Loss: 0.247\n",
      "Epoch: 7814, Train Loss: 0.255, Validation Loss: 0.247\n",
      "Epoch: 7815, Train Loss: 0.295, Validation Loss: 0.247\n",
      "Epoch: 7816, Train Loss: 0.375, Validation Loss: 0.246\n",
      "Epoch: 7817, Train Loss: 0.331, Validation Loss: 0.246\n",
      "Epoch: 7818, Train Loss: 0.207, Validation Loss: 0.247\n",
      "Epoch: 7819, Train Loss: 0.254, Validation Loss: 0.248\n",
      "Epoch: 7820, Train Loss: 0.256, Validation Loss: 0.246\n",
      "Epoch: 7821, Train Loss: 0.193, Validation Loss: 0.248\n",
      "Epoch: 7822, Train Loss: 0.286, Validation Loss: 0.248\n",
      "Epoch: 7823, Train Loss: 0.225, Validation Loss: 0.247\n",
      "Epoch: 7824, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 7825, Train Loss: 0.376, Validation Loss: 0.247\n",
      "Epoch: 7826, Train Loss: 0.359, Validation Loss: 0.244\n",
      "Epoch: 7827, Train Loss: 0.275, Validation Loss: 0.246\n",
      "Epoch: 7828, Train Loss: 0.293, Validation Loss: 0.246\n",
      "Epoch: 7829, Train Loss: 0.463, Validation Loss: 0.249\n",
      "Epoch: 7830, Train Loss: 0.180, Validation Loss: 0.247\n",
      "Epoch: 7831, Train Loss: 0.295, Validation Loss: 0.248\n",
      "Epoch: 7832, Train Loss: 0.171, Validation Loss: 0.245\n",
      "Epoch: 7833, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 7834, Train Loss: 0.265, Validation Loss: 0.252\n",
      "Epoch: 7835, Train Loss: 0.242, Validation Loss: 0.250\n",
      "Epoch: 7836, Train Loss: 0.246, Validation Loss: 0.252\n",
      "Epoch: 7837, Train Loss: 0.280, Validation Loss: 0.256\n",
      "Epoch: 7838, Train Loss: 0.368, Validation Loss: 0.244\n",
      "Epoch: 7839, Train Loss: 0.250, Validation Loss: 0.244\n",
      "Epoch: 7840, Train Loss: 0.308, Validation Loss: 0.245\n",
      "Epoch: 7841, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 7842, Train Loss: 0.419, Validation Loss: 0.244\n",
      "Epoch: 7843, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 7844, Train Loss: 0.204, Validation Loss: 0.249\n",
      "Epoch: 7845, Train Loss: 0.383, Validation Loss: 0.250\n",
      "Epoch: 7846, Train Loss: 0.199, Validation Loss: 0.247\n",
      "Epoch: 7847, Train Loss: 0.610, Validation Loss: 0.244\n",
      "Epoch: 7848, Train Loss: 0.239, Validation Loss: 0.246\n",
      "Epoch: 7849, Train Loss: 0.230, Validation Loss: 0.248\n",
      "Epoch: 7850, Train Loss: 0.306, Validation Loss: 0.249\n",
      "Epoch: 7851, Train Loss: 0.190, Validation Loss: 0.245\n",
      "Epoch: 7852, Train Loss: 0.273, Validation Loss: 0.246\n",
      "Epoch: 7853, Train Loss: 0.440, Validation Loss: 0.247\n",
      "Epoch: 7854, Train Loss: 0.203, Validation Loss: 0.245\n",
      "Epoch: 7855, Train Loss: 0.341, Validation Loss: 0.245\n",
      "Epoch: 7856, Train Loss: 0.264, Validation Loss: 0.248\n",
      "Epoch: 7857, Train Loss: 0.193, Validation Loss: 0.251\n",
      "Epoch: 7858, Train Loss: 0.207, Validation Loss: 0.245\n",
      "Epoch: 7859, Train Loss: 0.335, Validation Loss: 0.246\n",
      "Epoch: 7860, Train Loss: 0.217, Validation Loss: 0.247\n",
      "Epoch: 7861, Train Loss: 0.300, Validation Loss: 0.246\n",
      "Epoch: 7862, Train Loss: 0.228, Validation Loss: 0.247\n",
      "Epoch: 7863, Train Loss: 0.315, Validation Loss: 0.251\n",
      "Epoch: 7864, Train Loss: 0.276, Validation Loss: 0.246\n",
      "Epoch: 7865, Train Loss: 0.387, Validation Loss: 0.249\n",
      "Epoch: 7866, Train Loss: 0.235, Validation Loss: 0.247\n",
      "Epoch: 7867, Train Loss: 0.289, Validation Loss: 0.244\n",
      "Epoch: 7868, Train Loss: 0.311, Validation Loss: 0.247\n",
      "Epoch: 7869, Train Loss: 0.430, Validation Loss: 0.244\n",
      "Epoch: 7870, Train Loss: 0.279, Validation Loss: 0.248\n",
      "Epoch: 7871, Train Loss: 0.367, Validation Loss: 0.248\n",
      "Epoch: 7872, Train Loss: 0.327, Validation Loss: 0.245\n",
      "Epoch: 7873, Train Loss: 0.180, Validation Loss: 0.247\n",
      "Epoch: 7874, Train Loss: 0.219, Validation Loss: 0.246\n",
      "Epoch: 7875, Train Loss: 0.331, Validation Loss: 0.244\n",
      "Epoch: 7876, Train Loss: 0.261, Validation Loss: 0.250\n",
      "Epoch: 7877, Train Loss: 0.389, Validation Loss: 0.248\n",
      "Epoch: 7878, Train Loss: 0.508, Validation Loss: 0.247\n",
      "Epoch: 7879, Train Loss: 0.236, Validation Loss: 0.246\n",
      "Epoch: 7880, Train Loss: 0.417, Validation Loss: 0.252\n",
      "Epoch: 7881, Train Loss: 0.353, Validation Loss: 0.245\n",
      "Epoch: 7882, Train Loss: 0.278, Validation Loss: 0.245\n",
      "Epoch: 7883, Train Loss: 0.183, Validation Loss: 0.251\n",
      "Epoch: 7884, Train Loss: 0.215, Validation Loss: 0.249\n",
      "Epoch: 7885, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 7886, Train Loss: 0.337, Validation Loss: 0.254\n",
      "Epoch: 7887, Train Loss: 0.488, Validation Loss: 0.250\n",
      "Epoch: 7888, Train Loss: 0.360, Validation Loss: 0.248\n",
      "Epoch: 7889, Train Loss: 0.244, Validation Loss: 0.253\n",
      "Epoch: 7890, Train Loss: 0.213, Validation Loss: 0.253\n",
      "Epoch: 7891, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 7892, Train Loss: 0.273, Validation Loss: 0.246\n",
      "Epoch: 7893, Train Loss: 0.210, Validation Loss: 0.246\n",
      "Epoch: 7894, Train Loss: 0.288, Validation Loss: 0.247\n",
      "Epoch: 7895, Train Loss: 0.243, Validation Loss: 0.248\n",
      "Epoch: 7896, Train Loss: 0.196, Validation Loss: 0.250\n",
      "Epoch: 7897, Train Loss: 0.367, Validation Loss: 0.248\n",
      "Epoch: 7898, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 7899, Train Loss: 0.355, Validation Loss: 0.245\n",
      "Epoch: 7900, Train Loss: 0.237, Validation Loss: 0.247\n",
      "Epoch: 7901, Train Loss: 0.225, Validation Loss: 0.251\n",
      "Epoch: 7902, Train Loss: 0.232, Validation Loss: 0.248\n",
      "Epoch: 7903, Train Loss: 0.258, Validation Loss: 0.247\n",
      "Epoch: 7904, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 7905, Train Loss: 0.224, Validation Loss: 0.249\n",
      "Epoch: 7906, Train Loss: 0.326, Validation Loss: 0.253\n",
      "Epoch: 7907, Train Loss: 0.233, Validation Loss: 0.252\n",
      "Epoch: 7908, Train Loss: 0.407, Validation Loss: 0.249\n",
      "Epoch: 7909, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 7910, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 7911, Train Loss: 0.218, Validation Loss: 0.251\n",
      "Epoch: 7912, Train Loss: 0.207, Validation Loss: 0.249\n",
      "Epoch: 7913, Train Loss: 0.170, Validation Loss: 0.252\n",
      "Epoch: 7914, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 7915, Train Loss: 0.445, Validation Loss: 0.248\n",
      "Epoch: 7916, Train Loss: 0.277, Validation Loss: 0.249\n",
      "Epoch: 7917, Train Loss: 0.186, Validation Loss: 0.248\n",
      "Epoch: 7918, Train Loss: 0.192, Validation Loss: 0.251\n",
      "Epoch: 7919, Train Loss: 0.193, Validation Loss: 0.253\n",
      "Epoch: 7920, Train Loss: 0.242, Validation Loss: 0.254\n",
      "Epoch: 7921, Train Loss: 0.200, Validation Loss: 0.249\n",
      "Epoch: 7922, Train Loss: 0.300, Validation Loss: 0.250\n",
      "Epoch: 7923, Train Loss: 0.214, Validation Loss: 0.253\n",
      "Epoch: 7924, Train Loss: 0.359, Validation Loss: 0.249\n",
      "Epoch: 7925, Train Loss: 0.188, Validation Loss: 0.245\n",
      "Epoch: 7926, Train Loss: 0.288, Validation Loss: 0.243\n",
      "Epoch: 7927, Train Loss: 0.343, Validation Loss: 0.247\n",
      "Epoch: 7928, Train Loss: 0.200, Validation Loss: 0.248\n",
      "Epoch: 7929, Train Loss: 0.254, Validation Loss: 0.252\n",
      "Epoch: 7930, Train Loss: 0.289, Validation Loss: 0.250\n",
      "Epoch: 7931, Train Loss: 0.239, Validation Loss: 0.250\n",
      "Epoch: 7932, Train Loss: 0.451, Validation Loss: 0.246\n",
      "Epoch: 7933, Train Loss: 0.232, Validation Loss: 0.248\n",
      "Epoch: 7934, Train Loss: 0.173, Validation Loss: 0.246\n",
      "Epoch: 7935, Train Loss: 0.267, Validation Loss: 0.245\n",
      "Epoch: 7936, Train Loss: 0.195, Validation Loss: 0.245\n",
      "Epoch: 7937, Train Loss: 0.146, Validation Loss: 0.245\n",
      "Epoch: 7938, Train Loss: 0.205, Validation Loss: 0.248\n",
      "Epoch: 7939, Train Loss: 0.194, Validation Loss: 0.250\n",
      "Epoch: 7940, Train Loss: 0.185, Validation Loss: 0.252\n",
      "Epoch: 7941, Train Loss: 0.224, Validation Loss: 0.252\n",
      "Epoch: 7942, Train Loss: 0.289, Validation Loss: 0.249\n",
      "Epoch: 7943, Train Loss: 0.191, Validation Loss: 0.247\n",
      "Epoch: 7944, Train Loss: 0.210, Validation Loss: 0.244\n",
      "Epoch: 7945, Train Loss: 0.399, Validation Loss: 0.244\n",
      "Epoch: 7946, Train Loss: 0.499, Validation Loss: 0.249\n",
      "Epoch: 7947, Train Loss: 0.227, Validation Loss: 0.245\n",
      "Epoch: 7948, Train Loss: 0.153, Validation Loss: 0.245\n",
      "Epoch: 7949, Train Loss: 0.200, Validation Loss: 0.246\n",
      "Epoch: 7950, Train Loss: 0.404, Validation Loss: 0.245\n",
      "Epoch: 7951, Train Loss: 0.214, Validation Loss: 0.248\n",
      "Epoch: 7952, Train Loss: 0.283, Validation Loss: 0.245\n",
      "Epoch: 7953, Train Loss: 0.225, Validation Loss: 0.246\n",
      "Epoch: 7954, Train Loss: 0.171, Validation Loss: 0.250\n",
      "Epoch: 7955, Train Loss: 0.279, Validation Loss: 0.255\n",
      "Epoch: 7956, Train Loss: 0.208, Validation Loss: 0.254\n",
      "Epoch: 7957, Train Loss: 0.286, Validation Loss: 0.249\n",
      "Epoch: 7958, Train Loss: 0.309, Validation Loss: 0.253\n",
      "Epoch: 7959, Train Loss: 0.529, Validation Loss: 0.249\n",
      "Epoch: 7960, Train Loss: 0.182, Validation Loss: 0.245\n",
      "Epoch: 7961, Train Loss: 0.257, Validation Loss: 0.247\n",
      "Epoch: 7962, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 7963, Train Loss: 0.227, Validation Loss: 0.252\n",
      "Epoch: 7964, Train Loss: 0.259, Validation Loss: 0.254\n",
      "Epoch: 7965, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 7966, Train Loss: 0.256, Validation Loss: 0.248\n",
      "Epoch: 7967, Train Loss: 0.394, Validation Loss: 0.247\n",
      "Epoch: 7968, Train Loss: 0.234, Validation Loss: 0.247\n",
      "Epoch: 7969, Train Loss: 0.376, Validation Loss: 0.249\n",
      "Epoch: 7970, Train Loss: 0.166, Validation Loss: 0.251\n",
      "Epoch: 7971, Train Loss: 0.272, Validation Loss: 0.248\n",
      "Epoch: 7972, Train Loss: 0.205, Validation Loss: 0.246\n",
      "Epoch: 7973, Train Loss: 0.265, Validation Loss: 0.249\n",
      "Epoch: 7974, Train Loss: 0.249, Validation Loss: 0.245\n",
      "Epoch: 7975, Train Loss: 0.236, Validation Loss: 0.245\n",
      "Epoch: 7976, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 7977, Train Loss: 0.191, Validation Loss: 0.250\n",
      "Epoch: 7978, Train Loss: 0.259, Validation Loss: 0.247\n",
      "Epoch: 7979, Train Loss: 0.315, Validation Loss: 0.252\n",
      "Epoch: 7980, Train Loss: 0.217, Validation Loss: 0.247\n",
      "Epoch: 7981, Train Loss: 0.251, Validation Loss: 0.249\n",
      "Epoch: 7982, Train Loss: 0.206, Validation Loss: 0.246\n",
      "Epoch: 7983, Train Loss: 0.303, Validation Loss: 0.248\n",
      "Epoch: 7984, Train Loss: 0.295, Validation Loss: 0.251\n",
      "Epoch: 7985, Train Loss: 0.220, Validation Loss: 0.248\n",
      "Epoch: 7986, Train Loss: 0.259, Validation Loss: 0.247\n",
      "Epoch: 7987, Train Loss: 0.215, Validation Loss: 0.247\n",
      "Epoch: 7988, Train Loss: 0.609, Validation Loss: 0.250\n",
      "Epoch: 7989, Train Loss: 0.361, Validation Loss: 0.248\n",
      "Epoch: 7990, Train Loss: 0.271, Validation Loss: 0.253\n",
      "Epoch: 7991, Train Loss: 0.210, Validation Loss: 0.253\n",
      "Epoch: 7992, Train Loss: 0.325, Validation Loss: 0.252\n",
      "Epoch: 7993, Train Loss: 0.454, Validation Loss: 0.248\n",
      "Epoch: 7994, Train Loss: 0.350, Validation Loss: 0.248\n",
      "Epoch: 7995, Train Loss: 0.169, Validation Loss: 0.248\n",
      "Epoch: 7996, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 7997, Train Loss: 0.360, Validation Loss: 0.248\n",
      "Epoch: 7998, Train Loss: 0.537, Validation Loss: 0.249\n",
      "Epoch: 7999, Train Loss: 0.455, Validation Loss: 0.246\n",
      "Epoch: 8000, Train Loss: 0.298, Validation Loss: 0.253\n",
      "Epoch: 8001, Train Loss: 0.230, Validation Loss: 0.250\n",
      "Epoch: 8002, Train Loss: 0.241, Validation Loss: 0.249\n",
      "Epoch: 8003, Train Loss: 0.276, Validation Loss: 0.254\n",
      "Epoch: 8004, Train Loss: 0.245, Validation Loss: 0.252\n",
      "Epoch: 8005, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 8006, Train Loss: 0.291, Validation Loss: 0.250\n",
      "Epoch: 8007, Train Loss: 0.297, Validation Loss: 0.246\n",
      "Epoch: 8008, Train Loss: 0.198, Validation Loss: 0.251\n",
      "Epoch: 8009, Train Loss: 0.332, Validation Loss: 0.250\n",
      "Epoch: 8010, Train Loss: 0.392, Validation Loss: 0.253\n",
      "Epoch: 8011, Train Loss: 0.440, Validation Loss: 0.255\n",
      "Epoch: 8012, Train Loss: 0.222, Validation Loss: 0.251\n",
      "Epoch: 8013, Train Loss: 0.293, Validation Loss: 0.248\n",
      "Epoch: 8014, Train Loss: 0.210, Validation Loss: 0.249\n",
      "Epoch: 8015, Train Loss: 0.213, Validation Loss: 0.250\n",
      "Epoch: 8016, Train Loss: 0.235, Validation Loss: 0.249\n",
      "Epoch: 8017, Train Loss: 0.332, Validation Loss: 0.248\n",
      "Epoch: 8018, Train Loss: 0.240, Validation Loss: 0.251\n",
      "Epoch: 8019, Train Loss: 0.387, Validation Loss: 0.260\n",
      "Epoch: 8020, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 8021, Train Loss: 0.197, Validation Loss: 0.251\n",
      "Epoch: 8022, Train Loss: 0.195, Validation Loss: 0.251\n",
      "Epoch: 8023, Train Loss: 0.240, Validation Loss: 0.248\n",
      "Epoch: 8024, Train Loss: 0.203, Validation Loss: 0.251\n",
      "Epoch: 8025, Train Loss: 0.207, Validation Loss: 0.249\n",
      "Epoch: 8026, Train Loss: 0.230, Validation Loss: 0.249\n",
      "Epoch: 8027, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 8028, Train Loss: 0.291, Validation Loss: 0.248\n",
      "Epoch: 8029, Train Loss: 0.383, Validation Loss: 0.244\n",
      "Epoch: 8030, Train Loss: 0.285, Validation Loss: 0.246\n",
      "Epoch: 8031, Train Loss: 0.342, Validation Loss: 0.244\n",
      "Epoch: 8032, Train Loss: 0.222, Validation Loss: 0.248\n",
      "Epoch: 8033, Train Loss: 0.244, Validation Loss: 0.248\n",
      "Epoch: 8034, Train Loss: 0.461, Validation Loss: 0.248\n",
      "Epoch: 8035, Train Loss: 0.204, Validation Loss: 0.246\n",
      "Epoch: 8036, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 8037, Train Loss: 0.182, Validation Loss: 0.249\n",
      "Epoch: 8038, Train Loss: 0.288, Validation Loss: 0.246\n",
      "Epoch: 8039, Train Loss: 0.543, Validation Loss: 0.246\n",
      "Epoch: 8040, Train Loss: 0.193, Validation Loss: 0.248\n",
      "Epoch: 8041, Train Loss: 0.430, Validation Loss: 0.252\n",
      "Epoch: 8042, Train Loss: 0.195, Validation Loss: 0.247\n",
      "Epoch: 8043, Train Loss: 0.229, Validation Loss: 0.248\n",
      "Epoch: 8044, Train Loss: 0.331, Validation Loss: 0.245\n",
      "Epoch: 8045, Train Loss: 0.194, Validation Loss: 0.247\n",
      "Epoch: 8046, Train Loss: 0.282, Validation Loss: 0.253\n",
      "Epoch: 8047, Train Loss: 0.330, Validation Loss: 0.247\n",
      "Epoch: 8048, Train Loss: 0.199, Validation Loss: 0.248\n",
      "Epoch: 8049, Train Loss: 0.222, Validation Loss: 0.245\n",
      "Epoch: 8050, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 8051, Train Loss: 0.194, Validation Loss: 0.248\n",
      "Epoch: 8052, Train Loss: 0.454, Validation Loss: 0.248\n",
      "Epoch: 8053, Train Loss: 0.193, Validation Loss: 0.251\n",
      "Epoch: 8054, Train Loss: 0.187, Validation Loss: 0.251\n",
      "Epoch: 8055, Train Loss: 0.278, Validation Loss: 0.249\n",
      "Epoch: 8056, Train Loss: 0.332, Validation Loss: 0.254\n",
      "Epoch: 8057, Train Loss: 0.450, Validation Loss: 0.247\n",
      "Epoch: 8058, Train Loss: 0.277, Validation Loss: 0.246\n",
      "Epoch: 8059, Train Loss: 0.171, Validation Loss: 0.248\n",
      "Epoch: 8060, Train Loss: 0.278, Validation Loss: 0.252\n",
      "Epoch: 8061, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 8062, Train Loss: 0.251, Validation Loss: 0.254\n",
      "Epoch: 8063, Train Loss: 0.226, Validation Loss: 0.249\n",
      "Epoch: 8064, Train Loss: 0.325, Validation Loss: 0.249\n",
      "Epoch: 8065, Train Loss: 0.227, Validation Loss: 0.252\n",
      "Epoch: 8066, Train Loss: 0.300, Validation Loss: 0.249\n",
      "Epoch: 8067, Train Loss: 0.319, Validation Loss: 0.249\n",
      "Epoch: 8068, Train Loss: 0.224, Validation Loss: 0.251\n",
      "Epoch: 8069, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 8070, Train Loss: 0.263, Validation Loss: 0.251\n",
      "Epoch: 8071, Train Loss: 0.214, Validation Loss: 0.256\n",
      "Epoch: 8072, Train Loss: 0.214, Validation Loss: 0.262\n",
      "Epoch: 8073, Train Loss: 0.253, Validation Loss: 0.256\n",
      "Epoch: 8074, Train Loss: 0.163, Validation Loss: 0.250\n",
      "Epoch: 8075, Train Loss: 0.241, Validation Loss: 0.256\n",
      "Epoch: 8076, Train Loss: 0.246, Validation Loss: 0.254\n",
      "Epoch: 8077, Train Loss: 0.472, Validation Loss: 0.252\n",
      "Epoch: 8078, Train Loss: 0.210, Validation Loss: 0.250\n",
      "Epoch: 8079, Train Loss: 0.195, Validation Loss: 0.248\n",
      "Epoch: 8080, Train Loss: 0.224, Validation Loss: 0.248\n",
      "Epoch: 8081, Train Loss: 0.194, Validation Loss: 0.247\n",
      "Epoch: 8082, Train Loss: 0.258, Validation Loss: 0.249\n",
      "Epoch: 8083, Train Loss: 0.300, Validation Loss: 0.249\n",
      "Epoch: 8084, Train Loss: 0.205, Validation Loss: 0.252\n",
      "Epoch: 8085, Train Loss: 0.286, Validation Loss: 0.255\n",
      "Epoch: 8086, Train Loss: 0.222, Validation Loss: 0.252\n",
      "Epoch: 8087, Train Loss: 0.245, Validation Loss: 0.254\n",
      "Epoch: 8088, Train Loss: 0.254, Validation Loss: 0.252\n",
      "Epoch: 8089, Train Loss: 0.189, Validation Loss: 0.251\n",
      "Epoch: 8090, Train Loss: 0.453, Validation Loss: 0.248\n",
      "Epoch: 8091, Train Loss: 0.279, Validation Loss: 0.251\n",
      "Epoch: 8092, Train Loss: 0.227, Validation Loss: 0.249\n",
      "Epoch: 8093, Train Loss: 0.289, Validation Loss: 0.249\n",
      "Epoch: 8094, Train Loss: 0.309, Validation Loss: 0.252\n",
      "Epoch: 8095, Train Loss: 0.235, Validation Loss: 0.247\n",
      "Epoch: 8096, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 8097, Train Loss: 0.179, Validation Loss: 0.247\n",
      "Epoch: 8098, Train Loss: 0.285, Validation Loss: 0.246\n",
      "Epoch: 8099, Train Loss: 0.251, Validation Loss: 0.246\n",
      "Epoch: 8100, Train Loss: 0.286, Validation Loss: 0.250\n",
      "Epoch: 8101, Train Loss: 0.517, Validation Loss: 0.247\n",
      "Epoch: 8102, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 8103, Train Loss: 0.415, Validation Loss: 0.251\n",
      "Epoch: 8104, Train Loss: 0.256, Validation Loss: 0.254\n",
      "Epoch: 8105, Train Loss: 0.308, Validation Loss: 0.251\n",
      "Epoch: 8106, Train Loss: 0.278, Validation Loss: 0.253\n",
      "Epoch: 8107, Train Loss: 0.287, Validation Loss: 0.249\n",
      "Epoch: 8108, Train Loss: 0.269, Validation Loss: 0.250\n",
      "Epoch: 8109, Train Loss: 0.182, Validation Loss: 0.246\n",
      "Epoch: 8110, Train Loss: 0.219, Validation Loss: 0.248\n",
      "Epoch: 8111, Train Loss: 0.413, Validation Loss: 0.246\n",
      "Epoch: 8112, Train Loss: 0.265, Validation Loss: 0.247\n",
      "Epoch: 8113, Train Loss: 0.206, Validation Loss: 0.249\n",
      "Epoch: 8114, Train Loss: 0.192, Validation Loss: 0.244\n",
      "Epoch: 8115, Train Loss: 0.560, Validation Loss: 0.245\n",
      "Epoch: 8116, Train Loss: 0.268, Validation Loss: 0.246\n",
      "Epoch: 8117, Train Loss: 0.198, Validation Loss: 0.248\n",
      "Epoch: 8118, Train Loss: 0.268, Validation Loss: 0.246\n",
      "Epoch: 8119, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 8120, Train Loss: 0.240, Validation Loss: 0.248\n",
      "Epoch: 8121, Train Loss: 0.270, Validation Loss: 0.251\n",
      "Epoch: 8122, Train Loss: 0.257, Validation Loss: 0.253\n",
      "Epoch: 8123, Train Loss: 0.379, Validation Loss: 0.254\n",
      "Epoch: 8124, Train Loss: 0.608, Validation Loss: 0.250\n",
      "Epoch: 8125, Train Loss: 0.181, Validation Loss: 0.249\n",
      "Epoch: 8126, Train Loss: 0.220, Validation Loss: 0.250\n",
      "Epoch: 8127, Train Loss: 0.469, Validation Loss: 0.255\n",
      "Epoch: 8128, Train Loss: 0.378, Validation Loss: 0.251\n",
      "Epoch: 8129, Train Loss: 0.490, Validation Loss: 0.248\n",
      "Epoch: 8130, Train Loss: 0.370, Validation Loss: 0.247\n",
      "Epoch: 8131, Train Loss: 0.191, Validation Loss: 0.248\n",
      "Epoch: 8132, Train Loss: 0.215, Validation Loss: 0.251\n",
      "Epoch: 8133, Train Loss: 0.329, Validation Loss: 0.250\n",
      "Epoch: 8134, Train Loss: 0.199, Validation Loss: 0.250\n",
      "Epoch: 8135, Train Loss: 0.304, Validation Loss: 0.249\n",
      "Epoch: 8136, Train Loss: 0.214, Validation Loss: 0.254\n",
      "Epoch: 8137, Train Loss: 0.204, Validation Loss: 0.257\n",
      "Epoch: 8138, Train Loss: 0.403, Validation Loss: 0.249\n",
      "Epoch: 8139, Train Loss: 0.245, Validation Loss: 0.249\n",
      "Epoch: 8140, Train Loss: 0.161, Validation Loss: 0.247\n",
      "Epoch: 8141, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 8142, Train Loss: 0.229, Validation Loss: 0.246\n",
      "Epoch: 8143, Train Loss: 0.447, Validation Loss: 0.246\n",
      "Epoch: 8144, Train Loss: 0.238, Validation Loss: 0.246\n",
      "Epoch: 8145, Train Loss: 0.240, Validation Loss: 0.252\n",
      "Epoch: 8146, Train Loss: 0.217, Validation Loss: 0.253\n",
      "Epoch: 8147, Train Loss: 0.371, Validation Loss: 0.253\n",
      "Epoch: 8148, Train Loss: 0.262, Validation Loss: 0.256\n",
      "Epoch: 8149, Train Loss: 0.183, Validation Loss: 0.253\n",
      "Epoch: 8150, Train Loss: 0.256, Validation Loss: 0.248\n",
      "Epoch: 8151, Train Loss: 0.657, Validation Loss: 0.251\n",
      "Epoch: 8152, Train Loss: 0.234, Validation Loss: 0.247\n",
      "Epoch: 8153, Train Loss: 0.208, Validation Loss: 0.249\n",
      "Epoch: 8154, Train Loss: 0.421, Validation Loss: 0.248\n",
      "Epoch: 8155, Train Loss: 0.207, Validation Loss: 0.247\n",
      "Epoch: 8156, Train Loss: 0.483, Validation Loss: 0.250\n",
      "Epoch: 8157, Train Loss: 0.188, Validation Loss: 0.249\n",
      "Epoch: 8158, Train Loss: 0.196, Validation Loss: 0.247\n",
      "Epoch: 8159, Train Loss: 0.153, Validation Loss: 0.247\n",
      "Epoch: 8160, Train Loss: 0.231, Validation Loss: 0.250\n",
      "Epoch: 8161, Train Loss: 0.299, Validation Loss: 0.251\n",
      "Epoch: 8162, Train Loss: 0.270, Validation Loss: 0.247\n",
      "Epoch: 8163, Train Loss: 0.268, Validation Loss: 0.246\n",
      "Epoch: 8164, Train Loss: 0.301, Validation Loss: 0.250\n",
      "Epoch: 8165, Train Loss: 0.167, Validation Loss: 0.250\n",
      "Epoch: 8166, Train Loss: 0.508, Validation Loss: 0.247\n",
      "Epoch: 8167, Train Loss: 0.174, Validation Loss: 0.251\n",
      "Epoch: 8168, Train Loss: 0.419, Validation Loss: 0.247\n",
      "Epoch: 8169, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 8170, Train Loss: 0.222, Validation Loss: 0.246\n",
      "Epoch: 8171, Train Loss: 0.454, Validation Loss: 0.246\n",
      "Epoch: 8172, Train Loss: 0.232, Validation Loss: 0.249\n",
      "Epoch: 8173, Train Loss: 0.252, Validation Loss: 0.249\n",
      "Epoch: 8174, Train Loss: 0.201, Validation Loss: 0.250\n",
      "Epoch: 8175, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 8176, Train Loss: 0.279, Validation Loss: 0.253\n",
      "Epoch: 8177, Train Loss: 0.187, Validation Loss: 0.249\n",
      "Epoch: 8178, Train Loss: 0.267, Validation Loss: 0.247\n",
      "Epoch: 8179, Train Loss: 0.267, Validation Loss: 0.248\n",
      "Epoch: 8180, Train Loss: 0.386, Validation Loss: 0.250\n",
      "Epoch: 8181, Train Loss: 0.282, Validation Loss: 0.251\n",
      "Epoch: 8182, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 8183, Train Loss: 0.235, Validation Loss: 0.250\n",
      "Epoch: 8184, Train Loss: 0.189, Validation Loss: 0.249\n",
      "Epoch: 8185, Train Loss: 0.351, Validation Loss: 0.250\n",
      "Epoch: 8186, Train Loss: 0.195, Validation Loss: 0.248\n",
      "Epoch: 8187, Train Loss: 0.186, Validation Loss: 0.246\n",
      "Epoch: 8188, Train Loss: 0.242, Validation Loss: 0.249\n",
      "Epoch: 8189, Train Loss: 0.208, Validation Loss: 0.249\n",
      "Epoch: 8190, Train Loss: 0.273, Validation Loss: 0.249\n",
      "Epoch: 8191, Train Loss: 0.547, Validation Loss: 0.248\n",
      "Epoch: 8192, Train Loss: 0.190, Validation Loss: 0.250\n",
      "Epoch: 8193, Train Loss: 0.254, Validation Loss: 0.253\n",
      "Epoch: 8194, Train Loss: 0.403, Validation Loss: 0.249\n",
      "Epoch: 8195, Train Loss: 0.230, Validation Loss: 0.251\n",
      "Epoch: 8196, Train Loss: 0.182, Validation Loss: 0.250\n",
      "Epoch: 8197, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 8198, Train Loss: 0.424, Validation Loss: 0.252\n",
      "Epoch: 8199, Train Loss: 0.475, Validation Loss: 0.251\n",
      "Epoch: 8200, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 8201, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 8202, Train Loss: 0.223, Validation Loss: 0.255\n",
      "Epoch: 8203, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 8204, Train Loss: 0.217, Validation Loss: 0.257\n",
      "Epoch: 8205, Train Loss: 0.195, Validation Loss: 0.256\n",
      "Epoch: 8206, Train Loss: 0.330, Validation Loss: 0.254\n",
      "Epoch: 8207, Train Loss: 0.320, Validation Loss: 0.252\n",
      "Epoch: 8208, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 8209, Train Loss: 0.250, Validation Loss: 0.253\n",
      "Epoch: 8210, Train Loss: 0.239, Validation Loss: 0.256\n",
      "Epoch: 8211, Train Loss: 0.213, Validation Loss: 0.254\n",
      "Epoch: 8212, Train Loss: 0.383, Validation Loss: 0.250\n",
      "Epoch: 8213, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 8214, Train Loss: 0.210, Validation Loss: 0.250\n",
      "Epoch: 8215, Train Loss: 0.425, Validation Loss: 0.249\n",
      "Epoch: 8216, Train Loss: 0.241, Validation Loss: 0.249\n",
      "Epoch: 8217, Train Loss: 0.314, Validation Loss: 0.250\n",
      "Epoch: 8218, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 8219, Train Loss: 0.319, Validation Loss: 0.256\n",
      "Epoch: 8220, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 8221, Train Loss: 0.299, Validation Loss: 0.251\n",
      "Epoch: 8222, Train Loss: 0.412, Validation Loss: 0.248\n",
      "Epoch: 8223, Train Loss: 0.360, Validation Loss: 0.250\n",
      "Epoch: 8224, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 8225, Train Loss: 0.226, Validation Loss: 0.250\n",
      "Epoch: 8226, Train Loss: 0.216, Validation Loss: 0.247\n",
      "Epoch: 8227, Train Loss: 0.429, Validation Loss: 0.247\n",
      "Epoch: 8228, Train Loss: 0.187, Validation Loss: 0.247\n",
      "Epoch: 8229, Train Loss: 0.455, Validation Loss: 0.253\n",
      "Epoch: 8230, Train Loss: 0.305, Validation Loss: 0.249\n",
      "Epoch: 8231, Train Loss: 0.319, Validation Loss: 0.254\n",
      "Epoch: 8232, Train Loss: 0.229, Validation Loss: 0.250\n",
      "Epoch: 8233, Train Loss: 0.204, Validation Loss: 0.248\n",
      "Epoch: 8234, Train Loss: 0.372, Validation Loss: 0.249\n",
      "Epoch: 8235, Train Loss: 0.193, Validation Loss: 0.253\n",
      "Epoch: 8236, Train Loss: 0.302, Validation Loss: 0.250\n",
      "Epoch: 8237, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 8238, Train Loss: 0.227, Validation Loss: 0.248\n",
      "Epoch: 8239, Train Loss: 0.265, Validation Loss: 0.251\n",
      "Epoch: 8240, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 8241, Train Loss: 0.260, Validation Loss: 0.250\n",
      "Epoch: 8242, Train Loss: 0.261, Validation Loss: 0.250\n",
      "Epoch: 8243, Train Loss: 0.366, Validation Loss: 0.257\n",
      "Epoch: 8244, Train Loss: 0.240, Validation Loss: 0.254\n",
      "Epoch: 8245, Train Loss: 0.244, Validation Loss: 0.251\n",
      "Epoch: 8246, Train Loss: 0.254, Validation Loss: 0.248\n",
      "Epoch: 8247, Train Loss: 0.232, Validation Loss: 0.250\n",
      "Epoch: 8248, Train Loss: 0.279, Validation Loss: 0.249\n",
      "Epoch: 8249, Train Loss: 0.286, Validation Loss: 0.246\n",
      "Epoch: 8250, Train Loss: 0.166, Validation Loss: 0.249\n",
      "Epoch: 8251, Train Loss: 0.272, Validation Loss: 0.254\n",
      "Epoch: 8252, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 8253, Train Loss: 0.215, Validation Loss: 0.255\n",
      "Epoch: 8254, Train Loss: 0.420, Validation Loss: 0.250\n",
      "Epoch: 8255, Train Loss: 0.299, Validation Loss: 0.249\n",
      "Epoch: 8256, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 8257, Train Loss: 0.497, Validation Loss: 0.252\n",
      "Epoch: 8258, Train Loss: 0.330, Validation Loss: 0.255\n",
      "Epoch: 8259, Train Loss: 0.219, Validation Loss: 0.250\n",
      "Epoch: 8260, Train Loss: 0.195, Validation Loss: 0.250\n",
      "Epoch: 8261, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 8262, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 8263, Train Loss: 0.203, Validation Loss: 0.250\n",
      "Epoch: 8264, Train Loss: 0.282, Validation Loss: 0.255\n",
      "Epoch: 8265, Train Loss: 0.223, Validation Loss: 0.251\n",
      "Epoch: 8266, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 8267, Train Loss: 0.258, Validation Loss: 0.253\n",
      "Epoch: 8268, Train Loss: 0.357, Validation Loss: 0.256\n",
      "Epoch: 8269, Train Loss: 0.197, Validation Loss: 0.250\n",
      "Epoch: 8270, Train Loss: 0.172, Validation Loss: 0.248\n",
      "Epoch: 8271, Train Loss: 0.342, Validation Loss: 0.253\n",
      "Epoch: 8272, Train Loss: 0.221, Validation Loss: 0.249\n",
      "Epoch: 8273, Train Loss: 0.343, Validation Loss: 0.248\n",
      "Epoch: 8274, Train Loss: 0.350, Validation Loss: 0.248\n",
      "Epoch: 8275, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 8276, Train Loss: 0.525, Validation Loss: 0.249\n",
      "Epoch: 8277, Train Loss: 0.307, Validation Loss: 0.252\n",
      "Epoch: 8278, Train Loss: 0.395, Validation Loss: 0.248\n",
      "Epoch: 8279, Train Loss: 0.246, Validation Loss: 0.249\n",
      "Epoch: 8280, Train Loss: 0.177, Validation Loss: 0.249\n",
      "Epoch: 8281, Train Loss: 0.362, Validation Loss: 0.250\n",
      "Epoch: 8282, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 8283, Train Loss: 0.259, Validation Loss: 0.254\n",
      "Epoch: 8284, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 8285, Train Loss: 0.232, Validation Loss: 0.252\n",
      "Epoch: 8286, Train Loss: 0.391, Validation Loss: 0.249\n",
      "Epoch: 8287, Train Loss: 0.535, Validation Loss: 0.251\n",
      "Epoch: 8288, Train Loss: 0.516, Validation Loss: 0.254\n",
      "Epoch: 8289, Train Loss: 0.237, Validation Loss: 0.254\n",
      "Epoch: 8290, Train Loss: 0.247, Validation Loss: 0.256\n",
      "Epoch: 8291, Train Loss: 0.221, Validation Loss: 0.251\n",
      "Epoch: 8292, Train Loss: 0.160, Validation Loss: 0.251\n",
      "Epoch: 8293, Train Loss: 0.437, Validation Loss: 0.250\n",
      "Epoch: 8294, Train Loss: 0.271, Validation Loss: 0.256\n",
      "Epoch: 8295, Train Loss: 0.236, Validation Loss: 0.258\n",
      "Epoch: 8296, Train Loss: 0.276, Validation Loss: 0.251\n",
      "Epoch: 8297, Train Loss: 0.236, Validation Loss: 0.250\n",
      "Epoch: 8298, Train Loss: 0.219, Validation Loss: 0.254\n",
      "Epoch: 8299, Train Loss: 0.217, Validation Loss: 0.254\n",
      "Epoch: 8300, Train Loss: 0.478, Validation Loss: 0.256\n",
      "Epoch: 8301, Train Loss: 0.229, Validation Loss: 0.252\n",
      "Epoch: 8302, Train Loss: 0.207, Validation Loss: 0.252\n",
      "Epoch: 8303, Train Loss: 0.287, Validation Loss: 0.256\n",
      "Epoch: 8304, Train Loss: 0.253, Validation Loss: 0.256\n",
      "Epoch: 8305, Train Loss: 0.424, Validation Loss: 0.249\n",
      "Epoch: 8306, Train Loss: 0.244, Validation Loss: 0.253\n",
      "Epoch: 8307, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 8308, Train Loss: 0.294, Validation Loss: 0.255\n",
      "Epoch: 8309, Train Loss: 0.248, Validation Loss: 0.257\n",
      "Epoch: 8310, Train Loss: 0.251, Validation Loss: 0.251\n",
      "Epoch: 8311, Train Loss: 0.215, Validation Loss: 0.251\n",
      "Epoch: 8312, Train Loss: 0.323, Validation Loss: 0.251\n",
      "Epoch: 8313, Train Loss: 0.196, Validation Loss: 0.253\n",
      "Epoch: 8314, Train Loss: 0.172, Validation Loss: 0.251\n",
      "Epoch: 8315, Train Loss: 0.172, Validation Loss: 0.250\n",
      "Epoch: 8316, Train Loss: 0.450, Validation Loss: 0.249\n",
      "Epoch: 8317, Train Loss: 0.285, Validation Loss: 0.251\n",
      "Epoch: 8318, Train Loss: 0.244, Validation Loss: 0.249\n",
      "Epoch: 8319, Train Loss: 0.277, Validation Loss: 0.250\n",
      "Epoch: 8320, Train Loss: 0.340, Validation Loss: 0.253\n",
      "Epoch: 8321, Train Loss: 0.187, Validation Loss: 0.250\n",
      "Epoch: 8322, Train Loss: 0.153, Validation Loss: 0.250\n",
      "Epoch: 8323, Train Loss: 0.324, Validation Loss: 0.250\n",
      "Epoch: 8324, Train Loss: 0.264, Validation Loss: 0.251\n",
      "Epoch: 8325, Train Loss: 0.474, Validation Loss: 0.245\n",
      "Epoch: 8326, Train Loss: 0.270, Validation Loss: 0.251\n",
      "Epoch: 8327, Train Loss: 0.383, Validation Loss: 0.256\n",
      "Epoch: 8328, Train Loss: 0.270, Validation Loss: 0.248\n",
      "Epoch: 8329, Train Loss: 0.319, Validation Loss: 0.248\n",
      "Epoch: 8330, Train Loss: 0.258, Validation Loss: 0.251\n",
      "Epoch: 8331, Train Loss: 0.250, Validation Loss: 0.248\n",
      "Epoch: 8332, Train Loss: 0.277, Validation Loss: 0.248\n",
      "Epoch: 8333, Train Loss: 0.168, Validation Loss: 0.249\n",
      "Epoch: 8334, Train Loss: 0.210, Validation Loss: 0.250\n",
      "Epoch: 8335, Train Loss: 0.255, Validation Loss: 0.246\n",
      "Epoch: 8336, Train Loss: 0.179, Validation Loss: 0.249\n",
      "Epoch: 8337, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 8338, Train Loss: 0.364, Validation Loss: 0.249\n",
      "Epoch: 8339, Train Loss: 0.192, Validation Loss: 0.250\n",
      "Epoch: 8340, Train Loss: 0.487, Validation Loss: 0.250\n",
      "Epoch: 8341, Train Loss: 0.194, Validation Loss: 0.249\n",
      "Epoch: 8342, Train Loss: 0.275, Validation Loss: 0.252\n",
      "Epoch: 8343, Train Loss: 0.244, Validation Loss: 0.248\n",
      "Epoch: 8344, Train Loss: 0.186, Validation Loss: 0.249\n",
      "Epoch: 8345, Train Loss: 0.278, Validation Loss: 0.250\n",
      "Epoch: 8346, Train Loss: 0.217, Validation Loss: 0.249\n",
      "Epoch: 8347, Train Loss: 0.218, Validation Loss: 0.249\n",
      "Epoch: 8348, Train Loss: 0.183, Validation Loss: 0.256\n",
      "Epoch: 8349, Train Loss: 0.290, Validation Loss: 0.262\n",
      "Epoch: 8350, Train Loss: 0.227, Validation Loss: 0.256\n",
      "Epoch: 8351, Train Loss: 0.283, Validation Loss: 0.252\n",
      "Epoch: 8352, Train Loss: 0.248, Validation Loss: 0.255\n",
      "Epoch: 8353, Train Loss: 0.255, Validation Loss: 0.257\n",
      "Epoch: 8354, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 8355, Train Loss: 0.236, Validation Loss: 0.253\n",
      "Epoch: 8356, Train Loss: 0.234, Validation Loss: 0.256\n",
      "Epoch: 8357, Train Loss: 0.307, Validation Loss: 0.252\n",
      "Epoch: 8358, Train Loss: 0.209, Validation Loss: 0.255\n",
      "Epoch: 8359, Train Loss: 0.191, Validation Loss: 0.255\n",
      "Epoch: 8360, Train Loss: 0.266, Validation Loss: 0.253\n",
      "Epoch: 8361, Train Loss: 0.183, Validation Loss: 0.254\n",
      "Epoch: 8362, Train Loss: 0.205, Validation Loss: 0.251\n",
      "Epoch: 8363, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 8364, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 8365, Train Loss: 0.204, Validation Loss: 0.248\n",
      "Epoch: 8366, Train Loss: 0.300, Validation Loss: 0.255\n",
      "Epoch: 8367, Train Loss: 0.351, Validation Loss: 0.248\n",
      "Epoch: 8368, Train Loss: 0.180, Validation Loss: 0.252\n",
      "Epoch: 8369, Train Loss: 0.212, Validation Loss: 0.252\n",
      "Epoch: 8370, Train Loss: 0.242, Validation Loss: 0.255\n",
      "Epoch: 8371, Train Loss: 0.221, Validation Loss: 0.256\n",
      "Epoch: 8372, Train Loss: 0.302, Validation Loss: 0.256\n",
      "Epoch: 8373, Train Loss: 0.340, Validation Loss: 0.251\n",
      "Epoch: 8374, Train Loss: 0.421, Validation Loss: 0.251\n",
      "Epoch: 8375, Train Loss: 0.304, Validation Loss: 0.254\n",
      "Epoch: 8376, Train Loss: 0.252, Validation Loss: 0.254\n",
      "Epoch: 8377, Train Loss: 0.251, Validation Loss: 0.261\n",
      "Epoch: 8378, Train Loss: 0.182, Validation Loss: 0.255\n",
      "Epoch: 8379, Train Loss: 0.205, Validation Loss: 0.254\n",
      "Epoch: 8380, Train Loss: 0.206, Validation Loss: 0.248\n",
      "Epoch: 8381, Train Loss: 0.429, Validation Loss: 0.249\n",
      "Epoch: 8382, Train Loss: 0.233, Validation Loss: 0.252\n",
      "Epoch: 8383, Train Loss: 0.312, Validation Loss: 0.262\n",
      "Epoch: 8384, Train Loss: 0.210, Validation Loss: 0.254\n",
      "Epoch: 8385, Train Loss: 0.192, Validation Loss: 0.255\n",
      "Epoch: 8386, Train Loss: 0.254, Validation Loss: 0.257\n",
      "Epoch: 8387, Train Loss: 0.152, Validation Loss: 0.254\n",
      "Epoch: 8388, Train Loss: 0.197, Validation Loss: 0.252\n",
      "Epoch: 8389, Train Loss: 0.446, Validation Loss: 0.247\n",
      "Epoch: 8390, Train Loss: 0.237, Validation Loss: 0.253\n",
      "Epoch: 8391, Train Loss: 0.266, Validation Loss: 0.250\n",
      "Epoch: 8392, Train Loss: 0.174, Validation Loss: 0.253\n",
      "Epoch: 8393, Train Loss: 0.201, Validation Loss: 0.250\n",
      "Epoch: 8394, Train Loss: 0.429, Validation Loss: 0.253\n",
      "Epoch: 8395, Train Loss: 0.212, Validation Loss: 0.251\n",
      "Epoch: 8396, Train Loss: 0.273, Validation Loss: 0.253\n",
      "Epoch: 8397, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 8398, Train Loss: 0.211, Validation Loss: 0.248\n",
      "Epoch: 8399, Train Loss: 0.201, Validation Loss: 0.249\n",
      "Epoch: 8400, Train Loss: 0.180, Validation Loss: 0.251\n",
      "Epoch: 8401, Train Loss: 0.259, Validation Loss: 0.250\n",
      "Epoch: 8402, Train Loss: 0.167, Validation Loss: 0.252\n",
      "Epoch: 8403, Train Loss: 0.300, Validation Loss: 0.250\n",
      "Epoch: 8404, Train Loss: 0.428, Validation Loss: 0.251\n",
      "Epoch: 8405, Train Loss: 0.323, Validation Loss: 0.251\n",
      "Epoch: 8406, Train Loss: 0.495, Validation Loss: 0.265\n",
      "Epoch: 8407, Train Loss: 0.321, Validation Loss: 0.254\n",
      "Epoch: 8408, Train Loss: 0.222, Validation Loss: 0.252\n",
      "Epoch: 8409, Train Loss: 0.281, Validation Loss: 0.248\n",
      "Epoch: 8410, Train Loss: 0.544, Validation Loss: 0.251\n",
      "Epoch: 8411, Train Loss: 0.200, Validation Loss: 0.247\n",
      "Epoch: 8412, Train Loss: 0.252, Validation Loss: 0.251\n",
      "Epoch: 8413, Train Loss: 0.344, Validation Loss: 0.255\n",
      "Epoch: 8414, Train Loss: 0.256, Validation Loss: 0.252\n",
      "Epoch: 8415, Train Loss: 0.286, Validation Loss: 0.253\n",
      "Epoch: 8416, Train Loss: 0.265, Validation Loss: 0.247\n",
      "Epoch: 8417, Train Loss: 0.204, Validation Loss: 0.248\n",
      "Epoch: 8418, Train Loss: 0.243, Validation Loss: 0.249\n",
      "Epoch: 8419, Train Loss: 0.553, Validation Loss: 0.249\n",
      "Epoch: 8420, Train Loss: 0.242, Validation Loss: 0.254\n",
      "Epoch: 8421, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 8422, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 8423, Train Loss: 0.245, Validation Loss: 0.250\n",
      "Epoch: 8424, Train Loss: 0.169, Validation Loss: 0.252\n",
      "Epoch: 8425, Train Loss: 0.336, Validation Loss: 0.253\n",
      "Epoch: 8426, Train Loss: 0.312, Validation Loss: 0.250\n",
      "Epoch: 8427, Train Loss: 0.198, Validation Loss: 0.247\n",
      "Epoch: 8428, Train Loss: 0.165, Validation Loss: 0.248\n",
      "Epoch: 8429, Train Loss: 0.175, Validation Loss: 0.251\n",
      "Epoch: 8430, Train Loss: 0.380, Validation Loss: 0.251\n",
      "Epoch: 8431, Train Loss: 0.290, Validation Loss: 0.254\n",
      "Epoch: 8432, Train Loss: 0.175, Validation Loss: 0.253\n",
      "Epoch: 8433, Train Loss: 0.305, Validation Loss: 0.250\n",
      "Epoch: 8434, Train Loss: 0.272, Validation Loss: 0.253\n",
      "Epoch: 8435, Train Loss: 0.173, Validation Loss: 0.253\n",
      "Epoch: 8436, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 8437, Train Loss: 0.224, Validation Loss: 0.252\n",
      "Epoch: 8438, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 8439, Train Loss: 0.279, Validation Loss: 0.246\n",
      "Epoch: 8440, Train Loss: 0.286, Validation Loss: 0.252\n",
      "Epoch: 8441, Train Loss: 0.259, Validation Loss: 0.253\n",
      "Epoch: 8442, Train Loss: 0.192, Validation Loss: 0.253\n",
      "Epoch: 8443, Train Loss: 0.259, Validation Loss: 0.252\n",
      "Epoch: 8444, Train Loss: 0.208, Validation Loss: 0.248\n",
      "Epoch: 8445, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 8446, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 8447, Train Loss: 0.213, Validation Loss: 0.256\n",
      "Epoch: 8448, Train Loss: 0.212, Validation Loss: 0.254\n",
      "Epoch: 8449, Train Loss: 0.196, Validation Loss: 0.248\n",
      "Epoch: 8450, Train Loss: 0.332, Validation Loss: 0.253\n",
      "Epoch: 8451, Train Loss: 0.376, Validation Loss: 0.251\n",
      "Epoch: 8452, Train Loss: 0.284, Validation Loss: 0.249\n",
      "Epoch: 8453, Train Loss: 0.372, Validation Loss: 0.251\n",
      "Epoch: 8454, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 8455, Train Loss: 0.209, Validation Loss: 0.252\n",
      "Epoch: 8456, Train Loss: 0.219, Validation Loss: 0.251\n",
      "Epoch: 8457, Train Loss: 0.254, Validation Loss: 0.248\n",
      "Epoch: 8458, Train Loss: 0.187, Validation Loss: 0.250\n",
      "Epoch: 8459, Train Loss: 0.203, Validation Loss: 0.250\n",
      "Epoch: 8460, Train Loss: 0.333, Validation Loss: 0.252\n",
      "Epoch: 8461, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 8462, Train Loss: 0.241, Validation Loss: 0.254\n",
      "Epoch: 8463, Train Loss: 0.231, Validation Loss: 0.254\n",
      "Epoch: 8464, Train Loss: 0.353, Validation Loss: 0.254\n",
      "Epoch: 8465, Train Loss: 0.200, Validation Loss: 0.249\n",
      "Epoch: 8466, Train Loss: 0.210, Validation Loss: 0.251\n",
      "Epoch: 8467, Train Loss: 0.221, Validation Loss: 0.251\n",
      "Epoch: 8468, Train Loss: 0.285, Validation Loss: 0.252\n",
      "Epoch: 8469, Train Loss: 0.286, Validation Loss: 0.253\n",
      "Epoch: 8470, Train Loss: 0.242, Validation Loss: 0.254\n",
      "Epoch: 8471, Train Loss: 0.229, Validation Loss: 0.254\n",
      "Epoch: 8472, Train Loss: 0.514, Validation Loss: 0.251\n",
      "Epoch: 8473, Train Loss: 0.228, Validation Loss: 0.249\n",
      "Epoch: 8474, Train Loss: 0.304, Validation Loss: 0.252\n",
      "Epoch: 8475, Train Loss: 0.185, Validation Loss: 0.248\n",
      "Epoch: 8476, Train Loss: 0.392, Validation Loss: 0.252\n",
      "Epoch: 8477, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 8478, Train Loss: 0.507, Validation Loss: 0.249\n",
      "Epoch: 8479, Train Loss: 0.260, Validation Loss: 0.249\n",
      "Epoch: 8480, Train Loss: 0.253, Validation Loss: 0.251\n",
      "Epoch: 8481, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 8482, Train Loss: 0.351, Validation Loss: 0.251\n",
      "Epoch: 8483, Train Loss: 0.214, Validation Loss: 0.251\n",
      "Epoch: 8484, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 8485, Train Loss: 0.172, Validation Loss: 0.256\n",
      "Epoch: 8486, Train Loss: 0.173, Validation Loss: 0.251\n",
      "Epoch: 8487, Train Loss: 0.189, Validation Loss: 0.254\n",
      "Epoch: 8488, Train Loss: 0.258, Validation Loss: 0.252\n",
      "Epoch: 8489, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 8490, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 8491, Train Loss: 0.253, Validation Loss: 0.249\n",
      "Epoch: 8492, Train Loss: 0.293, Validation Loss: 0.247\n",
      "Epoch: 8493, Train Loss: 0.410, Validation Loss: 0.253\n",
      "Epoch: 8494, Train Loss: 0.294, Validation Loss: 0.250\n",
      "Epoch: 8495, Train Loss: 0.254, Validation Loss: 0.250\n",
      "Epoch: 8496, Train Loss: 0.221, Validation Loss: 0.255\n",
      "Epoch: 8497, Train Loss: 0.303, Validation Loss: 0.257\n",
      "Epoch: 8498, Train Loss: 0.213, Validation Loss: 0.253\n",
      "Epoch: 8499, Train Loss: 0.179, Validation Loss: 0.252\n",
      "Epoch: 8500, Train Loss: 0.334, Validation Loss: 0.258\n",
      "Epoch: 8501, Train Loss: 0.267, Validation Loss: 0.252\n",
      "Epoch: 8502, Train Loss: 0.282, Validation Loss: 0.253\n",
      "Epoch: 8503, Train Loss: 0.364, Validation Loss: 0.251\n",
      "Epoch: 8504, Train Loss: 0.269, Validation Loss: 0.255\n",
      "Epoch: 8505, Train Loss: 0.255, Validation Loss: 0.255\n",
      "Epoch: 8506, Train Loss: 0.241, Validation Loss: 0.252\n",
      "Epoch: 8507, Train Loss: 0.240, Validation Loss: 0.255\n",
      "Epoch: 8508, Train Loss: 0.321, Validation Loss: 0.253\n",
      "Epoch: 8509, Train Loss: 0.215, Validation Loss: 0.260\n",
      "Epoch: 8510, Train Loss: 0.298, Validation Loss: 0.258\n",
      "Epoch: 8511, Train Loss: 0.219, Validation Loss: 0.253\n",
      "Epoch: 8512, Train Loss: 0.268, Validation Loss: 0.253\n",
      "Epoch: 8513, Train Loss: 0.205, Validation Loss: 0.258\n",
      "Epoch: 8514, Train Loss: 0.151, Validation Loss: 0.256\n",
      "Epoch: 8515, Train Loss: 0.329, Validation Loss: 0.254\n",
      "Epoch: 8516, Train Loss: 0.246, Validation Loss: 0.257\n",
      "Epoch: 8517, Train Loss: 0.320, Validation Loss: 0.253\n",
      "Epoch: 8518, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 8519, Train Loss: 0.251, Validation Loss: 0.255\n",
      "Epoch: 8520, Train Loss: 0.213, Validation Loss: 0.257\n",
      "Epoch: 8521, Train Loss: 0.324, Validation Loss: 0.261\n",
      "Epoch: 8522, Train Loss: 0.252, Validation Loss: 0.257\n",
      "Epoch: 8523, Train Loss: 0.225, Validation Loss: 0.255\n",
      "Epoch: 8524, Train Loss: 0.231, Validation Loss: 0.249\n",
      "Epoch: 8525, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 8526, Train Loss: 0.273, Validation Loss: 0.257\n",
      "Epoch: 8527, Train Loss: 0.466, Validation Loss: 0.251\n",
      "Epoch: 8528, Train Loss: 0.234, Validation Loss: 0.252\n",
      "Epoch: 8529, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 8530, Train Loss: 0.212, Validation Loss: 0.254\n",
      "Epoch: 8531, Train Loss: 0.318, Validation Loss: 0.249\n",
      "Epoch: 8532, Train Loss: 0.371, Validation Loss: 0.251\n",
      "Epoch: 8533, Train Loss: 0.241, Validation Loss: 0.256\n",
      "Epoch: 8534, Train Loss: 0.211, Validation Loss: 0.255\n",
      "Epoch: 8535, Train Loss: 0.425, Validation Loss: 0.253\n",
      "Epoch: 8536, Train Loss: 0.179, Validation Loss: 0.254\n",
      "Epoch: 8537, Train Loss: 0.219, Validation Loss: 0.256\n",
      "Epoch: 8538, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 8539, Train Loss: 0.158, Validation Loss: 0.253\n",
      "Epoch: 8540, Train Loss: 0.267, Validation Loss: 0.254\n",
      "Epoch: 8541, Train Loss: 0.438, Validation Loss: 0.252\n",
      "Epoch: 8542, Train Loss: 0.200, Validation Loss: 0.253\n",
      "Epoch: 8543, Train Loss: 0.272, Validation Loss: 0.257\n",
      "Epoch: 8544, Train Loss: 0.188, Validation Loss: 0.257\n",
      "Epoch: 8545, Train Loss: 0.198, Validation Loss: 0.259\n",
      "Epoch: 8546, Train Loss: 0.186, Validation Loss: 0.260\n",
      "Epoch: 8547, Train Loss: 0.255, Validation Loss: 0.255\n",
      "Epoch: 8548, Train Loss: 0.272, Validation Loss: 0.257\n",
      "Epoch: 8549, Train Loss: 0.243, Validation Loss: 0.256\n",
      "Epoch: 8550, Train Loss: 0.308, Validation Loss: 0.262\n",
      "Epoch: 8551, Train Loss: 0.219, Validation Loss: 0.257\n",
      "Epoch: 8552, Train Loss: 0.273, Validation Loss: 0.255\n",
      "Epoch: 8553, Train Loss: 0.389, Validation Loss: 0.254\n",
      "Epoch: 8554, Train Loss: 0.182, Validation Loss: 0.255\n",
      "Epoch: 8555, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 8556, Train Loss: 0.273, Validation Loss: 0.252\n",
      "Epoch: 8557, Train Loss: 0.277, Validation Loss: 0.251\n",
      "Epoch: 8558, Train Loss: 0.190, Validation Loss: 0.256\n",
      "Epoch: 8559, Train Loss: 0.227, Validation Loss: 0.257\n",
      "Epoch: 8560, Train Loss: 0.587, Validation Loss: 0.252\n",
      "Epoch: 8561, Train Loss: 0.460, Validation Loss: 0.253\n",
      "Epoch: 8562, Train Loss: 0.308, Validation Loss: 0.257\n",
      "Epoch: 8563, Train Loss: 0.349, Validation Loss: 0.260\n",
      "Epoch: 8564, Train Loss: 0.268, Validation Loss: 0.258\n",
      "Epoch: 8565, Train Loss: 0.239, Validation Loss: 0.258\n",
      "Epoch: 8566, Train Loss: 0.292, Validation Loss: 0.252\n",
      "Epoch: 8567, Train Loss: 0.278, Validation Loss: 0.254\n",
      "Epoch: 8568, Train Loss: 0.238, Validation Loss: 0.259\n",
      "Epoch: 8569, Train Loss: 0.331, Validation Loss: 0.258\n",
      "Epoch: 8570, Train Loss: 0.236, Validation Loss: 0.257\n",
      "Epoch: 8571, Train Loss: 0.280, Validation Loss: 0.258\n",
      "Epoch: 8572, Train Loss: 0.359, Validation Loss: 0.255\n",
      "Epoch: 8573, Train Loss: 0.213, Validation Loss: 0.258\n",
      "Epoch: 8574, Train Loss: 0.197, Validation Loss: 0.260\n",
      "Epoch: 8575, Train Loss: 0.288, Validation Loss: 0.261\n",
      "Epoch: 8576, Train Loss: 0.228, Validation Loss: 0.262\n",
      "Epoch: 8577, Train Loss: 0.266, Validation Loss: 0.252\n",
      "Epoch: 8578, Train Loss: 0.320, Validation Loss: 0.253\n",
      "Epoch: 8579, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 8580, Train Loss: 0.399, Validation Loss: 0.251\n",
      "Epoch: 8581, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 8582, Train Loss: 0.218, Validation Loss: 0.255\n",
      "Epoch: 8583, Train Loss: 0.225, Validation Loss: 0.254\n",
      "Epoch: 8584, Train Loss: 0.180, Validation Loss: 0.255\n",
      "Epoch: 8585, Train Loss: 0.492, Validation Loss: 0.255\n",
      "Epoch: 8586, Train Loss: 0.177, Validation Loss: 0.257\n",
      "Epoch: 8587, Train Loss: 0.234, Validation Loss: 0.259\n",
      "Epoch: 8588, Train Loss: 0.190, Validation Loss: 0.257\n",
      "Epoch: 8589, Train Loss: 0.193, Validation Loss: 0.259\n",
      "Epoch: 8590, Train Loss: 0.201, Validation Loss: 0.261\n",
      "Epoch: 8591, Train Loss: 0.435, Validation Loss: 0.268\n",
      "Epoch: 8592, Train Loss: 0.279, Validation Loss: 0.262\n",
      "Epoch: 8593, Train Loss: 0.175, Validation Loss: 0.255\n",
      "Epoch: 8594, Train Loss: 0.335, Validation Loss: 0.252\n",
      "Epoch: 8595, Train Loss: 0.265, Validation Loss: 0.257\n",
      "Epoch: 8596, Train Loss: 0.224, Validation Loss: 0.251\n",
      "Epoch: 8597, Train Loss: 0.185, Validation Loss: 0.252\n",
      "Epoch: 8598, Train Loss: 0.271, Validation Loss: 0.256\n",
      "Epoch: 8599, Train Loss: 0.542, Validation Loss: 0.252\n",
      "Epoch: 8600, Train Loss: 0.299, Validation Loss: 0.251\n",
      "Epoch: 8601, Train Loss: 0.176, Validation Loss: 0.248\n",
      "Epoch: 8602, Train Loss: 0.357, Validation Loss: 0.256\n",
      "Epoch: 8603, Train Loss: 0.271, Validation Loss: 0.256\n",
      "Epoch: 8604, Train Loss: 0.240, Validation Loss: 0.255\n",
      "Epoch: 8605, Train Loss: 0.390, Validation Loss: 0.249\n",
      "Epoch: 8606, Train Loss: 0.506, Validation Loss: 0.251\n",
      "Epoch: 8607, Train Loss: 0.378, Validation Loss: 0.248\n",
      "Epoch: 8608, Train Loss: 0.214, Validation Loss: 0.251\n",
      "Epoch: 8609, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 8610, Train Loss: 0.404, Validation Loss: 0.250\n",
      "Epoch: 8611, Train Loss: 0.234, Validation Loss: 0.249\n",
      "Epoch: 8612, Train Loss: 0.281, Validation Loss: 0.252\n",
      "Epoch: 8613, Train Loss: 0.346, Validation Loss: 0.248\n",
      "Epoch: 8614, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 8615, Train Loss: 0.175, Validation Loss: 0.252\n",
      "Epoch: 8616, Train Loss: 0.196, Validation Loss: 0.252\n",
      "Epoch: 8617, Train Loss: 0.248, Validation Loss: 0.251\n",
      "Epoch: 8618, Train Loss: 0.250, Validation Loss: 0.254\n",
      "Epoch: 8619, Train Loss: 0.335, Validation Loss: 0.253\n",
      "Epoch: 8620, Train Loss: 0.191, Validation Loss: 0.254\n",
      "Epoch: 8621, Train Loss: 0.247, Validation Loss: 0.250\n",
      "Epoch: 8622, Train Loss: 0.239, Validation Loss: 0.254\n",
      "Epoch: 8623, Train Loss: 0.246, Validation Loss: 0.251\n",
      "Epoch: 8624, Train Loss: 0.541, Validation Loss: 0.251\n",
      "Epoch: 8625, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 8626, Train Loss: 0.220, Validation Loss: 0.254\n",
      "Epoch: 8627, Train Loss: 0.307, Validation Loss: 0.250\n",
      "Epoch: 8628, Train Loss: 0.281, Validation Loss: 0.254\n",
      "Epoch: 8629, Train Loss: 0.220, Validation Loss: 0.251\n",
      "Epoch: 8630, Train Loss: 0.142, Validation Loss: 0.247\n",
      "Epoch: 8631, Train Loss: 0.214, Validation Loss: 0.249\n",
      "Epoch: 8632, Train Loss: 0.440, Validation Loss: 0.254\n",
      "Epoch: 8633, Train Loss: 0.209, Validation Loss: 0.254\n",
      "Epoch: 8634, Train Loss: 0.208, Validation Loss: 0.259\n",
      "Epoch: 8635, Train Loss: 0.229, Validation Loss: 0.252\n",
      "Epoch: 8636, Train Loss: 0.210, Validation Loss: 0.254\n",
      "Epoch: 8637, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 8638, Train Loss: 0.393, Validation Loss: 0.252\n",
      "Epoch: 8639, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 8640, Train Loss: 0.730, Validation Loss: 0.247\n",
      "Epoch: 8641, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 8642, Train Loss: 0.190, Validation Loss: 0.251\n",
      "Epoch: 8643, Train Loss: 0.190, Validation Loss: 0.253\n",
      "Epoch: 8644, Train Loss: 0.245, Validation Loss: 0.249\n",
      "Epoch: 8645, Train Loss: 0.228, Validation Loss: 0.248\n",
      "Epoch: 8646, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 8647, Train Loss: 0.266, Validation Loss: 0.254\n",
      "Epoch: 8648, Train Loss: 0.187, Validation Loss: 0.252\n",
      "Epoch: 8649, Train Loss: 0.256, Validation Loss: 0.252\n",
      "Epoch: 8650, Train Loss: 0.232, Validation Loss: 0.253\n",
      "Epoch: 8651, Train Loss: 0.383, Validation Loss: 0.252\n",
      "Epoch: 8652, Train Loss: 0.266, Validation Loss: 0.248\n",
      "Epoch: 8653, Train Loss: 0.253, Validation Loss: 0.249\n",
      "Epoch: 8654, Train Loss: 0.288, Validation Loss: 0.257\n",
      "Epoch: 8655, Train Loss: 0.238, Validation Loss: 0.253\n",
      "Epoch: 8656, Train Loss: 0.288, Validation Loss: 0.249\n",
      "Epoch: 8657, Train Loss: 0.222, Validation Loss: 0.256\n",
      "Epoch: 8658, Train Loss: 0.193, Validation Loss: 0.253\n",
      "Epoch: 8659, Train Loss: 0.421, Validation Loss: 0.252\n",
      "Epoch: 8660, Train Loss: 0.188, Validation Loss: 0.251\n",
      "Epoch: 8661, Train Loss: 0.252, Validation Loss: 0.250\n",
      "Epoch: 8662, Train Loss: 0.210, Validation Loss: 0.253\n",
      "Epoch: 8663, Train Loss: 0.208, Validation Loss: 0.252\n",
      "Epoch: 8664, Train Loss: 0.295, Validation Loss: 0.254\n",
      "Epoch: 8665, Train Loss: 0.237, Validation Loss: 0.252\n",
      "Epoch: 8666, Train Loss: 0.258, Validation Loss: 0.250\n",
      "Epoch: 8667, Train Loss: 0.233, Validation Loss: 0.252\n",
      "Epoch: 8668, Train Loss: 0.231, Validation Loss: 0.254\n",
      "Epoch: 8669, Train Loss: 0.187, Validation Loss: 0.252\n",
      "Epoch: 8670, Train Loss: 0.195, Validation Loss: 0.253\n",
      "Epoch: 8671, Train Loss: 0.295, Validation Loss: 0.255\n",
      "Epoch: 8672, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 8673, Train Loss: 0.356, Validation Loss: 0.254\n",
      "Epoch: 8674, Train Loss: 0.251, Validation Loss: 0.252\n",
      "Epoch: 8675, Train Loss: 0.243, Validation Loss: 0.247\n",
      "Epoch: 8676, Train Loss: 0.196, Validation Loss: 0.247\n",
      "Epoch: 8677, Train Loss: 0.316, Validation Loss: 0.255\n",
      "Epoch: 8678, Train Loss: 0.363, Validation Loss: 0.247\n",
      "Epoch: 8679, Train Loss: 0.178, Validation Loss: 0.249\n",
      "Epoch: 8680, Train Loss: 0.246, Validation Loss: 0.253\n",
      "Epoch: 8681, Train Loss: 0.243, Validation Loss: 0.256\n",
      "Epoch: 8682, Train Loss: 0.336, Validation Loss: 0.248\n",
      "Epoch: 8683, Train Loss: 0.228, Validation Loss: 0.249\n",
      "Epoch: 8684, Train Loss: 0.159, Validation Loss: 0.251\n",
      "Epoch: 8685, Train Loss: 0.299, Validation Loss: 0.248\n",
      "Epoch: 8686, Train Loss: 0.137, Validation Loss: 0.249\n",
      "Epoch: 8687, Train Loss: 0.163, Validation Loss: 0.249\n",
      "Epoch: 8688, Train Loss: 0.277, Validation Loss: 0.253\n",
      "Epoch: 8689, Train Loss: 0.218, Validation Loss: 0.253\n",
      "Epoch: 8690, Train Loss: 0.263, Validation Loss: 0.257\n",
      "Epoch: 8691, Train Loss: 0.268, Validation Loss: 0.255\n",
      "Epoch: 8692, Train Loss: 0.223, Validation Loss: 0.257\n",
      "Epoch: 8693, Train Loss: 0.246, Validation Loss: 0.256\n",
      "Epoch: 8694, Train Loss: 0.301, Validation Loss: 0.253\n",
      "Epoch: 8695, Train Loss: 0.228, Validation Loss: 0.253\n",
      "Epoch: 8696, Train Loss: 0.258, Validation Loss: 0.256\n",
      "Epoch: 8697, Train Loss: 0.298, Validation Loss: 0.257\n",
      "Epoch: 8698, Train Loss: 0.246, Validation Loss: 0.252\n",
      "Epoch: 8699, Train Loss: 0.274, Validation Loss: 0.253\n",
      "Epoch: 8700, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 8701, Train Loss: 0.493, Validation Loss: 0.254\n",
      "Epoch: 8702, Train Loss: 0.186, Validation Loss: 0.253\n",
      "Epoch: 8703, Train Loss: 0.211, Validation Loss: 0.251\n",
      "Epoch: 8704, Train Loss: 0.184, Validation Loss: 0.251\n",
      "Epoch: 8705, Train Loss: 0.320, Validation Loss: 0.255\n",
      "Epoch: 8706, Train Loss: 0.204, Validation Loss: 0.250\n",
      "Epoch: 8707, Train Loss: 0.411, Validation Loss: 0.255\n",
      "Epoch: 8708, Train Loss: 0.189, Validation Loss: 0.250\n",
      "Epoch: 8709, Train Loss: 0.348, Validation Loss: 0.255\n",
      "Epoch: 8710, Train Loss: 0.306, Validation Loss: 0.251\n",
      "Epoch: 8711, Train Loss: 0.184, Validation Loss: 0.252\n",
      "Epoch: 8712, Train Loss: 0.217, Validation Loss: 0.252\n",
      "Epoch: 8713, Train Loss: 0.224, Validation Loss: 0.250\n",
      "Epoch: 8714, Train Loss: 0.584, Validation Loss: 0.248\n",
      "Epoch: 8715, Train Loss: 0.346, Validation Loss: 0.250\n",
      "Epoch: 8716, Train Loss: 0.276, Validation Loss: 0.252\n",
      "Epoch: 8717, Train Loss: 0.269, Validation Loss: 0.249\n",
      "Epoch: 8718, Train Loss: 0.416, Validation Loss: 0.254\n",
      "Epoch: 8719, Train Loss: 0.314, Validation Loss: 0.253\n",
      "Epoch: 8720, Train Loss: 0.183, Validation Loss: 0.251\n",
      "Epoch: 8721, Train Loss: 0.225, Validation Loss: 0.253\n",
      "Epoch: 8722, Train Loss: 0.221, Validation Loss: 0.251\n",
      "Epoch: 8723, Train Loss: 0.196, Validation Loss: 0.254\n",
      "Epoch: 8724, Train Loss: 0.236, Validation Loss: 0.258\n",
      "Epoch: 8725, Train Loss: 0.310, Validation Loss: 0.252\n",
      "Epoch: 8726, Train Loss: 0.333, Validation Loss: 0.259\n",
      "Epoch: 8727, Train Loss: 0.250, Validation Loss: 0.251\n",
      "Epoch: 8728, Train Loss: 0.203, Validation Loss: 0.253\n",
      "Epoch: 8729, Train Loss: 0.257, Validation Loss: 0.252\n",
      "Epoch: 8730, Train Loss: 0.361, Validation Loss: 0.253\n",
      "Epoch: 8731, Train Loss: 0.249, Validation Loss: 0.253\n",
      "Epoch: 8732, Train Loss: 0.168, Validation Loss: 0.258\n",
      "Epoch: 8733, Train Loss: 0.289, Validation Loss: 0.254\n",
      "Epoch: 8734, Train Loss: 0.226, Validation Loss: 0.255\n",
      "Epoch: 8735, Train Loss: 0.364, Validation Loss: 0.262\n",
      "Epoch: 8736, Train Loss: 0.262, Validation Loss: 0.257\n",
      "Epoch: 8737, Train Loss: 0.300, Validation Loss: 0.254\n",
      "Epoch: 8738, Train Loss: 0.269, Validation Loss: 0.252\n",
      "Epoch: 8739, Train Loss: 0.164, Validation Loss: 0.257\n",
      "Epoch: 8740, Train Loss: 0.435, Validation Loss: 0.255\n",
      "Epoch: 8741, Train Loss: 0.202, Validation Loss: 0.256\n",
      "Epoch: 8742, Train Loss: 0.549, Validation Loss: 0.255\n",
      "Epoch: 8743, Train Loss: 0.391, Validation Loss: 0.252\n",
      "Epoch: 8744, Train Loss: 0.364, Validation Loss: 0.252\n",
      "Epoch: 8745, Train Loss: 0.321, Validation Loss: 0.258\n",
      "Epoch: 8746, Train Loss: 0.255, Validation Loss: 0.255\n",
      "Epoch: 8747, Train Loss: 0.229, Validation Loss: 0.259\n",
      "Epoch: 8748, Train Loss: 0.170, Validation Loss: 0.254\n",
      "Epoch: 8749, Train Loss: 0.307, Validation Loss: 0.253\n",
      "Epoch: 8750, Train Loss: 0.251, Validation Loss: 0.258\n",
      "Epoch: 8751, Train Loss: 0.231, Validation Loss: 0.257\n",
      "Epoch: 8752, Train Loss: 0.258, Validation Loss: 0.258\n",
      "Epoch: 8753, Train Loss: 0.277, Validation Loss: 0.254\n",
      "Epoch: 8754, Train Loss: 0.318, Validation Loss: 0.254\n",
      "Epoch: 8755, Train Loss: 0.264, Validation Loss: 0.254\n",
      "Epoch: 8756, Train Loss: 0.208, Validation Loss: 0.255\n",
      "Epoch: 8757, Train Loss: 0.224, Validation Loss: 0.256\n",
      "Epoch: 8758, Train Loss: 0.192, Validation Loss: 0.258\n",
      "Epoch: 8759, Train Loss: 0.226, Validation Loss: 0.255\n",
      "Epoch: 8760, Train Loss: 0.328, Validation Loss: 0.254\n",
      "Epoch: 8761, Train Loss: 0.385, Validation Loss: 0.251\n",
      "Epoch: 8762, Train Loss: 0.185, Validation Loss: 0.253\n",
      "Epoch: 8763, Train Loss: 0.448, Validation Loss: 0.254\n",
      "Epoch: 8764, Train Loss: 0.206, Validation Loss: 0.260\n",
      "Epoch: 8765, Train Loss: 0.274, Validation Loss: 0.258\n",
      "Epoch: 8766, Train Loss: 0.342, Validation Loss: 0.252\n",
      "Epoch: 8767, Train Loss: 0.239, Validation Loss: 0.258\n",
      "Epoch: 8768, Train Loss: 0.191, Validation Loss: 0.252\n",
      "Epoch: 8769, Train Loss: 0.291, Validation Loss: 0.253\n",
      "Epoch: 8770, Train Loss: 0.283, Validation Loss: 0.255\n",
      "Epoch: 8771, Train Loss: 0.277, Validation Loss: 0.258\n",
      "Epoch: 8772, Train Loss: 0.150, Validation Loss: 0.254\n",
      "Epoch: 8773, Train Loss: 0.291, Validation Loss: 0.259\n",
      "Epoch: 8774, Train Loss: 0.277, Validation Loss: 0.256\n",
      "Epoch: 8775, Train Loss: 0.204, Validation Loss: 0.261\n",
      "Epoch: 8776, Train Loss: 0.259, Validation Loss: 0.258\n",
      "Epoch: 8777, Train Loss: 0.211, Validation Loss: 0.256\n",
      "Epoch: 8778, Train Loss: 0.223, Validation Loss: 0.256\n",
      "Epoch: 8779, Train Loss: 0.221, Validation Loss: 0.256\n",
      "Epoch: 8780, Train Loss: 0.308, Validation Loss: 0.251\n",
      "Epoch: 8781, Train Loss: 0.214, Validation Loss: 0.250\n",
      "Epoch: 8782, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 8783, Train Loss: 0.383, Validation Loss: 0.259\n",
      "Epoch: 8784, Train Loss: 0.263, Validation Loss: 0.255\n",
      "Epoch: 8785, Train Loss: 0.196, Validation Loss: 0.251\n",
      "Epoch: 8786, Train Loss: 0.232, Validation Loss: 0.250\n",
      "Epoch: 8787, Train Loss: 0.219, Validation Loss: 0.253\n",
      "Epoch: 8788, Train Loss: 0.314, Validation Loss: 0.249\n",
      "Epoch: 8789, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 8790, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 8791, Train Loss: 0.335, Validation Loss: 0.254\n",
      "Epoch: 8792, Train Loss: 0.567, Validation Loss: 0.250\n",
      "Epoch: 8793, Train Loss: 0.302, Validation Loss: 0.249\n",
      "Epoch: 8794, Train Loss: 0.298, Validation Loss: 0.251\n",
      "Epoch: 8795, Train Loss: 0.353, Validation Loss: 0.250\n",
      "Epoch: 8796, Train Loss: 0.247, Validation Loss: 0.248\n",
      "Epoch: 8797, Train Loss: 0.311, Validation Loss: 0.255\n",
      "Epoch: 8798, Train Loss: 0.226, Validation Loss: 0.253\n",
      "Epoch: 8799, Train Loss: 0.398, Validation Loss: 0.251\n",
      "Epoch: 8800, Train Loss: 0.254, Validation Loss: 0.253\n",
      "Epoch: 8801, Train Loss: 0.186, Validation Loss: 0.255\n",
      "Epoch: 8802, Train Loss: 0.150, Validation Loss: 0.253\n",
      "Epoch: 8803, Train Loss: 0.398, Validation Loss: 0.252\n",
      "Epoch: 8804, Train Loss: 0.324, Validation Loss: 0.253\n",
      "Epoch: 8805, Train Loss: 0.208, Validation Loss: 0.259\n",
      "Epoch: 8806, Train Loss: 0.225, Validation Loss: 0.259\n",
      "Epoch: 8807, Train Loss: 0.330, Validation Loss: 0.255\n",
      "Epoch: 8808, Train Loss: 0.257, Validation Loss: 0.250\n",
      "Epoch: 8809, Train Loss: 0.240, Validation Loss: 0.252\n",
      "Epoch: 8810, Train Loss: 0.200, Validation Loss: 0.253\n",
      "Epoch: 8811, Train Loss: 0.247, Validation Loss: 0.255\n",
      "Epoch: 8812, Train Loss: 0.276, Validation Loss: 0.254\n",
      "Epoch: 8813, Train Loss: 0.230, Validation Loss: 0.256\n",
      "Epoch: 8814, Train Loss: 0.191, Validation Loss: 0.252\n",
      "Epoch: 8815, Train Loss: 0.538, Validation Loss: 0.256\n",
      "Epoch: 8816, Train Loss: 0.230, Validation Loss: 0.252\n",
      "Epoch: 8817, Train Loss: 0.224, Validation Loss: 0.253\n",
      "Epoch: 8818, Train Loss: 0.225, Validation Loss: 0.254\n",
      "Epoch: 8819, Train Loss: 0.236, Validation Loss: 0.253\n",
      "Epoch: 8820, Train Loss: 0.195, Validation Loss: 0.255\n",
      "Epoch: 8821, Train Loss: 0.418, Validation Loss: 0.253\n",
      "Epoch: 8822, Train Loss: 0.215, Validation Loss: 0.252\n",
      "Epoch: 8823, Train Loss: 0.197, Validation Loss: 0.257\n",
      "Epoch: 8824, Train Loss: 0.237, Validation Loss: 0.250\n",
      "Epoch: 8825, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 8826, Train Loss: 0.377, Validation Loss: 0.248\n",
      "Epoch: 8827, Train Loss: 0.382, Validation Loss: 0.254\n",
      "Epoch: 8828, Train Loss: 0.230, Validation Loss: 0.249\n",
      "Epoch: 8829, Train Loss: 0.251, Validation Loss: 0.250\n",
      "Epoch: 8830, Train Loss: 0.219, Validation Loss: 0.248\n",
      "Epoch: 8831, Train Loss: 0.363, Validation Loss: 0.245\n",
      "Epoch: 8832, Train Loss: 0.251, Validation Loss: 0.249\n",
      "Epoch: 8833, Train Loss: 0.363, Validation Loss: 0.247\n",
      "Epoch: 8834, Train Loss: 0.256, Validation Loss: 0.249\n",
      "Epoch: 8835, Train Loss: 0.205, Validation Loss: 0.249\n",
      "Epoch: 8836, Train Loss: 0.198, Validation Loss: 0.253\n",
      "Epoch: 8837, Train Loss: 0.284, Validation Loss: 0.250\n",
      "Epoch: 8838, Train Loss: 0.203, Validation Loss: 0.252\n",
      "Epoch: 8839, Train Loss: 0.487, Validation Loss: 0.249\n",
      "Epoch: 8840, Train Loss: 0.237, Validation Loss: 0.257\n",
      "Epoch: 8841, Train Loss: 0.216, Validation Loss: 0.252\n",
      "Epoch: 8842, Train Loss: 0.204, Validation Loss: 0.254\n",
      "Epoch: 8843, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 8844, Train Loss: 0.202, Validation Loss: 0.254\n",
      "Epoch: 8845, Train Loss: 0.208, Validation Loss: 0.254\n",
      "Epoch: 8846, Train Loss: 0.465, Validation Loss: 0.251\n",
      "Epoch: 8847, Train Loss: 0.282, Validation Loss: 0.251\n",
      "Epoch: 8848, Train Loss: 0.204, Validation Loss: 0.252\n",
      "Epoch: 8849, Train Loss: 0.337, Validation Loss: 0.251\n",
      "Epoch: 8850, Train Loss: 0.226, Validation Loss: 0.253\n",
      "Epoch: 8851, Train Loss: 0.223, Validation Loss: 0.252\n",
      "Epoch: 8852, Train Loss: 0.239, Validation Loss: 0.253\n",
      "Epoch: 8853, Train Loss: 0.354, Validation Loss: 0.252\n",
      "Epoch: 8854, Train Loss: 0.239, Validation Loss: 0.250\n",
      "Epoch: 8855, Train Loss: 0.242, Validation Loss: 0.253\n",
      "Epoch: 8856, Train Loss: 0.245, Validation Loss: 0.251\n",
      "Epoch: 8857, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 8858, Train Loss: 0.199, Validation Loss: 0.251\n",
      "Epoch: 8859, Train Loss: 0.314, Validation Loss: 0.248\n",
      "Epoch: 8860, Train Loss: 0.333, Validation Loss: 0.249\n",
      "Epoch: 8861, Train Loss: 0.276, Validation Loss: 0.257\n",
      "Epoch: 8862, Train Loss: 0.321, Validation Loss: 0.255\n",
      "Epoch: 8863, Train Loss: 0.260, Validation Loss: 0.254\n",
      "Epoch: 8864, Train Loss: 0.236, Validation Loss: 0.253\n",
      "Epoch: 8865, Train Loss: 0.227, Validation Loss: 0.251\n",
      "Epoch: 8866, Train Loss: 0.227, Validation Loss: 0.257\n",
      "Epoch: 8867, Train Loss: 0.286, Validation Loss: 0.258\n",
      "Epoch: 8868, Train Loss: 0.327, Validation Loss: 0.255\n",
      "Epoch: 8869, Train Loss: 0.214, Validation Loss: 0.255\n",
      "Epoch: 8870, Train Loss: 0.425, Validation Loss: 0.257\n",
      "Epoch: 8871, Train Loss: 0.305, Validation Loss: 0.256\n",
      "Epoch: 8872, Train Loss: 0.219, Validation Loss: 0.261\n",
      "Epoch: 8873, Train Loss: 0.245, Validation Loss: 0.261\n",
      "Epoch: 8874, Train Loss: 0.609, Validation Loss: 0.257\n",
      "Epoch: 8875, Train Loss: 0.295, Validation Loss: 0.259\n",
      "Epoch: 8876, Train Loss: 0.266, Validation Loss: 0.260\n",
      "Epoch: 8877, Train Loss: 0.250, Validation Loss: 0.260\n",
      "Epoch: 8878, Train Loss: 0.287, Validation Loss: 0.262\n",
      "Epoch: 8879, Train Loss: 0.243, Validation Loss: 0.261\n",
      "Epoch: 8880, Train Loss: 0.244, Validation Loss: 0.259\n",
      "Epoch: 8881, Train Loss: 0.212, Validation Loss: 0.256\n",
      "Epoch: 8882, Train Loss: 0.944, Validation Loss: 0.254\n",
      "Epoch: 8883, Train Loss: 0.233, Validation Loss: 0.256\n",
      "Epoch: 8884, Train Loss: 0.468, Validation Loss: 0.252\n",
      "Epoch: 8885, Train Loss: 0.174, Validation Loss: 0.255\n",
      "Epoch: 8886, Train Loss: 0.658, Validation Loss: 0.258\n",
      "Epoch: 8887, Train Loss: 0.254, Validation Loss: 0.256\n",
      "Epoch: 8888, Train Loss: 0.157, Validation Loss: 0.256\n",
      "Epoch: 8889, Train Loss: 0.204, Validation Loss: 0.258\n",
      "Epoch: 8890, Train Loss: 0.232, Validation Loss: 0.259\n",
      "Epoch: 8891, Train Loss: 0.246, Validation Loss: 0.256\n",
      "Epoch: 8892, Train Loss: 0.519, Validation Loss: 0.256\n",
      "Epoch: 8893, Train Loss: 0.232, Validation Loss: 0.260\n",
      "Epoch: 8894, Train Loss: 0.328, Validation Loss: 0.258\n",
      "Epoch: 8895, Train Loss: 0.425, Validation Loss: 0.260\n",
      "Epoch: 8896, Train Loss: 0.268, Validation Loss: 0.259\n",
      "Epoch: 8897, Train Loss: 0.279, Validation Loss: 0.261\n",
      "Epoch: 8898, Train Loss: 0.345, Validation Loss: 0.265\n",
      "Epoch: 8899, Train Loss: 0.254, Validation Loss: 0.265\n",
      "Epoch: 8900, Train Loss: 0.144, Validation Loss: 0.262\n",
      "Epoch: 8901, Train Loss: 0.227, Validation Loss: 0.260\n",
      "Epoch: 8902, Train Loss: 0.182, Validation Loss: 0.257\n",
      "Epoch: 8903, Train Loss: 0.391, Validation Loss: 0.252\n",
      "Epoch: 8904, Train Loss: 0.276, Validation Loss: 0.253\n",
      "Epoch: 8905, Train Loss: 0.267, Validation Loss: 0.254\n",
      "Epoch: 8906, Train Loss: 0.332, Validation Loss: 0.259\n",
      "Epoch: 8907, Train Loss: 0.501, Validation Loss: 0.253\n",
      "Epoch: 8908, Train Loss: 0.207, Validation Loss: 0.251\n",
      "Epoch: 8909, Train Loss: 0.178, Validation Loss: 0.249\n",
      "Epoch: 8910, Train Loss: 0.222, Validation Loss: 0.250\n",
      "Epoch: 8911, Train Loss: 0.184, Validation Loss: 0.252\n",
      "Epoch: 8912, Train Loss: 0.259, Validation Loss: 0.249\n",
      "Epoch: 8913, Train Loss: 0.285, Validation Loss: 0.247\n",
      "Epoch: 8914, Train Loss: 0.197, Validation Loss: 0.253\n",
      "Epoch: 8915, Train Loss: 0.406, Validation Loss: 0.248\n",
      "Epoch: 8916, Train Loss: 0.211, Validation Loss: 0.250\n",
      "Epoch: 8917, Train Loss: 0.294, Validation Loss: 0.250\n",
      "Epoch: 8918, Train Loss: 0.292, Validation Loss: 0.255\n",
      "Epoch: 8919, Train Loss: 0.271, Validation Loss: 0.256\n",
      "Epoch: 8920, Train Loss: 0.215, Validation Loss: 0.247\n",
      "Epoch: 8921, Train Loss: 0.397, Validation Loss: 0.245\n",
      "Epoch: 8922, Train Loss: 0.328, Validation Loss: 0.246\n",
      "Epoch: 8923, Train Loss: 0.473, Validation Loss: 0.250\n",
      "Epoch: 8924, Train Loss: 0.199, Validation Loss: 0.253\n",
      "Epoch: 8925, Train Loss: 0.497, Validation Loss: 0.252\n",
      "Epoch: 8926, Train Loss: 0.250, Validation Loss: 0.249\n",
      "Epoch: 8927, Train Loss: 0.279, Validation Loss: 0.248\n",
      "Epoch: 8928, Train Loss: 0.269, Validation Loss: 0.250\n",
      "Epoch: 8929, Train Loss: 0.277, Validation Loss: 0.249\n",
      "Epoch: 8930, Train Loss: 0.221, Validation Loss: 0.252\n",
      "Epoch: 8931, Train Loss: 0.296, Validation Loss: 0.256\n",
      "Epoch: 8932, Train Loss: 0.243, Validation Loss: 0.254\n",
      "Epoch: 8933, Train Loss: 0.263, Validation Loss: 0.260\n",
      "Epoch: 8934, Train Loss: 0.304, Validation Loss: 0.259\n",
      "Epoch: 8935, Train Loss: 0.458, Validation Loss: 0.251\n",
      "Epoch: 8936, Train Loss: 0.173, Validation Loss: 0.252\n",
      "Epoch: 8937, Train Loss: 0.202, Validation Loss: 0.255\n",
      "Epoch: 8938, Train Loss: 0.303, Validation Loss: 0.255\n",
      "Epoch: 8939, Train Loss: 0.241, Validation Loss: 0.256\n",
      "Epoch: 8940, Train Loss: 0.172, Validation Loss: 0.253\n",
      "Epoch: 8941, Train Loss: 0.354, Validation Loss: 0.261\n",
      "Epoch: 8942, Train Loss: 0.366, Validation Loss: 0.266\n",
      "Epoch: 8943, Train Loss: 0.222, Validation Loss: 0.252\n",
      "Epoch: 8944, Train Loss: 0.348, Validation Loss: 0.253\n",
      "Epoch: 8945, Train Loss: 0.302, Validation Loss: 0.255\n",
      "Epoch: 8946, Train Loss: 0.198, Validation Loss: 0.257\n",
      "Epoch: 8947, Train Loss: 0.309, Validation Loss: 0.255\n",
      "Epoch: 8948, Train Loss: 0.266, Validation Loss: 0.262\n",
      "Epoch: 8949, Train Loss: 0.337, Validation Loss: 0.257\n",
      "Epoch: 8950, Train Loss: 0.412, Validation Loss: 0.253\n",
      "Epoch: 8951, Train Loss: 0.264, Validation Loss: 0.258\n",
      "Epoch: 8952, Train Loss: 0.359, Validation Loss: 0.248\n",
      "Epoch: 8953, Train Loss: 0.399, Validation Loss: 0.247\n",
      "Epoch: 8954, Train Loss: 0.241, Validation Loss: 0.249\n",
      "Epoch: 8955, Train Loss: 0.178, Validation Loss: 0.256\n",
      "Epoch: 8956, Train Loss: 0.168, Validation Loss: 0.256\n",
      "Epoch: 8957, Train Loss: 0.210, Validation Loss: 0.255\n",
      "Epoch: 8958, Train Loss: 0.211, Validation Loss: 0.250\n",
      "Epoch: 8959, Train Loss: 0.246, Validation Loss: 0.253\n",
      "Epoch: 8960, Train Loss: 0.364, Validation Loss: 0.252\n",
      "Epoch: 8961, Train Loss: 0.217, Validation Loss: 0.249\n",
      "Epoch: 8962, Train Loss: 0.311, Validation Loss: 0.252\n",
      "Epoch: 8963, Train Loss: 0.248, Validation Loss: 0.249\n",
      "Epoch: 8964, Train Loss: 0.253, Validation Loss: 0.247\n",
      "Epoch: 8965, Train Loss: 0.232, Validation Loss: 0.248\n",
      "Epoch: 8966, Train Loss: 0.419, Validation Loss: 0.249\n",
      "Epoch: 8967, Train Loss: 0.466, Validation Loss: 0.252\n",
      "Epoch: 8968, Train Loss: 0.229, Validation Loss: 0.252\n",
      "Epoch: 8969, Train Loss: 0.474, Validation Loss: 0.253\n",
      "Epoch: 8970, Train Loss: 0.445, Validation Loss: 0.252\n",
      "Epoch: 8971, Train Loss: 0.192, Validation Loss: 0.252\n",
      "Epoch: 8972, Train Loss: 0.269, Validation Loss: 0.257\n",
      "Epoch: 8973, Train Loss: 0.326, Validation Loss: 0.258\n",
      "Epoch: 8974, Train Loss: 0.348, Validation Loss: 0.251\n",
      "Epoch: 8975, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 8976, Train Loss: 0.275, Validation Loss: 0.250\n",
      "Epoch: 8977, Train Loss: 0.211, Validation Loss: 0.258\n",
      "Epoch: 8978, Train Loss: 0.351, Validation Loss: 0.264\n",
      "Epoch: 8979, Train Loss: 0.378, Validation Loss: 0.254\n",
      "Epoch: 8980, Train Loss: 0.275, Validation Loss: 0.253\n",
      "Epoch: 8981, Train Loss: 0.240, Validation Loss: 0.253\n",
      "Epoch: 8982, Train Loss: 0.160, Validation Loss: 0.254\n",
      "Epoch: 8983, Train Loss: 0.459, Validation Loss: 0.257\n",
      "Epoch: 8984, Train Loss: 0.377, Validation Loss: 0.263\n",
      "Epoch: 8985, Train Loss: 0.198, Validation Loss: 0.260\n",
      "Epoch: 8986, Train Loss: 0.213, Validation Loss: 0.257\n",
      "Epoch: 8987, Train Loss: 0.233, Validation Loss: 0.254\n",
      "Epoch: 8988, Train Loss: 0.200, Validation Loss: 0.256\n",
      "Epoch: 8989, Train Loss: 0.224, Validation Loss: 0.257\n",
      "Epoch: 8990, Train Loss: 0.215, Validation Loss: 0.254\n",
      "Epoch: 8991, Train Loss: 0.253, Validation Loss: 0.257\n",
      "Epoch: 8992, Train Loss: 0.227, Validation Loss: 0.251\n",
      "Epoch: 8993, Train Loss: 0.261, Validation Loss: 0.254\n",
      "Epoch: 8994, Train Loss: 0.179, Validation Loss: 0.258\n",
      "Epoch: 8995, Train Loss: 0.333, Validation Loss: 0.259\n",
      "Epoch: 8996, Train Loss: 0.255, Validation Loss: 0.254\n",
      "Epoch: 8997, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 8998, Train Loss: 0.273, Validation Loss: 0.254\n",
      "Epoch: 8999, Train Loss: 0.343, Validation Loss: 0.262\n",
      "Epoch: 9000, Train Loss: 0.469, Validation Loss: 0.256\n",
      "Epoch: 9001, Train Loss: 0.223, Validation Loss: 0.257\n",
      "Epoch: 9002, Train Loss: 0.401, Validation Loss: 0.254\n",
      "Epoch: 9003, Train Loss: 0.212, Validation Loss: 0.259\n",
      "Epoch: 9004, Train Loss: 0.233, Validation Loss: 0.257\n",
      "Epoch: 9005, Train Loss: 0.306, Validation Loss: 0.256\n",
      "Epoch: 9006, Train Loss: 0.583, Validation Loss: 0.253\n",
      "Epoch: 9007, Train Loss: 0.215, Validation Loss: 0.254\n",
      "Epoch: 9008, Train Loss: 0.249, Validation Loss: 0.256\n",
      "Epoch: 9009, Train Loss: 0.293, Validation Loss: 0.261\n",
      "Epoch: 9010, Train Loss: 0.231, Validation Loss: 0.260\n",
      "Epoch: 9011, Train Loss: 0.189, Validation Loss: 0.260\n",
      "Epoch: 9012, Train Loss: 0.245, Validation Loss: 0.254\n",
      "Epoch: 9013, Train Loss: 0.242, Validation Loss: 0.258\n",
      "Epoch: 9014, Train Loss: 0.219, Validation Loss: 0.256\n",
      "Epoch: 9015, Train Loss: 0.422, Validation Loss: 0.265\n",
      "Epoch: 9016, Train Loss: 0.357, Validation Loss: 0.253\n",
      "Epoch: 9017, Train Loss: 0.386, Validation Loss: 0.252\n",
      "Epoch: 9018, Train Loss: 0.317, Validation Loss: 0.249\n",
      "Epoch: 9019, Train Loss: 0.247, Validation Loss: 0.250\n",
      "Epoch: 9020, Train Loss: 0.258, Validation Loss: 0.255\n",
      "Epoch: 9021, Train Loss: 0.303, Validation Loss: 0.256\n",
      "Epoch: 9022, Train Loss: 0.554, Validation Loss: 0.254\n",
      "Epoch: 9023, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 9024, Train Loss: 0.341, Validation Loss: 0.256\n",
      "Epoch: 9025, Train Loss: 0.200, Validation Loss: 0.259\n",
      "Epoch: 9026, Train Loss: 0.341, Validation Loss: 0.260\n",
      "Epoch: 9027, Train Loss: 0.208, Validation Loss: 0.257\n",
      "Epoch: 9028, Train Loss: 0.262, Validation Loss: 0.254\n",
      "Epoch: 9029, Train Loss: 0.262, Validation Loss: 0.252\n",
      "Epoch: 9030, Train Loss: 0.199, Validation Loss: 0.258\n",
      "Epoch: 9031, Train Loss: 0.211, Validation Loss: 0.255\n",
      "Epoch: 9032, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 9033, Train Loss: 0.225, Validation Loss: 0.258\n",
      "Epoch: 9034, Train Loss: 0.283, Validation Loss: 0.258\n",
      "Epoch: 9035, Train Loss: 0.494, Validation Loss: 0.249\n",
      "Epoch: 9036, Train Loss: 0.261, Validation Loss: 0.254\n",
      "Epoch: 9037, Train Loss: 0.365, Validation Loss: 0.251\n",
      "Epoch: 9038, Train Loss: 0.284, Validation Loss: 0.256\n",
      "Epoch: 9039, Train Loss: 0.323, Validation Loss: 0.256\n",
      "Epoch: 9040, Train Loss: 0.459, Validation Loss: 0.250\n",
      "Epoch: 9041, Train Loss: 0.613, Validation Loss: 0.251\n",
      "Epoch: 9042, Train Loss: 0.236, Validation Loss: 0.255\n",
      "Epoch: 9043, Train Loss: 0.259, Validation Loss: 0.256\n",
      "Epoch: 9044, Train Loss: 0.377, Validation Loss: 0.253\n",
      "Epoch: 9045, Train Loss: 0.278, Validation Loss: 0.257\n",
      "Epoch: 9046, Train Loss: 0.255, Validation Loss: 0.251\n",
      "Epoch: 9047, Train Loss: 0.212, Validation Loss: 0.256\n",
      "Epoch: 9048, Train Loss: 0.218, Validation Loss: 0.251\n",
      "Epoch: 9049, Train Loss: 0.288, Validation Loss: 0.256\n",
      "Epoch: 9050, Train Loss: 0.284, Validation Loss: 0.249\n",
      "Epoch: 9051, Train Loss: 0.179, Validation Loss: 0.252\n",
      "Epoch: 9052, Train Loss: 0.236, Validation Loss: 0.248\n",
      "Epoch: 9053, Train Loss: 0.241, Validation Loss: 0.251\n",
      "Epoch: 9054, Train Loss: 0.227, Validation Loss: 0.250\n",
      "Epoch: 9055, Train Loss: 0.264, Validation Loss: 0.249\n",
      "Epoch: 9056, Train Loss: 0.277, Validation Loss: 0.246\n",
      "Epoch: 9057, Train Loss: 0.202, Validation Loss: 0.249\n",
      "Epoch: 9058, Train Loss: 0.446, Validation Loss: 0.252\n",
      "Epoch: 9059, Train Loss: 0.413, Validation Loss: 0.249\n",
      "Epoch: 9060, Train Loss: 0.299, Validation Loss: 0.249\n",
      "Epoch: 9061, Train Loss: 0.266, Validation Loss: 0.253\n",
      "Epoch: 9062, Train Loss: 0.299, Validation Loss: 0.253\n",
      "Epoch: 9063, Train Loss: 0.215, Validation Loss: 0.249\n",
      "Epoch: 9064, Train Loss: 0.244, Validation Loss: 0.250\n",
      "Epoch: 9065, Train Loss: 0.201, Validation Loss: 0.251\n",
      "Epoch: 9066, Train Loss: 0.257, Validation Loss: 0.250\n",
      "Epoch: 9067, Train Loss: 0.332, Validation Loss: 0.255\n",
      "Epoch: 9068, Train Loss: 0.208, Validation Loss: 0.250\n",
      "Epoch: 9069, Train Loss: 0.232, Validation Loss: 0.252\n",
      "Epoch: 9070, Train Loss: 0.237, Validation Loss: 0.253\n",
      "Epoch: 9071, Train Loss: 0.265, Validation Loss: 0.254\n",
      "Epoch: 9072, Train Loss: 0.249, Validation Loss: 0.255\n",
      "Epoch: 9073, Train Loss: 0.572, Validation Loss: 0.252\n",
      "Epoch: 9074, Train Loss: 0.361, Validation Loss: 0.251\n",
      "Epoch: 9075, Train Loss: 0.273, Validation Loss: 0.256\n",
      "Epoch: 9076, Train Loss: 0.242, Validation Loss: 0.256\n",
      "Epoch: 9077, Train Loss: 0.264, Validation Loss: 0.254\n",
      "Epoch: 9078, Train Loss: 0.229, Validation Loss: 0.258\n",
      "Epoch: 9079, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 9080, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 9081, Train Loss: 0.307, Validation Loss: 0.259\n",
      "Epoch: 9082, Train Loss: 0.219, Validation Loss: 0.256\n",
      "Epoch: 9083, Train Loss: 0.158, Validation Loss: 0.256\n",
      "Epoch: 9084, Train Loss: 0.181, Validation Loss: 0.253\n",
      "Epoch: 9085, Train Loss: 0.434, Validation Loss: 0.258\n",
      "Epoch: 9086, Train Loss: 0.248, Validation Loss: 0.252\n",
      "Epoch: 9087, Train Loss: 0.299, Validation Loss: 0.258\n",
      "Epoch: 9088, Train Loss: 0.248, Validation Loss: 0.254\n",
      "Epoch: 9089, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 9090, Train Loss: 0.304, Validation Loss: 0.255\n",
      "Epoch: 9091, Train Loss: 0.211, Validation Loss: 0.257\n",
      "Epoch: 9092, Train Loss: 0.304, Validation Loss: 0.257\n",
      "Epoch: 9093, Train Loss: 0.216, Validation Loss: 0.258\n",
      "Epoch: 9094, Train Loss: 0.198, Validation Loss: 0.253\n",
      "Epoch: 9095, Train Loss: 0.176, Validation Loss: 0.258\n",
      "Epoch: 9096, Train Loss: 0.303, Validation Loss: 0.259\n",
      "Epoch: 9097, Train Loss: 0.203, Validation Loss: 0.256\n",
      "Epoch: 9098, Train Loss: 0.250, Validation Loss: 0.256\n",
      "Epoch: 9099, Train Loss: 0.238, Validation Loss: 0.256\n",
      "Epoch: 9100, Train Loss: 0.270, Validation Loss: 0.256\n",
      "Epoch: 9101, Train Loss: 0.308, Validation Loss: 0.265\n",
      "Epoch: 9102, Train Loss: 0.236, Validation Loss: 0.256\n",
      "Epoch: 9103, Train Loss: 0.243, Validation Loss: 0.258\n",
      "Epoch: 9104, Train Loss: 0.169, Validation Loss: 0.257\n",
      "Epoch: 9105, Train Loss: 0.204, Validation Loss: 0.258\n",
      "Epoch: 9106, Train Loss: 0.343, Validation Loss: 0.254\n",
      "Epoch: 9107, Train Loss: 0.387, Validation Loss: 0.261\n",
      "Epoch: 9108, Train Loss: 0.619, Validation Loss: 0.254\n",
      "Epoch: 9109, Train Loss: 0.212, Validation Loss: 0.250\n",
      "Epoch: 9110, Train Loss: 0.353, Validation Loss: 0.246\n",
      "Epoch: 9111, Train Loss: 0.308, Validation Loss: 0.254\n",
      "Epoch: 9112, Train Loss: 0.302, Validation Loss: 0.249\n",
      "Epoch: 9113, Train Loss: 0.227, Validation Loss: 0.250\n",
      "Epoch: 9114, Train Loss: 0.215, Validation Loss: 0.255\n",
      "Epoch: 9115, Train Loss: 0.216, Validation Loss: 0.256\n",
      "Epoch: 9116, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 9117, Train Loss: 0.597, Validation Loss: 0.252\n",
      "Epoch: 9118, Train Loss: 0.218, Validation Loss: 0.250\n",
      "Epoch: 9119, Train Loss: 0.187, Validation Loss: 0.251\n",
      "Epoch: 9120, Train Loss: 0.295, Validation Loss: 0.251\n",
      "Epoch: 9121, Train Loss: 0.205, Validation Loss: 0.253\n",
      "Epoch: 9122, Train Loss: 0.165, Validation Loss: 0.252\n",
      "Epoch: 9123, Train Loss: 0.220, Validation Loss: 0.253\n",
      "Epoch: 9124, Train Loss: 0.379, Validation Loss: 0.252\n",
      "Epoch: 9125, Train Loss: 0.445, Validation Loss: 0.250\n",
      "Epoch: 9126, Train Loss: 0.299, Validation Loss: 0.250\n",
      "Epoch: 9127, Train Loss: 0.194, Validation Loss: 0.253\n",
      "Epoch: 9128, Train Loss: 0.313, Validation Loss: 0.255\n",
      "Epoch: 9129, Train Loss: 0.425, Validation Loss: 0.252\n",
      "Epoch: 9130, Train Loss: 0.303, Validation Loss: 0.254\n",
      "Epoch: 9131, Train Loss: 0.225, Validation Loss: 0.258\n",
      "Epoch: 9132, Train Loss: 0.247, Validation Loss: 0.261\n",
      "Epoch: 9133, Train Loss: 0.191, Validation Loss: 0.254\n",
      "Epoch: 9134, Train Loss: 0.283, Validation Loss: 0.260\n",
      "Epoch: 9135, Train Loss: 0.275, Validation Loss: 0.260\n",
      "Epoch: 9136, Train Loss: 0.221, Validation Loss: 0.252\n",
      "Epoch: 9137, Train Loss: 0.237, Validation Loss: 0.253\n",
      "Epoch: 9138, Train Loss: 0.352, Validation Loss: 0.260\n",
      "Epoch: 9139, Train Loss: 0.258, Validation Loss: 0.257\n",
      "Epoch: 9140, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 9141, Train Loss: 0.293, Validation Loss: 0.254\n",
      "Epoch: 9142, Train Loss: 0.255, Validation Loss: 0.257\n",
      "Epoch: 9143, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 9144, Train Loss: 0.222, Validation Loss: 0.255\n",
      "Epoch: 9145, Train Loss: 0.193, Validation Loss: 0.254\n",
      "Epoch: 9146, Train Loss: 0.233, Validation Loss: 0.256\n",
      "Epoch: 9147, Train Loss: 0.265, Validation Loss: 0.259\n",
      "Epoch: 9148, Train Loss: 0.224, Validation Loss: 0.259\n",
      "Epoch: 9149, Train Loss: 0.442, Validation Loss: 0.253\n",
      "Epoch: 9150, Train Loss: 0.260, Validation Loss: 0.260\n",
      "Epoch: 9151, Train Loss: 0.213, Validation Loss: 0.265\n",
      "Epoch: 9152, Train Loss: 0.292, Validation Loss: 0.260\n",
      "Epoch: 9153, Train Loss: 0.273, Validation Loss: 0.258\n",
      "Epoch: 9154, Train Loss: 0.493, Validation Loss: 0.255\n",
      "Epoch: 9155, Train Loss: 0.219, Validation Loss: 0.255\n",
      "Epoch: 9156, Train Loss: 0.254, Validation Loss: 0.257\n",
      "Epoch: 9157, Train Loss: 0.222, Validation Loss: 0.256\n",
      "Epoch: 9158, Train Loss: 0.343, Validation Loss: 0.253\n",
      "Epoch: 9159, Train Loss: 0.491, Validation Loss: 0.252\n",
      "Epoch: 9160, Train Loss: 0.296, Validation Loss: 0.251\n",
      "Epoch: 9161, Train Loss: 0.435, Validation Loss: 0.255\n",
      "Epoch: 9162, Train Loss: 0.208, Validation Loss: 0.252\n",
      "Epoch: 9163, Train Loss: 0.223, Validation Loss: 0.252\n",
      "Epoch: 9164, Train Loss: 0.229, Validation Loss: 0.249\n",
      "Epoch: 9165, Train Loss: 0.220, Validation Loss: 0.252\n",
      "Epoch: 9166, Train Loss: 0.192, Validation Loss: 0.249\n",
      "Epoch: 9167, Train Loss: 0.252, Validation Loss: 0.250\n",
      "Epoch: 9168, Train Loss: 0.212, Validation Loss: 0.254\n",
      "Epoch: 9169, Train Loss: 0.262, Validation Loss: 0.255\n",
      "Epoch: 9170, Train Loss: 0.341, Validation Loss: 0.248\n",
      "Epoch: 9171, Train Loss: 0.253, Validation Loss: 0.252\n",
      "Epoch: 9172, Train Loss: 0.351, Validation Loss: 0.250\n",
      "Epoch: 9173, Train Loss: 0.219, Validation Loss: 0.252\n",
      "Epoch: 9174, Train Loss: 0.292, Validation Loss: 0.254\n",
      "Epoch: 9175, Train Loss: 0.282, Validation Loss: 0.250\n",
      "Epoch: 9176, Train Loss: 0.192, Validation Loss: 0.253\n",
      "Epoch: 9177, Train Loss: 0.250, Validation Loss: 0.259\n",
      "Epoch: 9178, Train Loss: 0.275, Validation Loss: 0.259\n",
      "Epoch: 9179, Train Loss: 0.243, Validation Loss: 0.260\n",
      "Epoch: 9180, Train Loss: 0.289, Validation Loss: 0.253\n",
      "Epoch: 9181, Train Loss: 0.234, Validation Loss: 0.255\n",
      "Epoch: 9182, Train Loss: 0.456, Validation Loss: 0.260\n",
      "Epoch: 9183, Train Loss: 0.221, Validation Loss: 0.259\n",
      "Epoch: 9184, Train Loss: 0.241, Validation Loss: 0.259\n",
      "Epoch: 9185, Train Loss: 0.328, Validation Loss: 0.254\n",
      "Epoch: 9186, Train Loss: 0.241, Validation Loss: 0.257\n",
      "Epoch: 9187, Train Loss: 0.155, Validation Loss: 0.256\n",
      "Epoch: 9188, Train Loss: 0.221, Validation Loss: 0.256\n",
      "Epoch: 9189, Train Loss: 0.299, Validation Loss: 0.257\n",
      "Epoch: 9190, Train Loss: 0.188, Validation Loss: 0.256\n",
      "Epoch: 9191, Train Loss: 0.197, Validation Loss: 0.255\n",
      "Epoch: 9192, Train Loss: 0.195, Validation Loss: 0.255\n",
      "Epoch: 9193, Train Loss: 0.244, Validation Loss: 0.258\n",
      "Epoch: 9194, Train Loss: 0.384, Validation Loss: 0.251\n",
      "Epoch: 9195, Train Loss: 0.346, Validation Loss: 0.253\n",
      "Epoch: 9196, Train Loss: 0.238, Validation Loss: 0.250\n",
      "Epoch: 9197, Train Loss: 0.292, Validation Loss: 0.255\n",
      "Epoch: 9198, Train Loss: 0.223, Validation Loss: 0.258\n",
      "Epoch: 9199, Train Loss: 0.299, Validation Loss: 0.254\n",
      "Epoch: 9200, Train Loss: 0.410, Validation Loss: 0.250\n",
      "Epoch: 9201, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 9202, Train Loss: 0.185, Validation Loss: 0.257\n",
      "Epoch: 9203, Train Loss: 0.407, Validation Loss: 0.260\n",
      "Epoch: 9204, Train Loss: 0.274, Validation Loss: 0.253\n",
      "Epoch: 9205, Train Loss: 0.514, Validation Loss: 0.257\n",
      "Epoch: 9206, Train Loss: 0.476, Validation Loss: 0.255\n",
      "Epoch: 9207, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 9208, Train Loss: 0.644, Validation Loss: 0.256\n",
      "Epoch: 9209, Train Loss: 0.254, Validation Loss: 0.254\n",
      "Epoch: 9210, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 9211, Train Loss: 0.186, Validation Loss: 0.254\n",
      "Epoch: 9212, Train Loss: 0.199, Validation Loss: 0.252\n",
      "Epoch: 9213, Train Loss: 0.503, Validation Loss: 0.252\n",
      "Epoch: 9214, Train Loss: 0.274, Validation Loss: 0.251\n",
      "Epoch: 9215, Train Loss: 0.164, Validation Loss: 0.253\n",
      "Epoch: 9216, Train Loss: 0.193, Validation Loss: 0.255\n",
      "Epoch: 9217, Train Loss: 0.263, Validation Loss: 0.250\n",
      "Epoch: 9218, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 9219, Train Loss: 0.434, Validation Loss: 0.250\n",
      "Epoch: 9220, Train Loss: 0.237, Validation Loss: 0.252\n",
      "Epoch: 9221, Train Loss: 0.435, Validation Loss: 0.249\n",
      "Epoch: 9222, Train Loss: 0.251, Validation Loss: 0.254\n",
      "Epoch: 9223, Train Loss: 0.235, Validation Loss: 0.257\n",
      "Epoch: 9224, Train Loss: 0.219, Validation Loss: 0.255\n",
      "Epoch: 9225, Train Loss: 0.310, Validation Loss: 0.256\n",
      "Epoch: 9226, Train Loss: 0.255, Validation Loss: 0.260\n",
      "Epoch: 9227, Train Loss: 0.385, Validation Loss: 0.262\n",
      "Epoch: 9228, Train Loss: 0.390, Validation Loss: 0.256\n",
      "Epoch: 9229, Train Loss: 0.241, Validation Loss: 0.254\n",
      "Epoch: 9230, Train Loss: 0.279, Validation Loss: 0.254\n",
      "Epoch: 9231, Train Loss: 0.200, Validation Loss: 0.256\n",
      "Epoch: 9232, Train Loss: 0.208, Validation Loss: 0.257\n",
      "Epoch: 9233, Train Loss: 0.211, Validation Loss: 0.258\n",
      "Epoch: 9234, Train Loss: 0.392, Validation Loss: 0.260\n",
      "Epoch: 9235, Train Loss: 0.263, Validation Loss: 0.255\n",
      "Epoch: 9236, Train Loss: 0.262, Validation Loss: 0.260\n",
      "Epoch: 9237, Train Loss: 0.496, Validation Loss: 0.253\n",
      "Epoch: 9238, Train Loss: 0.243, Validation Loss: 0.253\n",
      "Epoch: 9239, Train Loss: 0.242, Validation Loss: 0.256\n",
      "Epoch: 9240, Train Loss: 0.242, Validation Loss: 0.260\n",
      "Epoch: 9241, Train Loss: 0.194, Validation Loss: 0.261\n",
      "Epoch: 9242, Train Loss: 0.243, Validation Loss: 0.261\n",
      "Epoch: 9243, Train Loss: 0.316, Validation Loss: 0.256\n",
      "Epoch: 9244, Train Loss: 0.179, Validation Loss: 0.257\n",
      "Epoch: 9245, Train Loss: 0.201, Validation Loss: 0.256\n",
      "Epoch: 9246, Train Loss: 0.258, Validation Loss: 0.259\n",
      "Epoch: 9247, Train Loss: 0.279, Validation Loss: 0.261\n",
      "Epoch: 9248, Train Loss: 0.214, Validation Loss: 0.256\n",
      "Epoch: 9249, Train Loss: 0.214, Validation Loss: 0.257\n",
      "Epoch: 9250, Train Loss: 0.213, Validation Loss: 0.255\n",
      "Epoch: 9251, Train Loss: 0.220, Validation Loss: 0.251\n",
      "Epoch: 9252, Train Loss: 0.172, Validation Loss: 0.253\n",
      "Epoch: 9253, Train Loss: 0.214, Validation Loss: 0.257\n",
      "Epoch: 9254, Train Loss: 0.452, Validation Loss: 0.257\n",
      "Epoch: 9255, Train Loss: 0.158, Validation Loss: 0.256\n",
      "Epoch: 9256, Train Loss: 0.267, Validation Loss: 0.257\n",
      "Epoch: 9257, Train Loss: 0.284, Validation Loss: 0.257\n",
      "Epoch: 9258, Train Loss: 0.270, Validation Loss: 0.251\n",
      "Epoch: 9259, Train Loss: 0.187, Validation Loss: 0.254\n",
      "Epoch: 9260, Train Loss: 0.229, Validation Loss: 0.253\n",
      "Epoch: 9261, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 9262, Train Loss: 0.241, Validation Loss: 0.254\n",
      "Epoch: 9263, Train Loss: 0.190, Validation Loss: 0.251\n",
      "Epoch: 9264, Train Loss: 0.189, Validation Loss: 0.252\n",
      "Epoch: 9265, Train Loss: 0.218, Validation Loss: 0.254\n",
      "Epoch: 9266, Train Loss: 0.256, Validation Loss: 0.256\n",
      "Epoch: 9267, Train Loss: 0.219, Validation Loss: 0.257\n",
      "Epoch: 9268, Train Loss: 0.247, Validation Loss: 0.255\n",
      "Epoch: 9269, Train Loss: 0.235, Validation Loss: 0.253\n",
      "Epoch: 9270, Train Loss: 0.259, Validation Loss: 0.254\n",
      "Epoch: 9271, Train Loss: 0.231, Validation Loss: 0.253\n",
      "Epoch: 9272, Train Loss: 0.209, Validation Loss: 0.256\n",
      "Epoch: 9273, Train Loss: 0.178, Validation Loss: 0.255\n",
      "Epoch: 9274, Train Loss: 0.228, Validation Loss: 0.253\n",
      "Epoch: 9275, Train Loss: 0.275, Validation Loss: 0.255\n",
      "Epoch: 9276, Train Loss: 0.276, Validation Loss: 0.259\n",
      "Epoch: 9277, Train Loss: 0.305, Validation Loss: 0.252\n",
      "Epoch: 9278, Train Loss: 0.333, Validation Loss: 0.248\n",
      "Epoch: 9279, Train Loss: 0.220, Validation Loss: 0.247\n",
      "Epoch: 9280, Train Loss: 0.238, Validation Loss: 0.254\n",
      "Epoch: 9281, Train Loss: 0.220, Validation Loss: 0.257\n",
      "Epoch: 9282, Train Loss: 0.210, Validation Loss: 0.256\n",
      "Epoch: 9283, Train Loss: 0.210, Validation Loss: 0.249\n",
      "Epoch: 9284, Train Loss: 0.336, Validation Loss: 0.250\n",
      "Epoch: 9285, Train Loss: 0.212, Validation Loss: 0.256\n",
      "Epoch: 9286, Train Loss: 0.221, Validation Loss: 0.256\n",
      "Epoch: 9287, Train Loss: 0.451, Validation Loss: 0.253\n",
      "Epoch: 9288, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 9289, Train Loss: 0.219, Validation Loss: 0.257\n",
      "Epoch: 9290, Train Loss: 0.270, Validation Loss: 0.257\n",
      "Epoch: 9291, Train Loss: 0.239, Validation Loss: 0.254\n",
      "Epoch: 9292, Train Loss: 0.300, Validation Loss: 0.252\n",
      "Epoch: 9293, Train Loss: 0.182, Validation Loss: 0.259\n",
      "Epoch: 9294, Train Loss: 0.323, Validation Loss: 0.259\n",
      "Epoch: 9295, Train Loss: 0.245, Validation Loss: 0.254\n",
      "Epoch: 9296, Train Loss: 0.283, Validation Loss: 0.255\n",
      "Epoch: 9297, Train Loss: 0.208, Validation Loss: 0.255\n",
      "Epoch: 9298, Train Loss: 0.306, Validation Loss: 0.254\n",
      "Epoch: 9299, Train Loss: 0.322, Validation Loss: 0.263\n",
      "Epoch: 9300, Train Loss: 0.235, Validation Loss: 0.260\n",
      "Epoch: 9301, Train Loss: 0.256, Validation Loss: 0.256\n",
      "Epoch: 9302, Train Loss: 0.182, Validation Loss: 0.255\n",
      "Epoch: 9303, Train Loss: 0.382, Validation Loss: 0.255\n",
      "Epoch: 9304, Train Loss: 0.340, Validation Loss: 0.256\n",
      "Epoch: 9305, Train Loss: 0.236, Validation Loss: 0.259\n",
      "Epoch: 9306, Train Loss: 0.361, Validation Loss: 0.255\n",
      "Epoch: 9307, Train Loss: 0.320, Validation Loss: 0.256\n",
      "Epoch: 9308, Train Loss: 0.296, Validation Loss: 0.258\n",
      "Epoch: 9309, Train Loss: 0.237, Validation Loss: 0.260\n",
      "Epoch: 9310, Train Loss: 0.405, Validation Loss: 0.252\n",
      "Epoch: 9311, Train Loss: 0.264, Validation Loss: 0.253\n",
      "Epoch: 9312, Train Loss: 0.197, Validation Loss: 0.257\n",
      "Epoch: 9313, Train Loss: 0.195, Validation Loss: 0.257\n",
      "Epoch: 9314, Train Loss: 0.226, Validation Loss: 0.257\n",
      "Epoch: 9315, Train Loss: 0.265, Validation Loss: 0.255\n",
      "Epoch: 9316, Train Loss: 0.256, Validation Loss: 0.254\n",
      "Epoch: 9317, Train Loss: 0.217, Validation Loss: 0.255\n",
      "Epoch: 9318, Train Loss: 0.225, Validation Loss: 0.253\n",
      "Epoch: 9319, Train Loss: 0.534, Validation Loss: 0.254\n",
      "Epoch: 9320, Train Loss: 0.416, Validation Loss: 0.256\n",
      "Epoch: 9321, Train Loss: 0.525, Validation Loss: 0.251\n",
      "Epoch: 9322, Train Loss: 0.270, Validation Loss: 0.252\n",
      "Epoch: 9323, Train Loss: 0.310, Validation Loss: 0.258\n",
      "Epoch: 9324, Train Loss: 0.254, Validation Loss: 0.256\n",
      "Epoch: 9325, Train Loss: 0.252, Validation Loss: 0.259\n",
      "Epoch: 9326, Train Loss: 0.197, Validation Loss: 0.255\n",
      "Epoch: 9327, Train Loss: 0.282, Validation Loss: 0.255\n",
      "Epoch: 9328, Train Loss: 0.220, Validation Loss: 0.260\n",
      "Epoch: 9329, Train Loss: 0.249, Validation Loss: 0.259\n",
      "Epoch: 9330, Train Loss: 0.186, Validation Loss: 0.259\n",
      "Epoch: 9331, Train Loss: 0.216, Validation Loss: 0.263\n",
      "Epoch: 9332, Train Loss: 0.277, Validation Loss: 0.263\n",
      "Epoch: 9333, Train Loss: 0.306, Validation Loss: 0.262\n",
      "Epoch: 9334, Train Loss: 0.361, Validation Loss: 0.261\n",
      "Epoch: 9335, Train Loss: 0.218, Validation Loss: 0.256\n",
      "Epoch: 9336, Train Loss: 0.201, Validation Loss: 0.260\n",
      "Epoch: 9337, Train Loss: 0.209, Validation Loss: 0.258\n",
      "Epoch: 9338, Train Loss: 0.203, Validation Loss: 0.258\n",
      "Epoch: 9339, Train Loss: 0.220, Validation Loss: 0.254\n",
      "Epoch: 9340, Train Loss: 0.158, Validation Loss: 0.254\n",
      "Epoch: 9341, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 9342, Train Loss: 0.260, Validation Loss: 0.254\n",
      "Epoch: 9343, Train Loss: 0.336, Validation Loss: 0.253\n",
      "Epoch: 9344, Train Loss: 0.187, Validation Loss: 0.257\n",
      "Epoch: 9345, Train Loss: 0.261, Validation Loss: 0.261\n",
      "Epoch: 9346, Train Loss: 0.204, Validation Loss: 0.257\n",
      "Epoch: 9347, Train Loss: 0.179, Validation Loss: 0.257\n",
      "Epoch: 9348, Train Loss: 0.332, Validation Loss: 0.255\n",
      "Epoch: 9349, Train Loss: 0.222, Validation Loss: 0.255\n",
      "Epoch: 9350, Train Loss: 0.216, Validation Loss: 0.254\n",
      "Epoch: 9351, Train Loss: 0.369, Validation Loss: 0.259\n",
      "Epoch: 9352, Train Loss: 0.318, Validation Loss: 0.252\n",
      "Epoch: 9353, Train Loss: 0.250, Validation Loss: 0.250\n",
      "Epoch: 9354, Train Loss: 0.291, Validation Loss: 0.248\n",
      "Epoch: 9355, Train Loss: 0.240, Validation Loss: 0.253\n",
      "Epoch: 9356, Train Loss: 0.493, Validation Loss: 0.261\n",
      "Epoch: 9357, Train Loss: 0.258, Validation Loss: 0.262\n",
      "Epoch: 9358, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 9359, Train Loss: 0.330, Validation Loss: 0.251\n",
      "Epoch: 9360, Train Loss: 0.205, Validation Loss: 0.253\n",
      "Epoch: 9361, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 9362, Train Loss: 0.208, Validation Loss: 0.255\n",
      "Epoch: 9363, Train Loss: 0.200, Validation Loss: 0.256\n",
      "Epoch: 9364, Train Loss: 0.461, Validation Loss: 0.252\n",
      "Epoch: 9365, Train Loss: 0.244, Validation Loss: 0.252\n",
      "Epoch: 9366, Train Loss: 0.253, Validation Loss: 0.252\n",
      "Epoch: 9367, Train Loss: 0.179, Validation Loss: 0.251\n",
      "Epoch: 9368, Train Loss: 0.197, Validation Loss: 0.248\n",
      "Epoch: 9369, Train Loss: 0.203, Validation Loss: 0.250\n",
      "Epoch: 9370, Train Loss: 0.384, Validation Loss: 0.259\n",
      "Epoch: 9371, Train Loss: 0.232, Validation Loss: 0.255\n",
      "Epoch: 9372, Train Loss: 0.222, Validation Loss: 0.253\n",
      "Epoch: 9373, Train Loss: 0.257, Validation Loss: 0.256\n",
      "Epoch: 9374, Train Loss: 0.243, Validation Loss: 0.256\n",
      "Epoch: 9375, Train Loss: 0.286, Validation Loss: 0.257\n",
      "Epoch: 9376, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 9377, Train Loss: 0.207, Validation Loss: 0.255\n",
      "Epoch: 9378, Train Loss: 0.516, Validation Loss: 0.252\n",
      "Epoch: 9379, Train Loss: 0.285, Validation Loss: 0.254\n",
      "Epoch: 9380, Train Loss: 0.265, Validation Loss: 0.255\n",
      "Epoch: 9381, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 9382, Train Loss: 0.242, Validation Loss: 0.251\n",
      "Epoch: 9383, Train Loss: 0.182, Validation Loss: 0.253\n",
      "Epoch: 9384, Train Loss: 0.471, Validation Loss: 0.253\n",
      "Epoch: 9385, Train Loss: 0.631, Validation Loss: 0.255\n",
      "Epoch: 9386, Train Loss: 0.307, Validation Loss: 0.253\n",
      "Epoch: 9387, Train Loss: 0.298, Validation Loss: 0.254\n",
      "Epoch: 9388, Train Loss: 0.281, Validation Loss: 0.258\n",
      "Epoch: 9389, Train Loss: 0.610, Validation Loss: 0.251\n",
      "Epoch: 9390, Train Loss: 0.315, Validation Loss: 0.253\n",
      "Epoch: 9391, Train Loss: 0.259, Validation Loss: 0.258\n",
      "Epoch: 9392, Train Loss: 0.239, Validation Loss: 0.255\n",
      "Epoch: 9393, Train Loss: 0.347, Validation Loss: 0.257\n",
      "Epoch: 9394, Train Loss: 0.284, Validation Loss: 0.254\n",
      "Epoch: 9395, Train Loss: 0.212, Validation Loss: 0.255\n",
      "Epoch: 9396, Train Loss: 0.202, Validation Loss: 0.256\n",
      "Epoch: 9397, Train Loss: 0.241, Validation Loss: 0.254\n",
      "Epoch: 9398, Train Loss: 0.174, Validation Loss: 0.252\n",
      "Epoch: 9399, Train Loss: 0.269, Validation Loss: 0.252\n",
      "Epoch: 9400, Train Loss: 0.210, Validation Loss: 0.255\n",
      "Epoch: 9401, Train Loss: 0.303, Validation Loss: 0.256\n",
      "Epoch: 9402, Train Loss: 0.255, Validation Loss: 0.264\n",
      "Epoch: 9403, Train Loss: 0.222, Validation Loss: 0.261\n",
      "Epoch: 9404, Train Loss: 0.231, Validation Loss: 0.257\n",
      "Epoch: 9405, Train Loss: 0.291, Validation Loss: 0.256\n",
      "Epoch: 9406, Train Loss: 0.280, Validation Loss: 0.261\n",
      "Epoch: 9407, Train Loss: 0.287, Validation Loss: 0.258\n",
      "Epoch: 9408, Train Loss: 0.265, Validation Loss: 0.255\n",
      "Epoch: 9409, Train Loss: 0.397, Validation Loss: 0.254\n",
      "Epoch: 9410, Train Loss: 0.177, Validation Loss: 0.257\n",
      "Epoch: 9411, Train Loss: 0.204, Validation Loss: 0.258\n",
      "Epoch: 9412, Train Loss: 0.209, Validation Loss: 0.255\n",
      "Epoch: 9413, Train Loss: 0.308, Validation Loss: 0.255\n",
      "Epoch: 9414, Train Loss: 0.275, Validation Loss: 0.255\n",
      "Epoch: 9415, Train Loss: 0.294, Validation Loss: 0.251\n",
      "Epoch: 9416, Train Loss: 0.231, Validation Loss: 0.253\n",
      "Epoch: 9417, Train Loss: 0.274, Validation Loss: 0.253\n",
      "Epoch: 9418, Train Loss: 0.167, Validation Loss: 0.257\n",
      "Epoch: 9419, Train Loss: 0.386, Validation Loss: 0.257\n",
      "Epoch: 9420, Train Loss: 0.174, Validation Loss: 0.257\n",
      "Epoch: 9421, Train Loss: 0.343, Validation Loss: 0.253\n",
      "Epoch: 9422, Train Loss: 0.190, Validation Loss: 0.258\n",
      "Epoch: 9423, Train Loss: 0.190, Validation Loss: 0.260\n",
      "Epoch: 9424, Train Loss: 0.217, Validation Loss: 0.260\n",
      "Epoch: 9425, Train Loss: 0.360, Validation Loss: 0.254\n",
      "Epoch: 9426, Train Loss: 0.278, Validation Loss: 0.253\n",
      "Epoch: 9427, Train Loss: 0.371, Validation Loss: 0.254\n",
      "Epoch: 9428, Train Loss: 0.424, Validation Loss: 0.260\n",
      "Epoch: 9429, Train Loss: 0.215, Validation Loss: 0.256\n",
      "Epoch: 9430, Train Loss: 0.190, Validation Loss: 0.255\n",
      "Epoch: 9431, Train Loss: 0.243, Validation Loss: 0.252\n",
      "Epoch: 9432, Train Loss: 0.260, Validation Loss: 0.252\n",
      "Epoch: 9433, Train Loss: 0.201, Validation Loss: 0.255\n",
      "Epoch: 9434, Train Loss: 0.297, Validation Loss: 0.258\n",
      "Epoch: 9435, Train Loss: 0.262, Validation Loss: 0.259\n",
      "Epoch: 9436, Train Loss: 0.298, Validation Loss: 0.261\n",
      "Epoch: 9437, Train Loss: 0.420, Validation Loss: 0.253\n",
      "Epoch: 9438, Train Loss: 0.294, Validation Loss: 0.255\n",
      "Epoch: 9439, Train Loss: 0.210, Validation Loss: 0.253\n",
      "Epoch: 9440, Train Loss: 0.484, Validation Loss: 0.252\n",
      "Epoch: 9441, Train Loss: 0.253, Validation Loss: 0.254\n",
      "Epoch: 9442, Train Loss: 0.409, Validation Loss: 0.260\n",
      "Epoch: 9443, Train Loss: 0.237, Validation Loss: 0.255\n",
      "Epoch: 9444, Train Loss: 0.204, Validation Loss: 0.257\n",
      "Epoch: 9445, Train Loss: 0.240, Validation Loss: 0.252\n",
      "Epoch: 9446, Train Loss: 0.344, Validation Loss: 0.256\n",
      "Epoch: 9447, Train Loss: 0.267, Validation Loss: 0.258\n",
      "Epoch: 9448, Train Loss: 0.235, Validation Loss: 0.256\n",
      "Epoch: 9449, Train Loss: 0.313, Validation Loss: 0.253\n",
      "Epoch: 9450, Train Loss: 0.277, Validation Loss: 0.258\n",
      "Epoch: 9451, Train Loss: 0.282, Validation Loss: 0.254\n",
      "Epoch: 9452, Train Loss: 0.259, Validation Loss: 0.259\n",
      "Epoch: 9453, Train Loss: 0.378, Validation Loss: 0.257\n",
      "Epoch: 9454, Train Loss: 0.248, Validation Loss: 0.256\n",
      "Epoch: 9455, Train Loss: 0.489, Validation Loss: 0.253\n",
      "Epoch: 9456, Train Loss: 0.195, Validation Loss: 0.252\n",
      "Epoch: 9457, Train Loss: 0.246, Validation Loss: 0.250\n",
      "Epoch: 9458, Train Loss: 0.233, Validation Loss: 0.254\n",
      "Epoch: 9459, Train Loss: 0.201, Validation Loss: 0.255\n",
      "Epoch: 9460, Train Loss: 0.246, Validation Loss: 0.253\n",
      "Epoch: 9461, Train Loss: 0.229, Validation Loss: 0.248\n",
      "Epoch: 9462, Train Loss: 0.210, Validation Loss: 0.248\n",
      "Epoch: 9463, Train Loss: 0.177, Validation Loss: 0.253\n",
      "Epoch: 9464, Train Loss: 0.173, Validation Loss: 0.255\n",
      "Epoch: 9465, Train Loss: 0.250, Validation Loss: 0.251\n",
      "Epoch: 9466, Train Loss: 0.181, Validation Loss: 0.251\n",
      "Epoch: 9467, Train Loss: 0.338, Validation Loss: 0.256\n",
      "Epoch: 9468, Train Loss: 0.278, Validation Loss: 0.258\n",
      "Epoch: 9469, Train Loss: 0.563, Validation Loss: 0.254\n",
      "Epoch: 9470, Train Loss: 0.229, Validation Loss: 0.256\n",
      "Epoch: 9471, Train Loss: 0.342, Validation Loss: 0.251\n",
      "Epoch: 9472, Train Loss: 0.291, Validation Loss: 0.249\n",
      "Epoch: 9473, Train Loss: 0.252, Validation Loss: 0.253\n",
      "Epoch: 9474, Train Loss: 0.210, Validation Loss: 0.253\n",
      "Epoch: 9475, Train Loss: 0.213, Validation Loss: 0.254\n",
      "Epoch: 9476, Train Loss: 0.294, Validation Loss: 0.255\n",
      "Epoch: 9477, Train Loss: 0.385, Validation Loss: 0.251\n",
      "Epoch: 9478, Train Loss: 0.192, Validation Loss: 0.256\n",
      "Epoch: 9479, Train Loss: 0.250, Validation Loss: 0.258\n",
      "Epoch: 9480, Train Loss: 0.291, Validation Loss: 0.260\n",
      "Epoch: 9481, Train Loss: 0.200, Validation Loss: 0.257\n",
      "Epoch: 9482, Train Loss: 0.347, Validation Loss: 0.254\n",
      "Epoch: 9483, Train Loss: 0.251, Validation Loss: 0.251\n",
      "Epoch: 9484, Train Loss: 0.173, Validation Loss: 0.251\n",
      "Epoch: 9485, Train Loss: 0.210, Validation Loss: 0.252\n",
      "Epoch: 9486, Train Loss: 0.403, Validation Loss: 0.254\n",
      "Epoch: 9487, Train Loss: 0.264, Validation Loss: 0.253\n",
      "Epoch: 9488, Train Loss: 0.206, Validation Loss: 0.252\n",
      "Epoch: 9489, Train Loss: 0.306, Validation Loss: 0.251\n",
      "Epoch: 9490, Train Loss: 0.368, Validation Loss: 0.252\n",
      "Epoch: 9491, Train Loss: 0.565, Validation Loss: 0.253\n",
      "Epoch: 9492, Train Loss: 0.256, Validation Loss: 0.251\n",
      "Epoch: 9493, Train Loss: 0.194, Validation Loss: 0.253\n",
      "Epoch: 9494, Train Loss: 0.349, Validation Loss: 0.251\n",
      "Epoch: 9495, Train Loss: 0.325, Validation Loss: 0.251\n",
      "Epoch: 9496, Train Loss: 0.502, Validation Loss: 0.254\n",
      "Epoch: 9497, Train Loss: 0.261, Validation Loss: 0.251\n",
      "Epoch: 9498, Train Loss: 0.220, Validation Loss: 0.252\n",
      "Epoch: 9499, Train Loss: 0.248, Validation Loss: 0.256\n",
      "Epoch: 9500, Train Loss: 0.189, Validation Loss: 0.253\n",
      "Epoch: 9501, Train Loss: 0.431, Validation Loss: 0.250\n",
      "Epoch: 9502, Train Loss: 0.293, Validation Loss: 0.251\n",
      "Epoch: 9503, Train Loss: 0.276, Validation Loss: 0.254\n",
      "Epoch: 9504, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 9505, Train Loss: 0.232, Validation Loss: 0.253\n",
      "Epoch: 9506, Train Loss: 0.223, Validation Loss: 0.251\n",
      "Epoch: 9507, Train Loss: 0.213, Validation Loss: 0.251\n",
      "Epoch: 9508, Train Loss: 0.202, Validation Loss: 0.254\n",
      "Epoch: 9509, Train Loss: 0.302, Validation Loss: 0.251\n",
      "Epoch: 9510, Train Loss: 0.440, Validation Loss: 0.253\n",
      "Epoch: 9511, Train Loss: 0.279, Validation Loss: 0.259\n",
      "Epoch: 9512, Train Loss: 0.208, Validation Loss: 0.258\n",
      "Epoch: 9513, Train Loss: 0.162, Validation Loss: 0.252\n",
      "Epoch: 9514, Train Loss: 0.236, Validation Loss: 0.254\n",
      "Epoch: 9515, Train Loss: 0.258, Validation Loss: 0.255\n",
      "Epoch: 9516, Train Loss: 0.203, Validation Loss: 0.255\n",
      "Epoch: 9517, Train Loss: 0.211, Validation Loss: 0.256\n",
      "Epoch: 9518, Train Loss: 0.206, Validation Loss: 0.256\n",
      "Epoch: 9519, Train Loss: 0.199, Validation Loss: 0.255\n",
      "Epoch: 9520, Train Loss: 0.219, Validation Loss: 0.260\n",
      "Epoch: 9521, Train Loss: 0.332, Validation Loss: 0.253\n",
      "Epoch: 9522, Train Loss: 0.302, Validation Loss: 0.257\n",
      "Epoch: 9523, Train Loss: 0.209, Validation Loss: 0.254\n",
      "Epoch: 9524, Train Loss: 0.289, Validation Loss: 0.254\n",
      "Epoch: 9525, Train Loss: 0.207, Validation Loss: 0.254\n",
      "Epoch: 9526, Train Loss: 0.447, Validation Loss: 0.252\n",
      "Epoch: 9527, Train Loss: 0.409, Validation Loss: 0.253\n",
      "Epoch: 9528, Train Loss: 0.255, Validation Loss: 0.261\n",
      "Epoch: 9529, Train Loss: 0.289, Validation Loss: 0.261\n",
      "Epoch: 9530, Train Loss: 0.344, Validation Loss: 0.258\n",
      "Epoch: 9531, Train Loss: 0.256, Validation Loss: 0.254\n",
      "Epoch: 9532, Train Loss: 0.279, Validation Loss: 0.257\n",
      "Epoch: 9533, Train Loss: 0.281, Validation Loss: 0.257\n",
      "Epoch: 9534, Train Loss: 0.297, Validation Loss: 0.259\n",
      "Epoch: 9535, Train Loss: 0.395, Validation Loss: 0.254\n",
      "Epoch: 9536, Train Loss: 0.363, Validation Loss: 0.251\n",
      "Epoch: 9537, Train Loss: 0.443, Validation Loss: 0.254\n",
      "Epoch: 9538, Train Loss: 0.386, Validation Loss: 0.265\n",
      "Epoch: 9539, Train Loss: 0.229, Validation Loss: 0.263\n",
      "Epoch: 9540, Train Loss: 0.205, Validation Loss: 0.262\n",
      "Epoch: 9541, Train Loss: 0.342, Validation Loss: 0.263\n",
      "Epoch: 9542, Train Loss: 0.242, Validation Loss: 0.262\n",
      "Epoch: 9543, Train Loss: 0.261, Validation Loss: 0.258\n",
      "Epoch: 9544, Train Loss: 0.294, Validation Loss: 0.256\n",
      "Epoch: 9545, Train Loss: 0.223, Validation Loss: 0.264\n",
      "Epoch: 9546, Train Loss: 0.206, Validation Loss: 0.261\n",
      "Epoch: 9547, Train Loss: 0.247, Validation Loss: 0.261\n",
      "Epoch: 9548, Train Loss: 0.262, Validation Loss: 0.258\n",
      "Epoch: 9549, Train Loss: 0.225, Validation Loss: 0.264\n",
      "Epoch: 9550, Train Loss: 0.229, Validation Loss: 0.260\n",
      "Epoch: 9551, Train Loss: 0.215, Validation Loss: 0.255\n",
      "Epoch: 9552, Train Loss: 0.298, Validation Loss: 0.258\n",
      "Epoch: 9553, Train Loss: 0.268, Validation Loss: 0.253\n",
      "Epoch: 9554, Train Loss: 0.247, Validation Loss: 0.257\n",
      "Epoch: 9555, Train Loss: 0.425, Validation Loss: 0.258\n",
      "Epoch: 9556, Train Loss: 0.240, Validation Loss: 0.257\n",
      "Epoch: 9557, Train Loss: 0.314, Validation Loss: 0.253\n",
      "Epoch: 9558, Train Loss: 0.174, Validation Loss: 0.255\n",
      "Epoch: 9559, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 9560, Train Loss: 0.148, Validation Loss: 0.253\n",
      "Epoch: 9561, Train Loss: 0.204, Validation Loss: 0.252\n",
      "Epoch: 9562, Train Loss: 0.194, Validation Loss: 0.256\n",
      "Epoch: 9563, Train Loss: 0.238, Validation Loss: 0.254\n",
      "Epoch: 9564, Train Loss: 0.181, Validation Loss: 0.255\n",
      "Epoch: 9565, Train Loss: 0.445, Validation Loss: 0.263\n",
      "Epoch: 9566, Train Loss: 0.683, Validation Loss: 0.253\n",
      "Epoch: 9567, Train Loss: 0.259, Validation Loss: 0.252\n",
      "Epoch: 9568, Train Loss: 0.187, Validation Loss: 0.258\n",
      "Epoch: 9569, Train Loss: 0.191, Validation Loss: 0.260\n",
      "Epoch: 9570, Train Loss: 0.217, Validation Loss: 0.256\n",
      "Epoch: 9571, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 9572, Train Loss: 0.493, Validation Loss: 0.254\n",
      "Epoch: 9573, Train Loss: 0.166, Validation Loss: 0.252\n",
      "Epoch: 9574, Train Loss: 0.336, Validation Loss: 0.255\n",
      "Epoch: 9575, Train Loss: 0.213, Validation Loss: 0.257\n",
      "Epoch: 9576, Train Loss: 0.340, Validation Loss: 0.256\n",
      "Epoch: 9577, Train Loss: 0.346, Validation Loss: 0.253\n",
      "Epoch: 9578, Train Loss: 0.267, Validation Loss: 0.251\n",
      "Epoch: 9579, Train Loss: 0.265, Validation Loss: 0.252\n",
      "Epoch: 9580, Train Loss: 0.261, Validation Loss: 0.252\n",
      "Epoch: 9581, Train Loss: 0.397, Validation Loss: 0.263\n",
      "Epoch: 9582, Train Loss: 0.255, Validation Loss: 0.254\n",
      "Epoch: 9583, Train Loss: 0.266, Validation Loss: 0.257\n",
      "Epoch: 9584, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 9585, Train Loss: 0.259, Validation Loss: 0.257\n",
      "Epoch: 9586, Train Loss: 0.179, Validation Loss: 0.257\n",
      "Epoch: 9587, Train Loss: 0.180, Validation Loss: 0.257\n",
      "Epoch: 9588, Train Loss: 0.267, Validation Loss: 0.257\n",
      "Epoch: 9589, Train Loss: 0.351, Validation Loss: 0.252\n",
      "Epoch: 9590, Train Loss: 0.131, Validation Loss: 0.257\n",
      "Epoch: 9591, Train Loss: 0.331, Validation Loss: 0.255\n",
      "Epoch: 9592, Train Loss: 0.273, Validation Loss: 0.265\n",
      "Epoch: 9593, Train Loss: 0.197, Validation Loss: 0.259\n",
      "Epoch: 9594, Train Loss: 0.176, Validation Loss: 0.253\n",
      "Epoch: 9595, Train Loss: 0.267, Validation Loss: 0.255\n",
      "Epoch: 9596, Train Loss: 0.260, Validation Loss: 0.255\n",
      "Epoch: 9597, Train Loss: 0.313, Validation Loss: 0.260\n",
      "Epoch: 9598, Train Loss: 0.219, Validation Loss: 0.256\n",
      "Epoch: 9599, Train Loss: 0.297, Validation Loss: 0.257\n",
      "Epoch: 9600, Train Loss: 0.258, Validation Loss: 0.254\n",
      "Epoch: 9601, Train Loss: 0.196, Validation Loss: 0.258\n",
      "Epoch: 9602, Train Loss: 0.261, Validation Loss: 0.256\n",
      "Epoch: 9603, Train Loss: 0.302, Validation Loss: 0.252\n",
      "Epoch: 9604, Train Loss: 0.265, Validation Loss: 0.253\n",
      "Epoch: 9605, Train Loss: 0.245, Validation Loss: 0.260\n",
      "Epoch: 9606, Train Loss: 0.267, Validation Loss: 0.257\n",
      "Epoch: 9607, Train Loss: 0.332, Validation Loss: 0.254\n",
      "Epoch: 9608, Train Loss: 0.333, Validation Loss: 0.256\n",
      "Epoch: 9609, Train Loss: 0.213, Validation Loss: 0.261\n",
      "Epoch: 9610, Train Loss: 0.340, Validation Loss: 0.253\n",
      "Epoch: 9611, Train Loss: 0.231, Validation Loss: 0.255\n",
      "Epoch: 9612, Train Loss: 0.184, Validation Loss: 0.261\n",
      "Epoch: 9613, Train Loss: 0.305, Validation Loss: 0.256\n",
      "Epoch: 9614, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 9615, Train Loss: 0.389, Validation Loss: 0.248\n",
      "Epoch: 9616, Train Loss: 0.165, Validation Loss: 0.254\n",
      "Epoch: 9617, Train Loss: 0.354, Validation Loss: 0.251\n",
      "Epoch: 9618, Train Loss: 0.168, Validation Loss: 0.253\n",
      "Epoch: 9619, Train Loss: 0.383, Validation Loss: 0.254\n",
      "Epoch: 9620, Train Loss: 0.401, Validation Loss: 0.252\n",
      "Epoch: 9621, Train Loss: 0.157, Validation Loss: 0.256\n",
      "Epoch: 9622, Train Loss: 0.187, Validation Loss: 0.256\n",
      "Epoch: 9623, Train Loss: 0.283, Validation Loss: 0.252\n",
      "Epoch: 9624, Train Loss: 0.234, Validation Loss: 0.253\n",
      "Epoch: 9625, Train Loss: 0.258, Validation Loss: 0.254\n",
      "Epoch: 9626, Train Loss: 0.265, Validation Loss: 0.256\n",
      "Epoch: 9627, Train Loss: 0.261, Validation Loss: 0.255\n",
      "Epoch: 9628, Train Loss: 0.366, Validation Loss: 0.260\n",
      "Epoch: 9629, Train Loss: 0.257, Validation Loss: 0.254\n",
      "Epoch: 9630, Train Loss: 0.203, Validation Loss: 0.253\n",
      "Epoch: 9631, Train Loss: 0.211, Validation Loss: 0.256\n",
      "Epoch: 9632, Train Loss: 0.239, Validation Loss: 0.259\n",
      "Epoch: 9633, Train Loss: 0.252, Validation Loss: 0.257\n",
      "Epoch: 9634, Train Loss: 0.368, Validation Loss: 0.255\n",
      "Epoch: 9635, Train Loss: 0.230, Validation Loss: 0.257\n",
      "Epoch: 9636, Train Loss: 0.226, Validation Loss: 0.255\n",
      "Epoch: 9637, Train Loss: 0.222, Validation Loss: 0.257\n",
      "Epoch: 9638, Train Loss: 0.158, Validation Loss: 0.258\n",
      "Epoch: 9639, Train Loss: 0.217, Validation Loss: 0.255\n",
      "Epoch: 9640, Train Loss: 0.202, Validation Loss: 0.256\n",
      "Epoch: 9641, Train Loss: 0.292, Validation Loss: 0.257\n",
      "Epoch: 9642, Train Loss: 0.248, Validation Loss: 0.259\n",
      "Epoch: 9643, Train Loss: 0.240, Validation Loss: 0.258\n",
      "Epoch: 9644, Train Loss: 0.184, Validation Loss: 0.256\n",
      "Epoch: 9645, Train Loss: 0.223, Validation Loss: 0.254\n",
      "Epoch: 9646, Train Loss: 0.443, Validation Loss: 0.254\n",
      "Epoch: 9647, Train Loss: 0.287, Validation Loss: 0.256\n",
      "Epoch: 9648, Train Loss: 0.257, Validation Loss: 0.254\n",
      "Epoch: 9649, Train Loss: 0.226, Validation Loss: 0.258\n",
      "Epoch: 9650, Train Loss: 0.267, Validation Loss: 0.257\n",
      "Epoch: 9651, Train Loss: 0.259, Validation Loss: 0.254\n",
      "Epoch: 9652, Train Loss: 0.232, Validation Loss: 0.254\n",
      "Epoch: 9653, Train Loss: 0.290, Validation Loss: 0.250\n",
      "Epoch: 9654, Train Loss: 0.218, Validation Loss: 0.251\n",
      "Epoch: 9655, Train Loss: 0.266, Validation Loss: 0.252\n",
      "Epoch: 9656, Train Loss: 0.270, Validation Loss: 0.255\n",
      "Epoch: 9657, Train Loss: 0.245, Validation Loss: 0.253\n",
      "Epoch: 9658, Train Loss: 0.221, Validation Loss: 0.250\n",
      "Epoch: 9659, Train Loss: 0.232, Validation Loss: 0.249\n",
      "Epoch: 9660, Train Loss: 0.238, Validation Loss: 0.251\n",
      "Epoch: 9661, Train Loss: 0.278, Validation Loss: 0.252\n",
      "Epoch: 9662, Train Loss: 0.247, Validation Loss: 0.257\n",
      "Epoch: 9663, Train Loss: 0.292, Validation Loss: 0.260\n",
      "Epoch: 9664, Train Loss: 0.202, Validation Loss: 0.257\n",
      "Epoch: 9665, Train Loss: 0.344, Validation Loss: 0.255\n",
      "Epoch: 9666, Train Loss: 0.219, Validation Loss: 0.253\n",
      "Epoch: 9667, Train Loss: 0.475, Validation Loss: 0.252\n",
      "Epoch: 9668, Train Loss: 0.367, Validation Loss: 0.249\n",
      "Epoch: 9669, Train Loss: 0.463, Validation Loss: 0.250\n",
      "Epoch: 9670, Train Loss: 0.192, Validation Loss: 0.253\n",
      "Epoch: 9671, Train Loss: 0.432, Validation Loss: 0.256\n",
      "Epoch: 9672, Train Loss: 0.173, Validation Loss: 0.255\n",
      "Epoch: 9673, Train Loss: 0.246, Validation Loss: 0.253\n",
      "Epoch: 9674, Train Loss: 0.302, Validation Loss: 0.255\n",
      "Epoch: 9675, Train Loss: 0.292, Validation Loss: 0.259\n",
      "Epoch: 9676, Train Loss: 0.437, Validation Loss: 0.256\n",
      "Epoch: 9677, Train Loss: 0.210, Validation Loss: 0.252\n",
      "Epoch: 9678, Train Loss: 0.258, Validation Loss: 0.252\n",
      "Epoch: 9679, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 9680, Train Loss: 0.391, Validation Loss: 0.253\n",
      "Epoch: 9681, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 9682, Train Loss: 0.237, Validation Loss: 0.251\n",
      "Epoch: 9683, Train Loss: 0.318, Validation Loss: 0.252\n",
      "Epoch: 9684, Train Loss: 0.270, Validation Loss: 0.254\n",
      "Epoch: 9685, Train Loss: 0.280, Validation Loss: 0.258\n",
      "Epoch: 9686, Train Loss: 0.360, Validation Loss: 0.256\n",
      "Epoch: 9687, Train Loss: 0.172, Validation Loss: 0.255\n",
      "Epoch: 9688, Train Loss: 0.310, Validation Loss: 0.253\n",
      "Epoch: 9689, Train Loss: 0.178, Validation Loss: 0.254\n",
      "Epoch: 9690, Train Loss: 0.172, Validation Loss: 0.254\n",
      "Epoch: 9691, Train Loss: 0.213, Validation Loss: 0.253\n",
      "Epoch: 9692, Train Loss: 0.290, Validation Loss: 0.251\n",
      "Epoch: 9693, Train Loss: 0.204, Validation Loss: 0.254\n",
      "Epoch: 9694, Train Loss: 0.241, Validation Loss: 0.256\n",
      "Epoch: 9695, Train Loss: 0.298, Validation Loss: 0.257\n",
      "Epoch: 9696, Train Loss: 0.135, Validation Loss: 0.254\n",
      "Epoch: 9697, Train Loss: 0.351, Validation Loss: 0.258\n",
      "Epoch: 9698, Train Loss: 0.195, Validation Loss: 0.256\n",
      "Epoch: 9699, Train Loss: 0.486, Validation Loss: 0.252\n",
      "Epoch: 9700, Train Loss: 0.233, Validation Loss: 0.253\n",
      "Epoch: 9701, Train Loss: 0.522, Validation Loss: 0.254\n",
      "Epoch: 9702, Train Loss: 0.293, Validation Loss: 0.251\n",
      "Epoch: 9703, Train Loss: 0.249, Validation Loss: 0.258\n",
      "Epoch: 9704, Train Loss: 0.205, Validation Loss: 0.256\n",
      "Epoch: 9705, Train Loss: 0.260, Validation Loss: 0.253\n",
      "Epoch: 9706, Train Loss: 0.191, Validation Loss: 0.252\n",
      "Epoch: 9707, Train Loss: 0.237, Validation Loss: 0.248\n",
      "Epoch: 9708, Train Loss: 0.262, Validation Loss: 0.252\n",
      "Epoch: 9709, Train Loss: 0.208, Validation Loss: 0.254\n",
      "Epoch: 9710, Train Loss: 0.205, Validation Loss: 0.257\n",
      "Epoch: 9711, Train Loss: 0.235, Validation Loss: 0.256\n",
      "Epoch: 9712, Train Loss: 0.186, Validation Loss: 0.253\n",
      "Epoch: 9713, Train Loss: 0.221, Validation Loss: 0.250\n",
      "Epoch: 9714, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 9715, Train Loss: 0.413, Validation Loss: 0.260\n",
      "Epoch: 9716, Train Loss: 0.234, Validation Loss: 0.253\n",
      "Epoch: 9717, Train Loss: 0.206, Validation Loss: 0.255\n",
      "Epoch: 9718, Train Loss: 0.285, Validation Loss: 0.255\n",
      "Epoch: 9719, Train Loss: 0.199, Validation Loss: 0.256\n",
      "Epoch: 9720, Train Loss: 0.345, Validation Loss: 0.258\n",
      "Epoch: 9721, Train Loss: 0.566, Validation Loss: 0.256\n",
      "Epoch: 9722, Train Loss: 0.498, Validation Loss: 0.258\n",
      "Epoch: 9723, Train Loss: 0.324, Validation Loss: 0.256\n",
      "Epoch: 9724, Train Loss: 0.286, Validation Loss: 0.257\n",
      "Epoch: 9725, Train Loss: 0.292, Validation Loss: 0.259\n",
      "Epoch: 9726, Train Loss: 0.196, Validation Loss: 0.257\n",
      "Epoch: 9727, Train Loss: 0.391, Validation Loss: 0.262\n",
      "Epoch: 9728, Train Loss: 0.467, Validation Loss: 0.255\n",
      "Epoch: 9729, Train Loss: 0.203, Validation Loss: 0.254\n",
      "Epoch: 9730, Train Loss: 0.190, Validation Loss: 0.254\n",
      "Epoch: 9731, Train Loss: 0.226, Validation Loss: 0.252\n",
      "Epoch: 9732, Train Loss: 0.258, Validation Loss: 0.256\n",
      "Epoch: 9733, Train Loss: 0.178, Validation Loss: 0.256\n",
      "Epoch: 9734, Train Loss: 0.236, Validation Loss: 0.259\n",
      "Epoch: 9735, Train Loss: 0.230, Validation Loss: 0.255\n",
      "Epoch: 9736, Train Loss: 0.235, Validation Loss: 0.252\n",
      "Epoch: 9737, Train Loss: 0.232, Validation Loss: 0.257\n",
      "Epoch: 9738, Train Loss: 0.234, Validation Loss: 0.255\n",
      "Epoch: 9739, Train Loss: 0.271, Validation Loss: 0.252\n",
      "Epoch: 9740, Train Loss: 0.222, Validation Loss: 0.254\n",
      "Epoch: 9741, Train Loss: 0.212, Validation Loss: 0.256\n",
      "Epoch: 9742, Train Loss: 0.236, Validation Loss: 0.258\n",
      "Epoch: 9743, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 9744, Train Loss: 0.170, Validation Loss: 0.251\n",
      "Epoch: 9745, Train Loss: 0.450, Validation Loss: 0.252\n",
      "Epoch: 9746, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 9747, Train Loss: 0.298, Validation Loss: 0.249\n",
      "Epoch: 9748, Train Loss: 0.284, Validation Loss: 0.249\n",
      "Epoch: 9749, Train Loss: 0.191, Validation Loss: 0.251\n",
      "Epoch: 9750, Train Loss: 0.243, Validation Loss: 0.251\n",
      "Epoch: 9751, Train Loss: 0.266, Validation Loss: 0.253\n",
      "Epoch: 9752, Train Loss: 0.378, Validation Loss: 0.251\n",
      "Epoch: 9753, Train Loss: 0.230, Validation Loss: 0.252\n",
      "Epoch: 9754, Train Loss: 0.225, Validation Loss: 0.253\n",
      "Epoch: 9755, Train Loss: 0.378, Validation Loss: 0.253\n",
      "Epoch: 9756, Train Loss: 0.191, Validation Loss: 0.254\n",
      "Epoch: 9757, Train Loss: 0.253, Validation Loss: 0.250\n",
      "Epoch: 9758, Train Loss: 0.280, Validation Loss: 0.251\n",
      "Epoch: 9759, Train Loss: 0.252, Validation Loss: 0.253\n",
      "Epoch: 9760, Train Loss: 0.214, Validation Loss: 0.256\n",
      "Epoch: 9761, Train Loss: 0.233, Validation Loss: 0.260\n",
      "Epoch: 9762, Train Loss: 0.167, Validation Loss: 0.260\n",
      "Epoch: 9763, Train Loss: 0.266, Validation Loss: 0.254\n",
      "Epoch: 9764, Train Loss: 0.179, Validation Loss: 0.255\n",
      "Epoch: 9765, Train Loss: 0.207, Validation Loss: 0.254\n",
      "Epoch: 9766, Train Loss: 0.360, Validation Loss: 0.262\n",
      "Epoch: 9767, Train Loss: 0.239, Validation Loss: 0.258\n",
      "Epoch: 9768, Train Loss: 0.247, Validation Loss: 0.256\n",
      "Epoch: 9769, Train Loss: 0.272, Validation Loss: 0.257\n",
      "Epoch: 9770, Train Loss: 0.249, Validation Loss: 0.260\n",
      "Epoch: 9771, Train Loss: 0.252, Validation Loss: 0.260\n",
      "Epoch: 9772, Train Loss: 0.197, Validation Loss: 0.264\n",
      "Epoch: 9773, Train Loss: 0.440, Validation Loss: 0.262\n",
      "Epoch: 9774, Train Loss: 0.590, Validation Loss: 0.261\n",
      "Epoch: 9775, Train Loss: 0.254, Validation Loss: 0.259\n",
      "Epoch: 9776, Train Loss: 0.282, Validation Loss: 0.258\n",
      "Epoch: 9777, Train Loss: 0.263, Validation Loss: 0.260\n",
      "Epoch: 9778, Train Loss: 0.236, Validation Loss: 0.265\n",
      "Epoch: 9779, Train Loss: 0.303, Validation Loss: 0.267\n",
      "Epoch: 9780, Train Loss: 0.300, Validation Loss: 0.267\n",
      "Epoch: 9781, Train Loss: 0.238, Validation Loss: 0.262\n",
      "Epoch: 9782, Train Loss: 0.301, Validation Loss: 0.260\n",
      "Epoch: 9783, Train Loss: 0.319, Validation Loss: 0.257\n",
      "Epoch: 9784, Train Loss: 0.170, Validation Loss: 0.255\n",
      "Epoch: 9785, Train Loss: 0.396, Validation Loss: 0.255\n",
      "Epoch: 9786, Train Loss: 0.179, Validation Loss: 0.258\n",
      "Epoch: 9787, Train Loss: 0.194, Validation Loss: 0.252\n",
      "Epoch: 9788, Train Loss: 0.167, Validation Loss: 0.253\n",
      "Epoch: 9789, Train Loss: 0.303, Validation Loss: 0.253\n",
      "Epoch: 9790, Train Loss: 0.301, Validation Loss: 0.253\n",
      "Epoch: 9791, Train Loss: 0.308, Validation Loss: 0.252\n",
      "Epoch: 9792, Train Loss: 0.199, Validation Loss: 0.250\n",
      "Epoch: 9793, Train Loss: 0.294, Validation Loss: 0.250\n",
      "Epoch: 9794, Train Loss: 0.399, Validation Loss: 0.252\n",
      "Epoch: 9795, Train Loss: 0.176, Validation Loss: 0.252\n",
      "Epoch: 9796, Train Loss: 0.583, Validation Loss: 0.252\n",
      "Epoch: 9797, Train Loss: 0.199, Validation Loss: 0.257\n",
      "Epoch: 9798, Train Loss: 0.284, Validation Loss: 0.253\n",
      "Epoch: 9799, Train Loss: 0.200, Validation Loss: 0.253\n",
      "Epoch: 9800, Train Loss: 0.274, Validation Loss: 0.257\n",
      "Epoch: 9801, Train Loss: 0.159, Validation Loss: 0.252\n",
      "Epoch: 9802, Train Loss: 0.276, Validation Loss: 0.250\n",
      "Epoch: 9803, Train Loss: 0.188, Validation Loss: 0.253\n",
      "Epoch: 9804, Train Loss: 0.403, Validation Loss: 0.260\n",
      "Epoch: 9805, Train Loss: 0.209, Validation Loss: 0.255\n",
      "Epoch: 9806, Train Loss: 0.211, Validation Loss: 0.256\n",
      "Epoch: 9807, Train Loss: 0.629, Validation Loss: 0.253\n",
      "Epoch: 9808, Train Loss: 0.221, Validation Loss: 0.252\n",
      "Epoch: 9809, Train Loss: 0.260, Validation Loss: 0.261\n",
      "Epoch: 9810, Train Loss: 0.746, Validation Loss: 0.255\n",
      "Epoch: 9811, Train Loss: 0.167, Validation Loss: 0.254\n",
      "Epoch: 9812, Train Loss: 0.311, Validation Loss: 0.253\n",
      "Epoch: 9813, Train Loss: 0.205, Validation Loss: 0.255\n",
      "Epoch: 9814, Train Loss: 0.285, Validation Loss: 0.252\n",
      "Epoch: 9815, Train Loss: 0.237, Validation Loss: 0.258\n",
      "Epoch: 9816, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 9817, Train Loss: 0.372, Validation Loss: 0.252\n",
      "Epoch: 9818, Train Loss: 0.209, Validation Loss: 0.256\n",
      "Epoch: 9819, Train Loss: 0.137, Validation Loss: 0.257\n",
      "Epoch: 9820, Train Loss: 0.233, Validation Loss: 0.254\n",
      "Epoch: 9821, Train Loss: 0.452, Validation Loss: 0.254\n",
      "Epoch: 9822, Train Loss: 0.261, Validation Loss: 0.253\n",
      "Epoch: 9823, Train Loss: 0.215, Validation Loss: 0.253\n",
      "Epoch: 9824, Train Loss: 0.206, Validation Loss: 0.255\n",
      "Epoch: 9825, Train Loss: 0.177, Validation Loss: 0.261\n",
      "Epoch: 9826, Train Loss: 0.305, Validation Loss: 0.253\n",
      "Epoch: 9827, Train Loss: 0.186, Validation Loss: 0.254\n",
      "Epoch: 9828, Train Loss: 0.258, Validation Loss: 0.248\n",
      "Epoch: 9829, Train Loss: 0.185, Validation Loss: 0.248\n",
      "Epoch: 9830, Train Loss: 0.233, Validation Loss: 0.249\n",
      "Epoch: 9831, Train Loss: 0.209, Validation Loss: 0.253\n",
      "Epoch: 9832, Train Loss: 0.277, Validation Loss: 0.254\n",
      "Epoch: 9833, Train Loss: 0.262, Validation Loss: 0.254\n",
      "Epoch: 9834, Train Loss: 0.273, Validation Loss: 0.252\n",
      "Epoch: 9835, Train Loss: 0.298, Validation Loss: 0.250\n",
      "Epoch: 9836, Train Loss: 0.199, Validation Loss: 0.252\n",
      "Epoch: 9837, Train Loss: 0.214, Validation Loss: 0.252\n",
      "Epoch: 9838, Train Loss: 0.246, Validation Loss: 0.249\n",
      "Epoch: 9839, Train Loss: 0.190, Validation Loss: 0.251\n",
      "Epoch: 9840, Train Loss: 0.205, Validation Loss: 0.253\n",
      "Epoch: 9841, Train Loss: 0.307, Validation Loss: 0.264\n",
      "Epoch: 9842, Train Loss: 0.248, Validation Loss: 0.253\n",
      "Epoch: 9843, Train Loss: 0.481, Validation Loss: 0.260\n",
      "Epoch: 9844, Train Loss: 0.342, Validation Loss: 0.256\n",
      "Epoch: 9845, Train Loss: 0.296, Validation Loss: 0.250\n",
      "Epoch: 9846, Train Loss: 0.267, Validation Loss: 0.249\n",
      "Epoch: 9847, Train Loss: 0.383, Validation Loss: 0.252\n",
      "Epoch: 9848, Train Loss: 0.198, Validation Loss: 0.257\n",
      "Epoch: 9849, Train Loss: 0.222, Validation Loss: 0.255\n",
      "Epoch: 9850, Train Loss: 0.228, Validation Loss: 0.253\n",
      "Epoch: 9851, Train Loss: 0.188, Validation Loss: 0.256\n",
      "Epoch: 9852, Train Loss: 0.398, Validation Loss: 0.256\n",
      "Epoch: 9853, Train Loss: 0.301, Validation Loss: 0.256\n",
      "Epoch: 9854, Train Loss: 0.291, Validation Loss: 0.263\n",
      "Epoch: 9855, Train Loss: 0.310, Validation Loss: 0.263\n",
      "Epoch: 9856, Train Loss: 0.209, Validation Loss: 0.255\n",
      "Epoch: 9857, Train Loss: 0.165, Validation Loss: 0.254\n",
      "Epoch: 9858, Train Loss: 0.248, Validation Loss: 0.256\n",
      "Epoch: 9859, Train Loss: 0.197, Validation Loss: 0.256\n",
      "Epoch: 9860, Train Loss: 0.297, Validation Loss: 0.254\n",
      "Epoch: 9861, Train Loss: 0.277, Validation Loss: 0.254\n",
      "Epoch: 9862, Train Loss: 0.216, Validation Loss: 0.253\n",
      "Epoch: 9863, Train Loss: 0.233, Validation Loss: 0.251\n",
      "Epoch: 9864, Train Loss: 0.238, Validation Loss: 0.259\n",
      "Epoch: 9865, Train Loss: 0.227, Validation Loss: 0.262\n",
      "Epoch: 9866, Train Loss: 0.395, Validation Loss: 0.260\n",
      "Epoch: 9867, Train Loss: 0.240, Validation Loss: 0.257\n",
      "Epoch: 9868, Train Loss: 0.270, Validation Loss: 0.257\n",
      "Epoch: 9869, Train Loss: 0.190, Validation Loss: 0.254\n",
      "Epoch: 9870, Train Loss: 0.300, Validation Loss: 0.251\n",
      "Epoch: 9871, Train Loss: 0.347, Validation Loss: 0.254\n",
      "Epoch: 9872, Train Loss: 0.273, Validation Loss: 0.264\n",
      "Epoch: 9873, Train Loss: 0.199, Validation Loss: 0.262\n",
      "Epoch: 9874, Train Loss: 0.286, Validation Loss: 0.256\n",
      "Epoch: 9875, Train Loss: 0.221, Validation Loss: 0.257\n",
      "Epoch: 9876, Train Loss: 0.220, Validation Loss: 0.256\n",
      "Epoch: 9877, Train Loss: 0.207, Validation Loss: 0.257\n",
      "Epoch: 9878, Train Loss: 0.239, Validation Loss: 0.257\n",
      "Epoch: 9879, Train Loss: 0.606, Validation Loss: 0.254\n",
      "Epoch: 9880, Train Loss: 0.196, Validation Loss: 0.256\n",
      "Epoch: 9881, Train Loss: 0.263, Validation Loss: 0.252\n",
      "Epoch: 9882, Train Loss: 0.247, Validation Loss: 0.249\n",
      "Epoch: 9883, Train Loss: 0.251, Validation Loss: 0.255\n",
      "Epoch: 9884, Train Loss: 0.266, Validation Loss: 0.255\n",
      "Epoch: 9885, Train Loss: 0.707, Validation Loss: 0.251\n",
      "Epoch: 9886, Train Loss: 0.214, Validation Loss: 0.249\n",
      "Epoch: 9887, Train Loss: 0.271, Validation Loss: 0.251\n",
      "Epoch: 9888, Train Loss: 0.457, Validation Loss: 0.249\n",
      "Epoch: 9889, Train Loss: 0.232, Validation Loss: 0.251\n",
      "Epoch: 9890, Train Loss: 0.203, Validation Loss: 0.257\n",
      "Epoch: 9891, Train Loss: 0.202, Validation Loss: 0.255\n",
      "Epoch: 9892, Train Loss: 0.208, Validation Loss: 0.255\n",
      "Epoch: 9893, Train Loss: 0.185, Validation Loss: 0.258\n",
      "Epoch: 9894, Train Loss: 0.373, Validation Loss: 0.254\n",
      "Epoch: 9895, Train Loss: 0.227, Validation Loss: 0.253\n",
      "Epoch: 9896, Train Loss: 0.184, Validation Loss: 0.262\n",
      "Epoch: 9897, Train Loss: 0.489, Validation Loss: 0.255\n",
      "Epoch: 9898, Train Loss: 0.336, Validation Loss: 0.254\n",
      "Epoch: 9899, Train Loss: 0.420, Validation Loss: 0.265\n",
      "Epoch: 9900, Train Loss: 0.508, Validation Loss: 0.258\n",
      "Epoch: 9901, Train Loss: 0.203, Validation Loss: 0.254\n",
      "Epoch: 9902, Train Loss: 0.229, Validation Loss: 0.254\n",
      "Epoch: 9903, Train Loss: 0.171, Validation Loss: 0.253\n",
      "Epoch: 9904, Train Loss: 0.182, Validation Loss: 0.255\n",
      "Epoch: 9905, Train Loss: 0.212, Validation Loss: 0.255\n",
      "Epoch: 9906, Train Loss: 0.176, Validation Loss: 0.255\n",
      "Epoch: 9907, Train Loss: 0.188, Validation Loss: 0.253\n",
      "Epoch: 9908, Train Loss: 0.230, Validation Loss: 0.254\n",
      "Epoch: 9909, Train Loss: 0.341, Validation Loss: 0.251\n",
      "Epoch: 9910, Train Loss: 0.461, Validation Loss: 0.252\n",
      "Epoch: 9911, Train Loss: 0.246, Validation Loss: 0.253\n",
      "Epoch: 9912, Train Loss: 0.300, Validation Loss: 0.251\n",
      "Epoch: 9913, Train Loss: 0.244, Validation Loss: 0.250\n",
      "Epoch: 9914, Train Loss: 0.255, Validation Loss: 0.249\n",
      "Epoch: 9915, Train Loss: 0.284, Validation Loss: 0.250\n",
      "Epoch: 9916, Train Loss: 0.343, Validation Loss: 0.255\n",
      "Epoch: 9917, Train Loss: 0.202, Validation Loss: 0.251\n",
      "Epoch: 9918, Train Loss: 0.290, Validation Loss: 0.250\n",
      "Epoch: 9919, Train Loss: 0.203, Validation Loss: 0.256\n",
      "Epoch: 9920, Train Loss: 0.238, Validation Loss: 0.260\n",
      "Epoch: 9921, Train Loss: 0.310, Validation Loss: 0.257\n",
      "Epoch: 9922, Train Loss: 0.220, Validation Loss: 0.254\n",
      "Epoch: 9923, Train Loss: 0.220, Validation Loss: 0.255\n",
      "Epoch: 9924, Train Loss: 0.216, Validation Loss: 0.258\n",
      "Epoch: 9925, Train Loss: 0.359, Validation Loss: 0.261\n",
      "Epoch: 9926, Train Loss: 0.232, Validation Loss: 0.255\n",
      "Epoch: 9927, Train Loss: 0.496, Validation Loss: 0.251\n",
      "Epoch: 9928, Train Loss: 0.201, Validation Loss: 0.253\n",
      "Epoch: 9929, Train Loss: 0.459, Validation Loss: 0.259\n",
      "Epoch: 9930, Train Loss: 0.204, Validation Loss: 0.258\n",
      "Epoch: 9931, Train Loss: 0.229, Validation Loss: 0.254\n",
      "Epoch: 9932, Train Loss: 0.235, Validation Loss: 0.254\n",
      "Epoch: 9933, Train Loss: 0.294, Validation Loss: 0.256\n",
      "Epoch: 9934, Train Loss: 0.189, Validation Loss: 0.257\n",
      "Epoch: 9935, Train Loss: 0.208, Validation Loss: 0.256\n",
      "Epoch: 9936, Train Loss: 0.279, Validation Loss: 0.254\n",
      "Epoch: 9937, Train Loss: 0.255, Validation Loss: 0.255\n",
      "Epoch: 9938, Train Loss: 0.226, Validation Loss: 0.256\n",
      "Epoch: 9939, Train Loss: 0.404, Validation Loss: 0.255\n",
      "Epoch: 9940, Train Loss: 0.533, Validation Loss: 0.254\n",
      "Epoch: 9941, Train Loss: 0.251, Validation Loss: 0.258\n",
      "Epoch: 9942, Train Loss: 0.257, Validation Loss: 0.257\n",
      "Epoch: 9943, Train Loss: 0.255, Validation Loss: 0.254\n",
      "Epoch: 9944, Train Loss: 0.291, Validation Loss: 0.259\n",
      "Epoch: 9945, Train Loss: 0.225, Validation Loss: 0.260\n",
      "Epoch: 9946, Train Loss: 0.210, Validation Loss: 0.257\n",
      "Epoch: 9947, Train Loss: 0.210, Validation Loss: 0.254\n",
      "Epoch: 9948, Train Loss: 0.206, Validation Loss: 0.253\n",
      "Epoch: 9949, Train Loss: 0.355, Validation Loss: 0.261\n",
      "Epoch: 9950, Train Loss: 0.192, Validation Loss: 0.259\n",
      "Epoch: 9951, Train Loss: 0.169, Validation Loss: 0.255\n",
      "Epoch: 9952, Train Loss: 0.174, Validation Loss: 0.255\n",
      "Epoch: 9953, Train Loss: 0.174, Validation Loss: 0.259\n",
      "Epoch: 9954, Train Loss: 0.347, Validation Loss: 0.254\n",
      "Epoch: 9955, Train Loss: 0.296, Validation Loss: 0.255\n",
      "Epoch: 9956, Train Loss: 0.251, Validation Loss: 0.258\n",
      "Epoch: 9957, Train Loss: 0.287, Validation Loss: 0.262\n",
      "Epoch: 9958, Train Loss: 0.169, Validation Loss: 0.255\n",
      "Epoch: 9959, Train Loss: 0.274, Validation Loss: 0.255\n",
      "Epoch: 9960, Train Loss: 0.376, Validation Loss: 0.254\n",
      "Epoch: 9961, Train Loss: 0.243, Validation Loss: 0.256\n",
      "Epoch: 9962, Train Loss: 0.289, Validation Loss: 0.256\n",
      "Epoch: 9963, Train Loss: 0.251, Validation Loss: 0.257\n",
      "Epoch: 9964, Train Loss: 0.256, Validation Loss: 0.253\n",
      "Epoch: 9965, Train Loss: 0.202, Validation Loss: 0.257\n",
      "Epoch: 9966, Train Loss: 0.240, Validation Loss: 0.257\n",
      "Epoch: 9967, Train Loss: 0.230, Validation Loss: 0.253\n",
      "Epoch: 9968, Train Loss: 0.277, Validation Loss: 0.255\n",
      "Epoch: 9969, Train Loss: 0.190, Validation Loss: 0.257\n",
      "Epoch: 9970, Train Loss: 0.401, Validation Loss: 0.259\n",
      "Epoch: 9971, Train Loss: 0.526, Validation Loss: 0.254\n",
      "Epoch: 9972, Train Loss: 0.272, Validation Loss: 0.250\n",
      "Epoch: 9973, Train Loss: 0.249, Validation Loss: 0.257\n",
      "Epoch: 9974, Train Loss: 0.426, Validation Loss: 0.256\n",
      "Epoch: 9975, Train Loss: 0.380, Validation Loss: 0.252\n",
      "Epoch: 9976, Train Loss: 0.306, Validation Loss: 0.262\n",
      "Epoch: 9977, Train Loss: 0.213, Validation Loss: 0.259\n",
      "Epoch: 9978, Train Loss: 0.361, Validation Loss: 0.257\n",
      "Epoch: 9979, Train Loss: 0.358, Validation Loss: 0.269\n",
      "Epoch: 9980, Train Loss: 0.398, Validation Loss: 0.258\n",
      "Epoch: 9981, Train Loss: 0.408, Validation Loss: 0.259\n",
      "Epoch: 9982, Train Loss: 0.273, Validation Loss: 0.259\n",
      "Epoch: 9983, Train Loss: 0.229, Validation Loss: 0.264\n",
      "Epoch: 9984, Train Loss: 0.233, Validation Loss: 0.260\n",
      "Epoch: 9985, Train Loss: 0.249, Validation Loss: 0.261\n",
      "Epoch: 9986, Train Loss: 0.363, Validation Loss: 0.252\n",
      "Epoch: 9987, Train Loss: 0.243, Validation Loss: 0.258\n",
      "Epoch: 9988, Train Loss: 0.197, Validation Loss: 0.260\n",
      "Epoch: 9989, Train Loss: 0.519, Validation Loss: 0.254\n",
      "Epoch: 9990, Train Loss: 0.228, Validation Loss: 0.256\n",
      "Epoch: 9991, Train Loss: 0.447, Validation Loss: 0.254\n",
      "Epoch: 9992, Train Loss: 0.204, Validation Loss: 0.259\n",
      "Epoch: 9993, Train Loss: 0.248, Validation Loss: 0.259\n",
      "Epoch: 9994, Train Loss: 0.278, Validation Loss: 0.263\n",
      "Epoch: 9995, Train Loss: 0.270, Validation Loss: 0.274\n",
      "Epoch: 9996, Train Loss: 0.308, Validation Loss: 0.263\n",
      "Epoch: 9997, Train Loss: 0.262, Validation Loss: 0.264\n",
      "Epoch: 9998, Train Loss: 0.348, Validation Loss: 0.262\n",
      "Epoch: 9999, Train Loss: 0.289, Validation Loss: 0.261\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  for i, (inputs, targets) in enumerate(train_loader):\n",
    "    model.train(True)\n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(inputs)\n",
    "    loss=criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  model.train(False)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(dataset.data[validation.indices])\n",
    "    loss2 = criterion(outputs, dataset.labels[validation.indices])\n",
    "    print('Epoch: %d, Train Loss: %.3f, Validation Loss: %.3f' % (epoch, loss.item(), loss2.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09876322746276855\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.no_grad()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "outputs = model(dataset.data[test.indices])\n",
    "loss = criterion(outputs, dataset.labels[test.indices])\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y=198179.8125, t=202665.0'"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x, t=next(iter(test_loader))\n",
    "t=t * labels_std + labels_mean\n",
    "\n",
    "y=model(x)\n",
    "y=y * labels_std + labels_mean\n",
    "\n",
    "f\"y={y.item()}, t={t.item()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
